{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스터디방 질문 정리 (1유형)\n",
    "\n",
    "# between 함수\n",
    "# 날짜와 시간이 같이 있는 데이터에 between 함수를 쓸 경우 형식이 동일하게(날짜+시간) 필터링 해야함\n",
    "\n",
    "# 반올림(int와 round 차이)\n",
    "# int() : 소수점 버림\n",
    "# round() : 반올림\n",
    "\n",
    "# 최빈값 함수 mode 주의사항\n",
    "# mode_변수 = df['컬럼'].mode()\n",
    "# 인덱싱 : mode_변수[0]\n",
    "\n",
    "# 시간 데이터 다룰 때\n",
    "# 시간이 \"변수\"로 있을 경우 (between 함수)\n",
    "# 시간이 \"index\"로 있을 경우 (bewteen_time, loc 함수)\n",
    "\n",
    "# 꿀팁\n",
    "# 각 조건마다 끊어서 코딩하기\n",
    "# print() 함수로 중간과정 체크하기\n",
    "# 소수점 반올림인지 내림인지 확인하기\n",
    "# 시간데이터를 다룰 때는 datetime으로 데이터 타입 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스터디방 질문 정리 (2유형)\n",
    "# 목표 : 적절한 예측값(y)를 제출하는 것\n",
    "# 적절한 예측값(y)을 제출하기 위해서는 train / validation set으로 나누고\n",
    "# validation set을 가지고 성능평가를 해봐야 한다\n",
    "\n",
    "# 실기시험에서 주어지는 데이터 set\n",
    "# train = pd.read_csv(\"data/000.csv\")\n",
    "# test = pd.read_csv(\"data/000.csv\")  (test = x_test / y_test는 출제기관에서만 가지고 있음!)\n",
    "\n",
    "# 분석 순서\n",
    "# 라이브러리 및 데이터 확인\n",
    "# 데이터 탐색(EDA)\n",
    "#  - 데이터 타입, 결측치, 기초통계량 등\n",
    "# 데이터 전처리 및 분리\n",
    "#  - 결측치, 이상치, 변수 처리\n",
    "# 모델링 및 성능 평가\n",
    "# 예측값 제출\n",
    "\n",
    "# 주의사항!\n",
    "# x_train과 y_train의 행의 수는 동일해야 한다!\n",
    "# x_test의 행은 절대로 삭제하면 안 된다!\n",
    "# x_train과 x_test의 컬럼 종류와 수는 일치시켜야 한다!\n",
    "\n",
    "# 회귀인지 분류인지 어떻게 구분하는가?\n",
    "# Y값(=종속변수=target)이 연속형이면 회귀, 범주형이면 분류\n",
    "\n",
    "# 데이터 스케일링 꼭 해야 하나요?\n",
    "# 개인의 선택 사항 (tree 계열 알고리즘의 경우 선응의 큰 영향을 주지 않음!)\n",
    "\n",
    "# 원핫인코딩 vs 라벨인코딩\n",
    "# 분석가 본인이 편한 방법으로 사용\n",
    "# 라벨인코딩은 범주형 변수 안에 범주들이 많거나\n",
    "# 연속형 변수 대비 범주형 변수가 많을 경우 이점이 있음 (랜덤포레스트 한정)\n",
    "# 선형회귀나 SVM 모델에서 사용 X\n",
    "\n",
    "# 원핫인코딩 이후 train과 test의 데이터의 컬럼 수가 다른 이유\n",
    "# 통일 시켜줘야 한다 (열의 이름, 순서)\n",
    "# 통일하는 방법\n",
    "# 1. reindex 함수\n",
    "# 2. train+test 셋 합친 이후 원핫인코딩 후 다시 재분리\n",
    "# 3. 특정 컬럼 삭제\n",
    "# df = pd.concat([df1, df2], axis=0) # 행방향으로 합친 후 원핫 인코딩 이후 분리\n",
    "\n",
    "# 결측치, 이상치를 어떤 기준으로 처리해야 하는가?\n",
    "# 데이터 상황에 맞게 논리적으로 처리해야 하는게 핵심임(모델이 좋은 성능을 내기 위해)\n",
    "# 시간이 된다면 처리 전/후의 성능을 비교해 볼 것!\n",
    "\n",
    "# 검증용(validation) 데이터셋으로 성능평가 하는 이유\n",
    "# 데이터 전처리 / 하이퍼파라미터 변경에 따른 성능 변화 유무 확인\n",
    "\n",
    "# x_train의 행을 삭제하는 경우, y_train은?\n",
    "# 동일하게 삭제해줘야 함 (x와 y가 짝을 이뤄야 함!)\n",
    "# df = pd.concat([df1,df2], axis=1)\n",
    "\n",
    "# test 셋의 행을 삭제하면 안되는 이유\n",
    "# 제출해야 하는 y값의 수가 정해져 있기 때문에 삭제를 해서는 안 된다!\n",
    "\n",
    "# 꿀팁\n",
    "# 분석 시작 전에 분석 순서 적어두기!\n",
    "# 1. 라이브러리 및 데이터 확인 : pandas, numpy\n",
    "# 2. 데이터 탐색(EDA) : head(), info(), describe(), value_counts()\n",
    "# 3. 데이터 전처리 및 분리 : 결측치, 이상치, 변수처리\n",
    "# 4. 모델링 및 성능 평가\n",
    "# 5. 예측값 제출\n",
    "\n",
    "# 분류 문제, 검증(validation) 분리할 때 stratify=y 옵션 적용!\n",
    "# help, dir 잘 활용 하기\n",
    "# 데이터 탐색 시 원하는 열 모두 보기 (ex> df.describe())\n",
    "# : pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스터디방 질문 정리 (3유형)\n",
    "# 내용이 많기 때문에 \"핵심 Concept\"에 대해 이해하고\n",
    "# \"문제풀이\"와 \"해석\"에 집중해야 한다!\n",
    "\n",
    "# 예상 문제\n",
    "# 1. 모평균 검정 : 검정통계량, p-value 값, 귀무가설 판단(채택/기각)\n",
    "# - 모집단 1개 : 단일 표본\n",
    "# - 모집단 2개 : 대응 표본(쌍체), 독립 표본\n",
    "# - 모집단 3개 : ANOVA(분산분석)\n",
    "# 2. 카이제곱검정 : 기댓값, 검정통계량, p-value 값, 귀무가설 판단(채택/기각)\n",
    "# - 적합성 검정\n",
    "# - 독립성 검정\n",
    "# 3. 상관분석 : 상관계수, 검정통계량, p-value 값, 귀무가설 판단(채택/기각)\n",
    "# 4. 회귀분석 : Rsq, odds, odds ratio, 회귀계수, p-value 값\n",
    "# - 다중선형회귀\n",
    "# - 로지스틱회귀\n",
    "\n",
    "# 꿀팁\n",
    "# 귀무가설, 대립가설 잘 확인하기\n",
    "# statsmodels로 회귀 분석 시에 상수항 추가하는 코드 필수 !\n",
    "# import statsmodels.api as sm\n",
    "# x = sm.add_constant\n",
    "\n",
    "# 로지스틱 회귀분석, penalty = None 옵션 필수!\n",
    "# LogisticRegression(penalty = 'none')    실기 체험환경 사이킷런 0.24.2 버전!\n",
    "# LogisticRegression(penalty = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중요 포인트 정리\n",
    "\n",
    "# 출제 경향\n",
    "\n",
    "# 1유형\n",
    "# 6회 - 시간 데이터, 날짜 데이터, 필터링\n",
    "# 5회 - 필터링(3개 조건), 파생변수 생성, 내림차순\n",
    "# 4회 - 날짜 데이터, 사분위수(IQR), 파생변수 생성, 필터링\n",
    "# 3회 - 날짜 데이터, 사분위수(Q1), 인덱싱(데이터 00% 추출), 필터링, 결측치\n",
    "# 2회 - 내림차순, 필터링, 평균, 중앙값, 결측치, 이상값\n",
    "\n",
    "# 2유형\n",
    "# 5회차 제외 모두 분류 문제가 나옴\n",
    "# 성능지표\n",
    "# macro F1 score, RMSE, macro F1 score, Accuracy, AUC\n",
    "# accuracy만 확인해도 모델의 적합성을 확인할 수 있다!\n",
    "# r2_score만 확인해도 값이 높으면 RMSE, MSE가 낮음을 알 수 있다!\n",
    "\n",
    "# 3유형\n",
    "# 6회 - 카이제곱(적합성), 회귀분석 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공지사항 필독!\n",
    "# 제7회 빅데이터분석기사 실기 자격검정 안내"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
