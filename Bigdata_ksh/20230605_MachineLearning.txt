20230605 MachineLearing 기초

- Decision Tree
 비선형, 계층적 구조
 노드로 구성, 부모와 자식의 관계
 2진 트리 : 부모 노드 - 두 개의 자식 노드
 리프(leaf) 노드 : 가장 마지막 끝단의 자식 노드
 깊이 : 부모에서부터 잎(leaf, 가장 마지막 끝단 자식 노드)까지의 세대수

 ex> 스무고개와 비슷한 형태

 주로 분류 형태이며 회귀도 가능하다!
 분류
  - 각 노드에서 분할 조건 적용
  - 최종 leaf 노드에서 분류 예측
 머신러닝
  - 학습데이터로부터 트리 생성
  - 트리를 이용하여 예측

 가지 분할의 방법(알고리즘)
  - ID3, C4.5, C5.0, CART

 ID3
  - 데이터의 target 값이 같다면 leaf 노드
  - 분류 기준으로 사용할 feature data가 남지 않았다면
    leaf 늗, 가장 확률이 높은 target 값으로 예측
  - 분류 : entropy/gini 계수가 낮은 분할을 만드는 조건 탐색, 분할, 반복

   * entropy
    - entropy(node) = -p1log2(p1) - ... -pnlog2(pn)
    - pi : 클래스 ci로 분류되는 데이터의 비율
    - pi 값이 0이거나 1일 때 , -p1log2(p1) 값이 최소

   * gini
    - gini(node) = 1-((p1)^2+...(pn)^2)
    - 값이 작으면 작을수록 좋다!

Overfitting
  - depth가 깊을수록 overfit 가능성이 높음
  - pruning (가지치기)
  - ensemble(앙상블) - random forest


------------------------------------------------------------------------------

KFold : 다양한 모델로 테스트를 진행한 후 Ensemble 할때
          테스트 영역을 나눠주는 역할

------------------------------------------------------------------------------

KNN : 데이터를 분포시킨 후 새로운 데이터에 가장 근접한 데이터의 수가
        많은 데이터를 채택

KNN을 기반으로 한 Clustering
