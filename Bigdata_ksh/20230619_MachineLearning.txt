20230619 Machine Learning* Deep Learing (Keras)- RNN (Recurrent Neural Network / 순환 신경망) Unit, Memory Cell 출력값을 입력값으로 되먹임 (순환 구조 형성) 순서가 있는 데이터 시계열 딥러닝 모델 이전 시점의 값들을 반영하므로 Memory Cell로도 불림 데이터에 순서가 있음! 종류 - sequence-sequence - sequence-vector - vector-sequence - Encoder-Decoder RNN의 단점 time이 오래 지속될수록 이전에 반영됐던 값의 영향력이 줄어들게 된다 -> LSTM(Long Short-term memory)를 통해 보완     연산이 많다는 단점이 존재      -> GRU(Gated Recurrent Unit)를 통해 보완 RNN Attention Layer Encoder->Context(vector)->Decoder RNN Transformer Encoder(CNN) -> Feature vector -> Decoder(RNN or LSTM)