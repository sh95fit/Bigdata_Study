{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pymysql\n",
    "import dotenv\n",
    "import os\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Normalization/Standardization\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, Dropout, Conv1D, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.saving import save_model\n",
    "\n",
    "# 경고 무시 코드 추가\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def pltconfig_default() :\n",
    "  sns.reset_defaults()\n",
    "  %matplotlib inline\n",
    "\n",
    "pltconfig_default()\n",
    "\n",
    "matplotlib.rcParams\n",
    "\n",
    "matplotlib.rcParams['font.family']\n",
    "\n",
    "current_font_list = matplotlib.rcParams['font.family']\n",
    "\n",
    "font_path = 'C:\\\\Windows\\\\Fonts\\\\batang.ttc'\n",
    "\n",
    "kfont = matplotlib.font_manager.FontProperties(fname=font_path).get_name()\n",
    "\n",
    "matplotlib.rcParams['font.family'] = [kfont] + current_font_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17422, 9)\n"
     ]
    }
   ],
   "source": [
    "# with open('StandardScalar_final_data', 'rb') as file :\n",
    "#   St_NotEncode_data = pickle.load(file)\n",
    "\n",
    "St_NotEncode_data = pd.read_pickle(\"StandardScalar_final_data\")\n",
    "  \n",
    "print(St_NotEncode_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler Not Encode Data\n",
      "(17422, 8) (17422,)\n",
      "(13937, 8) (3485, 8) (13937,) (3485,)\n",
      "=======================================\n"
     ]
    }
   ],
   "source": [
    "# Feature와 Label 분리하기\n",
    "def Feature_Label(datafile) :\n",
    "    X = datafile.iloc[:,:-1]\n",
    "    y = datafile.iloc[:,-1]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "print(\"StandardScaler Not Encode Data\")\n",
    "SNE_X, SNE_y = Feature_Label(St_NotEncode_data)\n",
    "print(SNE_X.shape, SNE_y.shape)\n",
    "SNE_X_train, SNE_X_test, SNE_y_train, SNE_y_test = train_test_split(SNE_X, SNE_y, test_size=0.2, random_state=10, shuffle=False)\n",
    "print(SNE_X_train.shape, SNE_X_test.shape, SNE_y_train.shape, SNE_y_test.shape)\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='8'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABTEAAAH4CAYAAACSW6mWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADKIklEQVR4nOzdeZwdVZ0+/qeTQMRAGGREIInCuMEo4+hXRDYZRFxQ0J/OKIrKgMpEFAccRRFZlRDFBGTfAlGWyCZISAhk3/d96ySdtTvd6SVJ73v3/f3R6Zt7b1fdqlN11qrn/Xop6XvrVp0659Q5pz51qqokk8lkQERERERERERERGSpQaYTQERERERERERERFQMg5hERERERERERERkNQYxiYiIiIiIiIiIyGoMYhIREREREREREZHVGMQkIiIiIiIiIiIiqzGISURERERERERERFZjEJOIiIiIiIiIiIisxiAmERERERERERERWW2I6QS4qre3F5WVlTjmmGNQUlJiOjlEREREREREREROyWQyaGpqwsknn4xBg4rPtWQQM6LKykqMGjXKdDKIiIiIiIiIiIicVl5ejpEjRxZdhkHMiI455hgAfZk8fPhww6khIiIiIiIiIiJyS2NjI0aNGpWNsxXDIGZE/beQDx8+nEFMIiIiIiIiIiKiiMI8qpEv9iEiIiIiIiIiIiKrMYhJREREREREREREVmMQk4iIiIiIiIiIiKzGICYRERERERERERFZjUFMIiIiIiIiIiIishqDmERERERERERERGQ1BjGJiIiIiIiIiIjIagxiEhERERERERERkdUYxCQiIiIiIiIiIiKrMYhJREREREREREREVmMQk4iIiIiIiIiIiKzGICYRERERERERERFZjUFMIiIiIiIiIiIishqDmERERERERERERGQ1BjGJiIiIiIiIiIjIagxiEhERERERERERkdUYxCQiIiIiIjqkpzeDju4e08kgIiKiAgxiEhERERERHfL5e+fijNvfRlsnA5lEREQ2YRCTiIiIiIjokO21Lejs7sX6vQ2mk0JEREQ5GMQkIiIiIiIiIiIiqzGISUREREREVCCTyZhOAhEREeVgEJOIiIiIiIiIiIisxiAmERERERERERERWY1BTCIiIiIiIiIiIrIag5hEREREREQF+ERMIiIiuzCISURERERERERERFYbYjoBRERERESUfKv2HMTKXQeRQQZnnXo8Pjbqn0wnqagS0wkgIiKiPAxiEhERERGRcl9/eFHe37vGftlQSsLh7eRERER24e3kREREREREREREZDUGMYmIiIiIiIiIiMhqDGISERERERERERGR1RjEJCIiIiIiKpDhQzGJiIiswiAmERERERERERERWY1BTCIiIiIiIiIiIrIag5hERERERERERERkNQYxiYiIiIhSLHPo4Y+ZgodAZjKZAZ8V/sbvbxe4mGYiIqI0YxCTiIiIiCilGlq7cO7YWTjl11Pwyd/PwO79LQD6AnxXPLkUX39kEXp784N9f5hWirPGzERNUzsAoKO7B58bPxfXTVqtPf1RtXX24MI/zcH/vbjWd5kMGOQkIiKyCYOYREREREQpNWn5HlQ29AUj97d04u6ppQCAtq4eLNq+H6v31KPiYFvebx6Zsx01TR14fO4OAMD8rXXYXtuCyWsr9SY+hrc37cOu/a14ZVWF6aQQERFRSAxiEhERERGlVOEd1WmZfcg7yYmIiNzDICYREREREQE4HNwrQYnZhChWkuzdIyIiSiQGMYmIiIiICAAizcPkpEYiIiLSgUFMIiIiIiIiIiIishqDmEREREREBMD7WZFBz8nkndlERESkA4OYRERERER0SF/AMswzI12+jbwk6TtIRESUQAxiEhERERGlVGEsL8pbuxnrIyIiIh0YxCQiKy3fdQBzt9aaTgYREZG1enozeGVlBXbVtUT6/c66Fry6am/eZ14ByUwG2LC3AdM27Mv7PMxt5GvL6zF9U3Wk9Jn28qoKzNtai1dXV6C3Nz9nahrb8eLycrR39RhKHRERUfoMMZ0AIiIv//XoYgDAit9+Dv989FDDqSEiIrLPSyvK8eu/rwcA7Br7ZeHfX/inOaGX/coDCwAAb1x33oDvigUzv/rQQgDAjJ9/RiRpyoUJwP591V78/VCQd1BJCb767yOy333j0UUoP9CGTVWNuP2yjyhKJREREeXiTEwistr+5k7TSSAiIrLSsl0HtGwndw7izpxZnyK3kZcfaJOWHhNW76nP+7t/f1ydZUpEROQiBjGJiIiIiAgAkInwUMwwvwjzHh2dRNNjW/qJiIjSiEFMIrJahq8LICIi0kak1xWJ6w1yPApY4rO3UYK+REREFI0VQczdu3fj6quvNp0MIrIETwiIiIjMEOmC+xcNE550PIbpm36OWIiIiPSx4sU+d911F1pbW/M+W7x4MSZPnowPfOADKC8vxxlnnIGvf/3r2e+rqqpw77334oMf/CBaWlrQ3t6OG2+8EYMG9cVlOzs7MXbsWLzrXe/CkCFDsHPnTtx00034p3/6p+w6nn76adTW1uL444/H5s2bcdVVV+EjH+GDuYmIiIiI+sm4uOg3k9EU0fQM8gtiMopJRESkjfEg5uzZs3HGGWdg4cKF2c+qq6tx55134o033sDgwYORyWRwxRVX4JRTTsEnPvEJZDIZXHXVVXj66adx0kknAQAefvhhPPjgg/jZz34GALjttttw/vnn45JLLgEArF+/Hj/60Y/w0ksvAQDeeustlJaW4g9/+AMAoKWlBV/84hfx1ltv4Z3vfKfOLCCiInhyQEREpE9/txtlRmYxfkFAU8SfielzOznnYhIREWlj9Hbyzs5ObNmyBWeccUbe5xMnTsR//ud/YvDgwQD6Bg0/+tGP8OCDDwIAli1bhne/+93ZACYAXHnllXjiiSfQ29uLtrY2TJ06FV/60pey359xxhmoq6vDrl27AAD33Xcfrrnmmuz3w4YNw2c/+1m8/PLLqnaXiCJgEJOIiEgfkVmXInFAvyCgK/xSz3EKERGRPkaDmJMmTcLll18+4PNZs2bh3HPPzfvsvPPOw5w5c3y/HzZsGI477jjs3r0ba9aswemnnz5gsHT++edj9uzZyGQy2Lx5M97//vfnfX/BBRdg5syZEvaMiIiIiCgZ/OJ0SXwmpl8Q138mJhEREeliLIhZWVmJd77znXnPqMz97oQTTsj77IgjjkBHRwcymYzn9wBwwgknoKqqKvD7AwcOYPjw4b7fe+no6EBjY2Pe/4jiKD/Qis/fOxcvLi83nRQAwIvLy/HZcXOwZV+T6aRwVgMREZGPteX1uGjcHMwurcn7/Iv3zUNNY7uSbX5u/FzPzycs2ImHZpeFWofOGObW6iZ8bvxcTFmXP64/2NKJL/15Ph6ft104PbbdDq/ac0t348I/zcE5d8/E3W9uNp0cIie0d/Xg/3t4Ica+WapsG5X1bfjCvfPw3NLdyrZBZDNjQcyXX34Z3/jGNzy/K3YbSyaTKXqFtLe3N/b3Xu6++24ce+yx2f+NGjXKN41EYdz6jw3YWt2MG19ZZzopAIAbX1mHHbUtuOctdZ1uFHzWFBER0WFXTVyO7bUtuGri8rzPS/c14U9vb4m9/v5hcm7/W+zi4j1vbfGfqZnzQ523k/9s0mqU1TTjJ8+vyvv80XnbsbmqEWOmio91fN9OntBhys2vbsDOuhZUNrTjsbk7TCeHyAlT11dh9Z56PDp3u7JtjJm6GVuqm3DzqxuUbYPIZkZe7HPw4EHs3r0b999/PwCgrKwMW7ZswX333Ydzzz0XJ598MmpqavCud70r+5uuri4ceeSRGDRoUPb7QtXV1RgxYgQGDRrk+/2pp56K448/3nMmZf/vvdx00034+c9/nv27sbGRgUyKpa2rx3QSPFU3dphOAhEREflo6ejO/rvwDdvtXd4X422g83by1k7vMVZXd/SIo9/bzF25TZ6I1OvuVX9Vw+Z2nkgHI0HM4447DuPGjcv+PWfOHNTV1eH6668HAFx00UVYuHAhTjvttOwyCxYswIUXXpj9/sEHH8To0aOz37e0tODgwYN43/vehxNPPBGbN29GJpPJu+o7b948XHXVVSgpKcHpp5+O7du35z0Xc+7cubjooos80zx06FAMHTpUyv4TUXhJneFAREQUxaCcsa2KuxWirDNMHM+G/jw34Cg6s9LvdnLGMImo3yBe1SBSzuiLffoV3iL+3//933jxxRfR3d2d/f6xxx7DT3/6UwDApz71KdTW1qKysjL7m6effho/+tGPMGjQIBx11FG45JJLMGXKlOz3a9euxbvf/W6ceuqpAIDrr78ejz76aPb75uZmzJgxA//5n/+pdF+JKJgF5zlERERWUn2ObEOwUZVYWcfgBBEFYCtBpJ6RmZi5Fi1ahCeeeAKLFy/G008/jauuugrvec97cPvtt+M3v/kNPvCBD6C8vBzf/OY38YlPfAJA3zN1nn76afzpT3/CBz7wATQ3N6O7uxu/+tWvsuu94447MGbMGJSVlWHIkCHYtWsXnnjiiez3X/jCF7B3716MGTMGxx9/PDZv3ozHH38c73znO7XnAaWT321JRERERH5Ujx6yz8QUCGb6PxMzdnKkGhTj7TwctRFREF7rIFLPeBDznHPOwTnnnDPg87PPPhtnn3227+9OOumkvFvSCx155JG4/fbbi2776quvDp1OIiIiIiLTcm9XLLwgalnMMI8NJ/clRf4K4nebqA37RUR24O3kROpZcTs5EdnDtreB2zaLg4iIyKTcc2Rb+mx3nomZEwD2eyam72/lp4eIkoXtBJF6DGISkdVsOUEjIiKyQZxbosNIQr/rF0iIE2Dwf7EPoxZE1KeEUUwi5RjEJIqptzeDuVtrsb+5w3RSpCg2GO/pzWD2lhrUt3YqTUPGhukaiq2vaMC26ibTySAicl5ZTRPWVdSbToY2ub30mj310te/prwe22ubhUKZXst29fRiVmmNrGT1jUFKa1DT1F50uU2Vjdi9vzX795Id+7P/jhNeKCkpQX1rJ2ZvqcHK3QdyPg/+bU1TO+ZtrbVyfFN+oBXLdh4IXG5WaTVW7zmIrRHGLmvL61FWwzEPmdPS0Y1ZpdXo6O5Ruh3dIcz528K1K7v3t2D5rgOYs6UGB1rUnscRqWb8mZhErntpZTl+9cp6/PPRR2LFby82nZzYis3AmLBgB8ZMLcW/vHsYZv3ff+hLVMIcbOnEpQ8uAADsGvtlw6khInLb58bPAwCs/O3ncPzRQw2nRr3cmT476lryvpMRJGvv6sVF4+Ziwx1fiLWeh2dvx70ztmb/jjtBaer6Klw3aTXOPOU4vDR64PP0AaCtsweX3D8/77PLH1+Ct2/4DD70nmMKnicq7usPLxqQ52F85o+z0d7Vi4e+8wl8+d9OirBldc7/42wAwBvXnYePjjjWd7mrJ67I/nvn3ZeEnnFW19yBrz60EADHPGTOj59bhXlba/H9s9+HO7/6UWXb0f1MzO9NWIbHv/f/8PmPnFh0uQvumZP998nHvgOLbrpIccqI1OFMTKKY3t5YDQCoa07+Va3X11YCAHbUig/go7Jw0kJsVQ3FZ5EQEZG4tLStxU6RTXWZXmn6++qKvL/j9udvbqgCACzfddB3maaOLs/PN1c1AsgPpPoF4fwCwSUlA4PGQLhgaHtXLwBg7lZ5M1NlW1fREHpZkbKsrG+LkBoiueZtrQUAPL90j9Lt6Ilh5h+AC8rqhH5dmZK+kpKLQUwiQ1x8ZAqf+0RERLbqTeJVL4NEZnV6LWmiOIJmQakYxaSx1okcaxw7UpqYaPd4hFHaMIhJRNZJ4wkBERHF08vOwyomXhCk8mSeMfLDRI41Fy/aE9kt/6Diy4QobRjEJCKrJfGcIQlvfiUiso2NL01JorDny4XFoeM8W+Rknqf9+UTGJiLL5hYJj1EiGXgcUboxiElEREREzuNMTGg5t/WKQ3kFBAuX0xG/GhQUmQwR5ExrNRIpH5Flc28n5zFKSWdiUiQnYlLaMIhJRKGZ6CSTeNWez4ciIlIhef2FSSK5aUvOB83EjNP7Jj1QIFKGIs/EHJRztsnn1pJpqo9jG58FTJQ0DGISxcR+Q76kj3F5OzkRkXyc5WUXExchRcZkouO3pI9NRAg9EzNvJiYzkSi+kiJ/ESUfg5hEMUUdjzH4SUREJE9vSqKYxcYPOi6SRR2/2DDu8UtDnIBrYuJyAjsi9HbyvGdiiiSISL5k1MH8nbChbSXSiUFMIgBPzt+BH/5lObp6ek0nxWpR+siH55Rh9DMr0dObwYQFO/GDicvR2R0+nwvHGi+tKMf3JixFY3uX72/KaprxrccWY9H2uggpJiIiU8oPtOLbjy/BrNLqwGXLaprwrccWZ//+9hNLMHdrrfQ0dfX04od/WY7vPrkU33psMS5/fDF++9p6z2VbO7vx/aeW4fmle9DTm8G1z63Eg7O2hd7W5LWVuOLJJahr7sh+9quX1+GuKZuyf5s+Cf/p86sHfOY1PqhsaM/7u1i6Z2yqxjcfXYyymuZQabjiySXYn5NHADB7Sw2++ehin1/0p/NwSv2Ca6L5u6+xHTe/erg+7N7fgm8+thhvrq8SW5FDRPIo9zml33psMdZXNGBnXQsuf3wx5m+rxd76Nnz78SWYuTn4mCe3zd1ai8sfX4zd+1tCLd/R3YOrJy7H0wt3Kk6Z3e6asgm/enmd7/dR3k7+/aeWoaWjO06yivrTW1tw/d9WJ/KxYGQeg5hEAH4/ZTNmbK7B62sqhX/Lq1/F/XHaFkzbuA8zN1fjd29swszSGry2em/o3xf2fb98eR3mb6vDw7O3+/7mmmdWYOnOA/jOE0ujJlspPhOTiMjbr15Zh8U79uPqiSsCl/3RX1di6c4D2b97M8CVTy2Tnqa5W2oxY3MNFpTVYenOA1iy4wCeXbInL9DY7+mFuzBvay1+8+p6zNtWi6nr9+FPb28Nva3rJq3GwrL9GPtmKYC+gNgLK8rxxPyd2meaCr3oJea2rnlmBZbtOoAxUzeHWn5h2X6Mm56fr6OfWYnSfU1Ff6dqzPbc0j1oPhQQ+ONbW7Bs5wH8+LlVA5ZLyvm8WGDicKavrWjAfz22CNdNWoUlOw7gexOW4aa/r8fiHfvxg78EH/PktiufWoYlOw7g5y+uDbX8yysrMKu0BndM3hS8cEL19GbwxPydeGFFOXbVeQd/ozRr87bWKg0OPzi7DK+tqcT6vQ3KtkHpxSAmUY7Wrh7TSbBbjNF/W07etnSKXPnzHig3tPnPxKxpHHhiaRM+E5OIyNv+5s7Qy9Y0tgcvJIHf2MArqJh7l0B7Z/QxRX1r33py7xDp74KTePG0PyvDzsQEgKb2/LFEh8BdHoVk9Mr9gb2dtf6zzGwuO6EXOcXIsPauXtQ2HR6nHWixe8xG8nldAPLS2iH/vMzmY9BL7qMbeiRfBWlSOBOzn8jdd0RhMYhJRNYJE+Tj7QlERMlj4wmmhUnylaaucXCEginJ+/fhvzim0Ft38m7rd+oII51s7A90yw1i+mVH1ENXx7HHlpVUYBCTiJxUbLDNkxEiIkoam7s2WafCIncqDBoUc6u5z8SMmIZcFhePdDL3NW4xkntMtmU2t6NectM7iFFdIgAMYhKR5fwGG8VOMlwanzDgSkR0WJQXFKhmYZL00PhMzDAKZw0NjlAwpsvS5i7f2HjEdKGQtRi0UxvEZPaSqxjEJDIkzbfPyBgna36/ARERkRDZJ4hp6PaKjY0KL14OiXI/ud+6JWSuzQFK2eIGPHOPDc7EJD8MsuW3e8wPoj4MYhLlStMI1EexLNDVd4Yphl6WFRFR4vAcrV9/HyeWI2nqGqPMSsqd6Zv7a10v3LM5CKGz6uRmA2fbpU/Y4411I79N98uOqBcVdORumvok0odBTCJD+IbqcHxzidlHRJQ4PGct5NXZ2ZdJOlJUOEtTVYBD5Ul3Uk7oZe6GfbWZbMH+oODFPswQIgAMYlJCZDIZbNjbgPaungHfldU0o6axHesrGtAbdA9yyM6hpzeDdRX16O7pRe7wq3Rfo0iyQ9m9vwU1Te3S1+tnV10L9jd3eH5XmD3bqpvQ0NoVar2bKg/nzcbKRjS0hfudn2IlGXSS0N7VgzXl9Xn1obK+DZX1bQCA+tZOlNU0DfhdW2cPNuxtkPrcqKSc0BBRsjW1d2HLvoHtYhR79rd69msHWzqxo7ZFyjZy7SzSr4Xhd4vzuooGdPX0Zv9ubO/CVp88WldRHzwGKdhqocN9T/H1ePVV1Y3tKD/QmreuDXsbiq5H5GJrnK5sR21zpN8NFrwPub2rJ28skktKXxxyHe1dPVhfIXcsAQD7mzsi5yUglgfrKxoOjYH7NLR2oaymCZsqG9HS0S20XZdn27V2dmNjZQPKappxsKXTdHISp7Bm7N7fgtqm6G05AHT3ZrBnf2vwghG0dnZjU1VAu5rJYH1FAzq6B56zesntNvyaPNnnEntzzolE9Z8jE6nEICYlwvPL9uArDyzAVU8vz/t8e20zPjd+Lj41ZiYufXABnlq4s/iKQvYCf5xWisseXIhb/rEBuaPWL943H4u214VaR5hnYu5v7sAF98zBp+6aGWqdMrR09uD//X5G4HKbKhtx8b3zcOaY4GUB4LF5O7L/fmVVBX70lxWhfudXJHFuJ7/51Q342kML8ffVewEAHd09OGfsLJwzdhY6u3vx8d9Nx+fGz8PW6vyT0W88sghfeWAB3lhXFXnbREQuuvBPc/CF++Zh+a4DsdZzsKUTn7lntme/9vHfTUebx8XIOCrr23Dhn+aE6tdE/fCvK/DzF9dm//7MH2dj9pZaz2Uve3AhHphVJrD2iLeTI4NvPrYYX3lgAV5fW5n9/KwxM3H+H2ejsb3vAuKkZeX4ygMLhNatQvmBVnx23NxIvxUNfl3++BJMWX+4/zY1q+kHf1mOSx9cgGeX7pG63v/3+xn47Li5kYMPIqOqqyYux62vb8z+/Ynf942bLrl/Pi65f37g7/Py3t0YJi57cCG+fP8CfG78XHz8d9NNJydxcutJ3aFzojPvit+Wf+ae2UqCzl99cCEemr296DITF+3CpQ8uwI/+ujLcSnNvJ9dwsLR39eDcnHMiUWPf3IzLHlyoIGVEhzGISYnwzOLdAIDFO/bnfb5sZ/7J1tMLd0nZXn9AbtKy8gHfvbVhn5RtAMB2BTNS4sjtOudv6ztRi9LBAcCykCfCUWYqBM0eeWVVBQDgyfl95djYdnjWQHNHdzZwurSgPm2q6pvB8dLKCuE0ERG5rK6574Tv7Y3x+rgdddFnihUKE4RaV1F8Vky47fh/NzknUFg/4M6E/B8+Pq/4ya1Aiop+u/7QDMuXPfqq/gDXs0t2B25Fx50Cq/YczN+mQChN9IUwa8rrxX6gyMKyvrHFs4uDyyCK9QEzbGV5PicI25MzXWy34Cw3l1/sU1Yjrz1Lk7BtS27bKzuvd+2Xf461LUQa/7JoFwBg3lbvC16FcttE2ceKV992sPVwcLetU/yi4hPz8ycMyZ5xTgQwiEkkgcOjr5Tr71f9TlD57BkiIrmE7qgOYP/JUZz0edxOLrgGnS/AY29pz7PObX7Jh/d2WXvSJmwVVdmEuTjG98sOZdnkXhZRSjCISami44Qn7BYc7DsTJ+iEQ/ZbAA//PtbPiYiMidt+6W7/3O1rowaiDu9wr8eNEiL5L5ICWcUqEtCSWZWS1C/LvFCgwyCejZIBxoL2FnVKvIBArmK3QWQxi/o5Y6KMxWWdjOjo3B071yAiikXmxcQwJ4MyNhe9J9DfiedenOv/t1eehxlfaLnwq6kT9KorSR1iuRCQzX8kZlJLguLieZB+LrQfRAxiUqrouPolcwvsSBTfSlL07a/qBk8clBGRq+I2yem6nTwOr/5JbA1ey4v0Pzpyt/COCFW3ZHvVFdlbsqU62nJbe1gcE5EJSap3UdserzzIBHwvyq3WiFzBICZRLgmtdZIba123QITpjIstE7YMggb6fg/Qdu12SiIiWeK3f3obwCSdqIrS2VeZyGapF41zZ7A63ke7dju5TbfXUnqYmgHsUm13Ka2ULgxiEuWybOTKcV1EgsXol828xYmIKF/cWV4ye9lkBz8kPBMz0387ucdyYW4nF0hD1HItTJvOZ2Imtfa4MEM5t/65/HZy0kd2NXGl+wg1sUNiz+pC+0HEICZRBMU6Pkf6xNh0df5+HbOM7XveTp6/gFCaiIiSLo0z0aP2N4W/ixt0Fe17Yme1gbJS1b/qCHiLpty2sYSpoE5axs0kLnecbtfRkg7JvlBILmMQk2LZXNWInz6/CjtqmyP9/s8ztuHPM7ZJTpW/vfVteGzudt/vb/nHRszcXB24nmJNuupOtuJgK376/CqsKa9HQ2sXrv/baszdWpv9ftH2Ovxs0mrUNXfk/W7P/r7f3fT3dbjtHxtCXWm7d/pW/GFaaeByP3luFf7nmRX4zavr8bNJq7G/YNt+MpkMbn99I/73b6tx7XMrsXt/C/bsb8V1k1aF+G2oTRRfx6HS8uukBx36vL2rBz9/cY3UbR9eF4dlRCRu5uZq/PT5VaHb2yCbKvv68511LUWXm7hoF95YVxl5O70Cbd6vXl6H7h6PV2yHtLCsDtf/bU327+smrUZNY7vnsn9btgc3v7oevRLvxS3cVZH2fsbmGrywfI/4NnNGIb2ZDLZWN+G6Sauzn/1s0mqs2nNQeL2qtHb25P1dfqANExfulL6doLyX0RVfN2kVtlU3FV3mpZUV8TcU4H//tga/eXU9rpu0Gj+btBpT1lV5LlfV0JZXN2QOR3p6M7jp7+twx+SNedvolxucyh2DZTIZ3PLaBjy/NLju17d24rpJq/HWxn2h0/XXxbtw++sbtY699jW047pJq7Fy94FIv4/aNj27ZDdufHltrDZUlcL876+LK3cfbpve3rgPv3l1ffbvn3nUo7DueSv4XEalspom/PT5Vdha0D5c9fQyXPPXFbj51fW44YU1aO7olrrdB2dtw/jpW32/LwGwcvdBXDdpNaoa2gZ8/7NJq7Fhb0OsNPxs0mos2xmt7qu0YW8Dfvr8KuzeX3zME8bEhTvxuzc28ZxOoyGmE0Bu++pDC9HZ3Yv1exsw95cXCv22vrUT987oa1j/+9xTcOxRR0hPn1do6u43S/E/F7zf9zc/+MsK7Br75eLrLSnJjvZUXqTyWvX//m0NVu4+iDfWVeGKs96L19ZU4rU1ldk0f+eJpQD6Tl4e/M4nsr8b/exKbKpqzP79hY+eiHPe/8++227p6MafZ/YFmK869xSccMw7fIO3U9YPHCDf/+2PB+wdsGL3QUxctCv7d2d3BhUHW1G6L6eT19wf5PY/Rw7pu87z9MJd+PuqvXoTQkRUxA/+sgIAcNKx78DNX/7X2Ov72sPh+/OfPr8aX/m3kyNtR6RJf2FFOT55ynH4r0+OirStK55cmvf35LWVaOvsxpNXnjlg2V//ve9k+aLTT8BnT3tPwbdmZqP86pX1mPHzCyL/PpMBvvnYYtS3dmU/21rdjK8/vAhnjDg28Pc6nq342LyBF5Zvn7wJ/33uqeo37sNvhmTQCerCsv341uNLcOLwd6hIlpDcIODrayvx5X8bOK79vxfXYtH2/Uq2P2V9FSYtKw+1bO7RNW9bHZ5ZshsA8J2z3lv0d0/O34nJaysxeW1l4Li9363/2AgA+PK/nYQzT3lXqN/E9cuX12L+tjqhdObqb5su/PAJ+Ny/FrZN/n772gYAwOdOfw8+/5EThber089fWIvFO/bn5dE1z6zMW6amKdoFu/IDrXho9sB2Ruckw+88sRQ1TR2Yv60Oxx99ZPbz2Vtq85Y78dh34FdfPE3KNls7u/Gnt/vOs7/36ff5LveNRxYBAOqaOjDpmk/nnQfNKq3BnC012HG3eL3tV9PUgW8+tjhS3VfpKw8sAACU7muK1c8CfX0WAFz2sZPxsVH/FDdpFAJnYlIsnd19V/d272+N/FsAUmc+5FI1/s7t91RedPFade4Vo8r6gVfN+pUfzP+ucHZNU3vxq309OTvW3SO2k3uLpCtXY1tX3t+r9xzEjtqCK2I+gwxVg4/ck5ejjhgMAKiNOHAiIlJtQJsZUZz+XKXcAJwM5QeK90+NbfJmwsjup/q75eKPtMm//VJ2/slW3Zis/vVAS2foZU0/d1vlsV7fWjwfcutw7r8Lx4XF7Iwxg6qpXd9xISufGwTyJld9xN+pVHhWseeAurrY1tUTvJBi/QHYoDKs9rlTIIjXuWjuqXVHd3Ae+JWBay8KExX1blIvsmfSkj8GMcmY3DZR9yM33J7ufTizBhXJuMJ9LFw0ShaoOiHT/VtRMvKOiIjsp/I5hVGeLxar3y3SWdnyqDNdyQjKe3brcuuEJdXLV699d1gHYh2VK+lvJxedcGNLn6CbzONK5HE5FA+DmGRM7oGu6sHBfmuV2cbovp18kM/V60ID3/hZ+L3486GMdPhRykpSMvvzaEDeyXwLoLQ1EVEaudaGuHieZPLkTnS8ErZ/suVcK07eiuyD2xev9ZCaRRELVt9LI90TuQ47sLMqy90v21wJ2nklP0xVGJT3rNngdfcvzqYyOuadPgxikhRROoLcAz1uR5Kmt6eF3dXCE5liszbDbzz+KnJ5tvUht1F0d+J0IuyAiIiUMd3Epmi4EJuOt2dLGZtIputE1La3k+tkutQZ1DarMPtNtAMWNj1S5e5fmLbG9OMtkoAzMfVhEJOkiNLs5R7mcTsv0cGIy01Mfl7551vhrTIDbokW2KaN+aXqDeH5VyW985d9FBHZIumnHTY8xsRkHovuf+EzMeOsV0dfFydvRfIm8HZyduxW3E6uK5Di4nP+IifZgU5ikMI0+tVrY7eTSzjQRFfB5k0PZrM+DGKSFFEa5NyX+ejuRmwYrEbtxPJCmEVWUXg1qHB7gVngeTt5OFLLM8rKZN9OHiMATEREhzlwPm0VV54dHVWcE3oX9o+8lfhckBeanRqr/B2sPA4mOaw03VFXVNQnBgQ0hmFmCGZvJ09yRfOgalIMqcUgJkkR9wpa3ENetPNzuYnJ3VeRvY4zPvD6qYwrmF6N/YC1aniWTe4m2P8QEZGNsm8nN5sMc2I9P5OdOx3mYnWIHFxyYF9VtmmuPxPTi2j99Zt5nPdot4jrpsOYd/owiElSdPVk0NDWhcr6ttADRRkHev/2hG8nj7HthrYudEu4DyXqgDq30xV5sU/hLfsig6GqhrYB25NxpS7WoyszfbN5+9PWr62zB53dh++lr2vuEEzT4VRVNbQjk8kovUKce8xUNXgfP7VNHWjv6hmwr16qGtryZjkTEYkS7c9FmG6dgprzfQ0d6OjuQU1je/xtCS7vtc3c9FYe6iPC5mGxJcOkTaSs9oXIL69lhPJI27Mq9ci9GNzc0Y2Gtq4By3T19EqpixUHW2OvQ0TQ2Muv3IUukMcYmlU1tKO7R/8rykXHpLmSFCDJbZuaO7rR2N6tPQ1Rq49f3yjjOA1KlF8dqG7sQFdPLyrr29DQ1oWm9i6UH8g95oMrz8HWLrR19qCqYeB+HGjpDPy9LC0d3WhoHdgWyqRqf3JPv2qbOvLOR0kuBjFJmo/d8TbOGTsLt7++MdTycR9++/i87Thn7Cz86e0twr+NGoBr7+rBx+54O9JvZRmUNxPTv7frKcjfwtmyInGubzyyGI/N3a7l+TEiJXPDi2tw9t2zMGVdVfazwvI57w+zAjur3KzKzZfbXt+Im1/bEHp2aBQX3DMH988sw6urK3D23bNw48vr8r7fvb8FZ941A6fdMg1n3z0Lr6+t9F3X5LWVOPvuWfi/l9bKSyARpU5/f37H5E2mk1JUpOdxB7Tff5hWig//dho+NWYm1lc09G1Hw5SddRX1+NSYmUWXuWjcXNw7fWvodcYNeogEsW95bUPgMj+btHrAZ0e/Y4hQmqIKfCZmiHXIDiL1j0V7ezP46G1v4WN3vI32rp68Zf7r0cV5dTGq8/4wGzM2Vcdah4j7ZmyL9Lu1FfXhF45RHne+sQnfnbA0+goi+uTvZxQEl8JL0jMxc4+lj972VqzgbhDfZ2JGyJcn5u3AOWNn4Z638s8915QHt9/Z7Rb70qOQPe9aK1jJtI378MGb38Q5Y2fhY3e8jTNufxsX3zsv+32Yc76Gti6cfus0fPuJJQO++8TvpuOgpkDmR257Cx+78220dqoJbB9s6cQnfjddybr7Yxs76/rO3b5w37yAX1BUDGKSdH9ZvDvUcnHHgmOmlgIAHpq9XduzVPZ5XJ0qFHaQGybNXouEnYkZJOjkpDDQe/ebpVa8YCHXP9b0BfQenF2W/ayz4Mp6e1cvNlYWH/wXC2o/v3SP0PJR3DtjK+6d3jfgf2llRd530wtOOh6Y6X9icP+h715dvVdq+ojIXion50xctEv6OmV2I6onJr2yqq891jHCeGlFRfBCAO6fVWZjTCKyb505KvzCSdrxHF05b2IsnAW1prwewOG6GEfuWMk4n7J8cUW5tiQs2XFA27Zyzdlaa2S7FN9dUzcDAB6esz3v8xeW66m32edWGpiVu25vvAsponbVqZk9vkbkQklE0zbsA9AXzCQ1GMQkK6h6VpFf0C3q5jyDitFWFUpQOl1+nkufEM/EDLMWifXH5edmuV8fiIjUitJOutorFO3OLOkw3nHEYC3bsbFv90qSXzrj3r0EAD2WPmrGkqpovcjZZGexa+N/6FhY8TQnSWRShu42NG0vGCIxDGKSMVJnY/g0rLLb28LnSnpJy2BMx63lYQWVs8ib2D2XLXw7uYJ+1a/eFJ64sEsnolz2tMT6ubbvstKrqx+I2tcpO9lVuONhkiz9bpT+9YaoGRbGYKWJvG+uNQD9JDwTn+IzlZ9Ft2vxcZ7kNojcwyAmGWOyLZQ5EzPqusP0nUHbixNIjB34s4iMGQr9vFZVmM86s0Zk12wKLBMRyVDs0SsOdVMA9KfXhfzR1Wt51SP/u3X0XBgXIXOcYwMp5Z6sLFHHwqGhzqJLUvC3vxkwsU+cGRksQVXNegxiUiL4neT4DlAjNsS6nr0ZWpxnYgbkgY6uyjNgaOBWv0zev8100mF3u9hytlVPIlKPpxXpE7apLzYj0pbuQqj+WvZcbp0cSqqw1I1dIu4wL1RH43ecu5ybLrVdRCowiElWiB2EErxqHnkmZrSfeadBwjripMeGDlBWEuQ+E3PgZyYH2IXJsaDYiIikiNt2a5vFF/V3qYvO2CuwrhnoXL3S5JcMG5/pGYfv5APN6TBCd1kmq+qkjsriE6mK2qutou0pfZeFwnVTPgYxyRiTA5WojUyYZ2LKVXx7cU6Qgm8n93jpjqWjy7gdXe7vQzwSU8nJhF9ZJuy8hYgks7RZ9mVrP1KMrGa4+KPQvLdidKwU+ZmY4ZeNdTE2ZsmYrosiqU/yWMDBJoEkMRmcN7VlV2fUJrkNIvcwiEnGyGwLRW8nj2qQxPWFW1XxXBJJTmHnI/CuG2Fh813W8yfj7kvuiVCYAZXJfrz47eRuDoyIKDrXzitET4TS3qoZfX64c7XLn0j/aONeJy2AkFsaCdu1YFHHapGnhEf8nUI667NtQ2Pb0kPkIgYxyRqT11biodllWrYV9srfxsoG3DF5Iw62dPZ9ELLjWV/RgDsnb0JDW1fEFA7Un+bcJLy+tjLUb59dshv7+/fhkFv/sQFLduyXlbxIvE6Qwp405e77zroWTNuwT3z7HpsSHVc9Mmc7Hp27Hbe/vhG76lqKbCuD8dO34q2Nwem8+83N6OrpPZSe/BRtq2nGs0t2e/6u+9BvVPnr4l14cv4OAMA/1uzFw3MGHq8rdx/E797YhLunbsa0DVVK06PC9tpm3PLaBuzZ3xp5HXXNHbj99Y3Ysq9JYsqI/PvJTZWN2b5qz/5W3P76RlQcbEVdcwfumDywLvb0ZvDHaaV4cNa2vr6q1b+vun/mNmWzZcKstn+RTCaD8W9vCdWGBtm9vwW3v74Re+vbYq+rmN9P2RR6WRWzc5IW+FLp9sl9x0wx46ZvlbrNHbUteHV1xYDP31xfhftmbM077gpf7LOjthm3v74R+xrapaUnSg18fN52adsHgIM5bdFt/9iAmqZw+zfu7S1F26mDLZ24/fWNvt+v2tM3dmnu6A6fWA+3v74Rj8zZjkfmHM6XAUGrEAfm62srcfOr6/PS3L+a9q4enPLrKbjiySW4/fWNqG3qKLqu372xCWvK67N/rymvx+/e2ISmdu92v3B819ndi7unbsaisrqi2/n7qgo8NldufZAhSju4aHsdxkzdjD+9tQVT19szlr1jcvFzjWK/i+vONzZhfUVD9u9FZX15dM9bpXgzRB61d/VgzNTNxs89VQrbhtY0teP21zfi/pnbcPfUzfjdG5uwas/Bor95ZsluPONz/pdGQ0wngAjo62Cum7QaAHDO+4/Hx997nNrthVzuy/cvAADUNXfigW9/PPRJxqUP9v2uuaMLf/zPj0VJ4iEDtyfaF3d09+C3r20Y8HlrZw9+9JcVWH/HFzx/Z8vJT9gOYfSzK7Fr7JcjbSPvdvIQz8TsX2ZTZSP+MK00+/mbG6qw9Def89zGnC21uH/mNgDAG9edN3AbOf9+bO4OjDzunfjep9/nua7fvrYB//XJkRg6ZHDe59tqmj2Xl6Gtswe3/qNvEPTVfx+B//3bGgDAZz74bnx0xLHZ5b7xyKK830UtE1NuemU9lu06gD0HWvGXqz8VaR2/enkdZpbWYOKiXc7tP9ktt5/Mdcn98wEANY0dWFtRj4qDbVhQVof3veudmFlag6cX5tfFyWsr8XDOSXZ9W/5Frlzjp2/Fp059l7R9iDoLZVZpDe6f1XdiHfe4+tZjS7CvsR2Lt+/HWzd8Jta6itktcDFExe3kxS4KcjZQvldX78Wmykal9cHLDS+sxZfPODn7dyYD/Pi5VQCAT77v8HHXW1CUX39kEepbu7C2oh6vXnuulLREGfaNmVqKi05/T6zt+lXFvyzejbaunlDj6AdmleEjJx+LL370RM/v75+1DRMX7fL9/dcfPjx2ueUr/xq4PT+527jwtHfjtBOHRxpP/+xQW+/lh39ZAQBYWLYfC8v2Y3ttM575wVm+yze1d+NrDy3Mtptfe2ghAKCrpxd3fvWjA5YvHN/9dfEuPDZvBx6bt6No2/vzF9cCAC46/QR84IRjiu/gISbPNYpt+ztPLM3725ax3Jsb9mHl7oM4I2fcHcbCMu/AoUj27znQiksfXJDNi+88KZZHExbsxOPzduDxgHqUBj9/YS0WFFwUmLBgp2++NLV34ZZD5/Jf/feTMfwdRyhPo+0YxCRj/AYtB1v9T6ZMKa1qBCA+6N9S7R9U0nUC0Vtkcl5TkSvOcW4ji/wcLUS7nTwq7zLweBaoT5oK62p1o//V8OpGsdkSQTNCdA/8unMqUkd3T/bfNh6vcSzbdQAAMHdrbeR1rN/bELwQUQx+x93mqkZUHOybXVhW0+w706ZwBmJpVfFZw0EzfXTwbF8j9qP7DrXHW6qL73d/H2FbvE/X+CFOX+6ioPqgit94q9gsxPpDMxbX5sywM6Uxwl1HYevwou3hZ20Vy6+Vu4vPcupXJvFicL3fDPeobyc/9Lv+cUq/jZWNkda3NaC+9/czIhdjAEi9C40GqmnqcPIiVJgZpDqekary0VthU7+uol5ovZ3dh8/BurrV3nXnCt5OTsa4NMjtT6vUt5MLZkD/8rb0WzL6ANOzPb22XzjbAZDzLNTcl0J57rfgNkznXT9b0mETZgmZUlj3wt49oPIZyXHX278Hnu2w4oOtv32z7ZgO2+7GvUXdtv3WxZZ+LTcdfmMuqc+Xl7guE4qVm4ky9c3PiInxeqxUHKHbESXjUxsOMhvSEI0tbRSRKQxikh0sb4xNvj0vLpkP5s89ISqWJbqfWS6Td4DR58VRIisOWLjw6/68tuUthu4eAfo53FyQ4wr7qvAvWSteaW3oAwe5OPVEgO623pbcTHixxpL7HEwLDkGpbBnbFFLx0lHZdVzW+lTVKZHVJqxaK5GUYz8Nbb2qXUxIFZCKQUwyxmRbJrNDiByws70x19BiiszCUaG/DILSMWAGUIQKlHsCLlL21tcTInJe4UtDCllxEuXVFiaofRS54Bg6OB2zI7cheJ0Gftmse4yU5NKWeUFfeNsDpsjHKzVZAeCgPIm6HTYbh4m2obqzTmdZhbkQyboTTOXt8C5hEJNIgMm2VXTbcU8+gn4t53Zyj+dPFr5EJ/5mfPPC++3kAz8s7HijpEnGLen5aWBPT0RyBHUXqtobkX7K8wRIcTPIc4VoGPyURPPt5Drl7o+8mYV25YbvflmSTq/HJ3kRLR4d5SBjG6aKIa1BqJTutqc4dcC2ds4UBjHJGB6CwWxr8G1Ljwqebyf3WzjijEqR/seWLGefKYKZRXYI234EzcQs9oI4XUy2hba0w6KKzaQKcxJle0umrF8yuuOHN677dvKo9TxJQRmZe9K/LntvJ7f9CE+f5BxJXpK9dyJ47MXHICZZwfZZZTalLuxgsX+5yG8X9ZqlaFNGKOJ1Mj9gdmiEfAi6LcevXH1nX6SgLIjIW9jbT8P2F0HNSVCQU6X+XRjkNWLV9ZZuPZuhAGk7BQ47U840F07IwyZRy57Evp1cDlV3XIXJw+xL0wzWHRtrrY1p0il3/x1oVoxI0kWjOBjEpEBtnT2enUx7V4/vb4p910/mIdjVIzhNJKBhbOvMT39HVy96JI8mi+1/e9fAPO//O2yH39bZg94YaTYRWFa5xUwmM6Bcc787/O+B3xd2GFHyJuqtU37Bz7YQx5gqufkYtcz8yiIuFevt6c2gvasn1Lo7u3vR1WN+5NWfZopGVf1UoVg5d4bsG4NvJx+orbMH7V09A/rGts6+z8LkYUtH+HwWfT6b3/bD5omoOHWmr3+Sn674z8SUlJAiiu13V08vOrsPf6+jZZUx1pMV9Pcrv6hte5vH2DL/ezNTrmVtN0qut3Xm9+2d3T3oltRG+E4m0HBghWmPgqq6ymR2dPfGO0eRkDaZ/byrcSWZ53pB+SmaR21dfeex/ePvKAFvrzR5JUM4juC3PY+2uaWjG+1dh8/JO7p7ih57ufvqNcaiPgxiUlEb9jbg9Fun4Tevrs/7vLWzG/92+9u+vzvtlmloaO0qum6/QzJKx1RW0yz+oyJOv3Uatuxryv69t74NF4+fK7VD91tVTWM7TrtlGr7/1LJY699b34bvPLkk1joKhe2AbHzr5E+eX4XTb52GXXUtwr8d8EzMKDMxc9YhdMu6j0/+fgZeXlkhnpCoctJ88b3zYq1q/rZanH7rNNzzVmnMROX7w7RSnH7rNCwqq5O63sseXIDTbpmG02+dht+9scl3ue6eXnxqzAw0tBVv+3T44n3z8G+3v+1UMM4Wd03ZhNNvnYalO/abTkooi7b7p7O2qSPUOoJf7DPw+9NvnYbTbpmGyx5ckP1s8tpKnH7rNLz/N1Nx1pgZONjSOeB3uf3Dx+58G2+sqwyVRpEToPIDrTj91mme3+2oFe8DgqzcfcB3e2FcPXE5Xlklpz0P30+rI9JF3jtjq+fnvb0ZnDt2Fs68a4a0oFIhr7HKJX+eH3u9pTnjxzi8zl1bOrrx0dveirS+sprmomPLP0wrxd1TNwuvN8rMoNzfzNtaK/x7UX5N3Om3Tss7dpfsOIAv3BdvjNNPVWArKL/XVdSHa49CDmZFyzfMaps7uvH/PbxQaL1R+fWDX31oIaZt2CdlG753RwiO972+s/1uxX6n3zoN0zdV+34vejh887HF+JffTM2Ov3/9yvrgH+VYW953HPz2teDffXrMTCnBwv/92xrc/WZ+G/qR297CabdMw7ceX4zO7l78v9/NQHNHt+fvKw72jV1+9NcVaO7oxkduewuXPrDAc9m0YxCTinpwVhkAYNKy8rzP15TXB85mmLdN/aBEpSfm78j7e0eE4FcU/1jTd0I3f5t3IEZkMLFkx4HIXZ+OGRiF21B1UpUBMHV930Dl2SW7hdLkJcrANOgnhevs/7vYtn7x0tq8vz/8nmPEE2bA7a9vBAA8NHu71PU+MqdvfXcWCTRGsbGyMfvvCQt2+i5X1dCO+oCLN7psq2lGZ08v1u9tMJ0U5zwxv6+Mx06TG2SXyaZZH7nHx//+bXX2343t3Z7jgMITstv+sTHUdkT6vueX7Qm9rAz3vLUl1u9nbxEbLxW7UCi37zZ38tza1YOapg40tHWh5lAQQna19woObKlusutN1gWW7TqA7hgn235jy36PzdtR9HsvttxOXiwZIincLulCh+xnYvbvQ9Dq/jxjW6j1BVWjyLeTh6wPaysatBxpU9b7Xyi78eW1vt+ZoP1IkrzBX7+yzve7uMfBCyvKgxfKcd+hC2TPLgkeD+xv6cT+lnAXfYM8Nte7DV2+6yB27W/xDWACwAvL+/ZxxuYaLNu5Hz29GWyqavRdPs0YxCRlRNrF3P7OppMzlYTf9qckFWq2F/YEwGs51cVvx1A7PJFzgxHHHaUuIRQoLW0XmScy68N29QEzl204rKSlQfPO2HhXRBwOVu9QXDxuKTzV5Rv1KHdlhp8XsZQnqx20WbFyCXMcGL0g4u7hkEoMYpIxJruUMB135BfixH0GVc7vk97t6uqrgvIxNx1CdcOyDk/t7YHydtaybJOGD9umtAtzDBQG1mKdtGhqTAJfgKGw9fXK02Ltce7iLjwTk8QU1gYbyihK32fL7E2VlI0JCl82GXE1vYoegWpbyRYrBhNpTfJQ0eRLAOPioyfdwiAmGaOjrXB9FoKMPIo6UEzSAFPV2+5syyHb0pM2g9xubqgAi1OcLXlmbfcVIV1J6ospmVTW0eIBqEzB30WWNXAcyb6dvHC9cYXNEdH0i2R1Upo3vzxKyO6FVuxlTbbkhV9Z2RCATdJdNqoxiEmJFmcWglcjF2Z9YQOnKh6ULVOc7YXNgzBvApctqAyVPRMz4DeuB9xFqN5TUzMiC18ARaSK/wlTtIZbZLY6mSfjmZhhmivbnqkt/ZmYtp8weiSksH9ztdsJ209bUxYWkTXGCQrs2ly1RILSNu+HabIPr9i3k0tLiTgbgphhsD73YRCTIgkTcBHpYGxsNkKfCBTeGidxb7xyOUmNV2FOeeWc9uBtmGUy+f9Vob+cReqT0tvJEzyDVZYkHZtk9+MBZLc9Nh+T/eXgWRo+RWRt0UW6ABZ9Z5J2cczmehpHnH7ehvNuU22l7fVb3dvJ5axHVd2x7VmbRfNLUlKVHoce67Yrhw+zoT2Kyoa0q7y4mDQMYpIxOoYefgMcuQEZ3q6dVlID1naPxSkMliGlnPZ2zJLnKtuEz8R0G7M8n8jt5MWYqMuqgqyy9iVs/onuh8izBW0LeOqQ5PG+y+e2NiTdhjS4gkFMMsb24zRqJ6Ns0BI1WBp1ewZu9faceSp5k/kv8YmmP03sbKINWJI6frPxdnKXB5REUaVppmpUts9i8+JeiuWzsJtRSuz5ikk8UgcqrAOR307ucHZJS7ri48mrTspoe21tBgIe2KUpFdHwdnK3MIhJoT21YKfwAGHpjv34y6Jdgb/L/f6ROdtRVtMcKY0i3lhXianrq4qkKdx6CjujZ5bszv57bXk95myp8f5dmLe4Ghyt6rg6GqY+PTS7DPsa2mNuyP+rhtYuPDS7rGians0p075lxJMQNGgp3dckvlIA/1iz1/PzR+ZsxyNztmPl7gMAgBeW78HcrbWRthHHw3PK0NrZnfdZbvZNXCjergBAR3cPHpmzHWvK6yOla2ddCx6eU4aWju7ghX3sqmvBQ7PL0NTehZrGdjwyZ3vkdZF9XBwolh9oi/S73ftbi34f+gUQBblmqg+bsGBH6GX92lAg/Mnm4h37Q29PNRvuNHlodhkOtnTKS4gifnuXOybQwW97XulzMfgcR8XBNizeHv/4kj2m7e7pxePzivf5os3fs0t2Y1FZXeByUWvAk/N35L14RVXQpn9M19bZc+icLtr4Voem9uhjwCSQHfhv7ezx/W7SsvLA3+uII/repXnov0H1tuJgKx6aXYb6Vvv7uCQbYjoB5I4739iEk//pKHzxoyeG/s23Hl8CAHjf8e/Ef3z4hLzv/Drh5bsO4nPj52LX2C9HTWqgpvZu/PT51QCAzXd+MfwPIzSu//30cqF9yZsp6MhVoQEkjrEXbd+PK55cgpn/9x/yVnpICYBf/30d3tywL/uZV47vrY8WGIhjS8ig5v/+bQ3Ofv/xOOGYd+R9/odppdl/v3X9Z/CrV9YDQOTjKmpN/OO0Ldjf3IlbvvKvnt/fPnkT3nv8O/HZ094jtN6XV1bgD9NKcfywI7HylouF03Xhn+YAACrr2/D7r50h/HsA+Px989DZ3Ys9+1uxfm8DNlU1RloPUZqpeENuV0/4Fut//7YG537gnz2/S+OtjjL8eeY2rKuoN52MyJ5csFPr9h6azQtgxXz7iSVKzwmieG7pHoyZWhq8YEgrdx/Ab1/bAKDIOO1Qc1R4caiwlfJrK38/ZTPeNezIw7+T+BIwr/TcN3MrHpu7A3+YVmq0/HQE/nVfr2PPJF9/UD+o3n794UWoaerA2vJ6PP79T2pJG8ciA3EmJgnZURdthmTQLA/d2roOXynq6Pa+auTVIYk850W2qPFM3b9TYXtti7R15QaGMwAWFlz11rHfYTqjfY3hZ582tvVdSfYbRImsS4VVew7m/V2YzF114u3DuvIGAMB+j9k+ImPJFbsOBi/ko7O7FwCwfNcBBjAp0aLfriivQVXZNjc7Nhun2Alz6JPpMC8QiJHnC8vsmZ3qEpvGXuRvc4g+XySwVXFQz8XyrdU553FB6YsZmFu9pz5wmSSco5CdolaRoHpb09QBoG+SDZnDICYJid7ZDPyhyf5nUE7H7BeY9NpX1W8eH7CM0dvJzfw4zh5HOWGOs58ivxW+ki3xOVC23XyWtLFn0vaHqFDoOh6isbHxmX5BabItyTyBl8PZu11ImO1FHWq877OISPuk5Tnmlue1CiLZKqMPtK1PksWlGYc6n6GZtseIhMEgJmkRdJjrbrJyBwumHuTrTjOtj/Z6EDMVUU+AwnRGIvUyaEkZA6aknuyZvFBAdmPVEFeYZTKPL5Xl4dcm93/uUusn9ZmYLu14SrBdOsz2E/ugZ+/lLxtC/+3khb8VyAYd5zy2BaJMHjMycsJrHbJyOMltvF+xy7poqeJYsu3YsRmDmCSkV+L91CaHHrkNmF8j5NXIeb+xW1KiwhLdnsTZs3YPF/3ldgqZvM89lrXkdvL+dIRJT9AyKgf6UbLLpnokIy027Q9R0hTrY2U1137bsPWEIg2BrKReOAuSN17xGnNqTIvtCo/PYlXGRG0SOU4HCSwcZ3QuchonMnbMe1STJePofjxmKJes+qmzi7J1LGISg5gUSZi+1orxZ5ieS+h28nDLheGXNBuyDTA04Mv+XzSRyiLGjqrMI5EOK+hqoG0nvLbUcVmStj9EOlkxVrCYaDAvdHsf5gIZWzdKCJuC4l6HqK5xWt54UdWLfezJam1E8siyITkdIlpvU1jNrcIgJgmJesCGDQhK57OR3CueIumQORPVdUVvE4zYQ+vIXamDK4UJFqlqwTMx41MbsDXHtgCvbGyxorP9VkWdVL3FNi5Zm/NLt+w6wBoVXphHEcQNTDnZPrISOcN/hrfHsgq247ltLbMkSbWkNgM66mfg7eQhM1fnhRGORwdiEJOEqDpedV+1y20KRG4nj7NcXJFfqqRoOCGj8TbxPMKg/BDZq6h5G6YzEslf12bLqC71pAcmiVI500VhyxHUF6W1SUljPbOdjSezUVKkey/M3F0Ufi9FxsMDnokZ+pfqAi+63zIu9iIdgy9JVXXebNl6ksDmGceunefpwCAmFTXgeTMiLz3xeQ5h9rOIR3+Y32WXCXEVVOjt5CE/k8XkUFXL1dqCjQTtb1DZh0ly4SoKfxN3v/3SmLtvQs/EDLXNEAsdYsNsYhkpyH9uWEbJwFzGOm26hY0E2RcriMXVuuhVDP3tmLRnYgZ87+oJY9HmPgH1O07gx1Z5d/s6csxGecGFypdi2JZvhcnxqouDwjymK+gifJjzo+DNDCAaBMyIDGCL/d4hDibZqMIyDjuO91vG63PVRaJ8/T4b4ESNPgxikq8fP7sSb22szvssIDboq7Bxmby2Ep8dN1c4Ta+ursDHfzcdy3cd8F2mqqENnxozE+Pf3hKqhTl37CzhdOSatnFfpN/5NUI9FgSZ+gQ9Z1FvK7p7fwvOvGtG7PU8t3RP0e/DdaL+333xvvno6ukVTdYAQm8nD1j0O08uzf77Y3e+jWkbxOusTQO0X7+yDi+uqMj+/YGb38SpN02NtK6NlY34/RubPL/70V9XRFpnLln1gShXlOb3gnvmoLWzW35icuiaJfaxO9/Ggm110tZn80lBnKa3rKZZWjp0kx3IsKgLi8XGuvr/PbxI+Del+5oUpAT43RubcPbds3CgpTPv8x21LULrkXO3EXDDC2uw50Br/ro9lw0u2F+9sh6Pzt3u+d2T83fgk7+fgbKa4vmq5+3k8Xzhvnno7E7wuKlIWXsG4zwy1MJmQMiZd81A+aHjoqc3g0sfXIAf/CV4zH3mXTNR1dCW99m0Dfvw73dOx7yttUrS6ifKsSTykzD5kWYMYpKvNz0CHZmC/0Z13aTVkX53wwtrUd/aVTS4cP/Mbaht6sD9s8qiJs+XzM7fb1V+AzsbppKrHjwX28Oxb5airrmzyBL6jTzunQM+21LdhBW7DsZe91f/fQSAsO+m6s+54KWb2rvxy5fXRk/YwI0Li1uN/ra8PO/vuIH/Jxfs9Px8xuaaWOsF5NWHqFwf6BplvsmVas+BVryxrkrpNgr7CFX1r6m9G7e9vsG5+u1aemPRsLOxA02WH+Mmb4N1USYDTFiwE/sa2zFx0S7TyUEJgFdX7w29bBhj3ywd+NsS4PdTNmN/Sydu/cfGomvTcXtzJvyQ1PPcZmt1M5bt9J+sQtY3XYHqmjvxh2l9dXlzVSM27G3ErNLgMXddcwfum74t77PRz65EQ1sXvv/UsrzPo7aeYS/G2jS5I40YxCQhqoZTogG6Yg1H3nd+t5M73PKIz4KNtp04WRQ2jV4DdN+3todIj5TbfwWW9bv9x+u8Q/Rc5Jh3DBFOT1hN7WpnYwVx9+jz5nJ7Qm7SXeWiXkTznHEULylZNU0dktZk53MGbRCrnsWsowzgsW8RlVdl4r70SULW+78wTO56B7ZfcupN/3ZE0yvj0JV5+OtoSvxf4iRWFmlq96LW0riTeuKcZ3r/LvwPU1S8yjGISUKidmhaH34bJtgVdd0Rf+fFt8OzZNCq49xF5JmYcTotkSy1JPutY8NMYCKKyYLDWDgJhzpLrz5T3rMqAx6fImk7UZjsk5LU7rty7uhX3v1l4cp+mODK+C1uMgc8Y9OCSuF57mJJebh0kcqWc0Adwt46XyjszVd+i0l7lrY71SqRGMQkIVE7giQNhFXzbXQtyELV7bWJXbR1wJDkwGvS3k6epivnZAdbq5zOZMnclmttqBMsq6Ms4nRJa3n3tWVFbifXlhK10t5mW9a8RtIb8bGnqp/rqnJ8FZR03+9TXt+9MIhJQkQObKE2xpGDU3fAS0ZDGnnWqYaLqrKDP7qrkYlb9ZMgabtvayAcSF5ek1u8WngXT75sO45czEMZ5I8ZbCtZf/2TCHjRzJ/MrJFRM3zfLuz1mUDag589LLleR3+4YCCLh09CRPajWLaEPb6TkG2R29+QP1M+8SYJheCwIaY2XFdXh4cffhjvf//70dnZieXLl+OGG27ABz/4QQDA5MmTsXr1aowYMQJlZWW45JJLcP7552d/v2XLFkyYMAEf/vCHUVdXh+OOOw7XXHNN9vvGxkaMHTsW733ve9Hd3Y2amhrcfPPNGDp0KIC+k87x48dj8ODBGDZsGEpLS3HDDTdg5MiRejPCMSINgs0Hd+Tgk9xkBG/P8dvIRIM7JdA/QC9MobqTmsP7JRTfFxkYqcw6Dc9ITSqXTpTpMJvLTfszMcOeNDDA4gwXS8rmC0Yq5L0spf92chcLThOd1SNOOXglUyzt+RvPbXdV1I8wd+HJznqZZWlzX17I8xZrh9IvQvW5uOjqTT47VWcaksJYEPPWW2/FSSedhCuuuAIAcOaZZ2L06NGYOXMmNmzYgBdeeAHPPPMMSkpK0NPTg0suuQQTJkzAyJEj0dHRgdGjR+ONN97AsGHDAAA33ngjXn/9dVx22WUAgJ/85Ce48cYbccYZZwAApk6diptuugnjx48HADz++OM46qijcO211wIAqqqqcMUVV2DmzJkchCsge2ARfyBrQ4cgVs9cSnGcIyhO2UqpZxoyOsw+igxa+pe09fyuMFlsYYnMUH0ypOb1EmlnLhdt7VOiSHq/k7YAr2p9+an/Ld/h+G886HZyrRTmkUhfpuOZmP7vOVC+aWf1P9syN4/ClKuq28lFV9tf5lID7n7rsuSQtomx28m///3v41vf+lb275EjR2Lv3r0AgIceeghXXXVVNpg4ePBgXH755XjqqacAAK+99hrOO++8bAATAH784x/jvvvuAwDs3bsXFRUV2QAmAHzpS1/C9OnT0dzcjEwmg8ceewxXXnll9vuTTjoJo0aNwvz585Xtc5qxDffi+/T2LCm3k0dsXU10vEmpJ+xrihsw+9XiUZ7NaSNKM50XnNPaptvW+sUp8/iz38zK3k5uOB2usKFsRZJg4/wZHUnyjdk49nZyisLO81OTz8T0/6HUZCSCsSDmpz/9aXzoQx8CAPT09GDcuHH45S9/CQCYNWsWzjnnnLzlL7jgAsycOTP7/bnnnpv3/amnnoqdO3eiu7sb8+bNw1lnnZX3fUlJCT7+8Y9j+fLl2LdvH4488si8IGjhNsjblPVV2LKvKdJAsrK+DS+uKEdn98An+co8Nt/etC9wmTQ9y/CFFeVFv+/u6cXLKysGfO61r3m3rITYdpT88qtbqvK+cL22PMo1kwFqmtrxUkD55VLa8fp8/vKqCuzZ36puwxJtrW7C31dVCOWprNm9W/Y1YfLaSgkrE/PKygqUH5BbPvubO/DC8j1o6ejO+7ytswcvLi9HbVNH6HWt3H0Qs0qrpaVta3UT/rFmr5Tg8/JdB7Fs5wEAwKLtdVhUVgcAWFtej7c3BvczKsU51qsbxdqVOGQ1SVUNbZ79lCwOdu2x2b7P3m+utT3V8fnNRHplVQW2VTcxIJMQG/Y2YNqGqoi/llMJwhxNG/Y2DOjvpm2owoa9DfnrylnZSyvKMX1TNZbtOiAhlfEF5Vb/2KWmqR2ZTAavrd4rtP6Vuw9g7pba6Aksst7ZW2qkrzeu6PU2X9i3jA/8XfAPt1Y3YY6CMlFtxmbv8fALy/WM2Vxi7HZyAGhubsYDDzyABQsW4OKLL8YPfvCD7OdHHXVU3rInnHACqqr6DprKykqccMIJA9Z3/PHHo6amxvf7/nUMHz7c9/slS5Z4prWjowMdHYdPzBobG8PvaIKU7mvCF+6bhxeu+XTgsnnP8skAF4+fi5bOHlTVt6tLIICDrV0K1y5zAC14O3mm/3lIYr/747QtRb9/ftke3PqPjULrVCXusMxv8O/X36k6IQpaa9iO+xuPLEL5gbbY6VFpyroqTFlXhV1jv+y7TGG5Kn87uc8WPn/vPOF1yaohX7ivb9vHHnUEPvOhd0taa7CXVlbgpZUVRctH1PcmLMOmqkYs3XEA47/179nPfzdlE55fugf/8u5hmPV//xFqXd94ZBEAYMGvLsTI494ZO239ZTz8HUfgwtMG9vOivvnYYmy+84v4zhNLAQAb7/gCvvrQQgDA9Bs+gw++55jY24giTtP1tYcWoqpBUT+s6OD+wr3z0NjeHbygIskPnblJaKabslTo899PL8f93/53z+9SEN/VKig74waTv/LAAgDAP35yLj426p9irUvZS1dxOJ391pbXY/SzqwDAd1wxY3MNZmxWG3wT2Y8Tj31H0e/HTN2MZ5bsxinHvxO/+MKHcf0La4TS8o1HFgstL7rev197TsCSeo1+dhUm//S82OvxCkaGKdcwy0QZ7+sQdKxurW72/Hzc9K0KUuM2o28nP/roo3HTTTfhjTfewHHHHYcbb7wRgHdgoaSkBL29vb7f5y4T93svd999N4499tjs/0aNGhW4f2mXe5xmkEFLZw8AYEFZ/CsjSXgiZhhewRjZgbclO/Z7fm7iQdLFtqhr9kGoDjTg+7hvnuxf3vYAZlgDX57kDtnH24bKhuCFLLepqu8i3tSCq/H9szV21LYIr3Of5KDaRon53Np5OHjWkvPv3Y7MQC6kLICpkOoApq4ZflHuYjH6gj+DG/fKq7Q9s74w+/fWJ2NMIEuxO2lUj2FlBVu213oHLQLWHOE34ryOt201UdLrT0cb868nDS/6ff8dfLv2t2LNnnrl6RFV0xj+7hZRUbM/Wr31SYNlZwWiz1DVnXpesOpjNIjZr6SkBFdeeSWmTJmC/fv345hjjkF7e/4gu7q6GiNGjAAAnHzyyaipGXiFp66uDieeeKLv9/3rCPrey0033YSGhobs/8rL0z2tV3QgmffQXocPPh1pz23MTTbsMvY1yip0Phzbqx6ryvPc9Ic5fGw7TmxLjy6S7iY//O8E5ePAfUlXgIH0SHutMtlkGN225MbS9WdiHpb2IyKaY95h9OZDX27WwYFkj52l5gsPGStFLhZl5an+YEzK8W4DI0HMlpYWfOQjH0FdXV3e5yUlJSgpKcFnP/tZLFy4MO+7uXPn4qKLLgIAXHTRRQO+37FjB0499VQMGTIEF1xwwYDbwjOZDFavXo0zzzwTJ510Ejo6OtDcnH8VIXcbhYYOHYrhw4fn/Y/k0X1Q29CIiAbr+j+WPRNBxVv7oiYx9u3kguUa9SSpP522PFvVteeEcTyZDIW1zqZJUo4dEsKi5nXkNivkcjqrQEmJvLYvaDWy9su1tpr0U32MJkmxdjDuoRbYJhjt78xt3JZuXqh4BRbWcRyJ151kHt3J3CvSxUgQ88gjj0R1dXX2beQAsGnTJowYMQLvete7cO2112LChAnZwV53dzeef/55XH311QCAr33ta5g/f35eEPLhhx/G9ddfDwAYMWIERo4cibVr12a/nzJlCi6++GIcffTRKCkpwejRozFx4sTs95WVldizZw/OP/98hXtO0oRs+WzpbL34DZByOzcVAcYB6VDQjbh0nla4/zJuJ9exBpcU1mKX9l5PfXBUGnfckn22tY0NdZHN5o65gA2B+aCX7EVlwa4VJbuK276/YdlQJ21hazvYT2R8Hadcc39r2625QfxSq7Oe6zjXymVTvbWtPTGbNeozw7b8dpmRufVHHHEEpkyZgmeffRYbNmxAb28vNm/ejOeeew4AcMYZZ+Db3/42brvtNowcORLbtm3DLbfcgpEjRwLomxX56KOP4rbbbsOHPvQh1NXV4YMf/CAuu+yy7DYefvhhjBkzBvPnz0d3dzfq6uowZsyY7PfXXHMNxo0bh3vuuQdHH300tmzZgmeeeSZ1z9sxQWcD5betqJ181LRnMpnQdSvv1nvLbicXPTpEZ51kImwj7HpVLGvbOlS2XnHqokXjNWGunRDoJDNvpAcsJB4MHBfYS3XZ9HdhsupnpGdiCm5dZpbEOdnmURMfex95hMevAbkvKxAlZbxYsBITXZZNgbk4ZGed7fliMn2m+gjZs6x5h4UZxh4QctZZZ+Gss87y/f7SSy/FpZde6vv9aaedhnHjxvl+P3z4cIwdO9b3+5KSEvziF78Il1iKLSkHeJzbh+MOKlRlod8VSFPBGz4gWVym4L8kTxLqhyoDTpzMJMOTzHJLSv/lKh0n5EkqYrn7YvfFK5F99XwmprSU6GNTO2ua0Fu51SXDKiUoCTgugoKzbuSUUDotqCd9jz85/G8RjhSJsITuVlGm3jeRRFa82IeSSWxwIT5jL1Qa/H5vQQvAyT0Dy8eGLBEZGKkM9NpQR2XRXa62HVv5LzZLUMEWiHU7nLxkKOV66UVOf8h6q/vYU3082daWpEmCm8pY/GbzRjkWXK/fxXZZdfWRlXfyX2Alb328gKRGGve5mLSMkUkuBjEpkjhXkVxuoHTchq7rBQNBYt1GdiiRQaso/L7Y8u7WmoHUzapVx+HDNhb5L2GSuz6TZO6Ki9niegDAdTKzP6hvN1nUrrYZsfMsxH6LHIM8XAdytW5FIf44pPjb1JW/hceByr5JV79nqm6q2j22PwOZyhP/Oqy+0nHcKA+DmJRK4V7WoaYxy2QyOOXXUzB9U7XgD/P+o1zQdu58Y5Pvdyt3H4y8Xb/2PUx++ZXrj/66wv83AX9TOOeOnYUL7pnt+V0GwMbKBlw0bg7e3rhPb8JSZlddCy4eP1fLtgovSMl8OP4zi3fhC/fOQ3Vju+f3v3hpLc6+eyYuGjcHU9dXoaGtC1++f77wdg60dOJLf56PJ+fv8F3mwj/N8f3uD9NK8dlxc/C58XPx6Nzt2c9nbKrGRePmYH1Fg+fv/jxjGy59YAFaOrqF02wzvxrQ1tmDrz64AOPf3uL5/Q8mLve9wHnzqxskpU7chAU78am7ZuCHRfoQ1UTrddiTpKU7DwQuEyeQILMvlXHid92k1QM+KzY2sJXMc+C99W0S15YusoJsv3x5Hf7vxbXBC+YoPB6EHqsQsGzQ9z8XTKsqqtoXv/VmMpkB7cVXHpiPL943T3h7a8rrhZZP6nnJ7C21uPUfcvv3DXv7zjWKETlevnz/fDS2d+GF5Xvw+XvnovxA68D1CaQvTReOVGMQk6yg+6COPKMy8jMxD/+wtqkj2kpUUXBVqKsnWkZZcYFKQ11U+cwdU/bWt2H3/oGde7//eWYltte24JpnVmpMVXyuvdjn5tfWY1tNs5ZtqcyZW/6xEVuqm3DPW95Br5dXVqCqoR3ba1tw7XOrMGH+DmysbBTezsOzy7C5qhG/n7LZd5nG9sOBxsI+4JE527GjtgVlNc0Y+2Zp9vMf/nUFtte24Id/Xe65zntnbMX6vQ14fuke4TS7pL9NenlVBdZWNOD+WWWey80srcGuIu2H//rlNHrF+vYaw312r+CBJvV5sPJWFYvfPvGE8DBmRb6BL7uxYoTp6ZVVFdrfkG0724prb33bgMkUG/Y2onRfU9HfuTaG1O2vi3fn/R03t/rPNeLIbSs2VjZi4sJd+NUr67G1uhl3TN4YM4UkC4OYpIWLTbjXgMKGAbPJfl32w6gtG6MIE3quuMKdzb5B14L66aUEQGtnj+lkRCLnIdyZnH+rpTOfddS3ju7eUMu1h1yuUFuX2vwKKo/Onmjpjkp1mfkFCrpClE+PaLQObj+eJulc79/JPUWfkSm5rQgzphN78VT09Ak9VkHRIxgiZ68jTXivpq7akeyQSuY+xxvTedf4ju7D62zvOlwRzL1dPY21ZCAGMUkL+c+VU38AK7t6FrHV0301T08eD/w7ztVyGXkUZh1R8sb1Psfx5FtDdT0wWc9UBOrDHmtR2yvV2TXItukkmmUvsChYt80zqyi+MH1x0qsAT1ZJtsDbyX3+bRvXDg3Z/VWa24ZiOTlIQZ/gd301Sgkkvc/SiUFMikS07bRtOr3Jtj/opNaWvLIjFfrZMi6IUg9s7Rx1Z6ncF36EWMaSOmOapdWvKNV9ma3HpCphdpe3Taols86ZbNtCPbs8gW2vSJBJ5HdpUKzuiwaRVOan17pF2sXCJW0oe1vOXaKwqUeyKS22UvcavoznGuI+RzbqslQcg5ikndfxa+Mx7Xk7uYS3kwcGMW3MjIhE3/gat/OOlHcRfhP3imqSypiC5Za3ywP9ICZnxsl4XrEKiTkhiVi2/T/L/bWNx4B9KYpO6jMx2VmRQ2zra21IQxw6+i+/PJLZ9Ji8cCZ+oTScJN2JkNvPxC13JXcE5T0Syu1jOkkYxKRIZDcSNg6UvRoqGckMyjq/vFWVRX7pMVEkNtSCcLM/4qU0zO9tOyTi7HMJ3A3m2Ng20UCRH8cVo3jD9IOqTjSiP34scrQ34hb7t0tA+mbmkp3Yr5kVtx0oLD2R9eUFej3qgTN1Q3MyTQavlM4KTljvrOJ2cr/8Z3duFoOYFInwlSXZz8SUuzqtgmZiBl0x1HcS5HIuhxenA49ar5N0BTUsV2uTq+mmcESPf9FjPmhAnbSmIFRg1//SmdS0pFVS6hRrgzquxKliKdhH4RdTKqyBwbenuldAspOclHasX9jdSdhuK1Esj1TMuu2N8NJBPzLqtXutgxoMYpIWth1wYTpbZbcfBKw2b9q6bRmnuHuNfTu5hDSEWUdQEFL/ANW6ikI58h6Uz6JSImq+Shyb+lDz+BB7T3S8U6YivfbmgT/Xjn/bkutimYuK/tii8L+zrVx1sP3YEym/YseB1NuwNRxwtpWL6fR4P3JNXaKse0Z1mLvhinwnYyZmYb3P3V5ufmWy/xVoey2r7y5jEJO0mL+ttuj3ym6V9umBZ5XWBP5WZqcxc3MNOrp7DqXJf7nG9i7MLvXOK93tnowyifIsGJ3d6Y66FnT15Ccy3K3edt1aObu0Fk3tXbHWsWh7Haoa2ny/j/2cmng/BwC0d/VgVmm10G9eX1uJF1eUh1p21Z6DAz6b7dFWrNpzEHO3Fm/T/GQANLR2YXZpDbp7eiOtAwBaOroxq7Q6266EsXj7flTW+5exCzq6vetAb9S3k8eo115t9ezSGnTllGtue7+jttmzjkXa9pbgPkyqgLPZoLpo+7jdxZlPfvzGEFGYzJY5HnU8OaVkVtz+Jw36635XTy9ml9ZEGmP53oYaNJnBkor++ymblW9D+6NRPIS5Oyryc7ej/SxVoo6nvVQ2tEtbV79iMYzWzm7P8wRSb4jpBFA6rN5Tn/23zuCY34nJvTO2Kt1uodHPrsR3znovxvx/ZxRd7ntPLkWnzwmwbmnoeNUFz9Ws18+Ds8uwZMd+/PPRQyP9fsmO/fjOE0sBALvGfllm0qS6Y/JGTFoWIiB5qADKD7TiZ5NWAwA+evKxRX9SfqAVX3940YDP//dvawZ85rVcMfubOw7/kcngG48uQllNM2760mn4nwveL7SufqOfXYn52+pw5dnvwx1f/Wjg8kt37Me3n1gCQF0Z66j3Y98sxdMLd0lbX5wToWeW7B7w2VUTl+P6z33Qc/nPjpsLAFj0689mP4uaZ88t3RPpd6ravKsnrsB/n3OKmpX7cPF2Qx1pbusKf2HDZj9/cW3gMkl7nhugJ4D1w7+uwI1f/LD6DWmW/wKOfFGPvXunb8XDc7bj4+/9J7x67bnZz8tqmqOtEN5l7DXDK6r472fuk3vuJvI7l/nVk9J9jXq2H3I5WRfebGhD75uxTWh53V3/1urDx3pufpWg7xxh+iaxyRUkB2dikjIunmDkkvl2cgB4PsRJ59qKhvztme9b8thepjI6dZE16HirYlgrdh+MXD+X7TwgOTViwuZXqABmjm01Tdl/r99bH3pZ2YYMzulqS0qyJz+vr62MvM752+oAhM+T5bvUl7GO9uFvgnVAtjBV9bXVe7P/9sqSXftbDq/PsjY+jueX7YlVB0w/a5sGsuEEN5flQxCjRI+H19dE739cICvI89LKCgADA3qbKuUGtYRuJy9yINg+Ti/kV06m2ne/7a4rOD8TFbZc7Gpx00nkEBINYLp2fNqMQUxSRqQDEu2swjYCcV6gYtvgXTcTAwgb2vY0nhincZ+NyclsFfmetKIMuz9O3Q7sUFKFJHW/JHKpmgKwvkyte56bBEHPUJbV1kV9BEdaBOWO9CebS1ph4DPZLTuo7UqNP5Pp9Jy5KykaZlsbqqN+uv6meTbdfRjEJO10PrTYqRPbAKr2xa8jNJF3GaTjKpWy29gtG4zYJPhlSzHWHdB+qSwV205ITCnMBVdyJWntXZjjSFadLSmRV86u1BeXqKjbA4/z5JWcrrFXgobHRqjMP5PnLpGf/Sg5zTKfGyrSFvktG7c54/icSC4GMUmZpJ2cARz0ySa7jsh6QowNkhSATzuWZHThnw+lNBk52xHbkOfSCewbZUjDcZLEcZEOzDf5knC8FWuO4/YJQW29ygB64CzQJBSepaK+jMl/fXZP0knihSCVGIy2B4OYZAXdbyePSkYy47/lWU8DqmNfC793rWuI/rZC9wYNLg6adR0rItuRnY1JH1CFvp28YEmrc8XBYykM/e1a0mu/ebZU1f7+Jw3lres25qTfTj7gxT4R1xPrJTkWZrFtabItPWSWjvrgN3LI9jNFYgdxxzm8ICcPg5ikH3usSHTnmvfbExVvU/H6w9BSPW3Y0Ryqgw8lJSVaH0Tfv7q8twgqrLxRbyeXcqEg5FqS3uwW7l/Y3VUdBrMt36MmJ0wuZTL6B+iWZS8plrbyVto3JyAzi7U3trW9IoLSXrjfMvuxqHUuanbr3l5Utl0yS+ozMXVw/ZmY1IdBTLKCK8c0b/G1m5QHJsdfhRQ6q5rqbQXelqVhX3noqic6GA7VnlpWbrY8L0y3MKnPwGt2vcAsZYNZ5HjxKMN80U/l85tzJX0mZlwmb+kWDbLIerO5TRJXPWU/Pou3k6cWy6wPg5hkBdHG2JE+2An+s8TiN5KBM9QSWpDe+62+0zE529BGtl9hdj2wZRPbczINRe1Vnz3bjRTkBZFuom1M0g9D1WOWcBd2wqdB33Od9WwnNNvSI1nCdy9R+s+hVJ45JPW81wQGMcla1/x1Bbp7ek0nQ6pTfj1FaPnczk/7wMPA7LiSnP83RcusQFXrFVjxg7O2KUqFeWvK6/Ho3O1Cv/nBX1YoSk2+OPVr2oZ9+M4TS7CvoV1egkL6zavrccqvp2DJjv3Cv81kMrjhhTW4563S7Gcrdh3Atx5fEvzjkM3B80v35P09fvpWvLiiHN09vfifZ1YI1wfZcmc9fefJpdl//3HaFkxcuDPw943tXfjehKWBy9nmp8+vxsrdB0Mt6+KFElN0nQjFKZP2LnnjNx0nl/YQz/Oxb5YGL1Qg6TMxc3fvD9NKcbC1S/IG5K4ub9VBt5MXHAm5f4sky/Nye+S7DSL+zufz4LeTyysA2wNL101abToJA1z/whol6012q2ThRQSHMYhJkYTpPHwfnBvys7c3VeOtjdViCVNMRttT29QhYS3JFDt/LekcvOt+ziDTgnT+6e2t2rYl+wVbYRSe1DW0ST6BydHU3q1s3blGP7sSi7bvx22vb9CyvVz9QcLLwwQeC2zY24hXV+/FQ7MPBxL/89HFWLbzQPCPYxwrN768DtMP9SNRTvJlKrYbt0/eFPj7R+Zsx/xtdRISEi1DQz0T0+fzbzyySMmsY9tPPFWyoQ/RqX9/C3c7bfnQZ+BOR7lIk8S889unR+bYnz8i7dkXP3qitHVROPVtnbF+L7tI+ExM+ZLYJiYZg5ikjN8VfJHmsq2rR05iJJHRwIlc/TZ5u6mUl44IPpzcBupuo3f8dvIYybfhtulehUkYedxRkX4XNVuKzigxmNd+9a+j21w7bqIPyT+5kFMejQqD8LJYcJjH4HTilbG9TG0cQ8SVm+ci+S86dklC3hl9jq7kNkNkXz5wwtG+aSkJWFfuVzZUAdvbmH4qx5BR8JmYlHYMYpIVXOnEZIg6aOjvaKS/ydlnfZ5vJ1c84imJuQ0pAUgtt5MHbyRFh4SWQZTJAG/uttM4YAz17DBF2ZKEE/UkyA3s+hV1r8Gnx6RpDEIEJL/Oxw7ySHjBku5bs4H4t5Nr2XDez6L9UORXMoYBccuSY5FwbJj0oLKspKzbfBZZgUFMUiaZU9TT03KYCLa4lrtifa1dt5Pn0pMcs+2Bya1rLW+OlPME9UOi2WXbsesKG05MkkTfMzHtkobWLSjPeSgdpuM4sLFLLUzTgGdkWphmUaznlESs1/IwiEme9J9wiN4GE66Hlr0furPF9bYuSvqT28BbvGMhMj1O6k08E7PQIAvSUEjJhQJHDyBVxSN7vZFnjVhSLJYkQwqZRasrX2Sl2Zb6pBufiekvjXkR9rZpF2Ty/h0v9Sbqgst9Y7hxggUJJQBmzyly62uUdKTxbixVGMQkK9jQiekSue1NUR5FJaMe2ZLNSTomjM3CyjnWTMYw824nl5wVNtWTOFmsaj9MB69tKh89fJ6FHaIcOLi3D2fQ6pf3TExzyUi9oPYo1GNS5CRFK1smawS/nTz+NryX9V6aTaEedmSzmYlSJIZBTEo02VdrtM9PNfnQcgPbjvtMTBl0dErs9gjgoFgH6TMxWWaR5LarNuahrjRZuOtOMz1eMIF1KBzVx7TssWLe6+CCnrMt+TEppF7YR6zZ2D/axmTwMO6xlcxH7ZnBICaRdm40YDK6CNGOxrW+O/rtM2r2VO3La6KnOehiAjv16JJysqLsdnLJdcu1Nko/vRUyrSd8aX0mZqEkln9uX5uQ5t0I1bdky656uqqyqmPG5WMxd5wgfTzqcL6QfFJeQCshHUkwxHQCyE623E4Qe70u96oFbNgT2Z379tpmqeuzIY9k0Xlrpeot7d7fgv0tndm/K+vbCravJgUb9zYoWW+hqob2SL+LutciMzZcoe52cjXrLWZnXUv235nsf4vv4Ia9DThyyCAcP+xIVNa345/eeQSOHDII7xn+DgDyglY21xejdx449nqzioNtwQtJsL5CTxsaxPWLNWU10cY6XrXS7zix+NA2Qv1MzDDLRLzQLbj8vsZoYxDvbeutSdHzKPh322ub8a53HillvbraINfbOh3i3mXpV+XWVTTgX959tFg6RCfrsKGWhkFMikT6FUhHDmoZ6RRre9VnTE1jh+fnvRoK5aHZ2/P+LoH5mQc66qIj1V2auubOvL/bu3q1bPdPb2/Vsp0DLZ3BCx2S9/B+TSc4Lot7QiX/dnI1uf+VBxZ4fr5r7JeVbM9GollbUsITPtXGT9fThgZxZYzopaymGZ8bPzf08g7vqlVU5+O7hh0Z2PdHTYNoP9PZrWdMpYJvUD5mAe6sa8FF4/qOu79d8+l4KwPwziP1hExcbutkMLn///fSWqzf21B0XJH3zOK0F5ZhvJ2crObXjpg6b5HRYNl2zrV5X6OydYvmVtzclVE+YYImsTfjYL/nYJKtZ8Nb23UwOc4LfpSBGFO74s5YOUT7aXimixd38pdcs3TnftNJoAiCmoT/+n8jg9eRonbFtl1dvuuA1PX928hjY/0+JcO92Ey/4G/iol1Kz9NZD+RhEJM8BTUhuo5Bv3TY1lmKEHpLXsb73+QtTS9eInfIfgyDrWMgG4OyQSniIew2WW0w23KyReCzGH0WEH4GecLrvKzeyK//PmIwT6FVzkQLHE44Un9Fg3K6h1FJbwe8BOWxyixJY36rwhaYIpH/QGs3jmo3UimJoZ21MA4yQNw0qqrvfEGOnXLLmwMYvWQHVkXLr/8kz/Vyd6FdJkoakXbD8SYmocKXSm5AMFZZxqwIQnVOQqWzoW8M07/pSqcN+WGUjkd6xdhGbl0xdeE+9XXkEAYxSRmRY9vvgLTtdnIZXEm7qcBynMZZ14AqcBnP78VKPsq+RH9beqSfOSVJ+1hsVxK0m1IEvdhH+HZyzRXJvWcu6evheNGGkoj9uFyRnz3dfwHKpzxUPnpIZVnKHNvLeMa3DhYnzTheoCRXMYhJykgJKMVfhVRyXuwTrcdQN3tPYFnBpOt/y72EZ2IqS7Pbs/GUDqodzA8RNgRbXM3iuHVD+ot95K5Ou+gn9KGXlLgufVy5GyStXC4d2fXdd3UuZxIJCerXdI05dD2H3vt3eunqIxhUNK9YEfDFPvZgEJM8BR2YsttYK9sBjzTpPtExmS2myoQdeHRRB648gddHRl7beoj4pcvkQC/3opGUEy7R28ljbzE9TI4DrByDUDpFnb3H1iZPf9MfeTZk/3p8erYw4y3f5/oHPvg0cNUBPw+3Aq9kCD23X2BZUba1ybpm1Wqf/GFZPtuAWeIGBjEpkjAHuNDt5H5vKw2/CmeI7JOOzkVkE6oDjLFXr3n2b9TNhbplPeK6yRtP8NwUt83J/XmvlPZB9+3kff81fXHH9PaJXMVjxwwbgjNRn2mqtJ9RtGqV42FKD5eqg7FnYjqVS+owiEnkR1HbZFtH7z97SsLKNc9akpJkDSMqN7sfdanmSV50haVi4wlBnIFe4f6Irsr0TEwiSrc4s7e9TlbZBolRlV3hnolpprD03U4uYR0+nwe+QVpi1nIISuQeBjFJP4+eya8zMhrU8vqxjA7bshGoqStJfqobO4xu30Ds1tP9M7dJWAv1s+Wwe2zuDtNJ0OrV1RX49SvrApe7btIqbKtuGvD5mxv24aUV5dm/Rcsx98U+UmZiGqhHf56xDc8u2SNlXZYcBlLsa2xHW1eP6WQIOdjahReWyylLSr4/TtsSelnRtmlvfZtgaux3z1vh8yuIyef6m320RviNm5wRdt2kVdhR2+z7fSoeeybBxEW7TCdBmF1nrWKSWo9MYBCTPCk9xqS8HSf+KqJIYtvjN2BxcV9d6RxsC2SbTo7p7bussCm07JoEbnhhLXbUtQQuV93YgW8/scTzu1++HBwE9ZM7I6VXQkWTsQ4Rje1duHfGVq3bVM33OXEGex2dxfqrV9br21hC2NZnqhT8uMTkjNl0iFt34vSpcZ/HGe23xX+9prw+xtoLtpXx/rfYOqL9cPmug/j+U8uibTQCHl968HFbFBaDmGQ1o+fjFgQDcjt33Y22ybcOOrM9vwBwAnvYJO5TErhwO3lYdc2dgcvIDtLaFvQt1NnTazoJROSANAV6+xUb86l/hrudnUdQupo6ujWlRL2Kg/pmE0ct7fQdlfEk/XmPto85XcIgJumn8XbyWG2F11v7HHlxDMUQ6ipgvJJRVq7sHMkk1r8B+vuMFMYXhJkMCiT9xImSjzXYW+Rbug/90v/8JMQzMQW2nj+rsfjvirWU1o5PBbcns8+0oX2Xfnu75PWRHlLiCCx8AAxiko/A21li3eug7+jjcR7M75mYXnln65XnfnKCzOmrNWnY4zTsI6kn/JKOuI2S5Ipr8+A3jW0vUaHA48AvqJbCw8f2MamNTZqqeuJy+x3m3QBG39GQImHqp+VHfVEuHye2YRCTrOB3ULvcUMnm4q1CokmOW966ciho4BzUSTlYlM53uybznLePyOPisRNHEnfXxr7MwiQRUYBwbwiPvHIAZvpvR+aJSOGXXlPjJtP5F3bzaR5WOlbFSREGMSmSWJ2Lw2f0Mq6gmO4gwzKRThuyJtxDpQ/dZhR9K5F/Se5x5ZhPOs7Ujs76GU+UaGxDg6W1bbJZ5PipwaLUv+1k11sbL9qlHUskGRjEpEhk306ue8ZeVHL6omjPyFHFPy/da+blvIxIRjokrCRFdGSXw9dOnKEji02XY/S3zUb7oS1tSdIDJMneO0oS37qawkoc5uKKybbLRPuts4/M278U1j8RYYsl7HJpzm7VVZynC25gEJM8Jf2ExRW55aDuOTbqaH9AuKYNxp2VZEtgol+o2aeWpVlUkm4nNx3IMylOOUqZSR97DaLbk7tF1el3vZ0gkk30kOAxFJ7KcxUpF7QNvMrTtfrjWnpVS3t22LD/Ss+LpdwRRACDmGSCxxl4VUObgYSIs7nhqKyXm4eV9e1S1+cKkdvJw68zY2V+puk2F1faGD+56Y9bbCbzIs62G9u70NbVI/Sb3O6mqmHgMZh7QeJAS2fg+kSPmcb2brQLpjl/e5F/aq3qRraFJAdL7TDZebG/uUPyGt1k4pqhyuDswVb/fq5vrBqtj4756FGPtERcYQQ6ylj27qT4WnasvOzu6UVNwBikrkjbV9PEdtEWDGKSfh490+hnVxlIiDibT3TOGTsLzyzeJW19d76xaeCHae41PfhVh8KP752xLS8/7a1FZuioVn9dvFvDVtR4e+M+nH33rOzf+2IGgc6+exambaiKm6wY294n/Lvunl782+1vx9r2RePm4u2N/tv+xO+mB564Rzl2P/PH2RF+ZReZz8T81Svrpa1LFrbJpIrs/s133CGxEtc2deD//X6GvBUa0N9mRX4EiIwZU7Ije4fEuRujpzfnDq+CDY2fvhVf+vP86Cu3lZSyjPhIGMHleTu5Wt+bsAy/fHld0WVW76n3/a6spllyiigqBjHJk8WxOjEW7ofKvB0ztVT4NyoDSLqDvra+uOP+mdukr9OLaFmK5BcfMWHOI3O35/29e3+r77Jhy+nhOduDFxJUEvLM6pE5ZcLrbumMPpsxb9tzi+/3qiKD16hqmjqS06cGSPOjDkg/F6qb8O3kkbcjr5FZseuAtHWpZPsLx1xr9h+YJdY3q3zZadL6EgYnwwlz3hinaizesT/Gr8kmDGKSfg73TEl8aZ9NxWFDUuRcfS++EtsCGgxQkk5Rapusdip3FoqXXsuOXVuOzLBtRJxZYra1i2S/NFYZ9teH2Z4XJu7eyiB8fykzCKz7pXdBwl5UJYoqSg3jOEceBjFJPwlHsMudk/7HfAdsw6IGNW5SbB/Q9rMlnXakwp502MrobW0KREnLIEltflAQMzhtFmVkBO72nGrZdHwQRcE6nC/uOMvki+B0FaUtY1EVbH78VxhB6Wdfbl6UGiZn9rLbdVsWBjHJSaEPYAtbeZPP59FN+5t8tb/1zcFCicjF+mcLGx/ZYLJpDJrt6EVWeoODmHZVdNnpibq2uDN2wsSgzV6btKvciUTJrMFJOhosa9J95abTxTQ7zcJzxSBJyfpCialTpByDmKSfzjMV2Y0hG1er2VI8QemwpZPOBkgsSU9Sxc1ehyeee4pS/3XdTq7q2I08IychxyZvJ6c4sl1VCipJ1MfRpCFvRFjxvMwUFUnUGWaqXlQl+469qOvjYUmkBoOYpJ/Dt5Mn8dYLkay0YEioHkccZJliVdLFR2tEeiZmxNan8FeFQczC7At8JmakVKSHg9XROAafKJcNtSFJh3Hc4FqcPlZk27mbSeK5hh82f+QqPhPTLAYxyWq2nRBpf6lD7u0lDg5q9OeXuWcYiazElpIUej6rLYl2kI23k6sQ+u2bEdIsq/3rCdh2wERNHgcBXH3TLMvVDS5etNGFddg+ImUicjt5sYt6OscEKrdk26Fu01iL7BDtmZgkC4OY5ElpWy3QMyWxzxA5GRc9cY/S6Scpj118BicxH9PGZHnHfSam7hOZpBwboW4nV58MK7dNJEJHXU3S8ZCUNtR2tr2dPH8bdqyDgvF4DcY86sMgJunnyNH399V7TSdBC9uudpqm49ltqgIhorNUXHgk5oa9Dbhz8iY0tHaZTopy22ubcfvrG1Hd2G46KUqZnFUeFMQMEv3ZljYfZeo9Nm+H6SRQAqTiOLJgF5+Yb+fxOm9rLca+WYrunt7AZeOObfuLYW99m/f3CseKcaqABdVHiA2H9I7alsBl/vBmaaR1u3gXHYUTZTyZij5MkyGmE0BuCtMoy7jtx7YAm5S3X0cd1Chr9yzLZMPk3JKevE7K1D595YEFAID61k4j29fpqw8uRHNHNzZVNuLF0WdHWkfo6muwcbV5JmaUN6dTsLrmDtNJsBarXLAk9ql+ou6rzLZr9Z56aeuS6ftPLQMAnHL8O3H5p95bdFkbLtIKPbIn998xy9K2c6ck2N+S/DEokUs4E5OU8e2EHe5dbR9G23YypPvEw7b9t50tJ4ZhmoTSfU3qE2JYc0c3AGBtRX3o39hRgn1UNu22HNvan/NrSQnr6LZNzlBw8fnNacRnYqa37uTut9/sSFXb8xKmKpooqxLoa89y90/2JlNazSkEdgMEMIhJPoJOnKK+KVY4HTHjoLacAOaK+qBvG9h/AqH3xT5+ywaVm23l6sJJkf0pNKOw6Kw/ROFGGv3Y2KckhdEZU3zWKVnCvrt13ObC+AbIvycqTpLd2Nv0sf/8yQ5hxliOHNKeHE66dRjEpEh03U5uG+0nOj7/9pPALCeFXBoIuHIi4kXncelwNpHFWK/kEu3bqY+T/YBgmgMvggp+TmrEeVmZ1+cyyy/0RA8LKk0Cb9rz5GTbRdKxGsjDICZZLW4npmvGaFoI56b2W/TsWEfgNhw83VCZL0nv1JO+fzroysLAstL8ogbWHT10ZzNPaEm2pNcp0d3rP38w2fYqu/OqyGA8k9F4O3nedpNd/yJjthApwSAmWS32W6Al9x4y1uZiAMsVcspHwjoMFTFD9mSSCxeN4h6a2oNdmrfnJ/wjXKJL0zlwhJeaplp/3XDyDh8X02w513PUK/251URXW2hD1VR1TmTBrsWSpv4wV5j9tqHeknkMYpKntDaeQUzmC69y2se2Z1dxtpedRAdchcurKB6OAfsU5nVQWfFYUSlFL/axJjztFifHQaK3k8degHQI1697F5bqIkzC7eSubSOIkxdgDLCgqMgRDGKS1dLe5usYsCt9o7C6VXtvz5Lez5JkBLIlv4hsEfw8Ot0vgHHrIE15lx1abrG6VsakVtT6kPRaZNtF2lDPxEx4oeS3Y+rWnQRs56kP64EssYOY1dXVWL16Nbq6umSkhxzR3tVjdPsunygJPSOn4O+e3gw6u3ulpidJZAQYdAw0VG3C5eOipzdjvF3RraO7B70e95X29vZ918/lcpUl8nFZOKvV0Pgx8qxtuclI3TEWFmdGkuvaOnlsq9afx5lMBu1dwWPxVoEyyQsIBrRHxcYEvRl95wnsT0g2kbGei22eK+9ucEHoIGZdXR2uv/56/OAHP8Df//53AMBtt92Gq6++GgsWLMCNN96I3bt3K0so6RV0fFw9cUXgOlSeeBu86czolr98/3zsqGvxXUZkwNTviEH2hEjipsSVht2WZNpy4l7V0IZL/jwfZ9z+Flo7u00nR5vyA224/PElAz7v7OnFv98xPXuCIFJKrhwDror+CImIs6skl+c9b22Ru8ICfCZmOL1p2lkJ+nMrDbdkBr9bzHuJrzywQH5ikkDioXb6rdNQuq8RVz69HE8t3Bm4/P+9tDbSdqK+oR4A1lU0YMbmmkjbFXXWmJl4ZWVFrHUkvSUUbbs4YzOcm19dj9NvnYZ1FfWmk0KGhA5iPvXUU7j11lsxYcIEAMCjjz6K2bNnY/Lkybjuuutw7733YsaMGcoSSu5JYjNsum8p3dckfZ2X/fuI0MuKnj+I5lfsl25ousIVeJJhuqIICpNalbv0ziOHYEt1E7p6Mli9p1779k1atuuA5+dtXT3YouB4t4ELLwDyE7Uahpm1QwbpfiZm3qwrCsu1vpXc5VfVHp+3A/O21upNjMWiBmr7+R3TKbheQTE8t3QPAOD+mWWGU0KmDAm74Omnn453vetdAICvf/3r+PznP4+bb74ZgwYdjoMec8wx8lNI5IF9mzxHHTHYdBKcFX12lR0nYpYkI4+NaTJFZVaoOEFIwvN1A2fAsIIqYzJn0/rWebIPmxhvXm1vuIvO7mVoUIp5DpRcaZhtLpdbx7dbqbVbpGdiNjY2YuXKlfjgBz+Y93lzc7OURBHZSkbjIzRAVfjQ7H5J6i+lPBMzxDqCsiz4djAivVw8kbNR5JdLxPilSxLUnSjF28nlSGM2pnGfBwgxcI39eCKTj49ysJBtee6z61wse5lE99617HItvTYTeibmqlWr0NDQgB//+Me4/vrr8eyzz+LAgb5b4TZs2ICNGzcqSyjpJaMR5ckMuRg4kXE7uSnCt/v3/9eB2Qymt09JUViPIh40KRM2l/hMzHDStK8ypWOWEitHoEMHUJjqIP1YU/W285SWu1/5mHsJn9wNs61Xy9bsVXtnkq17rVfo28mvvPJKPPXUU5gwYQIuueQSXHHFFaiursa3vvUtbN68GaeffjqeffZZlWklx6i9FdLMQFZ3Z8SGSgwHC0Rko+gvBJKbDvKmPZ813GWRJP2BhcIAQypimgXSWl+8drtYXriWTWktV1Vy2waXzqXScaEm+fyD8+7URduFDmIOGjQIP/zhD/M+e8973oPp06dLTxRREFONgK7blf1+SXbxK5HA6mlJUdrSmeYeE37HhyVJjYiD0riilr/oS4SivhlYFVuqvS3pUEV3ufJ28vRI+u2RRggEeiKPuDWXQ37QLWhZ+8YUtp3bRB4zGM5bW8blpgi/EDbl+ZVmkZ6JSckno0mwoYu1sW2zMU1hiZap6L5aUWe0bMO9SuByvTVPX+axmPLJPtZ4HKiTppOR9OypWkmsMgncJRKUphfM+e1KmFiiinhjkvKW7MPaJQ+DmOQk01fKdElbXxp3d2Xkl5w8d6Pgss/EdCS9JE86WlB7uDIbyE/Y+hKnXlmyq1rkniiz/Q3PxbGf7BSntbZEvSjuSlDKkWQ6w8GmIg+rQzjMp/RiEJO0W1tebzoJkakaZLy4vNzYtpPkodllsdcR5oSyrKYZs0qro2/DobJ8dXUFZmyKvq+h5ORHa2dP0CIOijmaFqgwflt6Yt6OeGnwEec4ECKpAsQ99qL+/uGIbZNrAa79LZ2mkxCJ7ja5161itYaLz8RkUZvxt+XlmLe1NvLvVZbbo3O3B2yv+NZtDOYn5e3ksvNWVR/u0nmEmMTuGACbJtu4j0FMslrcvkR2P6+q3bjxlXXYsq9p4PY0NFQqh0K629lpG/dp29bVE1dEfquiqnyRfbt/ZX0bbnhhLX741xXaynLc21s0bSmZ/MqpxSc4HNfVE1cI/0br+Zfkiht1dc8t3SM1HSSX/vf68CxEROTnTzsoifskW5gupKO7F99/apn0I03G+qobO4pvQ1MdsKGuJf3t5CQmTPbnHv8srvRiEJM82dIomJo1o5Jfkmqa2rWmg7zZWGfCkn3L6gFNs6pyN7+1ulnLNp1SEPX71idHGUoI8C//PMzYtmUorOqiAVXdJzgut0ei0rSvudK63+QtKMCd1iCLV75YOCExsrSWa1rIrqpJqvuiMj7/dgEvYMrDICaRAJWDDI5fSDvWOU3kXo0ZNMjc6PWIwf7DBhtvcZONh4w6HNwTkQiV42a/8b6OXk5XSyizyzbReid/xEFBGPxPLwYxSRkZnWMSz4lFGlzbrjaJBinS2rkE7bWqbFH6aACFZRkm3WmtS16S2C4GiRrgGjDzMmj5gHrGaphMbF+Ikkn2oa2jpUjX7eTqE2FyP/u3Lf2xBhaUnQphdsvpIXBCy80EBjHJmyUPnvVbR9gGzMa2wsY02cK1jil6YMWOWmBPOuQsQ+GlYdakF9Yji5k80Uz8BskVpp6pbTvdQZu05rNuzGdKIpVDbB4zfYaY2GhXVxcmTZqEoUOHorW1FaWlpTj//PPxla98BQAwefJkrF69GiNGjEBZWRkuueQSnH/++dnfb9myBRMmTMCHP/xh1NXV4bjjjsM111yT/b6xsRFjx47Fe9/7XnR3d6OmpgY333wzhg4dCqDvqs/48eMxePBgDBs2DKWlpbjhhhswcuRIvRlBFEDHFUqbYhk2NMwy8jypV0iJiM/EJNItTcdBinZVC1su1gbJreMuPhfVxjTZhM/ElMeFmsbDQT0jQcyxY8fiwgsvxHnnnQcA6O7uxic/+UmcffbZqKqqwgsvvIBnnnkGJSUl6OnpwSWXXIIJEyZg5MiR6OjowOjRo/HGG29g2LC+FwzceOONeP3113HZZZcBAH7yk5/gxhtvxBlnnAEAmDp1Km666SaMHz8eAPD444/jqKOOwrXXXgsAqKqqwhVXXIGZM2emdnaKCjZkpewk2HBLgivrdVWa8kNkX1OULdJJv53N0sJQ+zgDOb+Le6KlfzaQHYVtQ3+ulB3ZTBTI1vaf5ElTGfu+nTxEo5zmc/Y01ZFiXMsHx5JrNSO3ky9fvhzbtm3L/j1kyBC8733vw/bt2/HQQw/hqquuyjZMgwcPxuWXX46nnnoKAPDaa6/hvPPOywYwAeDHP/4x7rvvPgDA3r17UVFRkQ1gAsCXvvQlTJ8+Hc3NzchkMnjsscdw5ZVXZr8/6aSTMGrUKMyfP1/lblMEKe6fEsG1zkUX5ks+XsFPhiSUYhL2QQUdh6jJvLclWExEkkm6AKZTmoZEaWl707GX8YWp+7mhAdfqT5qObdWMBDFvuumm7CxMoG8m5rZt2/D+978fs2bNwjnnnJO3/AUXXICZM2cCAGbNmoVzzz037/tTTz0VO3fuRHd3N+bNm4ezzjor7/uSkhJ8/OMfx/Lly7Fv3z4ceeSReUHQwm2QPY1C3INd+oOUJazR/6pjuM9kEwkUpyGmLJTnEa8gqypX4Rcv9f/XhV7VgSSaIPNF5X71QGf9yGQyVtdH3SmzOCukS9W+5v47RftNwWxu/2yRwaG+wnRCJMrdGxf3zL0U68F8IVLDyO3kZ599dvbfmUwGv/jFL3DllVfi+OOPR3NzM4466qi85U844QRUVVUBACorK3HCCScMWOfxxx+Pmpoa3+/71zF8+HDf75csWeKb5o6ODnR0dGT/bmxsDN5RIolcHNRQcqg8r+I5W3EtnT15f+fGqgsD11FPgDdWNuC7Ty7Fzz//YXzv0+/Lfr6/uQOX3H/4LoVi7ZCMeOqpN02VsBZ1WFeJyCw2QvfP3Ib7Z24LXhDxcuvmV9fH+LWYvGdipqmIfV/gmqxpE3wmJsnCC119jL6dvKWlBVdeeSVOOeUU3HjjjQC8C6akpAS9vb2+3+cuE/d7P3fffTeOPfbY7P9GjRpVdN9IDr9G2lTjLafdCL8StlP6ycjzwHVYUrD97aEdqSnOhTT6iZv2sprm/PVJyIzCJvQXL63DwdYu3PLahrzPJyzYierGDpgWdZdlX/zRfTHJkqYi8SdMtuQz+WEBpZ3+YzSD55bu8UgH66KXyM+t9v08Xj7n9lkullhQPUtqNRQt96TmAwUzFsSsr6/HD37wA1x77bW4/vrrs7NJjjnmGLS3t+ctW11djREjRgAATj75ZNTU1AxYX11dHU488UTf7/vXEfS9n5tuugkNDQ3Z/5WXlwvtr2tsbxRMpU/tbDTLMx3Qcj/5YJn3x0agI0jhQElbJ+ExlMhk5YvvreQDtpeskhDdm7S+2EeHVO1renY19VjWZrmS/66k0ybF+m/ZQVXSI+nHQZrGOaoZCWL29PTgrrvuwoMPPohPf/rTAPqei7lmzRp89rOfxcKFC/OWnzt3Li666CIAwEUXXTTg+x07duDUU0/FkCFDcMEFFwy4LTyTyWD16tU488wzcdJJJ6GjowPNzfkzW3K34WXo0KEYPnx43v+IopD1ll0yz/UiEbzeqSgV7udjkiUrZBmirrEyetLyYp+UvkiDJzWUK6guciyYfIF1QE8ytGB9jibpd0ckFeu7PEaCmM899xx+/vOf45//+Z8B9AUZ//jHP+KYY47BtddeiwkTJmRnhXR3d+P555/H1VdfDQD42te+hvnz5+cFIR9++GFcf/31AIARI0Zg5MiRWLt2bfb7KVOm4OKLL8bRRx+NkpISjB49GhMnTsx+X1lZiT179uD8889XvOckS3oab/WtnejLYES42FhLuZ08/iqs42JZknxFn4mpsF2OOlNddr3lYZBMLFdSRbRdZFDbW9R8ifw7FoMgyY9uCbG6YsdW1PGI7GGMqrvsklo/k7pfJJ+RF/uMHz8ef/zjH7N/Hzx4EEcddRR+85vfAAC+/e1v47bbbsPIkSOxbds23HLLLRg5ciSAvhmRjz76KG677TZ86EMfQl1dHT74wQ/isssuy67v4YcfxpgxYzB//nx0d3ejrq4OY8aMyX5/zTXXYNy4cbjnnntw9NFHY8uWLXjmmWeUBnMoGdi2Jp9IGbs+q7Y/HX7p0dUksuWNTnUZqVi/y32t7sd+2NJWOFxklAC2HAdRuJx20ieT9+/0VBrb9tV0akxv3zW2tq9+YyYZybV0l7UzEsRcs2ZN0e8vvfRSXHrppb7fn3baaRg3bpzv98OHD8fYsWN9vy8pKcEvfvGLwHSmGQ8QbzJOYCO/oIKF4ozgB3K7UZi6khlqMw4HUWws7uizFAb+MJPJOB2YJDtYeJgok3vibmP7QOak6VZiHVx5NmLuuJBtAi+ckdv8jmFXzv9cYPTt5ERUnOttnW1XWEMRyHQn9y+HSPrd3lOKypYX+UR/O7lc+l/sQzrwxMJVySs3VkW76SgeF6uA7DuTEncchBxK2THiIrIfg5ikTOI6ILg5sJDJloCGLWy7wh+1dPyCmblXwlUez6HWnfaDz4fuY9KrrvSXnwszJ+LWY9cvXNjMZCCRpUquSOLYOoy07nfSJb1Ys/U25I4mPT+ChBlj8c4fAhjEpISzcdAjkqa0PiPHJKFnYkbdhi1F6ZGO11bv9QwmvLC8XEOCyDZhxope1XlWabX0tKhg+1g4TTME07Onfe3pwZZO08lIAMsPYDJO9jhNVY3LG++nqN2PI+xFXJfyc8q6KpQfaDWdDKu5VJ6FpDwT093dl4pBTPIko4FQe3JoaOAq483VPnkbtGoXGy2m2T3Xv7AGb23cN+DzV1ZVGEhNDofPVeVfgLCrku6saxnw2dUTV6DioPmBeGF7G/i82oC85e3kJMN9M7bh6r8sB8AyDiNNeZSmfaUcGc9/OiN6sDjaOVGSnf/H2aaTYMzeg21Cy3OCT3oxiEnKJDEYZHtj+el/eZfpJAAA3nFEOpoW38GX3dUkyy+ZaysaNKfDkQwjz5kPVQ3eg859De3StmvLMWVLOkguE+W6ek+9/o0mTvIOyLgXWpJKdpBMdzqksiIRdssdq1iRXQ5fiNepSuK40UpWVMZkSEekgVLL9lsFg4iOvYYOGawmIYKGv+MI00mITMfLbmzrwxiYSZ+oz9L0Oj4GOdTQuvYsJR6bujCjiegw3cHi3O2lqd3329W4PbV1wX7B5FiWem3CXHRwYRznQBKdxyAmeUpK42njQMD55ygKiJJk0886Edp85LcxKtpHdpopoa+gXa9ShUda3GNPf+tkR8Ov5QVSduyqdqb7PLe53kINxNogl5uHl3uJjpzPcXY17OHvXnamVlKKyu94sC647jAGMYkE6H8eWsbz36bwylI4xspK9Eqv+SoFIFw6XK56SvNZdcaEOOhLsv8Nl5goSdZ1TAWVVVoDTjry32Qfl9JiTYAEFlxgG6QnGbZJU9ubol31FTcLtFx4I+lE6346j5VU7vQADGKSMkk8xEzuU1oaatO3CYhNxExJoVggjTntf9JmWW44dK4QN+csy3mShOVqt/6mkOVEumiftOD4i32iSs042qFxEsXHST/qMYhJykh5w7lPq+9y4xA1LqGqm1eZl1HqgEtX231vFzA1k0KwLPsHj6Zz3OXj2Tay65bzReP4i+FtaQ45q4WISJ3cpt6Wdl8HHfuamkApWSPq+SGFxyAmebLlILOt45GRL0IvjhHcXpRgkC1lbQuR/GDeycF8jM6G0FKaAly29UlJktZ2IKW7HYmLLY3ohdmgNiat9cWW58mntZ3y03/eYXPfaLLMWF/EJD27WB/kYRCTyGL5V2bdafliPafb+O3k7uRzXA5VKSdPXvtZmc0hMzTM4di/jNJDV9m7sPITbWVZpQRPNIlYF2WLOqYz2x4FBbKTU0ni5HPo9/okJ7sSz6VzXTKLQUwiRzh5O3mU3zjUgfk+GSDw0QB27aNfeivr2/UmpIjttS2mk5Aaq/ccxEXj5mDOlppQy1/++BIs33VAcarsoP/lbqSDbW0yefMqpQdmbsNXHpiPpvYu7ekxwaUxkg1cyS5Xn4np8gVmcp+tx8ofppUqW7crbZpqDGKSJxkDehkHWdzbFGWfmNj+9lTVDVvY0nB6UCN0O7l7V/hzBSXjrimbtKSD7PK9CcuwvbYF//308tC/+eZji0Mvq3OytWibHZQ03YeuLW2FDina1TxpKuOoih3H46ZvxYa9jfjr4t0aU6QOq4M3/ReQ9G7QxPmFzIB41FX5TwYwcySwPSaVWL3kYRCTrGbb7AgpnVvkddiVF8W4k9KBxN5OHn8dNmvv6jWdBAqgIiDY3NEt/BvVA39pqzf0AjWyG09c3VCsuevsZn9FA7l4aLM9kiuJ2ZnEfQKSX/c5k14eBjFJGZUByPAzAt2ZE+iVX7mNXZh2T/UMJ75FWg51LycXKyC/zlT7jAd26tZi0eTjsUFkp6QcKTzkSdcEDhnPoI+7jqT3cbZNxiFKCgYxyWp+QRlTXYLRiZgWEB1ruDg2ERlQRb59RlG+RB8sef9uEIPWUtg4SE9L0Up/M632WwzTw8bjRIuU7nYUzKoUizzecuOxP3nb07RtG9rceC8CDbkNC/ZTtqSO4Rj0pbAYxCRvlrQhcRsz6Y2hhI5Q9nNj4nJptqp9/GYyWnIABfBL5uG3TbNuUHisLQmmoXBNtpputNjpFapLdaTfDcKTeLlczE0n0+xioi3G/AzJsXxK+2QomRjEJGVUNsBJPFkOfKO1Ba1WGmJaIvlsQ5nkkhWQ5huYyTaq6mRhm2ZbO2xNG2NLOhRx5cJT2qVgCBKIVTWZ8iZipqiM4+xr2DFvErMzifsEAL1J3bFD0nRsq8YgJiljw9vJZTM6U8TJls+9NOu4SmbbTAsnqxYBsK+NtE1h3WZVJyKbsT/2FnXc5Ex+aniUkQrxRyBqdib3AqXJ/LKprFwQ6v0P6pNBDmAQkzwlpc1NUufh0q4kKd+LifwESk2zykyvh8Jx6QKFQ0lVQvfu23bBQ6W01q00lXFcxXKKuUg6sJ55k92OxV1b0vuTpA7Tw5x/JLxoKSQGMYk0E+noczthGzpkHbO+TO+mlNvJDe2ErBcv9X/OYKYcQeVS7PaZnXUtwuszJmSFiVKvZJ0gxQ4Yp/VZC1raAlt2lly0rqLBdBKkcO1ODl2iN73RfjirtCbqBmNLYhmL9r3Ldh6QuXWJ67JD8vaoj/B5TMicWLCtzpIJAzakIRkYxCRlkniY6j9/dTsXregvFHK9fIIwiKlHb5ED5cI/zSn628IyCltmod/qGW4xITrbhWQfoSRL0vsq12UvrBVZZu7WWi1pEcWqJcefZ27Tur3x07dq3Z6rz8SMO07029dH5myPtW3bxq+iyalt7lCSDtuFOa+KUrTfnbAUs7eYuzDRT8ax7VL7oBKDmKSMHVc85JKxT9HfTp68/LSRjnxWdWyIDtr697UwOdm3k2u6YSWBTYUUNmaLSB2z7SQCAEpiJkr/7eSUdGz/wivMqkTmXcBOJXKfQ5i4aFek37mSX3l3XplLhjK+d/7oTYYzyg+0Fv3ewuGVFCqP1wXb9qtbOWnHICZ5sr3TNzmLyBjLn6OYFDJuJ3c94Kz7dnLX8ytI0P6Jtrcmj1kZx4fZ9Mera7b3jS5j3lISiTZ3PAzkcjE/XZwEYnOSjb7Yp+C/oX9ncX6axqwhgEFMIiEyGs7IL4ORsG3dXEyzCNf3L2iQxEGUHGnJR5Wxycgz2AV/aFtAPS11xzTbyp3CceEiLGuWWS62oQ4mOTIXy8cGzDY3yYkjsPQBBjFJIR5iYrw6ctEX+zgwnk8UvwBJUoKD2mZiOpIfqogOSHLzS3kRxSgcGwMMhXsjPEtKc2VN02DV5J6mvQ1yhYVNinasq2ap6gNMzL6UscWwjx3y25aWRzgp30Iwtl3yMC8JYBCTVLKh15A8KND+Yp+8Z+QEb1x18sIHJWwofHvZkjuHb3PxThEHCnKk9aQzifudwF2yRhLrSxgp3W0h2ec3F36ewMxL4j6Z5OSFoKAL4XpSYb2wY1Shx+A4krtJHZ+rDObbcGGd7bs8DGKSJ1cacd2kTANPUQvm4q6mqXyCxH0JSlhpz3ETVU7XS5tkSXsdIbXY7JMtOAZJp0zev/XUAbdGAekS+Cx1TenQTbT5Y3OZXgxiEjnCrdvJ7UmJCUFFparTlX1rbLpLUR6VYyxdgeYobEia7Ifpm5yNb5Qt6VAk4buXWDa0MbqxroqR3Yaq6nNNtPVSNhn2RasRH78kg0hQWPYF3sgXJVJ6oCd9t2VcoLBmXGgYg5ikjMoria7NIpJBVW6qaQzdbWFFUh59bKLomUpRf+f3w/QdZkqkdWaN79vJHa5Y6SxJUimt7UMU7rYcZIrsw0vH8ZqmJsG2XeWdiG5haaUXg5jkSUYHKmMdcS94ym7cZAxehIJkkretm4uDAZFsvv6FNbHXYZJv7FLzmaIr+aXSs0t2D/jsu08uVbrNaRv24TtPLEF1Y7uU9dk4K+p/nlmZ97drdc2x5MZisr/4xUtrjW2bwkvFMzFNJ4CMc6le93f7NqfZ5rT5CUqyhcMtKVwsKxE/fX616SQkxhDTCSAqJpGNmc8+eX2cG7hMYlZ4MV3mLgZe+8ka1Ogvg8MbvPhf36N748ZlMsBvX9sw4PPWzh6l2x39bF+A7/bXN/ous7c+eoBTZlDTlos42t9Obsl+65CiXSVBaaobwY+0SFFm5HjHEYPQ3tUr/DvZYzoduZ/EEvbbpzj1WcWt/a7cKZLEOgKIH69ulJZcKe0CBuBMTCJXWNBo2TjTykW2dEBB6TBR3KefeIyBraql9JmYEtZxoKXT97uuHvGTRiIiIpmOOmKw6SQo5fqdVzYTuwPOjqA3q0A4ItnEU9hkYRCTlEli+5vETkXlzMMo+ZWEQKlrbxUsTA9vJ5csaGaNYI2Q/aiOpGc/kc14/JGItNaXpAeDRAKXNu1T/1jC5ruYGBR2B4uKwmIQkzzJaEOseCZmghpDmwcIMpkuM9Pb18vc2yLJDSJtsMrYt6o6KXo7mva3k+vdnC8d/Y8t+0pkEo8Db9aMS7S8TTt5/MrPmnJ1TALme1BEaYkHBGEQk6zm+3ZbQ623jIZDZB35t5fE3rQ2LqW1kJYAviMZpOJ5Q14cyQ5ljO9/ke0bT5tm1u2udQlSh7NliHgc+LElX7Rc0LFjV7WIk59pDuQltYqE2q80FzxlMYhJyth2m7Lt2/UcoGVyv1e3bVXSejt5EFVFKZp3/eVTWE7abydP7HCsj+z9S8Mxokrcskh6XSX9XOzbKTzp5cv6IkR2/us5Xt0rZLZjxQnf9eFgHdAm79yY+ZRWDGKSJ1sahfi3k9uxH7miJknVntiWRabTY3r7Njgc3GRmyBD4ttk4K5cQ0NQ9WHY5CKv/dnIeg0R0WFrbhMjPxHQkv1wdboV9m7eScnBgLMHxtCDmUyBmUR8GMUkZGQeZfbeTS1hH1CCmFa2WAyOG2GQ8MsANtqTTiqrtEBueN+y9TvvbB9Y1IrIZ2ygfluSLqvLJDfKlqQ7E2teQv01ifto/2opGZVE5MEQlAQxiEjlic1VT4DK2BBH2t3Siqb3LdDIi0THYsWlA1dHdgw17G0wnI9GCH5FqUYUIUNXQbjoJallWFrYkJ23tok6uzBQjO6T3OIn4Owfzy8EkR+Zi+ZA6oeqDHae6ZBiDmKSMjH7JkphcltJnYnp+dvjTe2dsDV6H4tGASHlc+Kc56T05CygHW/IlkwF++JcV2FIdHCCn6FQeljKaSJH0NXd0S9iiObEfUSInGeG3Z0dTYUmLRWlly3Fgg7RmhS0X+/hin3z9faqR91kW6c9zJ3UIvVBVUd4LPxNT5WOIXJfqnad+DGKSJ5c60GLkP09db8bYVg4i6alr7lSXEJJm/rY63++0vZ1cy1bsZXr/TW8/DFltYdz12NYmJ4ktF3eITOJx4C36MzGTR1YdsaE/U/e8f1tuz4+2cQuKxgjRup3WfCIGMUklG3pHC6l93odlU1cdlKbbJnmypIfL+exuypOB+U+ULoEzsNgoCJE9g1PZMzFz37icopY/TvmoOONRdRolux4m9WxP5e3kPEdOFgYxiSg00fbfxcG2jMFj4G01sbegh67bt/I2k8JBhunjxJbb9HSIu6f6Z+PbUTaWJCOZmLckIE0BLhlcya3cdOpqb2UOt2zpq/rl3U4ukDRbdsO2/CSyDYOYpIzSGYdh0yA5EXLeuM6OiexgS1XMOymzJVEJV4Lc50XJWqf7jDzXiwAwb4nCSOtxktb9VklGnsbt99NSrJwFGE5a6kMcbAv7MIhJpJlI26OjnWJQNZ+cQLX6bXgpkRxG4qBLjsDytvgQtKUGpHX2kS17zZdZkEl+9S+JdSaBuyRF1DZI+mQGuas7vN6828mTx7ccLNtZDnvNEj1ek9gHUDgMYhJZwqshtq1xTkPfblmWKxVUv9JQ3jrY/hzcYvVA8wtFiVInTX0OBbNt3Ef59Dw3nZVAJqHJIxbewUdEAzGIScokseFO+8Ai3XsvjyuzyrSlMu3PxHSkPlB6+4CU7jZZLoXdBXsL49SUgKvjgP4LqdHfHh/jxT4JbgDcrA2kg6tthWwMYpKnpDz70XwKyDVJqfth2NIR5qXCkbwT4vA+iZwiqDyfkJaFBeux/WVlDlcdYSnaVUoR0Xod2C+nqVHIEX23HXw7eQKrgMlHQrgyJie15yXJDXmn0xDTCaDkun3yJtNJsJJIX/qbV9erS8ghIukR7QBcHDe8sqpC/UYcyRddHX7uAPP+WWUY9a534r8+OUrT1tULKu6fPr9aaH2b9zVm/y0jcLimvN73O0eqaiQTFuzE0wt3Cf1m3PStahJDqTzRLKtpxm/+rr6fT6oUVpnUijzTj3VEKRcCQyJV4Lmle5SlQ8TPBMeFicHjlULiTExykqlbCDgYojBMvcfF9lllYf3y5XWmk6DVgrI6oeXXVTRk/x21DBN8F1Zov3tj4IU2+44J6xJEEn33yaVYtuuA6WRYz77jMjzZF38dzgojXMwvW+6SEWHbMer6EKepo9t0EpxgWbXTwrZjzRQGMSnRZM/skLM2tj6khqsdW5Kfa6Qas06MayeHthzTOpJhya5qta+x3XQSnOZC+ye7XtvSJqSVlrYwgWXst09xdrXY8Z/x/UOvBBalUswvCotBTPLk2oke2Yn1yFsab5tMMxZ3gQiRB2ahYazERFbg+EGM/LdNq8//NBVxmvaVgrF9o7AYxCQSIOelL/HXIZNlyUkEU2XswqyUNHJ5UOZy2pOAuU/kL43NUwp3uU/Cd5x9rbhiQ97c75I4oSKp430eBhQWg5hE1rC/5bY/hW6wpZMOSkdSB0mkRonzT6Gyjy1thRZp2lciHwxmeYsaiHIxP3WlWEpwL9vtF1+X37dx0uBeycrjYLUOReluJWSImtCiF8YgJnlKauMYVxKv5qmU1nqUlN1Oa/nJxmyMT9eJqIsnvEnB/pX8pKlmBL7YJ02ZIYH0Z5JKXl92vZncf6enkJO+q/37x0kB4QjXh6RXIPLFICaRACm3k8dfBTnOljrAoAGpZOPY0sY0FWPLMWpHKoiIxLjW5ocha5dk3D1hMjYXdts21AEb0pAUvOuHAAYxiaxhqoNjx6of85xcYcub49N6yNjSVtiSDqK0S+uhaEsbpCodGZ9/qyTzIlnwDGLvBZTNbNWwDZMsGZqRAWmaqV0Mg5hEmlXWt5lOgjZpbWZd6WAcSabzVB7zUcexLR3dUtMBQOmUDNZVIkqDoKbOlfGFLWTPZleV+1UNh8cJaTpPiCPsRVaTh0x1YzsaWrvQ2il3zJXUZiDM8WrLHSpk1hDTCSA7JaV5kN3Iy1jd76dslrAWcpmqDlj2lVldV3qTfkH5ifk7la07ak1atadeZjISw7a+z7b0qJTUkzKKLxu4S0Ed4XHgLWq2NLZ1yU2HogKatKw8++/7ZmxTsg0VYt+toSg/X15ZoWS9or7/1DLTSXCKaHVgc5lenIlJJCLlo8uU737isDgpiIoTtqQHrWWyZdaVjnTYsadEZKOobdDGykap6bDlESu2CZxBHPF3Uc3bWqtozWRa1GdiJuVZmhwr9WEQkyjlVE7Lt+UE3DbMFpLFxSFZtOov56DhoUfkMBcbPMk4fhAj/Y4sFoBzknj7MWPpfZgN6cUgJnlKSiftyrNwKFlcOXyScpyTHQoHkzJrF6uqWTqyn2VMlMyAi0nMT7ux3ac4WH3Si0FMIkuwISYiolw8wSPK4eDxIHqxMPAtzy5mggTp3Gv7hZ0RqKIvCzsLL4n9aBL3CeDkijCYRX0YxCQSYHvDwWn1blDVSfOB2CSbLXXElnSklY6+L63BGQrGmnGY7eNQ2yQyvyzcqahJ4vOWKZdoWVl4KJAmDGKSk0w9C8T2k6woqVPZAdidW+rYXk8ouaS/dMCSqpzWgSrbEqIcDl6p5YtgzEpiC5qkfUrSvuiU1GYlrWM9EscgJnlKShvCxjAYs0g/W/I88LY1WxJKJEnQrA/b6rxt6VEpTftK6SF8O3nM75OK7cNhNuVF6FiayTTblGFUlMoLt0kN/KYVg5hEJIADgTA4XhLEgYW14gwoeRwkB4uSrJCGiujYhRbbMb/0iHpbeJzyYVAqeUp4QhACGzWAQUwiIRwMiblj8ibTSbCSPfXIPyGbqxqxraZZY1rIRiJ1VeUJRVpvq7anrSCyzwsryk0nQbu0toVRMb/8VTd2YMq6KgDAXxfvirSOg61dWLCtLnA51eXwysoKPD5vu8+2yRXPLNkttDyP7/RiEJM8JeXESfZuqMwWY3mucMNry+uVrZsGklmUX/rzfHkrI2ed+s/DTCcBgLy6nZCuTTu+fIFMyla/FEzS4XEgWQIzVGZ7/JPnV6G+tRO3/mNj5HV8d8LSyL+NtyeHG4T/e2ktxkwtxfZaXnwnSgMGMYmIJAt+ppUdo+qkXKwgdUYcd5T8lVpc8WxLmW3pUcriekGkC59VLRezK1h7V6+xbccLyA78bX1rV4z1kQty7/pJ4+3n7AP6MIhJTjL2dvIENhwJ3KXUsiU4KiqNgxBX2NLm2ZIO3XTMgCRyBg8HEpTENtTGPQq8eO+zgPziGbjCBFaBVMstT1fPeyg+BjHJSeyQyGauzKSwJBkchCRE6GB0hKtQuuoIw+lERMlhy3hLpiTtU7y+fWCP7ZU3SQxkkziO75KFQUzykYwGn/1WMJE8Yn7KoSobWT4kW6wbvSROvdBVt207hGxLj0pp2leKKAVnoUFBHQZkKElkV2ev1fGIoSRhfe7DICY5ydjt5Gw6KEFsORfi7eTJZEn1ymNLnQ/NkvTqyDfnyoY0yuT9J8lcuZPDFUnMLhv3KbDeCn4ehte5II+P5DMVAyC7MIhJJEJh5ygjQBqlXWdgVr7gmRSaEhIR6wRlqaisUW4nlz1bw/aDkIiIYutlW2812cXD8k6+vGdisrhTi0FM8pSURiFtwZh07a3L1JSU6FoZyHFfiYuXpKPcTp7S1i1N+832iIgoWJLaStl9nPczMaVuwgoOjvxIkiTW5ygYxCQnmbr9NIntBhtD+VzPU93HV1tXt9btJUlHVw96etVVOMersjDbTg5tSU6agqlkMQfP3Du6e4WWD3zLc/SkEHlq6+pRvg2/vlX+MzHTcYSkYy+9uXjtnuRjEJOcFLaTStstiGzX0020evo/o0hvPZ+6fp/W7SVJS2cPLh4/13QyAAwcWMpsLmU3vY1tDJyLsLzro4Qr3dfU9w8H6+E9b20RWp7PxJSL+RXswj/Nib2OqONG2edVjW1dA7chdQvkKgY/k4VBTKIEYUftBg6qKY5hRw7O+3tHXYuybdlSV2UnY962WslrVMOS7NciTftKYh6du910EqyRlplmhS4/c5TpJJBlvGJSXjem2D4BhcSwOAlgEJN82N4+GLudXOWLfQxlushm2XHIoSofRU9uWJ5u+uQp7zKdhFBknmyn9SQkTbudpn0l8uP6iwFVeccRg4MXSgkX64DvnT8O7osNOKmwTxrrT1rHw4UYxKRE44EejFmUXr4nS6wTdEisNlRi9WKVNIv5T1bgmTsJSuLbqq2cjRsxSbIf6Z3A4qYCvC2cAAYxyXLsjMhFQYEfawagliSDkoEDS/msaSuIbJCGwyHomZh6UpEYPI+wG/u4aJhr4kzdxUlqGA1i9vb2YtWqVbjrrrtMJoMSTP5b74jiUzaolvRiHyKVogwj09qW8wSciPKktFHgnVVu8yu+OMXaf+E0cOIAqw4lCKtznyGmNnzw4EE8++yzmDp1Kg4ePIibb7457/vJkydj9erVGDFiBMrKynDJJZfg/PPPz36/ZcsWTJgwAR/+8IdRV1eH4447Dtdcc032+8bGRowdOxbvfe970d3djZqaGtx8880YOnQogL4Gb/z48Rg8eDCGDRuG0tJS3HDDDRg5cqSeDLBcUhp82buh9JmY6lYdsN2EFDZJwxphN53lE2dbvs/AirKupHRKjtKR/SxhIh4HfqLmSxLHuEnqDmX37Uksby+cU0hpZyyIedxxx+G6667Dl770JXz3u9/N+27Dhg144YUX8Mwzz6CkpAQ9PT245JJLMGHCBIwcORIdHR0YPXo03njjDQwbNgwAcOONN+L111/HZZddBgD4yU9+ghtvvBFnnHEGAGDq1Km46aabMH78eADA448/jqOOOgrXXnstAKCqqgpXXHEFZs6ciRLeE2eNuJ1Rkjp6ZZhH0rnwkiaAxwepxfoVX5qykIFqCsThearahFxRmwc2K3owm8kE1rv0Mv5MzCFDBsZRH3roIVx11VXZYOLgwYNx+eWX46mnngIAvPbaazjvvPOyAUwA+PGPf4z77rsPALB3715UVFRkA5gA8KUvfQnTp09Hc3MzMpkMHnvsMVx55ZXZ70866SSMGjUK8+fPV7GbJJmpOLPKK3wyTuBUZ0tarnCqZksusjwpiEizpPJ5Q/Jn1TtS9y1JJ9sKskIKqqEzbRMZ42IN8etDZOxL7iHjdfgksf9K3h5RWOwi+hgPYnqZNWsWzjnnnLzPLrjgAsycOTP7/bnnnpv3/amnnoqdO3eiu7sb8+bNw1lnnZX3fUlJCT7+8Y9j+fLl2LdvH4488si8IGjhNgp1dHSgsbEx739JZluDn8lk8NSCneK/k7wfTy/cJXV9sqkutfnb6pSu/0BLp9L16xJUDqo6INGTH/9nFNl1/JM5EyK0u/1ktr+sksn36NztppNAZFxQW8e2UIzs7FI9Dg7DxjoQNU063h4fZxxjqzlbak0nwZiXV1ZE+h1vtE0WK4OYzc3NOOqoo/I+O+GEE1BVVQUAqKysxAknnDDgd8cffzxqamp8v+9fR9D3Xu6++24ce+yx2f+NGjUqyq5RRG9t3Ic739iU/Ttsn2djR++yqoZ200kgDXjcuEv2GG1vfVvk38qsR2kNrKdpr+uak3ERi+RL6eHvybZJBrpE3W/WHT0WlEUL7sZ6sc+hEY/XKnIDVtWNHdE3QkRWsjKI6XWyUlJSgt7eXt/vc5eJ+72Xm266CQ0NDdn/lZeXh9kViqm/qLbXtuR9zqsp3iK99Vd6KiiIqpMQ4WdiSloPkZdi9ejIwVYOP6xjywm4LekgonSK/kzM5DVeNgayd+9vKb6A350/8pMCAPjxBe9XtGaySRKP7yA2Hv8mGHuxTzHHHHMM2tvb8Y53vCP7WXV1NUaMGAEAOPnkk1FTUzPgd3V1dTjxxBNx8sknY926dQO+71+H3+9zt1Fo6NCh2TebkztcOsxltMN8668dArPUkixn2ZMpw48aIjTzTldN5SFBRCaZehwNURwmXrzUP6Eldyzb/68jeKGUKNGsPMI/+9nPYuHChXmfzZ07FxdddBEA4KKLLhrw/Y4dO3DqqadiyJAhuOCCC7BkyZK87zOZDFavXo0zzzwTJ510Ejo6OtDc3Oy7jbRLzCApMTtCJB+PDlJJZpBcx3OzbMQLDUTpEvhMTD3JsE7U/WYTqkfQ7DDdxcBiJ0o240HM7u5udHd353127bXXYsKECdnBe3d3N55//nlcffXVAICvfe1rmD9/fl4Q8uGHH8b1118PABgxYgRGjhyJtWvXZr+fMmUKLr74Yhx99NEoKSnB6NGjMXHixOz3lZWV2LNnD84//3xFe0omuNSJcXp4cpgqS+HBuu+LfWInhVKo8DEfrEZERERy2ThGizwTkyMFIorA2O3kvb29ePzxx/Hmm29i7dq1+PWvf42zzz4bX/3qV3HGGWfg29/+Nm677TaMHDkS27Ztwy233IKRI0cC6Lu1+9FHH8Vtt92GD33oQ6irq8MHP/hBXHbZZdn1P/zwwxgzZgzmz5+P7u5u1NXVYcyYMdnvr7nmGowbNw733HMPjj76aGzZsgXPPPMMSviwRavY2FEnDfNYP2Y5pYLMip7Sgyalu01EPtI6ZmOQzG6Rc1nyo7R49wL5SUyEh1UcgMEg5qBBgzB69GiMHj3a8/tLL70Ul156qe/vTzvtNIwbN873++HDh2Ps2LG+35eUlOAXv/hF+ASnTFL6AJf2Q0Za+WIfN6gaZIlPxGTpkzoy65fsmupK32BLOnliSCalqfoF35aboszIw7eT2yzwMQiaX+zDgidKNuO3kxOplLbBXrr21l6ujJ38B5WO7ABl2RhkKp4ksUsuFu5eqjD/yaQ03STlyosBXZHE7LKxvzeR0/3NgpXZQURKMYhJVktTv8ROmOISHdj6BjFZF53TX2YuFF1fWl1IqXnMJSIiM2+/pvB6eoMz2muMGicgm8n+d+A6QiSHUiYpVSIp+xGXsdvJiURE7eTSNnhJ0WQFq7kykcIvHRMX7dKZDJLg3+98GxkATe3dgcvq4tf+rt/bgH8++kixdWk6amybhWznjBsiM2w7Pk1gDpCN3cLsLbVFv2/u6MJ//nHRgM/j7EtVQzt++dJazCytyfv85lfX47mle6KvmBLpgVllppNAEjGISZ6SMlB0aS9kpDXKOmwcDCUd85xka7QoeNmveDUXu+Qie1ZFUvo4XZhbRHZI64UNvtjHba+trkTFwbYBn8ctnZdWVgz4jAHM9Ehpc0jg7eRE1jA1MOUATwFjZSm4PHt/UsjF+uVgkokSL03HpYvtpg6Rx6oJzE4Xd8mv/FjdicTwmOnDICZZLe5gLm0HeqS3k6csj2xgS5b3svCdZOtJbonCt2/Yus+q2bLbtqSD0ilNL/YJktZjMfpMTLIZJ1JQHOwb0otBTPKUlEGSS52jqdvJST9lARnB1fb0qkkGESC3PZJ9xPi+1ErydohInqSMTYtx5ZnaukXd7yReAEvSLsnelyTlDQVjeacXg5jkpNCNFhs3MsCVaseZmKSS1OqV0qrq0oU4IlXS1FWlaV8pGhf7hRJNrx51MW+IRLCO92EQk6yWqsPU0M4m8Sp1Wol2bAxiklqsX3HZcohy0ExkB1vaBN14O3ky8RyE4uDYJL0YxCQn8RkYZLOgMZktXS6DmOQK2QNV39vJeUgQWYvHZ3pP2qPudxLrTBL3iYhIBIOY5ITCDjtsB+5SPy9jYBrpxT6xt0rCLMl0PhOTVCrWToteiOrVVFdtCxDYlRoiUs22NsganImZSCwfIoqCQUxKtLTdppCuvbXXSyvLsa+hXft2Rat7b6+9NWbSsj14Zslu08kgAYVxydbOHt9la5s61CamiNbObry4otzzu7+v2qs5NcXZ0oXZkg6ipHtxeUXR73ksipm8ttJ0EgjAK6u86/XLK4vXd1E8PtJla3Wz6SRoxzreZ4jpBBAV5XOghp3F49KBbiqtLuWRK6obO/CVB+ZjxW8v9vzelpkWNt9OftPf15tOAsU0dlqptHXJrKl3Tt6EpTsPeH5XVpO+AXEY9rYUlAb/8u5hppOgTSdvkfDENugwF/OiyufCfrGLnUREfjgTk5xQGLS0OPZiVLTbyZmZKtQ1d/p+p6r+iq6XJe+mEkceCixztqXMWfXTNu6Tti7V2D4TAZf+28kAeDykWdrurKJoHBkeEVFMDGKSJ1vGCv0D1jS8lVBGWl3aXzLP5pmY5C+NJ3Pp2+M+KSxqogEYmDgsje0/kN4+wFNK60AYJZGmcxC5g0d/HwYxyWp+/XQSbycnikt0lorFj8QkBzHQQESkFrttYh3wx3EIUTowiElOSmJwUsY+RbqdPIF5aTtb8jytMzrIPTKrKs9xImBbQQax9h2W1kMxrftNREQDMYhJnmx57lCm4L/iv7djP3SJsrfpyiE7qKqXSXo7OVG+dNZVWy402JEKSjtLDgcygEV/GI8Df648M5woKlvGhaYxiElWS9Pt5KYCri7lEcnFoidXsJ0iSjEe/1lpuzjfjyfuFAZDmETpwCAmOYljGW8c5LnBlmLiRExyhcyq6tJMDVvaCiKyA9sEIn88PIjSgUFMslqarjhzYJoeqopadL0MepMr0lpVbdnttOY/2SFNY0HyxhpwGI8HovTi0d+HQUzyZMsJS9zbyScu2iUtLUk1adke00lIrMseXIDWzm7TyfDVa8uBTokwZ0utsnX/5PlVytZNRG5gjwU8tzSdY7Yp66pMJ4EcwIvzROnAICY5KYl9lIxdSmC2OG1dRQMmLSvXtj3hF/uwwlAKuXMzuT19HWf+kEm2HAdENuDxQERpxyAmWY39NLmus7t3wGe2DEBtSQcRERERBeMFaCJKOwYxyZM1/aNPlMWh9zKEJyGixKCUfbxv2bbjqZi8nZzIbpwBSXS4Z2OXRUTFsI2gxGMdB8AgJjmisFNKYifF28lJNz47iMhuthyitqSDiCjteHHLH/OGKB0YxCSrsSsi13kFCm0JCPCWJCIisp0tfSaRFXg8+GJbQZQODGKS1eK+ndwlMjpezqyzj1egUNnN5MIv9mF9IbIZj1AiIsrFfoEovTjbuA+DmOTJ9mCY5ckjyrK5rtqcNiJVnLoIZslBakcqKK0On7SxJhLZfo5mErOGKB0YxCSrpamjTtO+ponOK2aiW2KdI6Iw2FQQEdmB7bE/Zg1ROjCISVabvaUWDa1dAz53aiaNRhzY2Gfe1toBn80qrTGQkoFmWpIOIvLGJp2IiHK1dvWYToK1eHGeko5VvA+DmOTJluNj7tZa/NdjiwZ8nsQDWM7byROYMY5btade27ZEB28bKxsVpYTIZu5cBUtiX0ckiscB0WHPL91jOglEREYxiEnW21rdzOAcERERUYoxmElExbCJIEoHBjGJLCHn7eTx10HuYvETheHOkWLLBTxb0kHpxNpHRGHwdnJKOlbxPgxiEiUIGzYiouSwpk23JR1EREQ+etlXEaUCg5jkyZoTpxRhlhMRqcf+jcgxPGiJKIRethVEqcAgJlGC8Ja/dOPYLR1YzunBoiY6jMcDERXD8RElHat4HwYxiSwh4zku7LyJiIpzqZm0pU23JBmUUqx/RBQGn4lJlA4MYhIRJQSHbunAGddERERE+Tg6IkoHBjHJB7sBF7HUiIiKc2mmhi0Ba5fyjJKH1Y+Iwujlm32IUmGI6QQQhcEBbDjLdh4wnQQyaN7WWtNJIA3YHqYIy5oImUwGp/x6iulkEJHl2GVS0vGich/OxCSyBNskIiIionzr9zaaTgIROYATMYnSgUFM8sSAGhGRndg+p4ctRc06RyZ1dPeYTgIROYCz1IjSgUFMIkvY8uwzIiKyA0/IiIiIwulln0kJxxreh0FMIiIih/CCRzzMPXHMMyIish1jmETpwCAmkSXY8RIRUS72C0REROHwmZhE6cAgJnliH6Af85yIwmBgKx7mnzjmGZnE6kdEYfBOFUo6jsf6MIhJTkjD8cpGiYjCYFORHixrIiKicHguRZQODGISWYJXD4koFDYVsbj0shyHkkpERGSUS/07EUXHICZ5sq0P2FnXkvd3dWO7oZSos2Fvg+kkEJEDeMEjnsb2btNJCG1rdZPpJBAZt76C4yMiCvbCinLTSSBSjOcAAIOY5IjJayvz/u7o7jWUEnWmrt9nOglE5ADbLjKROgvK6kwnAQAD52TWngOtppNARA4oP9BmOglEpAGDmERERETki4FzIiIiIrIBg5hEREQOYTyJiIiIiIjSiEFM8sQHIxMR2YntMxERERFRuvAUoA+DmERERA7h+IWIiIiIiNKIQUwiIiKH8Cos6cbZv0RERERkAwYxyRNPV4iI7MT2mYiIiIgoXXgO0IdBTCIiIpdwVhwREREREaUQg5hEREQOYQiTiIiIiIjSiEFMIiIih3AiJun2l8W7TSeBiIiIKNV4DtCHQUzyxAOEiMhOGc7FJCIiIiKiFGIQk4iIyCG8yERERERERGnEICYREZFDGMQkIiIiIkoX3o3Vh0FM8sQDhIiIiIiIiIiIbMEgJhERkUN4iYmIiIiIiNKIQUwiIiKHZHg/ORERERERpRCDmERERERERERERJbiPIY+DGKSNx4gRERW4gCGiIiIiIjSiEFMIiIih2ypbjKdBCIiIiIiIu0YxCQiIiIiIiIiIrIUb8bqwyAmERERERERERERWY1BTPLEKD8REREREREREdmCQUwiIiIiIiIiIiJLZfh2TwAMYhIREREREREREZHlGMQkTwzyExERERERERGRLRjEJCIiIiIiIiIiIqsxiElERERERERERERWYxCTiIiIiIiIiIiIrMYgJnnKgA/FJCIiIiIiIiIiOzCISUREREREREREZCm+fLkPg5hERERERERERERkNQYxyROj/EREREREREREZAsGMYmIiIiIiIiIiCzF95b0YRCTiIiIiIiIiIiIrDbEdAJMymQyGD9+PAYPHoxhw4ahtLQUN9xwA0aOHGk6aURERERERERERHRIqoOYjz/+OI466ihce+21AICqqipcccUVmDlzJkpKSgynzixOVCYiIiIiIiIiMo/vLemT2tvJM5kMHnvsMVx55ZXZz0466SSMGjUK8+fPN5gyIiIiIiIiIiIiypXaIOa+fftw5JFHYtiwYXmfX3DBBZg5c6ahVNljf3OH6SQQEREREREREaVeHWM0AFIcxKysrMQJJ5ww4PMTTjgBVVVVAz7v6OhAY2Nj3v+S7E9vbTGdBCIiIiIiIiKi1Bs/favpJFghtUHMjM8DBUpKStDb2zvg87vvvhvHHnts9n+jRo1SnUSjPnXqu0wngYiIiIiIiIgo9T572sBJeGmU2hf7nHzyyaipqRnweXV1NUaMGDHg85tuugk///nPs383NjYmOpB53+Ufx32Xf9x0MoiIiIiIiIiIiNIbxDzppJPQ0dGB5uZmHH300dnP586dix/84AcDlh86dCiGDh2qM4lERERERERERESEFN9OXlJSgtGjR2PixInZzyorK7Fnzx6cf/755hJGREREREREREREeUoyfg+HTIFMJoNx48Yhk8ng6KOPxpYtW/CLX/wCI0eODPxtY2Mjjj32WDQ0NGD48OEaUktERERERERERJQcIvG11N5ODvTNxvzFL35hOhlERERERERERERURGpvJyciIiIiIiIiIiI3MIhJREREREREREREVmMQk4iIiIiIiIiIiKzGICYRERERERERERFZjUFMIiIiIiIiIiIishqDmERERERERERERGQ1BjGJiIiIiIiIiIjIagxiEhERERERERERkdUYxCQiIiIiIiIiIiKrMYhJREREREREREREVmMQk4iIiIiIiIiIiKzGICYRERERERERERFZjUFMIiIiIiIiIiIishqDmERERERERERERGS1IaYT4KpMJgMAaGxsNJwSIiIiIiIiIiIi9/TH1frjbMUwiBlRU1MTAGDUqFGGU0JEREREREREROSupqYmHHvssUWXKcmECXXSAL29vaisrMQxxxyDkpIS08mRrrGxEaNGjUJ5eTmGDx9uOjmUUqyHZAPWQ7IB6yGZxjpINmA9JBuwHpINklQPM5kMmpqacPLJJ2PQoOJPveRMzIgGDRqEkSNHmk6GcsOHD3f+gCD3sR6SDVgPyQash2Qa6yDZgPWQbMB6SDZISj0MmoHZjy/2ISIiIiIiIiIiIqsxiElERERERERERERWYxCTPA0dOhS33XYbhg4dajoplGKsh2QD1kOyAeshmcY6SDZgPSQbsB6SDdJaD/liHyIiIiIiIiIiIrIaZ2ISERERERERERGR1RjEJCIiIiIiIiIiIqsxiElERERElHC9vb1YtWoV7rrrLtNJoZRiHSQbsB6SDVgPo+MzMWmATCaD8ePHY/DgwRg2bBhKS0txww03YOTIkaaTRo7q6urCpEmTMHToULS2tqK0tBTnn38+vvKVr2DOnDn42c9+hiOPPDK7/LBhwzB79mwMGtR3nWXLli2YMGECPvzhD6Ourg7HHXccrrnmmuzyjY2NGDt2LN773veiu7sbNTU1uPnmm1P3kGPyd/fdd+OVV17J++y8887Dfffdl/178uTJWL16NUaMGIGysjJccsklOP/887Pfsx5SXHfccQfGjx+PU045BSUlJQCA5uZm3HHHHbjiiivYHpIyBw8exLPPPoupU6fi4MGDWLJkSd73qts/ji0pqA5OmTIFDQ0N6O7uRmVlJQYNGoRf/vKX2bby1FNPxfHHH5/3m7/+9a/413/9VwCsgxROsXqoow9mPSSgeD2cO3cuLr74Ynz4wx/G4MGDAfTVm7POOguPP/44ALaHyBAVePTRRzMPPfRQ9u/KysrMhRdemOnt7TWYKnLZnXfemZk/f372766urszHPvaxTF1dXWb27NmZ8vJy39+2t7dn/uM//iPT3Nyc/eyXv/xl5h//+Ef27+9+97uZdevWZf+eMmVK5oYbbpC8F+SyZ555puj369evz1xxxRXZdq67uzvz+c9/Pls3WQ9Jhuuvvz5z8ODBvM8eeOCBTHd3dyaTybA9JOW2bduWOeuss/I+09H+cWxJ/bzq4Lx58zK///3v8z676qqrMlOnTs3+HdSPsw6SCK96qKMPZj2kXF71cNy4cZm1a9fmffbyyy/n1c20t4e8nZzyZDIZPPbYY7jyyiuzn5100kkYNWoU5s+fbzBl5LLly5dj27Zt2b+HDBmC973vfdi+fXvgb1977TWcd955GDZsWPazH//4x9kZdHv37kVFRQXOOOOM7Pdf+tKXMH36dDQ3N8vbCUq0hx56CFdddVV2xsfg/7+9ewmJ6v3jOP4ZfhJKKpVmlhNphQvtJt00Ky0LatGFbohGVhKFixhMgqBtLsI2FoJaFpRBQVF0o0WmSbYwTLGisswKLE1rMAyDMzP/RXTwNFbKfybHfL9WM9/zzHAGPnzPwzPn8t9/yszMVEVFhSRyCN/IzMzUuHHjzPe1tbVasGCB+U/7n5BD/L+CgoK8av7uf8wt0d9AGayvr9eLFy8stdmzZ6u5uXlQ30kGMVQD5fBP6IXwtYFymJqaqjlz5pjvu7u75XQ6B32W5GjIIYuYsPjw4YPGjBljac6SlJaWpjt37gzTXmGkO3TokJYuXWq+NwxDLS0tmjFjhiTp8uXLOnnypEpKSpSbm6u6ujpzbFVVlVJTUy3fFxcXp9evX8swDN27d0+LFy+2bLfZbEpKSlJ9fb0ffxVGEpfLpeLiYlVWVqqoqEi5ublqb283t1dVVWnJkiWWz/Tve+QQvtA/I4ZhqLq6WsnJyZYx9EP8bf7uf8wt8Sfbtm3Tzp07LbXGxkYlJiaa7xsaGlRcXKzTp0/L4XCovLzc3EYG4Sv+PAaTQwzGzxkqKytTdna2pTba++HQ/4LAP629vV1RUVFe9aioKK971wCDlZKSYr72eDwqKChQTk6OIiIiNHHiRMXHx2vNmjWSpC9fvig9PV13795VeHj4LzMZERGhzs7O32b2/fv3/vtRGFHGjh2r9PR0TZs2TZLU1NSkXbt26fbt25K+35cwJCTE8pn+GSKH8LXS0lJt3rzZUqMfYjj4u/+Fh4czt8Rv2e12y1lGly5d0qdPn7R27VrLmP3790v6PpfcunWrEhISlJqaSgbhE/4+BpNDDFVTU5MiIiIUHBxsqY/2fsiZmLDw/OI5TzabTW63+y/vDf41vb29ysnJUWxsrA4ePChJSkxMNCcLkhQWFqZVq1bp6tWrkv6cSTKLwdiyZYu5gClJc+fOldPp1Lt37yQNnLP+GSKH8KXe3l7V1NSYN2D/gX6I4eDv/kcuMVgej0dFRUW6fv26Ll68aD5MRZLy8/PN1zabTbm5ueYtD8ggfMHfx2ByiKEqLCxUVlaWV32090MWMWExZcoUdXZ2etU7OjoUExMzDHuEf4XT6VRubq7y8vLkcDgsT+Z1uVyWsdHR0ealvr/KZFdXl6Kjo8ksBqWnp8er1j9nYWFh6uvrs2zvnyFyCF+6cOGC1yVpEv0Qw8Pf/Y9cYjDcbrcKCgoUERGhiooKy9nBhmHo69evlvGD6Y1kEEPh72MwOcRQvHr1SoZhKDQ01FKnH7KIiZ9MnjxZ375983oAQE1NjTIyMoZprzDSuVwuHTlyRCdOnDDv/2YYhhobG7Vjxw6VlpZaxre2tmr69OmSpIyMDN2/f99re1xcnIKCgpSWluZ16rvH49GjR4+0cOFCP/4qjCSxsbF6+vSppdbW1qbY2FhJ0sqVK71y1r/vkUP40rlz5zR//nyvOv0Qw8Hf/Y+5JQbj+PHjysrKsjxk6uHDh5KkkpISr3tm9u+NZBC+4O9jMDnEUFRWViopKcmrTj9kERM/sdls2rdvn86cOWPW2tvb9fbtWy1btmz4dgwjWmVlpfLz8xUZGSnpeyM9evSowsLClJycLKfTaY7t7u5WXV2d1q9fL0nauHGjamtrLY22pKREDodDkhQTEyO73a6mpiZz+40bN7R69Wqvf64wev2cs+rqaiUkJGjSpEmSpLy8PJ06dcq8xMIwDJ0/f167d++WRA7hW83NzZanlP9AP4S/GYYhwzAsNX/3P+aW6G+gDDY0NCgxMdHy505NTY2ePHkiSVq0aJHligq3263S0lLl5eVJIoMYuoFy6O9jMDnEzwbK4Q+/mivSDyWb51cXxWPU8ng8OnbsmDwej0JDQ/X8+XMVFBRYbrgNDMW8efMsDfrz588KCQnRy5cv5XK5VFpaquDgYPX29qqpqUkOh0OzZs0yxz979kzl5eWKj49XV1eXIiMjtXfvXnN7T0+PCgsLZbfbZRiGurq6dPjwYa+bIGP0+vjxo86ePasJEyaos7NTbW1tKiwstEwOrl27pvr6etntdrW0tGjdunVavny5uZ0cwldmzpyp+vp6jR8/3lKnH8Jf3G63ysrKdOvWLd28eVMHDhxQSkqKNmzYIMn//Y+5JX6XwT179ujBgwfm2L6+PrW2turNmzeaOnWqJOnKlSvq6OiQJD1+/FgrVqzQpk2bzM+QQQzG73L4N47B5BDSn4/JkrR9+3ZlZ2dbHnD2w2jvhyxiAgAAAAAAAAhoXE4OAAAAAAAAIKCxiAkAAAAAAAAgoLGICQAAAAAAACCgsYgJAAAAAAAAIKCxiAkAAAAAAAAgoLGICQAAAAAAACCgsYgJAAAAAAAAIKCxiAkAAAAAAAAgoLGICQAAAAAAACCgsYgJAAAAAAAAIKCxiAkAAAAAAAAgoP0PXSMZccqy04oAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fig, axe = plt.subplots(figsize=(16, 6), layout='constrained')\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "sns.lineplot(y=SNE_y, x=SNE_X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNE_X_train, SNE_X_test, SNE_y_train, SNE_y_test = train_test_split(SNE_X, SNE_y, test_size=0.2, random_state=10, shuffle=False)\n",
    "\n",
    "# print(SNE_X_train.shape, SNE_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#일변량 시계열 (발전량만을 활용한 시계열 데이터셋)\n",
    "\n",
    "def windowed_dataset(series, window_size, batch_size, shuffle) :\n",
    "  series = tf.expand_dims(series, axis=-1)\n",
    "  ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "  # window_size : 몇 개의 데이터로 다음 데이터를 예측할지 설정, stride : 윈도우 데이터셋을 몇 칸씩 이동할지 결정, drop_remainder : 뒤에 잔여 데이터 미처리 적용(데이터셋 사이즈가 달라지는 것을 방지)\n",
    "  ds = ds.window(window_size + 1, stride=1, shift=1, drop_remainder=True) # window_size + 1 : X(feature)와 y(target) 값을 포함하는 범위(즉 +1은 y(target) 포함을 의미)\n",
    "  # flat_map : map 함수와 동일하게 맵핑을 해주지만 flat한 결과값을 준다!(즉, 차원 -1)\n",
    "  ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "  if shuffle :\n",
    "    ds = ds.shuffle(1000)\n",
    "  ds = ds.map(lambda w : (w[:-1], w[-1])) # w[:-1] : 학습 데이터 , w[-1] : 예측 데이터\n",
    "  # batch : 배치를 구성해주는 함수 / prefetch : 미리 데이터를 fetch하는 개수 (병렬 처리하므로 학습 속도 개선 효과)\n",
    "  return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE=3\n",
    "BATCH_SIZE=32 # 한번에 여러 개의 데이터를 처리하는 병렬 처리 형태로 계산 효율을 높일 수 있다. 즉, 성능, 메모리 측면에서 유리 + 또한 가중치 업데이트 횟수를 제어할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = windowed_dataset(SNE_y_train, WINDOW_SIZE, BATCH_SIZE, True) # 기존 적용\n",
    "train_data = windowed_dataset(SNE_y_train, WINDOW_SIZE, BATCH_SIZE, True)\n",
    "test_data = windowed_dataset(SNE_y_test, WINDOW_SIZE, BATCH_SIZE, False)\n",
    "train_data_ns = windowed_dataset(SNE_y_train, WINDOW_SIZE, BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 1)\n",
      "(32, 1)\n"
     ]
    }
   ],
   "source": [
    "for data in train_data.take(1) :  # take : 1개의 배치만 가져오기\n",
    "  print(f'{data[0].shape}')\n",
    "  print(f'{data[1].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model = Sequential([\n",
    "#   Conv1D(filters=32, kernel_size=30,\n",
    "#          padding='causal', # 시계열 데이터와 같은 순차 데이터를 다룰 때 유용한 방법으로 입력 데이터 주변에 가상의 값을 추가하여 출력 크기를 조정하거나 경계 효과를 제어하는데 사용된다\n",
    "#          activation='relu',\n",
    "#          input_shape=[WINDOW_SIZE, 1]),\n",
    "#   LSTM(256, recurrent_dropout=0.5, activation='tanh', return_sequences=True),  \n",
    "#   # tanh함수는 출력 범위가 -1~1로 제한되며 양수와 음수를 모두 다룰 수 있음\n",
    "#   # ReLU함수는 출력 범위가 0~1로 제한되며 음수의 경우 0으로 출력하여 음수값을 제거하는 효과가 있음, But, 음수를 처리하지 못해 그래디언트 소실 문제가 발생할 수 있음\n",
    "#   LSTM(128, activation='tanh', return_sequences=True),\n",
    "#   LSTM(64, activation='tanh', return_sequences=True),\n",
    "#   LSTM(32, activation='tanh'),\n",
    "#   Dense(8, activation='relu'),\n",
    "#   # Dropout(0.5), # 과적합을 방지하기 위해 사용되는 정규화 기법 중 하나로 학습 과정에서 일부 뉴런의 출력을 랜덤하게 0으로 만들어 모델의 일반화 능력을 향상시킨다\n",
    "#   Dense(1)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재까지 loss가 가장 낮은 모델\n",
    "\n",
    "lstm_model = Sequential([\n",
    "  Conv1D(filters=32, kernel_size=30,\n",
    "         padding='causal', # 시계열 데이터와 같은 순차 데이터를 다룰 때 유용한 방법으로 입력 데이터 주변에 가상의 값을 추가하여 출력 크기를 조정하거나 경계 효과를 제어하는데 사용된다\n",
    "         activation='relu',\n",
    "         input_shape=[WINDOW_SIZE, 1]),\n",
    "  LSTM(128, activation='tanh', return_sequences=True),  \n",
    "  # tanh함수는 출력 범위가 -1~1로 제한되며 양수와 음수를 모두 다룰 수 있음\n",
    "  # ReLU함수는 출력 범위가 0~1로 제한되며 음수의 경우 0으로 출력하여 음수값을 제거하는 효과가 있음, But, 음수를 처리하지 못해 그래디언트 소실 문제가 발생할 수 있음\n",
    "  LSTM(64, activation='tanh', return_sequences=True),\n",
    "  LSTM(32, activation='tanh'),\n",
    "  Dense(8, activation='relu'),\n",
    "  # Dropout(0.5), # 과적합을 방지하기 위해 사용되는 정규화 기법 중 하나로 학습 과정에서 일부 뉴런의 출력을 랜덤하게 0으로 만들어 모델의 일반화 능력을 향상시킨다\n",
    "  Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = Sequential([\n",
    "  Conv1D(filters=32, kernel_size=30,\n",
    "         padding='causal', # 시계열 데이터와 같은 순차 데이터를 다룰 때 유용한 방법으로 입력 데이터 주변에 가상의 값을 추가하여 출력 크기를 조정하거나 경계 효과를 제어하는데 사용된다\n",
    "         activation='relu',\n",
    "         input_shape=[WINDOW_SIZE, 1]),\n",
    "  SimpleRNN(128, activation='tanh', return_sequences=True),  \n",
    "  # tanh함수는 출력 범위가 -1~1로 제한되며 양수와 음수를 모두 다룰 수 있음\n",
    "  # ReLU함수는 출력 범위가 0~1로 제한되며 음수의 경우 0으로 출력하여 음수값을 제거하는 효과가 있음, But, 음수를 처리하지 못해 그래디언트 소실 문제가 발생할 수 있음\n",
    "  SimpleRNN(64, activation='tanh', return_sequences=True),\n",
    "  SimpleRNN(32, activation='tanh'),\n",
    "  Dense(8, activation='relu'),\n",
    "  # Dropout(0.5), # 과적합을 방지하기 위해 사용되는 정규화 기법 중 하나로 학습 과정에서 일부 뉴런의 출력을 랜덤하게 0으로 만들어 모델의 일반화 능력을 향상시킨다\n",
    "  Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = Sequential([\n",
    "  Conv1D(filters=32, kernel_size=30,\n",
    "         padding='causal', # 시계열 데이터와 같은 순차 데이터를 다룰 때 유용한 방법으로 입력 데이터 주변에 가상의 값을 추가하여 출력 크기를 조정하거나 경계 효과를 제어하는데 사용된다\n",
    "         activation='relu',\n",
    "         input_shape=[WINDOW_SIZE, 1]),\n",
    "  GRU(128, activation='tanh', return_sequences=True),  \n",
    "  # tanh함수는 출력 범위가 -1~1로 제한되며 양수와 음수를 모두 다룰 수 있음\n",
    "  # ReLU함수는 출력 범위가 0~1로 제한되며 음수의 경우 0으로 출력하여 음수값을 제거하는 효과가 있음, But, 음수를 처리하지 못해 그래디언트 소실 문제가 발생할 수 있음\n",
    "  GRU(64, activation='tanh', return_sequences=True),\n",
    "  GRU(32, activation='tanh'),\n",
    "  Dense(8, activation='relu'),\n",
    "  # Dropout(0.5), # 과적합을 방지하기 위해 사용되는 정규화 기법 중 하나로 학습 과정에서 일부 뉴런의 출력을 랜덤하게 0으로 만들어 모델의 일반화 능력을 향상시킨다\n",
    "  Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = Huber() # MSE(Mean Squared Error)와 MAE(Mean Absolute Error)의 특성을 혼합한 것으로 이상치에 민감하지 않으면서도 큰 오차에 덜 민감한 특성을 가진다\n",
    "optimizer = Adam(learning_rate=0.001) # 0.0005\n",
    "lstm_model.compile(loss=loss, optimizer=optimizer, metrics=['mse', 'mae'])\n",
    "rnn_model.compile(loss=loss, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), metrics=['mse', 'mae'])\n",
    "gru_model.compile(loss=loss, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), metrics=['mse', 'mae'])\n",
    "# test_model.compile(loss=loss, optimizer=optimizer, metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReduceLROnPlateau : 학습 도중 learning_rate를 동적으로 조정하는 데 사용된다 (에코크 동안 지정된 지표(monitor)에 대한 개선이 없는 경우 learning_rate를 감소시킨다)\n",
    "# 주요 파라미터 : monitor - 모니터링할 지표(검증 손실(val_loss), val_rmse, val_mae 등), factor - 학습률을 감소시킬 비율, patience : 지정된 에포크 동안 개선이 없을 경우 학습률 감소, mode - 판단 방식('auto', #                          'min', 'max'), min_lr - learning_rate 하한값 지정\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10)\n",
    "\n",
    "# EarlyStopping : 모델의 성능이 개선되지 않을 경우 학습을 조기 종료하여 불필요한 계산을 줄이고 과적합을 방지\n",
    "# 주요 파라미터 : monitor - 모니터링할 지표, patience - 지정된 에포크 동안 개선이 없을 경우 종료, mode - 모니터링 지표의 개선 여부 판단 방식, verbose - EarlyStopping 동작 상황 출력 여부 지정\n",
    "#                restore_best_weights - 적용 후 최적의 모델 가중치를 복원할지 여부를 지정                  \n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "# ModelCheckpoint : 학습 도중 지정된 지표(monitor) 기반하여 가장 성능이 좋은 모델 가중치를 저장 (지표가 개선되었을 때만 가중치 저장)\n",
    "#                   filepath : 모델 가중치 저장 경로 지정 (`{epoch:02d}`와 같은 형식을 사용해 에포크 번호 등을 동적으로 포맷팅 가능), save_best_only - True 설정 시 가장 좋은 성능을 보인 모델 가중치만 저장\n",
    "\n",
    "# mc = ModelCheckpoint('test_weight.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_lstm = ModelCheckpoint('new_stne_lstm_weight.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_lstm_ns = ModelCheckpoint('new_stne_lstm_weight_ns.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_rnn = ModelCheckpoint('new_stne_rnn_weight.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_rnn_ns = ModelCheckpoint('new_stne_rnn_weight_ns.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_gru = ModelCheckpoint('new_stne_gru_weight.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_gru_ns = ModelCheckpoint('new_stne_gru_weight_ns.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "\n",
    "# callback = [reduce_lr, es, mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_history = test_model.fit(train_data, validation_data=test_data, epochs=500, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "    425/Unknown - 7s 4ms/step - loss: 7586.8765 - mse: 182972560.0000 - mae: 7587.1934\n",
      "Epoch 1: val_loss improved from inf to 7088.14014, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 9s 10ms/step - loss: 7609.0605 - mse: 183259456.0000 - mae: 7609.3784 - val_loss: 7088.1401 - val_mse: 170736240.0000 - val_mae: 7088.4214 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "425/436 [============================>.] - ETA: 0s - loss: 7543.8755 - mse: 181121888.0000 - mae: 7544.1777\n",
      "Epoch 2: val_loss improved from 7088.14014 to 6996.43994, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 2s 5ms/step - loss: 7538.8042 - mse: 180702384.0000 - mae: 7539.1060 - val_loss: 6996.4399 - val_mse: 167513248.0000 - val_mae: 6996.7334 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 7406.6309 - mse: 176171968.0000 - mae: 7406.9360\n",
      "Epoch 3: val_loss improved from 6996.43994 to 6854.73389, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 2s 5ms/step - loss: 7413.5923 - mse: 176343840.0000 - mae: 7413.8975 - val_loss: 6854.7339 - val_mse: 162656048.0000 - val_mae: 6855.0493 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 7237.9399 - mse: 170401808.0000 - mae: 7238.2476\n",
      "Epoch 4: val_loss improved from 6854.73389 to 6677.17725, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 2s 5ms/step - loss: 7239.5664 - mse: 170384048.0000 - mae: 7239.8740 - val_loss: 6677.1772 - val_mse: 156563824.0000 - val_mae: 6677.4971 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 7042.6968 - mse: 163346048.0000 - mae: 7042.9976\n",
      "Epoch 5: val_loss improved from 6677.17725 to 6484.41162, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 2s 5ms/step - loss: 7048.4365 - mse: 163507264.0000 - mae: 7048.7378 - val_loss: 6484.4116 - val_mse: 149705488.0000 - val_mae: 6484.7227 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "425/436 [============================>.] - ETA: 0s - loss: 6806.4912 - mse: 155433232.0000 - mae: 6806.7939\n",
      "Epoch 6: val_loss improved from 6484.41162 to 6268.79053, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 6ms/step - loss: 6826.1982 - mse: 155707952.0000 - mae: 6826.5039 - val_loss: 6268.7905 - val_mse: 142095488.0000 - val_mae: 6269.0879 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 6597.9692 - mse: 147554880.0000 - mae: 6598.3008\n",
      "Epoch 7: val_loss improved from 6268.79053 to 6060.25830, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 6ms/step - loss: 6604.8169 - mse: 147600784.0000 - mae: 6605.1489 - val_loss: 6060.2583 - val_mse: 134434704.0000 - val_mae: 6060.5894 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 6389.8521 - mse: 139728352.0000 - mae: 6390.1831\n",
      "Epoch 8: val_loss improved from 6060.25830 to 5871.80811, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 6ms/step - loss: 6386.0142 - mse: 139520352.0000 - mae: 6386.3457 - val_loss: 5871.8081 - val_mse: 126670352.0000 - val_mae: 5872.1367 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 6130.2847 - mse: 130455736.0000 - mae: 6130.6064\n",
      "Epoch 9: val_loss improved from 5871.80811 to 5638.98828, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 6ms/step - loss: 6142.2339 - mse: 130649648.0000 - mae: 6142.5566 - val_loss: 5638.9883 - val_mse: 118373392.0000 - val_mae: 5639.2930 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 5917.4077 - mse: 122025200.0000 - mae: 5917.7261\n",
      "Epoch 10: val_loss improved from 5638.98828 to 5500.32275, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 5917.1582 - mse: 122004400.0000 - mae: 5917.4766 - val_loss: 5500.3228 - val_mse: 111127528.0000 - val_mae: 5500.6362 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 5711.9893 - mse: 114097584.0000 - mae: 5712.3032\n",
      "Epoch 11: val_loss improved from 5500.32275 to 5207.89648, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 5702.4087 - mse: 113840344.0000 - mae: 5702.7231 - val_loss: 5207.8965 - val_mse: 102658352.0000 - val_mae: 5208.1982 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 5428.4761 - mse: 104913376.0000 - mae: 5428.7842\n",
      "Epoch 12: val_loss improved from 5207.89648 to 4976.50195, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 5438.7290 - mse: 105168968.0000 - mae: 5439.0366 - val_loss: 4976.5020 - val_mse: 94463104.0000 - val_mae: 4976.7798 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 5223.9800 - mse: 97109872.0000 - mae: 5224.2959\n",
      "Epoch 13: val_loss improved from 4976.50195 to 4818.68945, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 5218.7275 - mse: 97002696.0000 - mae: 5219.0444 - val_loss: 4818.6895 - val_mse: 87236672.0000 - val_mae: 4819.0200 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 5024.5591 - mse: 89442120.0000 - mae: 5024.8706\n",
      "Epoch 14: val_loss improved from 4818.68945 to 4623.65527, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 5024.5591 - mse: 89442120.0000 - mae: 5024.8706 - val_loss: 4623.6553 - val_mse: 80202464.0000 - val_mae: 4623.9346 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 4841.0034 - mse: 82379736.0000 - mae: 4841.3101\n",
      "Epoch 15: val_loss improved from 4623.65527 to 4617.26172, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 4841.1982 - mse: 82282496.0000 - mae: 4841.5044 - val_loss: 4617.2617 - val_mse: 75163760.0000 - val_mae: 4617.5820 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 4783.1650 - mse: 77582208.0000 - mae: 4783.4751\n",
      "Epoch 16: val_loss improved from 4617.26172 to 4537.64453, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 4778.8384 - mse: 77432664.0000 - mae: 4779.1479 - val_loss: 4537.6445 - val_mse: 70466944.0000 - val_mae: 4537.9248 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 4579.8613 - mse: 71861336.0000 - mae: 4580.1680\n",
      "Epoch 17: val_loss improved from 4537.64453 to 4156.93896, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 4580.1001 - mse: 71814344.0000 - mae: 4580.4072 - val_loss: 4156.9390 - val_mse: 63673056.0000 - val_mae: 4157.2471 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 4465.3193 - mse: 66527164.0000 - mae: 4465.6445\n",
      "Epoch 18: val_loss did not improve from 4156.93896\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 4468.0645 - mse: 66555240.0000 - mae: 4468.3887 - val_loss: 4161.3604 - val_mse: 59443208.0000 - val_mae: 4161.6436 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 4343.8174 - mse: 62090572.0000 - mae: 4344.1313\n",
      "Epoch 19: val_loss improved from 4156.93896 to 3943.01465, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 4340.2769 - mse: 61931012.0000 - mae: 4340.5908 - val_loss: 3943.0146 - val_mse: 54870444.0000 - val_mae: 3943.3176 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 4211.1885 - mse: 58186376.0000 - mae: 4211.5083\n",
      "Epoch 20: val_loss improved from 3943.01465 to 3886.13745, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 4210.9463 - mse: 58124448.0000 - mae: 4211.2666 - val_loss: 3886.1375 - val_mse: 50481496.0000 - val_mae: 3886.4272 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 4087.1406 - mse: 54656384.0000 - mae: 4087.4927\n",
      "Epoch 21: val_loss improved from 3886.13745 to 3686.25854, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 4082.9670 - mse: 54587096.0000 - mae: 4083.3188 - val_loss: 3686.2585 - val_mse: 47269512.0000 - val_mae: 3686.5962 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "427/436 [============================>.] - ETA: 0s - loss: 3885.8457 - mse: 50242952.0000 - mae: 3886.1912\n",
      "Epoch 22: val_loss improved from 3686.25854 to 3555.45483, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 6ms/step - loss: 3883.4939 - mse: 50161440.0000 - mae: 3883.8403 - val_loss: 3555.4548 - val_mse: 43567800.0000 - val_mae: 3555.8013 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 3678.2446 - mse: 44504456.0000 - mae: 3678.5615\n",
      "Epoch 23: val_loss improved from 3555.45483 to 3455.21387, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3671.9785 - mse: 44409040.0000 - mae: 3672.2959 - val_loss: 3455.2139 - val_mse: 40756444.0000 - val_mae: 3455.5518 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 3492.6194 - mse: 40757152.0000 - mae: 3492.9492\n",
      "Epoch 24: val_loss improved from 3455.21387 to 3361.39844, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3492.6194 - mse: 40757152.0000 - mae: 3492.9492 - val_loss: 3361.3984 - val_mse: 38115712.0000 - val_mae: 3361.7056 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 3473.1689 - mse: 39409564.0000 - mae: 3473.5044\n",
      "Epoch 25: val_loss improved from 3361.39844 to 3301.57373, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 3469.7222 - mse: 39313768.0000 - mae: 3470.0583 - val_loss: 3301.5737 - val_mse: 36014852.0000 - val_mae: 3301.9158 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 3318.1467 - mse: 36549784.0000 - mae: 3318.4841\n",
      "Epoch 26: val_loss did not improve from 3301.57373\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 3317.3416 - mse: 36533344.0000 - mae: 3317.6790 - val_loss: 3326.0193 - val_mse: 36129072.0000 - val_mae: 3326.3909 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 3244.7632 - mse: 34744316.0000 - mae: 3245.0925\n",
      "Epoch 27: val_loss improved from 3301.57373 to 3283.70239, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3243.4338 - mse: 34718516.0000 - mae: 3243.7632 - val_loss: 3283.7024 - val_mse: 36174460.0000 - val_mae: 3284.0479 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 3254.2556 - mse: 34723688.0000 - mae: 3254.5769\n",
      "Epoch 28: val_loss improved from 3283.70239 to 3136.33496, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 3260.1414 - mse: 34827196.0000 - mae: 3260.4624 - val_loss: 3136.3350 - val_mse: 33238684.0000 - val_mae: 3136.6111 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 3143.7427 - mse: 32922330.0000 - mae: 3144.0659\n",
      "Epoch 29: val_loss did not improve from 3136.33496\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 3142.1367 - mse: 32886060.0000 - mae: 3142.4600 - val_loss: 3244.8174 - val_mse: 34872736.0000 - val_mae: 3245.1650 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 3154.8601 - mse: 32986156.0000 - mae: 3155.2007\n",
      "Epoch 30: val_loss did not improve from 3136.33496\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 3157.6682 - mse: 33045844.0000 - mae: 3158.0088 - val_loss: 3280.7954 - val_mse: 36453852.0000 - val_mae: 3281.1167 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 3235.9600 - mse: 34365904.0000 - mae: 3236.2927\n",
      "Epoch 31: val_loss improved from 3136.33496 to 3073.39478, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 3241.3220 - mse: 34478184.0000 - mae: 3241.6550 - val_loss: 3073.3948 - val_mse: 31558304.0000 - val_mae: 3073.6680 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 3054.1494 - mse: 32004860.0000 - mae: 3054.4995\n",
      "Epoch 32: val_loss did not improve from 3073.39478\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 3052.0598 - mse: 31965220.0000 - mae: 3052.4097 - val_loss: 3141.3459 - val_mse: 33966720.0000 - val_mae: 3141.6692 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 3027.4866 - mse: 31753862.0000 - mae: 3027.8108\n",
      "Epoch 33: val_loss improved from 3073.39478 to 2964.84033, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3029.0608 - mse: 31768728.0000 - mae: 3029.3848 - val_loss: 2964.8403 - val_mse: 30839728.0000 - val_mae: 2965.1150 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 3078.7104 - mse: 32034284.0000 - mae: 3079.0325\n",
      "Epoch 34: val_loss did not improve from 2964.84033\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3086.5464 - mse: 32183986.0000 - mae: 3086.8684 - val_loss: 3361.9690 - val_mse: 37971892.0000 - val_mae: 3362.2898 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 3504.7639 - mse: 40536228.0000 - mae: 3505.0757\n",
      "Epoch 35: val_loss did not improve from 2964.84033\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 3510.0332 - mse: 40596476.0000 - mae: 3510.3450 - val_loss: 3120.0134 - val_mse: 32789228.0000 - val_mae: 3120.3262 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 3347.4390 - mse: 38115100.0000 - mae: 3347.7571\n",
      "Epoch 36: val_loss did not improve from 2964.84033\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 3347.4390 - mse: 38115100.0000 - mae: 3347.7571 - val_loss: 3038.4851 - val_mse: 31604126.0000 - val_mae: 3038.7668 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 3150.7297 - mse: 33844880.0000 - mae: 3151.0559\n",
      "Epoch 37: val_loss did not improve from 2964.84033\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3152.3606 - mse: 33877304.0000 - mae: 3152.6870 - val_loss: 2971.3599 - val_mse: 31635330.0000 - val_mae: 2971.6648 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2953.4854 - mse: 30296030.0000 - mae: 2953.8123\n",
      "Epoch 38: val_loss did not improve from 2964.84033\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2957.1130 - mse: 30336864.0000 - mae: 2957.4395 - val_loss: 3110.6436 - val_mse: 31141326.0000 - val_mae: 3110.9331 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 3013.3989 - mse: 30873874.0000 - mae: 3013.7019\n",
      "Epoch 39: val_loss did not improve from 2964.84033\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 3013.3989 - mse: 30873874.0000 - mae: 3013.7019 - val_loss: 3236.8340 - val_mse: 34453264.0000 - val_mae: 3237.0930 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 3010.3359 - mse: 32019698.0000 - mae: 3010.6414\n",
      "Epoch 40: val_loss improved from 2964.84033 to 2956.24854, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3019.1484 - mse: 32172034.0000 - mae: 3019.4546 - val_loss: 2956.2485 - val_mse: 31470392.0000 - val_mae: 2956.5549 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 3122.3755 - mse: 34176208.0000 - mae: 3122.6912\n",
      "Epoch 41: val_loss did not improve from 2956.24854\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3124.8684 - mse: 34143360.0000 - mae: 3125.1843 - val_loss: 3309.7051 - val_mse: 34799208.0000 - val_mae: 3310.0310 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 3085.9419 - mse: 32538254.0000 - mae: 3086.2478\n",
      "Epoch 42: val_loss did not improve from 2956.24854\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 3096.5435 - mse: 32678754.0000 - mae: 3096.8501 - val_loss: 3523.2146 - val_mse: 40391228.0000 - val_mae: 3523.5181 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 3261.5073 - mse: 35809308.0000 - mae: 3261.8193\n",
      "Epoch 43: val_loss did not improve from 2956.24854\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3261.7441 - mse: 35819364.0000 - mae: 3262.0566 - val_loss: 3169.7900 - val_mse: 35823616.0000 - val_mae: 3170.1143 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 3146.3018 - mse: 33722204.0000 - mae: 3146.6150\n",
      "Epoch 44: val_loss improved from 2956.24854 to 2947.09570, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 3152.7361 - mse: 33780988.0000 - mae: 3153.0498 - val_loss: 2947.0957 - val_mse: 30154096.0000 - val_mae: 2947.4043 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 3064.3577 - mse: 31868440.0000 - mae: 3064.6636\n",
      "Epoch 45: val_loss did not improve from 2947.09570\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 3062.7744 - mse: 31843316.0000 - mae: 3063.0806 - val_loss: 3251.2756 - val_mse: 37673776.0000 - val_mae: 3251.5864 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 3319.0264 - mse: 36503872.0000 - mae: 3319.3416\n",
      "Epoch 46: val_loss did not improve from 2947.09570\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3317.9773 - mse: 36447700.0000 - mae: 3318.2927 - val_loss: 3031.1541 - val_mse: 31279730.0000 - val_mae: 3031.4453 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 3293.5344 - mse: 36260012.0000 - mae: 3293.8425\n",
      "Epoch 47: val_loss improved from 2947.09570 to 2932.80469, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 3297.6187 - mse: 36267008.0000 - mae: 3297.9270 - val_loss: 2932.8047 - val_mse: 29826584.0000 - val_mae: 2933.1143 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 3048.6379 - mse: 32049988.0000 - mae: 3048.9463\n",
      "Epoch 48: val_loss improved from 2932.80469 to 2830.79199, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 3055.6729 - mse: 32139592.0000 - mae: 3055.9810 - val_loss: 2830.7920 - val_mse: 28402020.0000 - val_mae: 2831.1040 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2933.3386 - mse: 30427344.0000 - mae: 2933.6440\n",
      "Epoch 49: val_loss improved from 2830.79199 to 2815.15527, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2935.3501 - mse: 30441420.0000 - mae: 2935.6558 - val_loss: 2815.1553 - val_mse: 29554136.0000 - val_mae: 2815.4736 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2867.3762 - mse: 29502742.0000 - mae: 2867.6802\n",
      "Epoch 50: val_loss did not improve from 2815.15527\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2867.3762 - mse: 29502742.0000 - mae: 2867.6802 - val_loss: 2846.4248 - val_mse: 29372694.0000 - val_mae: 2846.7263 - lr: 0.0010\n",
      "Epoch 51/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2781.2229 - mse: 28205800.0000 - mae: 2781.5264\n",
      "Epoch 51: val_loss improved from 2815.15527 to 2758.86450, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2783.2522 - mse: 28201452.0000 - mae: 2783.5559 - val_loss: 2758.8645 - val_mse: 28738208.0000 - val_mae: 2759.1809 - lr: 0.0010\n",
      "Epoch 52/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2817.9578 - mse: 28715554.0000 - mae: 2818.2656\n",
      "Epoch 52: val_loss did not improve from 2758.86450\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2821.8438 - mse: 28784322.0000 - mae: 2822.1519 - val_loss: 2800.8384 - val_mse: 28856306.0000 - val_mae: 2801.1482 - lr: 0.0010\n",
      "Epoch 53/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2996.9099 - mse: 31642562.0000 - mae: 2997.2324\n",
      "Epoch 53: val_loss did not improve from 2758.86450\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3002.7651 - mse: 31706606.0000 - mae: 3003.0884 - val_loss: 3517.2681 - val_mse: 39483296.0000 - val_mae: 3517.6089 - lr: 0.0010\n",
      "Epoch 54/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2979.4260 - mse: 31557452.0000 - mae: 2979.7607\n",
      "Epoch 54: val_loss did not improve from 2758.86450\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2984.7974 - mse: 31617856.0000 - mae: 2985.1318 - val_loss: 2968.6025 - val_mse: 30361358.0000 - val_mae: 2968.8679 - lr: 0.0010\n",
      "Epoch 55/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 3148.6790 - mse: 35176528.0000 - mae: 3149.0051\n",
      "Epoch 55: val_loss did not improve from 2758.86450\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 3157.1238 - mse: 35391456.0000 - mae: 3157.4502 - val_loss: 3299.7881 - val_mse: 39101448.0000 - val_mae: 3300.0811 - lr: 0.0010\n",
      "Epoch 56/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 3197.3118 - mse: 35875244.0000 - mae: 3197.6350\n",
      "Epoch 56: val_loss did not improve from 2758.86450\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3207.1316 - mse: 35993660.0000 - mae: 3207.4548 - val_loss: 3169.5037 - val_mse: 33537242.0000 - val_mae: 3169.8240 - lr: 0.0010\n",
      "Epoch 57/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 3034.4314 - mse: 32642756.0000 - mae: 3034.7576\n",
      "Epoch 57: val_loss improved from 2758.86450 to 2741.03052, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3039.1023 - mse: 32624214.0000 - mae: 3039.4297 - val_loss: 2741.0305 - val_mse: 29337944.0000 - val_mae: 2741.3506 - lr: 0.0010\n",
      "Epoch 58/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2656.4097 - mse: 26661278.0000 - mae: 2656.7312\n",
      "Epoch 58: val_loss improved from 2741.03052 to 2651.60449, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2655.6594 - mse: 26643808.0000 - mae: 2655.9810 - val_loss: 2651.6045 - val_mse: 26716022.0000 - val_mae: 2651.9333 - lr: 0.0010\n",
      "Epoch 59/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2625.2964 - mse: 26182534.0000 - mae: 2625.6255\n",
      "Epoch 59: val_loss improved from 2651.60449 to 2624.96777, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2629.0046 - mse: 26264256.0000 - mae: 2629.3342 - val_loss: 2624.9678 - val_mse: 26492866.0000 - val_mae: 2625.2283 - lr: 0.0010\n",
      "Epoch 60/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2784.3582 - mse: 28598994.0000 - mae: 2784.6860\n",
      "Epoch 60: val_loss did not improve from 2624.96777\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2787.9851 - mse: 28711206.0000 - mae: 2788.3125 - val_loss: 2792.3740 - val_mse: 29708724.0000 - val_mae: 2792.6912 - lr: 0.0010\n",
      "Epoch 61/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2725.4163 - mse: 27786176.0000 - mae: 2725.7449\n",
      "Epoch 61: val_loss did not improve from 2624.96777\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2733.4624 - mse: 27873012.0000 - mae: 2733.7910 - val_loss: 2777.1943 - val_mse: 28546136.0000 - val_mae: 2777.5869 - lr: 0.0010\n",
      "Epoch 62/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2726.4136 - mse: 27202640.0000 - mae: 2726.7334\n",
      "Epoch 62: val_loss did not improve from 2624.96777\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2726.4136 - mse: 27202640.0000 - mae: 2726.7334 - val_loss: 2988.8059 - val_mse: 32274984.0000 - val_mae: 2989.1089 - lr: 0.0010\n",
      "Epoch 63/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2716.0288 - mse: 27376204.0000 - mae: 2716.3481\n",
      "Epoch 63: val_loss did not improve from 2624.96777\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2716.0288 - mse: 27376204.0000 - mae: 2716.3481 - val_loss: 2696.2593 - val_mse: 27148418.0000 - val_mae: 2696.5876 - lr: 0.0010\n",
      "Epoch 64/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2679.1533 - mse: 26648242.0000 - mae: 2679.4822\n",
      "Epoch 64: val_loss did not improve from 2624.96777\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2683.2517 - mse: 26665512.0000 - mae: 2683.5806 - val_loss: 2729.4734 - val_mse: 29353262.0000 - val_mae: 2729.7556 - lr: 0.0010\n",
      "Epoch 65/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2773.5823 - mse: 28438416.0000 - mae: 2773.9077\n",
      "Epoch 65: val_loss did not improve from 2624.96777\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2775.7683 - mse: 28414258.0000 - mae: 2776.0938 - val_loss: 2673.0344 - val_mse: 26806328.0000 - val_mae: 2673.3628 - lr: 0.0010\n",
      "Epoch 66/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2987.1855 - mse: 31421130.0000 - mae: 2987.5134\n",
      "Epoch 66: val_loss did not improve from 2624.96777\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2988.0884 - mse: 31443868.0000 - mae: 2988.4163 - val_loss: 2655.5210 - val_mse: 26752818.0000 - val_mae: 2655.8291 - lr: 0.0010\n",
      "Epoch 67/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2849.4375 - mse: 29146138.0000 - mae: 2849.7727\n",
      "Epoch 67: val_loss did not improve from 2624.96777\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2848.6526 - mse: 29133102.0000 - mae: 2848.9878 - val_loss: 2848.2876 - val_mse: 30512052.0000 - val_mae: 2848.6226 - lr: 0.0010\n",
      "Epoch 68/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2791.3337 - mse: 28105510.0000 - mae: 2791.6526\n",
      "Epoch 68: val_loss did not improve from 2624.96777\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2792.0854 - mse: 28108404.0000 - mae: 2792.4043 - val_loss: 2702.8240 - val_mse: 27061566.0000 - val_mae: 2703.1167 - lr: 0.0010\n",
      "Epoch 69/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2785.0398 - mse: 28391264.0000 - mae: 2785.3660\n",
      "Epoch 69: val_loss did not improve from 2624.96777\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2783.4104 - mse: 28357266.0000 - mae: 2783.7361 - val_loss: 2796.3394 - val_mse: 28637568.0000 - val_mae: 2796.6189 - lr: 0.0010\n",
      "Epoch 70/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2832.2578 - mse: 29044658.0000 - mae: 2832.5862\n",
      "Epoch 70: val_loss did not improve from 2624.96777\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2835.6575 - mse: 29103500.0000 - mae: 2835.9856 - val_loss: 2844.8237 - val_mse: 29206530.0000 - val_mae: 2845.0959 - lr: 5.0000e-04\n",
      "Epoch 71/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2941.3423 - mse: 30945272.0000 - mae: 2941.6626\n",
      "Epoch 71: val_loss did not improve from 2624.96777\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2939.9382 - mse: 30923628.0000 - mae: 2940.2583 - val_loss: 2839.9253 - val_mse: 28578444.0000 - val_mae: 2840.2119 - lr: 5.0000e-04\n",
      "Epoch 72/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2720.5154 - mse: 27079310.0000 - mae: 2720.8223\n",
      "Epoch 72: val_loss did not improve from 2624.96777\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2720.5154 - mse: 27079310.0000 - mae: 2720.8223 - val_loss: 2652.3438 - val_mse: 26269692.0000 - val_mae: 2652.6309 - lr: 5.0000e-04\n",
      "Epoch 73/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2677.4543 - mse: 26474288.0000 - mae: 2677.7761\n",
      "Epoch 73: val_loss improved from 2624.96777 to 2538.07349, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2690.4131 - mse: 26650998.0000 - mae: 2690.7358 - val_loss: 2538.0735 - val_mse: 25790920.0000 - val_mae: 2538.3816 - lr: 5.0000e-04\n",
      "Epoch 74/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2746.1238 - mse: 27306514.0000 - mae: 2746.4321\n",
      "Epoch 74: val_loss did not improve from 2538.07349\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2754.4309 - mse: 27444114.0000 - mae: 2754.7395 - val_loss: 2773.1711 - val_mse: 28662060.0000 - val_mae: 2773.4592 - lr: 5.0000e-04\n",
      "Epoch 75/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2721.3147 - mse: 27541306.0000 - mae: 2721.6323\n",
      "Epoch 75: val_loss did not improve from 2538.07349\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2721.0415 - mse: 27560172.0000 - mae: 2721.3589 - val_loss: 2569.1646 - val_mse: 25898384.0000 - val_mae: 2569.4546 - lr: 5.0000e-04\n",
      "Epoch 76/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2651.9695 - mse: 26651154.0000 - mae: 2652.2886\n",
      "Epoch 76: val_loss did not improve from 2538.07349\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2651.9946 - mse: 26644352.0000 - mae: 2652.3137 - val_loss: 2577.5198 - val_mse: 27222494.0000 - val_mae: 2577.8215 - lr: 5.0000e-04\n",
      "Epoch 77/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2595.5500 - mse: 25591040.0000 - mae: 2595.8594\n",
      "Epoch 77: val_loss did not improve from 2538.07349\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2595.5500 - mse: 25591040.0000 - mae: 2595.8594 - val_loss: 2576.8262 - val_mse: 25666886.0000 - val_mae: 2577.1118 - lr: 5.0000e-04\n",
      "Epoch 78/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2569.1646 - mse: 25287652.0000 - mae: 2569.4685\n",
      "Epoch 78: val_loss improved from 2538.07349 to 2533.98828, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2575.4348 - mse: 25353858.0000 - mae: 2575.7385 - val_loss: 2533.9883 - val_mse: 26053104.0000 - val_mae: 2534.2642 - lr: 5.0000e-04\n",
      "Epoch 79/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2551.4180 - mse: 25098692.0000 - mae: 2551.7222\n",
      "Epoch 79: val_loss did not improve from 2533.98828\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2556.7954 - mse: 25156274.0000 - mae: 2557.1001 - val_loss: 2577.2188 - val_mse: 25693906.0000 - val_mae: 2577.5110 - lr: 5.0000e-04\n",
      "Epoch 80/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2572.1404 - mse: 25068998.0000 - mae: 2572.4395\n",
      "Epoch 80: val_loss did not improve from 2533.98828\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2575.3062 - mse: 25128838.0000 - mae: 2575.6052 - val_loss: 2545.2803 - val_mse: 25221698.0000 - val_mae: 2545.5591 - lr: 5.0000e-04\n",
      "Epoch 81/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2581.5056 - mse: 25274856.0000 - mae: 2581.8110\n",
      "Epoch 81: val_loss did not improve from 2533.98828\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2586.4160 - mse: 25336616.0000 - mae: 2586.7212 - val_loss: 2632.7686 - val_mse: 26994442.0000 - val_mae: 2633.0254 - lr: 5.0000e-04\n",
      "Epoch 82/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2672.4575 - mse: 27109172.0000 - mae: 2672.7898\n",
      "Epoch 82: val_loss improved from 2533.98828 to 2476.08374, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2670.3572 - mse: 27118912.0000 - mae: 2670.6895 - val_loss: 2476.0837 - val_mse: 25126370.0000 - val_mae: 2476.3994 - lr: 5.0000e-04\n",
      "Epoch 83/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2581.2214 - mse: 25597036.0000 - mae: 2581.5576\n",
      "Epoch 83: val_loss did not improve from 2476.08374\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2581.2214 - mse: 25597036.0000 - mae: 2581.5576 - val_loss: 2525.9055 - val_mse: 24970714.0000 - val_mae: 2526.2188 - lr: 5.0000e-04\n",
      "Epoch 84/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2539.3730 - mse: 24792268.0000 - mae: 2539.6919\n",
      "Epoch 84: val_loss did not improve from 2476.08374\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2542.6492 - mse: 24840860.0000 - mae: 2542.9683 - val_loss: 2634.5308 - val_mse: 26749176.0000 - val_mae: 2634.8291 - lr: 5.0000e-04\n",
      "Epoch 85/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2592.2256 - mse: 26005450.0000 - mae: 2592.5444\n",
      "Epoch 85: val_loss did not improve from 2476.08374\n",
      "436/436 [==============================] - 4s 10ms/step - loss: 2591.9182 - mse: 26003222.0000 - mae: 2592.2371 - val_loss: 2557.2405 - val_mse: 27564468.0000 - val_mae: 2557.5273 - lr: 5.0000e-04\n",
      "Epoch 86/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2579.9417 - mse: 25768800.0000 - mae: 2580.2520\n",
      "Epoch 86: val_loss did not improve from 2476.08374\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2579.1213 - mse: 25766660.0000 - mae: 2579.4319 - val_loss: 2506.1216 - val_mse: 26235906.0000 - val_mae: 2506.4106 - lr: 5.0000e-04\n",
      "Epoch 87/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2546.9431 - mse: 25246624.0000 - mae: 2547.2581\n",
      "Epoch 87: val_loss did not improve from 2476.08374\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2556.1140 - mse: 25355052.0000 - mae: 2556.4294 - val_loss: 2588.2881 - val_mse: 26308420.0000 - val_mae: 2588.5874 - lr: 5.0000e-04\n",
      "Epoch 88/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2535.5564 - mse: 24899488.0000 - mae: 2535.8818\n",
      "Epoch 88: val_loss did not improve from 2476.08374\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2536.8728 - mse: 24918122.0000 - mae: 2537.1985 - val_loss: 2519.8469 - val_mse: 25189200.0000 - val_mae: 2520.1582 - lr: 5.0000e-04\n",
      "Epoch 89/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2533.8877 - mse: 24985698.0000 - mae: 2534.2222\n",
      "Epoch 89: val_loss did not improve from 2476.08374\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2530.0654 - mse: 24903440.0000 - mae: 2530.3999 - val_loss: 2546.9783 - val_mse: 25207268.0000 - val_mae: 2547.2969 - lr: 5.0000e-04\n",
      "Epoch 90/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2516.9143 - mse: 24797370.0000 - mae: 2517.2490\n",
      "Epoch 90: val_loss improved from 2476.08374 to 2463.34546, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2530.6045 - mse: 24990024.0000 - mae: 2530.9395 - val_loss: 2463.3455 - val_mse: 24275356.0000 - val_mae: 2463.6582 - lr: 5.0000e-04\n",
      "Epoch 91/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2546.0874 - mse: 24803660.0000 - mae: 2546.4214\n",
      "Epoch 91: val_loss did not improve from 2463.34546\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2553.4365 - mse: 24876962.0000 - mae: 2553.7700 - val_loss: 2488.7205 - val_mse: 24312560.0000 - val_mae: 2489.0085 - lr: 5.0000e-04\n",
      "Epoch 92/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2580.8525 - mse: 25326276.0000 - mae: 2581.1865\n",
      "Epoch 92: val_loss did not improve from 2463.34546\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2581.6882 - mse: 25330734.0000 - mae: 2582.0225 - val_loss: 2575.9922 - val_mse: 25492252.0000 - val_mae: 2576.3110 - lr: 5.0000e-04\n",
      "Epoch 93/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2580.2197 - mse: 25046126.0000 - mae: 2580.5574\n",
      "Epoch 93: val_loss did not improve from 2463.34546\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2585.8723 - mse: 25127852.0000 - mae: 2586.2102 - val_loss: 2584.4294 - val_mse: 25730362.0000 - val_mae: 2584.7590 - lr: 5.0000e-04\n",
      "Epoch 94/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2536.2217 - mse: 24822588.0000 - mae: 2536.5557\n",
      "Epoch 94: val_loss did not improve from 2463.34546\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2536.2217 - mse: 24822588.0000 - mae: 2536.5557 - val_loss: 2477.2976 - val_mse: 25350728.0000 - val_mae: 2477.6033 - lr: 5.0000e-04\n",
      "Epoch 95/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2543.9514 - mse: 25413090.0000 - mae: 2544.2732\n",
      "Epoch 95: val_loss did not improve from 2463.34546\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2554.5520 - mse: 25520176.0000 - mae: 2554.8748 - val_loss: 2581.5925 - val_mse: 26205124.0000 - val_mae: 2581.8889 - lr: 5.0000e-04\n",
      "Epoch 96/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2526.6008 - mse: 25161170.0000 - mae: 2526.9177\n",
      "Epoch 96: val_loss did not improve from 2463.34546\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2526.6008 - mse: 25161170.0000 - mae: 2526.9177 - val_loss: 2583.0486 - val_mse: 26253422.0000 - val_mae: 2583.3306 - lr: 5.0000e-04\n",
      "Epoch 97/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2581.4314 - mse: 25879698.0000 - mae: 2581.7544\n",
      "Epoch 97: val_loss did not improve from 2463.34546\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2582.8953 - mse: 25882668.0000 - mae: 2583.2183 - val_loss: 2592.8635 - val_mse: 26904864.0000 - val_mae: 2593.1565 - lr: 5.0000e-04\n",
      "Epoch 98/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2538.3525 - mse: 25316426.0000 - mae: 2538.6797\n",
      "Epoch 98: val_loss did not improve from 2463.34546\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2536.6819 - mse: 25259248.0000 - mae: 2537.0093 - val_loss: 2530.1338 - val_mse: 25270920.0000 - val_mae: 2530.4612 - lr: 5.0000e-04\n",
      "Epoch 99/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2536.5320 - mse: 24994626.0000 - mae: 2536.8577\n",
      "Epoch 99: val_loss did not improve from 2463.34546\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2536.0181 - mse: 24978948.0000 - mae: 2536.3440 - val_loss: 2553.8823 - val_mse: 25636976.0000 - val_mae: 2554.1797 - lr: 5.0000e-04\n",
      "Epoch 100/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2588.1562 - mse: 26136468.0000 - mae: 2588.4819\n",
      "Epoch 100: val_loss did not improve from 2463.34546\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2588.1562 - mse: 26136468.0000 - mae: 2588.4819 - val_loss: 2562.3386 - val_mse: 25976734.0000 - val_mae: 2562.5994 - lr: 5.0000e-04\n",
      "Epoch 101/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2540.4861 - mse: 25498492.0000 - mae: 2540.7949\n",
      "Epoch 101: val_loss did not improve from 2463.34546\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2544.2329 - mse: 25525164.0000 - mae: 2544.5417 - val_loss: 2544.0776 - val_mse: 25832628.0000 - val_mae: 2544.3545 - lr: 2.5000e-04\n",
      "Epoch 102/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2528.6687 - mse: 25273880.0000 - mae: 2528.9763\n",
      "Epoch 102: val_loss did not improve from 2463.34546\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2531.0339 - mse: 25291134.0000 - mae: 2531.3420 - val_loss: 2473.5959 - val_mse: 25265986.0000 - val_mae: 2473.8613 - lr: 2.5000e-04\n",
      "Epoch 103/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2552.4385 - mse: 25322848.0000 - mae: 2552.7451\n",
      "Epoch 103: val_loss did not improve from 2463.34546\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2556.3096 - mse: 25393158.0000 - mae: 2556.6165 - val_loss: 2467.2539 - val_mse: 24475524.0000 - val_mae: 2467.5259 - lr: 2.5000e-04\n",
      "Epoch 104/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2501.0315 - mse: 24514192.0000 - mae: 2501.3428\n",
      "Epoch 104: val_loss improved from 2463.34546 to 2452.50488, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2506.4917 - mse: 24634124.0000 - mae: 2506.8030 - val_loss: 2452.5049 - val_mse: 24061616.0000 - val_mae: 2452.8025 - lr: 2.5000e-04\n",
      "Epoch 105/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2512.0596 - mse: 24700612.0000 - mae: 2512.3704\n",
      "Epoch 105: val_loss did not improve from 2452.50488\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2513.6675 - mse: 24722288.0000 - mae: 2513.9785 - val_loss: 2470.4990 - val_mse: 24211512.0000 - val_mae: 2470.7654 - lr: 2.5000e-04\n",
      "Epoch 106/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2475.9026 - mse: 24168456.0000 - mae: 2476.2080\n",
      "Epoch 106: val_loss did not improve from 2452.50488\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2477.3655 - mse: 24203328.0000 - mae: 2477.6711 - val_loss: 2485.0320 - val_mse: 24858732.0000 - val_mae: 2485.3000 - lr: 2.5000e-04\n",
      "Epoch 107/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2496.0913 - mse: 24612666.0000 - mae: 2496.4014\n",
      "Epoch 107: val_loss did not improve from 2452.50488\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2497.0955 - mse: 24609902.0000 - mae: 2497.4055 - val_loss: 2496.8474 - val_mse: 24780918.0000 - val_mae: 2497.1250 - lr: 2.5000e-04\n",
      "Epoch 108/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2537.5542 - mse: 25392954.0000 - mae: 2537.8511\n",
      "Epoch 108: val_loss did not improve from 2452.50488\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2537.5542 - mse: 25392954.0000 - mae: 2537.8511 - val_loss: 2476.3716 - val_mse: 24863232.0000 - val_mae: 2476.6545 - lr: 2.5000e-04\n",
      "Epoch 109/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2549.1011 - mse: 25079172.0000 - mae: 2549.4053\n",
      "Epoch 109: val_loss did not improve from 2452.50488\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2559.1843 - mse: 25226086.0000 - mae: 2559.4888 - val_loss: 2468.6777 - val_mse: 23791414.0000 - val_mae: 2468.9626 - lr: 2.5000e-04\n",
      "Epoch 110/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2541.6738 - mse: 25170680.0000 - mae: 2541.9675\n",
      "Epoch 110: val_loss did not improve from 2452.50488\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2543.1953 - mse: 25173612.0000 - mae: 2543.4893 - val_loss: 2459.0063 - val_mse: 24293132.0000 - val_mae: 2459.2856 - lr: 2.5000e-04\n",
      "Epoch 111/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2545.1333 - mse: 25670606.0000 - mae: 2545.4290\n",
      "Epoch 111: val_loss did not improve from 2452.50488\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2545.7629 - mse: 25698364.0000 - mae: 2546.0588 - val_loss: 2549.1943 - val_mse: 26429004.0000 - val_mae: 2549.4768 - lr: 2.5000e-04\n",
      "Epoch 112/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2476.9917 - mse: 24306048.0000 - mae: 2477.2874\n",
      "Epoch 112: val_loss improved from 2452.50488 to 2444.00806, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2480.0249 - mse: 24285366.0000 - mae: 2480.3210 - val_loss: 2444.0081 - val_mse: 24068190.0000 - val_mae: 2444.2803 - lr: 2.5000e-04\n",
      "Epoch 113/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2441.4885 - mse: 23626022.0000 - mae: 2441.7847\n",
      "Epoch 113: val_loss did not improve from 2444.00806\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2445.8030 - mse: 23715878.0000 - mae: 2446.0994 - val_loss: 2445.8289 - val_mse: 24453370.0000 - val_mae: 2446.1079 - lr: 2.5000e-04\n",
      "Epoch 114/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2499.5525 - mse: 24596138.0000 - mae: 2499.8494\n",
      "Epoch 114: val_loss improved from 2444.00806 to 2411.61279, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2499.5525 - mse: 24596138.0000 - mae: 2499.8494 - val_loss: 2411.6128 - val_mse: 23356702.0000 - val_mae: 2411.9023 - lr: 2.5000e-04\n",
      "Epoch 115/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2455.1248 - mse: 23625790.0000 - mae: 2455.4158\n",
      "Epoch 115: val_loss did not improve from 2411.61279\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2462.2354 - mse: 23724770.0000 - mae: 2462.5273 - val_loss: 2545.0266 - val_mse: 25491742.0000 - val_mae: 2545.3325 - lr: 2.5000e-04\n",
      "Epoch 116/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2431.9077 - mse: 23485500.0000 - mae: 2432.2058\n",
      "Epoch 116: val_loss did not improve from 2411.61279\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2439.4136 - mse: 23587578.0000 - mae: 2439.7124 - val_loss: 2425.1460 - val_mse: 24382322.0000 - val_mae: 2425.4229 - lr: 2.5000e-04\n",
      "Epoch 117/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2410.7683 - mse: 23350830.0000 - mae: 2411.0659\n",
      "Epoch 117: val_loss did not improve from 2411.61279\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2419.4890 - mse: 23496232.0000 - mae: 2419.7874 - val_loss: 2493.7600 - val_mse: 25496350.0000 - val_mae: 2494.0479 - lr: 2.5000e-04\n",
      "Epoch 118/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2391.8489 - mse: 23212320.0000 - mae: 2392.1558\n",
      "Epoch 118: val_loss did not improve from 2411.61279\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2395.9531 - mse: 23295926.0000 - mae: 2396.2603 - val_loss: 2511.6973 - val_mse: 25196462.0000 - val_mae: 2512.0037 - lr: 2.5000e-04\n",
      "Epoch 119/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2415.6624 - mse: 23266758.0000 - mae: 2415.9626\n",
      "Epoch 119: val_loss improved from 2411.61279 to 2397.10938, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2414.6917 - mse: 23248420.0000 - mae: 2414.9917 - val_loss: 2397.1094 - val_mse: 23948174.0000 - val_mae: 2397.4077 - lr: 2.5000e-04\n",
      "Epoch 120/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2410.5264 - mse: 23605064.0000 - mae: 2410.8342\n",
      "Epoch 120: val_loss improved from 2397.10938 to 2396.80591, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2418.3433 - mse: 23734040.0000 - mae: 2418.6521 - val_loss: 2396.8059 - val_mse: 23864018.0000 - val_mae: 2397.1206 - lr: 2.5000e-04\n",
      "Epoch 121/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2400.3938 - mse: 23126764.0000 - mae: 2400.7056\n",
      "Epoch 121: val_loss did not improve from 2396.80591\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2402.3989 - mse: 23139258.0000 - mae: 2402.7112 - val_loss: 2502.6777 - val_mse: 25818072.0000 - val_mae: 2502.9863 - lr: 2.5000e-04\n",
      "Epoch 122/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2417.8337 - mse: 23358430.0000 - mae: 2418.1416\n",
      "Epoch 122: val_loss did not improve from 2396.80591\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2418.1279 - mse: 23345730.0000 - mae: 2418.4363 - val_loss: 2403.0393 - val_mse: 23935900.0000 - val_mae: 2403.3374 - lr: 2.5000e-04\n",
      "Epoch 123/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2419.7046 - mse: 23616340.0000 - mae: 2420.0168\n",
      "Epoch 123: val_loss improved from 2396.80591 to 2351.48804, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2427.1641 - mse: 23703868.0000 - mae: 2427.4771 - val_loss: 2351.4880 - val_mse: 23552208.0000 - val_mae: 2351.7671 - lr: 2.5000e-04\n",
      "Epoch 124/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2395.3586 - mse: 23055416.0000 - mae: 2395.6736\n",
      "Epoch 124: val_loss did not improve from 2351.48804\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2406.0320 - mse: 23141582.0000 - mae: 2406.3477 - val_loss: 2528.0400 - val_mse: 26044494.0000 - val_mae: 2528.3572 - lr: 2.5000e-04\n",
      "Epoch 125/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2381.4810 - mse: 23094054.0000 - mae: 2381.8057\n",
      "Epoch 125: val_loss did not improve from 2351.48804\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2383.7441 - mse: 23124000.0000 - mae: 2384.0688 - val_loss: 2455.1626 - val_mse: 25307318.0000 - val_mae: 2455.4844 - lr: 2.5000e-04\n",
      "Epoch 126/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2408.6616 - mse: 23492612.0000 - mae: 2408.9949\n",
      "Epoch 126: val_loss did not improve from 2351.48804\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2410.3647 - mse: 23543018.0000 - mae: 2410.6982 - val_loss: 2492.5466 - val_mse: 25603760.0000 - val_mae: 2492.8635 - lr: 2.5000e-04\n",
      "Epoch 127/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2404.0303 - mse: 23135710.0000 - mae: 2404.3665\n",
      "Epoch 127: val_loss improved from 2351.48804 to 2319.23218, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2407.0747 - mse: 23182346.0000 - mae: 2407.4111 - val_loss: 2319.2322 - val_mse: 22810114.0000 - val_mae: 2319.5637 - lr: 2.5000e-04\n",
      "Epoch 128/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2359.4082 - mse: 22487518.0000 - mae: 2359.7610\n",
      "Epoch 128: val_loss did not improve from 2319.23218\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2360.1248 - mse: 22503850.0000 - mae: 2360.4778 - val_loss: 2406.8186 - val_mse: 24433470.0000 - val_mae: 2407.1436 - lr: 2.5000e-04\n",
      "Epoch 129/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2343.4658 - mse: 22144778.0000 - mae: 2343.8137\n",
      "Epoch 129: val_loss did not improve from 2319.23218\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2345.4827 - mse: 22148978.0000 - mae: 2345.8306 - val_loss: 2326.8987 - val_mse: 22622964.0000 - val_mae: 2327.2373 - lr: 2.5000e-04\n",
      "Epoch 130/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2341.2263 - mse: 22453764.0000 - mae: 2341.5713\n",
      "Epoch 130: val_loss did not improve from 2319.23218\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2343.7068 - mse: 22458654.0000 - mae: 2344.0520 - val_loss: 2374.5203 - val_mse: 23504862.0000 - val_mae: 2374.8450 - lr: 2.5000e-04\n",
      "Epoch 131/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2337.9138 - mse: 21996480.0000 - mae: 2338.2661\n",
      "Epoch 131: val_loss did not improve from 2319.23218\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2341.4385 - mse: 22042206.0000 - mae: 2341.7913 - val_loss: 2441.0359 - val_mse: 23843774.0000 - val_mae: 2441.3826 - lr: 2.5000e-04\n",
      "Epoch 132/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2355.9937 - mse: 22476702.0000 - mae: 2356.3699\n",
      "Epoch 132: val_loss improved from 2319.23218 to 2300.87402, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2359.8015 - mse: 22515236.0000 - mae: 2360.1777 - val_loss: 2300.8740 - val_mse: 23205618.0000 - val_mae: 2301.2373 - lr: 2.5000e-04\n",
      "Epoch 133/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2305.3010 - mse: 22075664.0000 - mae: 2305.6619\n",
      "Epoch 133: val_loss did not improve from 2300.87402\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2311.6934 - mse: 22193354.0000 - mae: 2312.0542 - val_loss: 2372.6184 - val_mse: 23685030.0000 - val_mae: 2372.9612 - lr: 2.5000e-04\n",
      "Epoch 134/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2316.1443 - mse: 22077046.0000 - mae: 2316.4656\n",
      "Epoch 134: val_loss did not improve from 2300.87402\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2319.3887 - mse: 22099850.0000 - mae: 2319.7100 - val_loss: 2366.4697 - val_mse: 23712002.0000 - val_mae: 2366.7754 - lr: 2.5000e-04\n",
      "Epoch 135/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2314.1411 - mse: 22179526.0000 - mae: 2314.4517\n",
      "Epoch 135: val_loss improved from 2300.87402 to 2278.53125, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2314.1333 - mse: 22183640.0000 - mae: 2314.4438 - val_loss: 2278.5312 - val_mse: 22132014.0000 - val_mae: 2278.8352 - lr: 2.5000e-04\n",
      "Epoch 136/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2328.8005 - mse: 22225556.0000 - mae: 2329.1067\n",
      "Epoch 136: val_loss did not improve from 2278.53125\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2328.8005 - mse: 22225556.0000 - mae: 2329.1067 - val_loss: 2363.0591 - val_mse: 22946618.0000 - val_mae: 2363.3579 - lr: 2.5000e-04\n",
      "Epoch 137/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2320.2371 - mse: 22234980.0000 - mae: 2320.5332\n",
      "Epoch 137: val_loss did not improve from 2278.53125\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2325.7180 - mse: 22303226.0000 - mae: 2326.0144 - val_loss: 2308.2729 - val_mse: 22837030.0000 - val_mae: 2308.5776 - lr: 2.5000e-04\n",
      "Epoch 138/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2302.9304 - mse: 21849796.0000 - mae: 2303.2322\n",
      "Epoch 138: val_loss improved from 2278.53125 to 2218.48486, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2305.8967 - mse: 21867224.0000 - mae: 2306.1990 - val_loss: 2218.4849 - val_mse: 21488282.0000 - val_mae: 2218.8015 - lr: 2.5000e-04\n",
      "Epoch 139/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2293.8435 - mse: 21787690.0000 - mae: 2294.1477\n",
      "Epoch 139: val_loss did not improve from 2218.48486\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2299.4126 - mse: 21842242.0000 - mae: 2299.7173 - val_loss: 2365.1133 - val_mse: 23442774.0000 - val_mae: 2365.4023 - lr: 2.5000e-04\n",
      "Epoch 140/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2315.3647 - mse: 21850862.0000 - mae: 2315.6655\n",
      "Epoch 140: val_loss did not improve from 2218.48486\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2315.3647 - mse: 21850862.0000 - mae: 2315.6655 - val_loss: 2346.1919 - val_mse: 23156266.0000 - val_mae: 2346.5227 - lr: 2.5000e-04\n",
      "Epoch 141/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2335.5803 - mse: 21824226.0000 - mae: 2335.8831\n",
      "Epoch 141: val_loss did not improve from 2218.48486\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2338.1848 - mse: 21872452.0000 - mae: 2338.4880 - val_loss: 2362.3342 - val_mse: 22791526.0000 - val_mae: 2362.6587 - lr: 2.5000e-04\n",
      "Epoch 142/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2336.0117 - mse: 22091176.0000 - mae: 2336.3242\n",
      "Epoch 142: val_loss did not improve from 2218.48486\n",
      "436/436 [==============================] - 4s 10ms/step - loss: 2339.5828 - mse: 22120744.0000 - mae: 2339.8953 - val_loss: 2362.0168 - val_mse: 23254554.0000 - val_mae: 2362.2927 - lr: 2.5000e-04\n",
      "Epoch 143/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2316.8479 - mse: 21880836.0000 - mae: 2317.1553\n",
      "Epoch 143: val_loss did not improve from 2218.48486\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2321.3218 - mse: 21978396.0000 - mae: 2321.6296 - val_loss: 2287.2983 - val_mse: 22041862.0000 - val_mae: 2287.6006 - lr: 2.5000e-04\n",
      "Epoch 144/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2306.0815 - mse: 22080510.0000 - mae: 2306.3867\n",
      "Epoch 144: val_loss did not improve from 2218.48486\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2308.4866 - mse: 22090202.0000 - mae: 2308.7920 - val_loss: 2253.4546 - val_mse: 21688528.0000 - val_mae: 2253.7449 - lr: 2.5000e-04\n",
      "Epoch 145/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2334.5962 - mse: 22350118.0000 - mae: 2334.9104\n",
      "Epoch 145: val_loss did not improve from 2218.48486\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2336.6909 - mse: 22347924.0000 - mae: 2337.0056 - val_loss: 2304.2803 - val_mse: 22451574.0000 - val_mae: 2304.5923 - lr: 2.5000e-04\n",
      "Epoch 146/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2320.6694 - mse: 22006682.0000 - mae: 2320.9741\n",
      "Epoch 146: val_loss did not improve from 2218.48486\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2319.7795 - mse: 21987026.0000 - mae: 2320.0842 - val_loss: 2431.6062 - val_mse: 24373260.0000 - val_mae: 2431.9016 - lr: 2.5000e-04\n",
      "Epoch 147/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2346.9182 - mse: 22247818.0000 - mae: 2347.2271\n",
      "Epoch 147: val_loss did not improve from 2218.48486\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2348.5776 - mse: 22262888.0000 - mae: 2348.8862 - val_loss: 2332.9871 - val_mse: 22305838.0000 - val_mae: 2333.2717 - lr: 2.5000e-04\n",
      "Epoch 148/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2298.8586 - mse: 21506620.0000 - mae: 2299.1704\n",
      "Epoch 148: val_loss did not improve from 2218.48486\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2306.5332 - mse: 21614318.0000 - mae: 2306.8455 - val_loss: 2300.9028 - val_mse: 22246960.0000 - val_mae: 2301.2073 - lr: 2.5000e-04\n",
      "Epoch 149/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2292.4226 - mse: 21611106.0000 - mae: 2292.7476\n",
      "Epoch 149: val_loss did not improve from 2218.48486\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2292.8979 - mse: 21626494.0000 - mae: 2293.2229 - val_loss: 2237.2007 - val_mse: 21849878.0000 - val_mae: 2237.4807 - lr: 1.2500e-04\n",
      "Epoch 150/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2259.7307 - mse: 21202436.0000 - mae: 2260.0415\n",
      "Epoch 150: val_loss did not improve from 2218.48486\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2263.6338 - mse: 21253420.0000 - mae: 2263.9446 - val_loss: 2260.6499 - val_mse: 21943032.0000 - val_mae: 2260.9429 - lr: 1.2500e-04\n",
      "Epoch 151/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2256.6938 - mse: 21074252.0000 - mae: 2256.9929\n",
      "Epoch 151: val_loss did not improve from 2218.48486\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2256.0059 - mse: 21052770.0000 - mae: 2256.3047 - val_loss: 2228.5989 - val_mse: 21509586.0000 - val_mae: 2228.8813 - lr: 1.2500e-04\n",
      "Epoch 152/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2248.3806 - mse: 20794114.0000 - mae: 2248.6763\n",
      "Epoch 152: val_loss improved from 2218.48486 to 2214.90454, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2259.1382 - mse: 20953412.0000 - mae: 2259.4341 - val_loss: 2214.9045 - val_mse: 21510298.0000 - val_mae: 2215.1824 - lr: 1.2500e-04\n",
      "Epoch 153/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2248.2144 - mse: 20848468.0000 - mae: 2248.5098\n",
      "Epoch 153: val_loss improved from 2214.90454 to 2212.79688, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2246.4121 - mse: 20815342.0000 - mae: 2246.7080 - val_loss: 2212.7969 - val_mse: 21229640.0000 - val_mae: 2213.0955 - lr: 1.2500e-04\n",
      "Epoch 154/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2243.5159 - mse: 20895526.0000 - mae: 2243.8154\n",
      "Epoch 154: val_loss did not improve from 2212.79688\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2242.5964 - mse: 20879260.0000 - mae: 2242.8965 - val_loss: 2273.5000 - val_mse: 21880280.0000 - val_mae: 2273.8228 - lr: 1.2500e-04\n",
      "Epoch 155/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2269.3086 - mse: 21343948.0000 - mae: 2269.6069\n",
      "Epoch 155: val_loss did not improve from 2212.79688\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2271.4624 - mse: 21379300.0000 - mae: 2271.7610 - val_loss: 2252.8281 - val_mse: 21646972.0000 - val_mae: 2253.1421 - lr: 1.2500e-04\n",
      "Epoch 156/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2267.9590 - mse: 21295198.0000 - mae: 2268.2559\n",
      "Epoch 156: val_loss did not improve from 2212.79688\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2266.6770 - mse: 21276688.0000 - mae: 2266.9739 - val_loss: 2244.3401 - val_mse: 21445598.0000 - val_mae: 2244.6133 - lr: 1.2500e-04\n",
      "Epoch 157/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2271.7739 - mse: 21632706.0000 - mae: 2272.0698\n",
      "Epoch 157: val_loss improved from 2212.79688 to 2205.14551, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2284.9282 - mse: 21865606.0000 - mae: 2285.2246 - val_loss: 2205.1455 - val_mse: 21641832.0000 - val_mae: 2205.4434 - lr: 1.2500e-04\n",
      "Epoch 158/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2270.3320 - mse: 21757166.0000 - mae: 2270.6299\n",
      "Epoch 158: val_loss improved from 2205.14551 to 2192.56396, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2275.0820 - mse: 21818268.0000 - mae: 2275.3801 - val_loss: 2192.5640 - val_mse: 21126768.0000 - val_mae: 2192.8838 - lr: 1.2500e-04\n",
      "Epoch 159/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2255.3169 - mse: 21586270.0000 - mae: 2255.6121\n",
      "Epoch 159: val_loss did not improve from 2192.56396\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2258.2861 - mse: 21611856.0000 - mae: 2258.5811 - val_loss: 2194.7708 - val_mse: 21165190.0000 - val_mae: 2195.0234 - lr: 1.2500e-04\n",
      "Epoch 160/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2228.3274 - mse: 21023264.0000 - mae: 2228.6245\n",
      "Epoch 160: val_loss did not improve from 2192.56396\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2240.3232 - mse: 21182958.0000 - mae: 2240.6211 - val_loss: 2269.6492 - val_mse: 22037004.0000 - val_mae: 2269.9294 - lr: 1.2500e-04\n",
      "Epoch 161/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2243.4187 - mse: 21294056.0000 - mae: 2243.7183\n",
      "Epoch 161: val_loss did not improve from 2192.56396\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2243.0737 - mse: 21281896.0000 - mae: 2243.3733 - val_loss: 2204.5933 - val_mse: 20518310.0000 - val_mae: 2204.8848 - lr: 1.2500e-04\n",
      "Epoch 162/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2217.5112 - mse: 20649298.0000 - mae: 2217.7998\n",
      "Epoch 162: val_loss did not improve from 2192.56396\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2218.9585 - mse: 20683710.0000 - mae: 2219.2468 - val_loss: 2257.7437 - val_mse: 21558660.0000 - val_mae: 2258.0161 - lr: 1.2500e-04\n",
      "Epoch 163/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2251.8555 - mse: 21195208.0000 - mae: 2252.1548\n",
      "Epoch 163: val_loss did not improve from 2192.56396\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2253.3774 - mse: 21212276.0000 - mae: 2253.6770 - val_loss: 2242.9011 - val_mse: 21683090.0000 - val_mae: 2243.2097 - lr: 1.2500e-04\n",
      "Epoch 164/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2302.6335 - mse: 21673854.0000 - mae: 2302.9365\n",
      "Epoch 164: val_loss did not improve from 2192.56396\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2306.2661 - mse: 21741560.0000 - mae: 2306.5688 - val_loss: 2313.7502 - val_mse: 22445746.0000 - val_mae: 2314.0547 - lr: 1.2500e-04\n",
      "Epoch 165/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2274.4985 - mse: 21149892.0000 - mae: 2274.8113\n",
      "Epoch 165: val_loss did not improve from 2192.56396\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2275.6443 - mse: 21160984.0000 - mae: 2275.9570 - val_loss: 2200.5828 - val_mse: 20739234.0000 - val_mae: 2200.8774 - lr: 1.2500e-04\n",
      "Epoch 166/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2264.4485 - mse: 21058562.0000 - mae: 2264.7537\n",
      "Epoch 166: val_loss did not improve from 2192.56396\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2263.8594 - mse: 21069582.0000 - mae: 2264.1643 - val_loss: 2205.6372 - val_mse: 20893090.0000 - val_mae: 2205.8904 - lr: 1.2500e-04\n",
      "Epoch 167/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2262.0581 - mse: 21214338.0000 - mae: 2262.3584\n",
      "Epoch 167: val_loss did not improve from 2192.56396\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2261.1487 - mse: 21218538.0000 - mae: 2261.4495 - val_loss: 2229.1697 - val_mse: 20992116.0000 - val_mae: 2229.4988 - lr: 1.2500e-04\n",
      "Epoch 168/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2253.4773 - mse: 21179266.0000 - mae: 2253.7817\n",
      "Epoch 168: val_loss did not improve from 2192.56396\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2257.3335 - mse: 21181842.0000 - mae: 2257.6387 - val_loss: 2246.9897 - val_mse: 21159606.0000 - val_mae: 2247.2920 - lr: 1.2500e-04\n",
      "Epoch 169/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2271.3499 - mse: 21685422.0000 - mae: 2271.6470\n",
      "Epoch 169: val_loss did not improve from 2192.56396\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2271.3499 - mse: 21685422.0000 - mae: 2271.6470 - val_loss: 2198.0430 - val_mse: 20689064.0000 - val_mae: 2198.3271 - lr: 6.2500e-05\n",
      "Epoch 170/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2233.7368 - mse: 20952734.0000 - mae: 2234.0391\n",
      "Epoch 170: val_loss did not improve from 2192.56396\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2244.2043 - mse: 21100968.0000 - mae: 2244.5073 - val_loss: 2211.7129 - val_mse: 20852006.0000 - val_mae: 2211.9956 - lr: 6.2500e-05\n",
      "Epoch 171/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2230.5637 - mse: 21085082.0000 - mae: 2230.8645\n",
      "Epoch 171: val_loss did not improve from 2192.56396\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2234.6184 - mse: 21114826.0000 - mae: 2234.9192 - val_loss: 2207.8630 - val_mse: 20978610.0000 - val_mae: 2208.1184 - lr: 6.2500e-05\n",
      "Epoch 172/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2234.6506 - mse: 20946714.0000 - mae: 2234.9487\n",
      "Epoch 172: val_loss did not improve from 2192.56396\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2238.0532 - mse: 21030492.0000 - mae: 2238.3513 - val_loss: 2234.7661 - val_mse: 21412296.0000 - val_mae: 2235.0256 - lr: 6.2500e-05\n",
      "Epoch 173/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2238.0664 - mse: 20997322.0000 - mae: 2238.3635\n",
      "Epoch 173: val_loss did not improve from 2192.56396\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2239.9211 - mse: 21001038.0000 - mae: 2240.2185 - val_loss: 2201.1550 - val_mse: 21014564.0000 - val_mae: 2201.4238 - lr: 6.2500e-05\n",
      "Epoch 174/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2226.4563 - mse: 20849466.0000 - mae: 2226.7544\n",
      "Epoch 174: val_loss improved from 2192.56396 to 2191.82617, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2230.7651 - mse: 20894866.0000 - mae: 2231.0637 - val_loss: 2191.8262 - val_mse: 20815592.0000 - val_mae: 2192.1113 - lr: 6.2500e-05\n",
      "Epoch 175/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2210.7087 - mse: 20575486.0000 - mae: 2211.0051\n",
      "Epoch 175: val_loss did not improve from 2191.82617\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2213.2178 - mse: 20581844.0000 - mae: 2213.5139 - val_loss: 2207.4246 - val_mse: 21003610.0000 - val_mae: 2207.6724 - lr: 6.2500e-05\n",
      "Epoch 176/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2206.9131 - mse: 20498908.0000 - mae: 2207.2065\n",
      "Epoch 176: val_loss improved from 2191.82617 to 2170.96558, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2207.8020 - mse: 20511628.0000 - mae: 2208.0957 - val_loss: 2170.9656 - val_mse: 20650472.0000 - val_mae: 2171.2358 - lr: 6.2500e-05\n",
      "Epoch 177/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2211.7983 - mse: 20517612.0000 - mae: 2212.0945\n",
      "Epoch 177: val_loss did not improve from 2170.96558\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2212.4473 - mse: 20513814.0000 - mae: 2212.7434 - val_loss: 2215.3066 - val_mse: 21405856.0000 - val_mae: 2215.5571 - lr: 6.2500e-05\n",
      "Epoch 178/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2223.8127 - mse: 20825678.0000 - mae: 2224.1094\n",
      "Epoch 178: val_loss did not improve from 2170.96558\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2227.9624 - mse: 20895436.0000 - mae: 2228.2590 - val_loss: 2177.8740 - val_mse: 20861530.0000 - val_mae: 2178.1462 - lr: 6.2500e-05\n",
      "Epoch 179/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2176.1565 - mse: 20058030.0000 - mae: 2176.4539\n",
      "Epoch 179: val_loss did not improve from 2170.96558\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2186.1680 - mse: 20178080.0000 - mae: 2186.4663 - val_loss: 2193.7390 - val_mse: 20590284.0000 - val_mae: 2194.0193 - lr: 6.2500e-05\n",
      "Epoch 180/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2206.1101 - mse: 20351074.0000 - mae: 2206.4136\n",
      "Epoch 180: val_loss improved from 2170.96558 to 2145.02783, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2205.0603 - mse: 20334534.0000 - mae: 2205.3635 - val_loss: 2145.0278 - val_mse: 20272840.0000 - val_mae: 2145.3171 - lr: 6.2500e-05\n",
      "Epoch 181/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2196.7205 - mse: 20270304.0000 - mae: 2197.0208\n",
      "Epoch 181: val_loss did not improve from 2145.02783\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2201.4490 - mse: 20323328.0000 - mae: 2201.7498 - val_loss: 2150.9954 - val_mse: 20257386.0000 - val_mae: 2151.2961 - lr: 6.2500e-05\n",
      "Epoch 182/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2208.4478 - mse: 20292204.0000 - mae: 2208.7517\n",
      "Epoch 182: val_loss did not improve from 2145.02783\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2217.5930 - mse: 20449610.0000 - mae: 2217.8972 - val_loss: 2174.9500 - val_mse: 20914442.0000 - val_mae: 2175.2449 - lr: 6.2500e-05\n",
      "Epoch 183/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2202.9805 - mse: 20544018.0000 - mae: 2203.2781\n",
      "Epoch 183: val_loss did not improve from 2145.02783\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2212.0100 - mse: 20635492.0000 - mae: 2212.3076 - val_loss: 2176.0613 - val_mse: 20615274.0000 - val_mae: 2176.3511 - lr: 6.2500e-05\n",
      "Epoch 184/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2201.4067 - mse: 20445342.0000 - mae: 2201.7097\n",
      "Epoch 184: val_loss did not improve from 2145.02783\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2202.3818 - mse: 20458592.0000 - mae: 2202.6848 - val_loss: 2180.1697 - val_mse: 21167674.0000 - val_mae: 2180.4683 - lr: 6.2500e-05\n",
      "Epoch 185/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2209.9292 - mse: 20722778.0000 - mae: 2210.2219\n",
      "Epoch 185: val_loss did not improve from 2145.02783\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2208.3384 - mse: 20649766.0000 - mae: 2208.6313 - val_loss: 2176.7122 - val_mse: 20943486.0000 - val_mae: 2177.0063 - lr: 6.2500e-05\n",
      "Epoch 186/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2182.4827 - mse: 20107304.0000 - mae: 2182.7761\n",
      "Epoch 186: val_loss did not improve from 2145.02783\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2191.5969 - mse: 20232372.0000 - mae: 2191.8909 - val_loss: 2188.3340 - val_mse: 20577642.0000 - val_mae: 2188.5972 - lr: 6.2500e-05\n",
      "Epoch 187/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2190.1929 - mse: 20178538.0000 - mae: 2190.4910\n",
      "Epoch 187: val_loss did not improve from 2145.02783\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2189.0300 - mse: 20156748.0000 - mae: 2189.3284 - val_loss: 2187.2495 - val_mse: 20519134.0000 - val_mae: 2187.5156 - lr: 6.2500e-05\n",
      "Epoch 188/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2230.4885 - mse: 20725330.0000 - mae: 2230.7891\n",
      "Epoch 188: val_loss did not improve from 2145.02783\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2230.4885 - mse: 20725330.0000 - mae: 2230.7891 - val_loss: 2190.0283 - val_mse: 20479224.0000 - val_mae: 2190.2847 - lr: 6.2500e-05\n",
      "Epoch 189/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2213.7676 - mse: 20586386.0000 - mae: 2214.0610\n",
      "Epoch 189: val_loss improved from 2145.02783 to 2144.31738, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2213.7676 - mse: 20586386.0000 - mae: 2214.0610 - val_loss: 2144.3174 - val_mse: 20334786.0000 - val_mae: 2144.5796 - lr: 6.2500e-05\n",
      "Epoch 190/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2179.8806 - mse: 20300818.0000 - mae: 2180.1748\n",
      "Epoch 190: val_loss did not improve from 2144.31738\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2181.6599 - mse: 20276762.0000 - mae: 2181.9548 - val_loss: 2145.2942 - val_mse: 20500092.0000 - val_mae: 2145.5654 - lr: 6.2500e-05\n",
      "Epoch 191/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2191.9700 - mse: 20445254.0000 - mae: 2192.2737\n",
      "Epoch 191: val_loss did not improve from 2144.31738\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2193.5618 - mse: 20490668.0000 - mae: 2193.8657 - val_loss: 2204.8689 - val_mse: 21306536.0000 - val_mae: 2205.1702 - lr: 6.2500e-05\n",
      "Epoch 192/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2199.2339 - mse: 20669226.0000 - mae: 2199.5374\n",
      "Epoch 192: val_loss did not improve from 2144.31738\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2198.9158 - mse: 20624176.0000 - mae: 2199.2192 - val_loss: 2200.3684 - val_mse: 21220792.0000 - val_mae: 2200.6404 - lr: 6.2500e-05\n",
      "Epoch 193/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2194.9097 - mse: 20658758.0000 - mae: 2195.2009\n",
      "Epoch 193: val_loss improved from 2144.31738 to 2141.50146, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2197.9109 - mse: 20720594.0000 - mae: 2198.2026 - val_loss: 2141.5015 - val_mse: 20704730.0000 - val_mae: 2141.7961 - lr: 6.2500e-05\n",
      "Epoch 194/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2192.0862 - mse: 20513530.0000 - mae: 2192.3865\n",
      "Epoch 194: val_loss improved from 2141.50146 to 2128.86646, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2198.9917 - mse: 20590194.0000 - mae: 2199.2925 - val_loss: 2128.8665 - val_mse: 20320598.0000 - val_mae: 2129.1445 - lr: 6.2500e-05\n",
      "Epoch 195/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2186.6953 - mse: 20306970.0000 - mae: 2186.9895\n",
      "Epoch 195: val_loss did not improve from 2128.86646\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2191.5125 - mse: 20340310.0000 - mae: 2191.8071 - val_loss: 2170.5071 - val_mse: 20674514.0000 - val_mae: 2170.7932 - lr: 6.2500e-05\n",
      "Epoch 196/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2187.7568 - mse: 20124310.0000 - mae: 2188.0520\n",
      "Epoch 196: val_loss did not improve from 2128.86646\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2193.6875 - mse: 20198612.0000 - mae: 2193.9827 - val_loss: 2198.2068 - val_mse: 21014264.0000 - val_mae: 2198.4719 - lr: 6.2500e-05\n",
      "Epoch 197/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2188.3225 - mse: 20398454.0000 - mae: 2188.6226\n",
      "Epoch 197: val_loss did not improve from 2128.86646\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2191.5203 - mse: 20441812.0000 - mae: 2191.8206 - val_loss: 2159.1353 - val_mse: 20853754.0000 - val_mae: 2159.4275 - lr: 6.2500e-05\n",
      "Epoch 198/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2185.1472 - mse: 20318772.0000 - mae: 2185.4470\n",
      "Epoch 198: val_loss did not improve from 2128.86646\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2188.0496 - mse: 20356114.0000 - mae: 2188.3491 - val_loss: 2142.6748 - val_mse: 20531850.0000 - val_mae: 2142.9424 - lr: 6.2500e-05\n",
      "Epoch 199/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2179.5784 - mse: 20172338.0000 - mae: 2179.8796\n",
      "Epoch 199: val_loss did not improve from 2128.86646\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2182.6709 - mse: 20194018.0000 - mae: 2182.9724 - val_loss: 2139.1052 - val_mse: 20405694.0000 - val_mae: 2139.3696 - lr: 6.2500e-05\n",
      "Epoch 200/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2189.1777 - mse: 20443408.0000 - mae: 2189.4771\n",
      "Epoch 200: val_loss did not improve from 2128.86646\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2190.9163 - mse: 20449692.0000 - mae: 2191.2156 - val_loss: 2134.3757 - val_mse: 20470350.0000 - val_mae: 2134.6504 - lr: 6.2500e-05\n",
      "Epoch 201/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2193.9919 - mse: 20527614.0000 - mae: 2194.2925\n",
      "Epoch 201: val_loss did not improve from 2128.86646\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2195.2346 - mse: 20549364.0000 - mae: 2195.5349 - val_loss: 2167.4399 - val_mse: 20886344.0000 - val_mae: 2167.7180 - lr: 6.2500e-05\n",
      "Epoch 202/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2201.8174 - mse: 20674058.0000 - mae: 2202.1133\n",
      "Epoch 202: val_loss did not improve from 2128.86646\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2201.8174 - mse: 20674058.0000 - mae: 2202.1133 - val_loss: 2145.2349 - val_mse: 20371384.0000 - val_mae: 2145.5332 - lr: 6.2500e-05\n",
      "Epoch 203/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2172.6296 - mse: 20204600.0000 - mae: 2172.9297\n",
      "Epoch 203: val_loss did not improve from 2128.86646\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2174.7971 - mse: 20220198.0000 - mae: 2175.0974 - val_loss: 2176.9939 - val_mse: 20618156.0000 - val_mae: 2177.3044 - lr: 6.2500e-05\n",
      "Epoch 204/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2175.4456 - mse: 20153110.0000 - mae: 2175.7449\n",
      "Epoch 204: val_loss did not improve from 2128.86646\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2179.0005 - mse: 20191984.0000 - mae: 2179.3000 - val_loss: 2166.3547 - val_mse: 20912748.0000 - val_mae: 2166.6399 - lr: 6.2500e-05\n",
      "Epoch 205/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2192.9326 - mse: 20797362.0000 - mae: 2193.2278\n",
      "Epoch 205: val_loss did not improve from 2128.86646\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2190.5120 - mse: 20757860.0000 - mae: 2190.8069 - val_loss: 2132.0486 - val_mse: 20425610.0000 - val_mae: 2132.3379 - lr: 3.1250e-05\n",
      "Epoch 206/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2180.0220 - mse: 20392218.0000 - mae: 2180.3193\n",
      "Epoch 206: val_loss did not improve from 2128.86646\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2180.0220 - mse: 20392218.0000 - mae: 2180.3193 - val_loss: 2132.5408 - val_mse: 20223828.0000 - val_mae: 2132.8345 - lr: 3.1250e-05\n",
      "Epoch 207/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2169.6367 - mse: 20223678.0000 - mae: 2169.9399\n",
      "Epoch 207: val_loss did not improve from 2128.86646\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2170.5151 - mse: 20243160.0000 - mae: 2170.8186 - val_loss: 2138.7292 - val_mse: 20397584.0000 - val_mae: 2139.0278 - lr: 3.1250e-05\n",
      "Epoch 208/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2168.2339 - mse: 20174678.0000 - mae: 2168.5361\n",
      "Epoch 208: val_loss improved from 2128.86646 to 2112.41089, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2168.2339 - mse: 20174678.0000 - mae: 2168.5361 - val_loss: 2112.4109 - val_mse: 19948784.0000 - val_mae: 2112.7031 - lr: 3.1250e-05\n",
      "Epoch 209/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2159.1816 - mse: 20124262.0000 - mae: 2159.4866\n",
      "Epoch 209: val_loss did not improve from 2112.41089\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2164.8633 - mse: 20184762.0000 - mae: 2165.1689 - val_loss: 2136.0142 - val_mse: 20393982.0000 - val_mae: 2136.2910 - lr: 3.1250e-05\n",
      "Epoch 210/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2157.5847 - mse: 19989884.0000 - mae: 2157.8823\n",
      "Epoch 210: val_loss did not improve from 2112.41089\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2157.5847 - mse: 19989884.0000 - mae: 2157.8823 - val_loss: 2131.0642 - val_mse: 20308822.0000 - val_mae: 2131.3601 - lr: 3.1250e-05\n",
      "Epoch 211/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2173.2397 - mse: 20242906.0000 - mae: 2173.5361\n",
      "Epoch 211: val_loss did not improve from 2112.41089\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2174.4651 - mse: 20257540.0000 - mae: 2174.7615 - val_loss: 2127.6990 - val_mse: 20075670.0000 - val_mae: 2127.9849 - lr: 3.1250e-05\n",
      "Epoch 212/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2169.1475 - mse: 20273078.0000 - mae: 2169.4448\n",
      "Epoch 212: val_loss did not improve from 2112.41089\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2169.4041 - mse: 20266794.0000 - mae: 2169.7017 - val_loss: 2135.4653 - val_mse: 20083340.0000 - val_mae: 2135.7571 - lr: 3.1250e-05\n",
      "Epoch 213/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2164.6687 - mse: 20190758.0000 - mae: 2164.9651\n",
      "Epoch 213: val_loss did not improve from 2112.41089\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2171.2021 - mse: 20296562.0000 - mae: 2171.4990 - val_loss: 2138.7336 - val_mse: 20162482.0000 - val_mae: 2139.0232 - lr: 3.1250e-05\n",
      "Epoch 214/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2163.8440 - mse: 20158210.0000 - mae: 2164.1404\n",
      "Epoch 214: val_loss did not improve from 2112.41089\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2169.7036 - mse: 20266938.0000 - mae: 2170.0002 - val_loss: 2129.5813 - val_mse: 20262968.0000 - val_mae: 2129.8655 - lr: 3.1250e-05\n",
      "Epoch 215/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2161.6262 - mse: 19995072.0000 - mae: 2161.9258\n",
      "Epoch 215: val_loss did not improve from 2112.41089\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2162.9067 - mse: 19992588.0000 - mae: 2163.2063 - val_loss: 2135.2664 - val_mse: 20371952.0000 - val_mae: 2135.5493 - lr: 3.1250e-05\n",
      "Epoch 216/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2140.0798 - mse: 19645150.0000 - mae: 2140.3728\n",
      "Epoch 216: val_loss did not improve from 2112.41089\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2149.0747 - mse: 19749726.0000 - mae: 2149.3682 - val_loss: 2117.0444 - val_mse: 19806426.0000 - val_mae: 2117.3433 - lr: 3.1250e-05\n",
      "Epoch 217/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2156.7039 - mse: 19744664.0000 - mae: 2157.0034\n",
      "Epoch 217: val_loss did not improve from 2112.41089\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2156.0002 - mse: 19717132.0000 - mae: 2156.2996 - val_loss: 2130.5022 - val_mse: 20103538.0000 - val_mae: 2130.7861 - lr: 3.1250e-05\n",
      "Epoch 218/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2155.3533 - mse: 19976100.0000 - mae: 2155.6519\n",
      "Epoch 218: val_loss did not improve from 2112.41089\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2163.1526 - mse: 20053518.0000 - mae: 2163.4517 - val_loss: 2144.2231 - val_mse: 20220072.0000 - val_mae: 2144.5222 - lr: 3.1250e-05\n",
      "Epoch 219/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2177.9414 - mse: 20300630.0000 - mae: 2178.2422\n",
      "Epoch 219: val_loss did not improve from 2112.41089\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2178.3057 - mse: 20295992.0000 - mae: 2178.6064 - val_loss: 2116.6401 - val_mse: 19994148.0000 - val_mae: 2116.9368 - lr: 1.5625e-05\n",
      "Epoch 220/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2170.8049 - mse: 20291844.0000 - mae: 2171.1074\n",
      "Epoch 220: val_loss did not improve from 2112.41089\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2169.8867 - mse: 20261588.0000 - mae: 2170.1897 - val_loss: 2120.4404 - val_mse: 19975396.0000 - val_mae: 2120.7358 - lr: 1.5625e-05\n",
      "Epoch 221/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2157.7991 - mse: 19958730.0000 - mae: 2158.0986\n",
      "Epoch 221: val_loss did not improve from 2112.41089\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2166.4026 - mse: 20091348.0000 - mae: 2166.7024 - val_loss: 2116.2827 - val_mse: 20053104.0000 - val_mae: 2116.5803 - lr: 1.5625e-05\n",
      "Epoch 222/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2156.0991 - mse: 19920170.0000 - mae: 2156.3992\n",
      "Epoch 222: val_loss improved from 2112.41089 to 2106.75781, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2157.8479 - mse: 19927488.0000 - mae: 2158.1479 - val_loss: 2106.7578 - val_mse: 19945842.0000 - val_mae: 2107.0527 - lr: 1.5625e-05\n",
      "Epoch 223/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2154.2175 - mse: 19943130.0000 - mae: 2154.5159\n",
      "Epoch 223: val_loss did not improve from 2106.75781\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2159.1091 - mse: 20033892.0000 - mae: 2159.4080 - val_loss: 2110.1655 - val_mse: 19970280.0000 - val_mae: 2110.4631 - lr: 1.5625e-05\n",
      "Epoch 224/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2144.0776 - mse: 19822294.0000 - mae: 2144.3760\n",
      "Epoch 224: val_loss did not improve from 2106.75781\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2144.7959 - mse: 19807134.0000 - mae: 2145.0945 - val_loss: 2110.9121 - val_mse: 19847118.0000 - val_mae: 2111.2056 - lr: 1.5625e-05\n",
      "Epoch 225/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2127.2620 - mse: 19294096.0000 - mae: 2127.5598\n",
      "Epoch 225: val_loss did not improve from 2106.75781\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2142.2080 - mse: 19543346.0000 - mae: 2142.5068 - val_loss: 2132.5415 - val_mse: 20217440.0000 - val_mae: 2132.8340 - lr: 1.5625e-05\n",
      "Epoch 226/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2139.7122 - mse: 19344920.0000 - mae: 2140.0117\n",
      "Epoch 226: val_loss did not improve from 2106.75781\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2137.5249 - mse: 19307656.0000 - mae: 2137.8247 - val_loss: 2111.9668 - val_mse: 19776340.0000 - val_mae: 2112.2603 - lr: 1.5625e-05\n",
      "Epoch 227/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2129.1895 - mse: 19272936.0000 - mae: 2129.4849\n",
      "Epoch 227: val_loss improved from 2106.75781 to 2105.44360, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2133.8064 - mse: 19278750.0000 - mae: 2134.1023 - val_loss: 2105.4436 - val_mse: 19766424.0000 - val_mae: 2105.7375 - lr: 1.5625e-05\n",
      "Epoch 228/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2129.2859 - mse: 19312504.0000 - mae: 2129.5830\n",
      "Epoch 228: val_loss improved from 2105.44360 to 2086.23218, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2129.0601 - mse: 19304602.0000 - mae: 2129.3572 - val_loss: 2086.2322 - val_mse: 19365398.0000 - val_mae: 2086.5291 - lr: 1.5625e-05\n",
      "Epoch 229/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2121.3755 - mse: 19098032.0000 - mae: 2121.6743\n",
      "Epoch 229: val_loss improved from 2086.23218 to 2076.72437, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2121.6160 - mse: 19092608.0000 - mae: 2121.9148 - val_loss: 2076.7244 - val_mse: 19220822.0000 - val_mae: 2077.0181 - lr: 1.5625e-05\n",
      "Epoch 230/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2122.4900 - mse: 19087928.0000 - mae: 2122.7871\n",
      "Epoch 230: val_loss did not improve from 2076.72437\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2122.5789 - mse: 19090850.0000 - mae: 2122.8762 - val_loss: 2099.9756 - val_mse: 19351900.0000 - val_mae: 2100.2747 - lr: 1.5625e-05\n",
      "Epoch 231/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2127.9165 - mse: 19203782.0000 - mae: 2128.2153\n",
      "Epoch 231: val_loss did not improve from 2076.72437\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2127.1208 - mse: 19177636.0000 - mae: 2127.4199 - val_loss: 2098.1743 - val_mse: 19360596.0000 - val_mae: 2098.4709 - lr: 1.5625e-05\n",
      "Epoch 232/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2125.2512 - mse: 19234508.0000 - mae: 2125.5525\n",
      "Epoch 232: val_loss did not improve from 2076.72437\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2128.1448 - mse: 19261684.0000 - mae: 2128.4460 - val_loss: 2093.8276 - val_mse: 19595582.0000 - val_mae: 2094.1230 - lr: 1.5625e-05\n",
      "Epoch 233/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2118.6707 - mse: 19201752.0000 - mae: 2118.9658\n",
      "Epoch 233: val_loss improved from 2076.72437 to 2068.29614, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2123.0527 - mse: 19278222.0000 - mae: 2123.3481 - val_loss: 2068.2961 - val_mse: 19269722.0000 - val_mae: 2068.5896 - lr: 1.5625e-05\n",
      "Epoch 234/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2126.4402 - mse: 19276360.0000 - mae: 2126.7415\n",
      "Epoch 234: val_loss improved from 2068.29614 to 2067.32007, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2126.4402 - mse: 19276360.0000 - mae: 2126.7415 - val_loss: 2067.3201 - val_mse: 19173802.0000 - val_mae: 2067.6128 - lr: 1.5625e-05\n",
      "Epoch 235/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2121.0244 - mse: 19238920.0000 - mae: 2121.3220\n",
      "Epoch 235: val_loss did not improve from 2067.32007\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2121.0688 - mse: 19225980.0000 - mae: 2121.3667 - val_loss: 2073.2798 - val_mse: 19611970.0000 - val_mae: 2073.5679 - lr: 1.5625e-05\n",
      "Epoch 236/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2117.7788 - mse: 19209930.0000 - mae: 2118.0769\n",
      "Epoch 236: val_loss did not improve from 2067.32007\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2122.5671 - mse: 19285788.0000 - mae: 2122.8655 - val_loss: 2076.7205 - val_mse: 19309768.0000 - val_mae: 2077.0171 - lr: 1.5625e-05\n",
      "Epoch 237/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2110.1946 - mse: 18910248.0000 - mae: 2110.4966\n",
      "Epoch 237: val_loss did not improve from 2067.32007\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2115.1924 - mse: 19005610.0000 - mae: 2115.4944 - val_loss: 2087.7239 - val_mse: 19510252.0000 - val_mae: 2088.0127 - lr: 1.5625e-05\n",
      "Epoch 238/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2112.4092 - mse: 19028372.0000 - mae: 2112.7078\n",
      "Epoch 238: val_loss did not improve from 2067.32007\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2110.7676 - mse: 18986880.0000 - mae: 2111.0664 - val_loss: 2103.4453 - val_mse: 19797072.0000 - val_mae: 2103.7397 - lr: 1.5625e-05\n",
      "Epoch 239/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2107.6504 - mse: 18985266.0000 - mae: 2107.9463\n",
      "Epoch 239: val_loss did not improve from 2067.32007\n",
      "436/436 [==============================] - 3s 6ms/step - loss: 2107.6504 - mse: 18985266.0000 - mae: 2107.9463 - val_loss: 2084.2920 - val_mse: 19367440.0000 - val_mae: 2084.5818 - lr: 1.5625e-05\n",
      "Epoch 240/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2108.9636 - mse: 18980648.0000 - mae: 2109.2581\n",
      "Epoch 240: val_loss did not improve from 2067.32007\n",
      "436/436 [==============================] - 4s 10ms/step - loss: 2110.3569 - mse: 19003622.0000 - mae: 2110.6514 - val_loss: 2077.7202 - val_mse: 19345290.0000 - val_mae: 2078.0122 - lr: 1.5625e-05\n",
      "Epoch 241/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2107.7681 - mse: 18961260.0000 - mae: 2108.0635\n",
      "Epoch 241: val_loss did not improve from 2067.32007\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2108.3650 - mse: 18966582.0000 - mae: 2108.6602 - val_loss: 2071.1821 - val_mse: 19093232.0000 - val_mae: 2071.4717 - lr: 1.5625e-05\n",
      "Epoch 242/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2113.5266 - mse: 19076666.0000 - mae: 2113.8245\n",
      "Epoch 242: val_loss did not improve from 2067.32007\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2113.5266 - mse: 19076666.0000 - mae: 2113.8245 - val_loss: 2077.7957 - val_mse: 19236440.0000 - val_mae: 2078.0876 - lr: 1.5625e-05\n",
      "Epoch 243/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2109.1201 - mse: 19051562.0000 - mae: 2109.4160\n",
      "Epoch 243: val_loss did not improve from 2067.32007\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2111.2607 - mse: 19073572.0000 - mae: 2111.5566 - val_loss: 2071.0393 - val_mse: 19256122.0000 - val_mae: 2071.3320 - lr: 1.5625e-05\n",
      "Epoch 244/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2103.0068 - mse: 18882856.0000 - mae: 2103.3054\n",
      "Epoch 244: val_loss did not improve from 2067.32007\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2113.9119 - mse: 19027612.0000 - mae: 2114.2112 - val_loss: 2084.2100 - val_mse: 19467174.0000 - val_mae: 2084.5034 - lr: 1.5625e-05\n",
      "Epoch 245/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2116.0166 - mse: 19057620.0000 - mae: 2116.3176\n",
      "Epoch 245: val_loss did not improve from 2067.32007\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2115.6006 - mse: 19046738.0000 - mae: 2115.9019 - val_loss: 2069.9006 - val_mse: 19312878.0000 - val_mae: 2070.1895 - lr: 7.8125e-06\n",
      "Epoch 246/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2110.9800 - mse: 19005458.0000 - mae: 2111.2793\n",
      "Epoch 246: val_loss did not improve from 2067.32007\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2112.7085 - mse: 19006970.0000 - mae: 2113.0078 - val_loss: 2068.6921 - val_mse: 19290294.0000 - val_mae: 2068.9824 - lr: 7.8125e-06\n",
      "Epoch 247/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2105.4614 - mse: 18927440.0000 - mae: 2105.7598\n",
      "Epoch 247: val_loss did not improve from 2067.32007\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2105.4614 - mse: 18927440.0000 - mae: 2105.7598 - val_loss: 2070.0000 - val_mse: 19276702.0000 - val_mae: 2070.2930 - lr: 7.8125e-06\n",
      "Epoch 248/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2104.0876 - mse: 18908162.0000 - mae: 2104.3901\n",
      "Epoch 248: val_loss did not improve from 2067.32007\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2103.5217 - mse: 18883436.0000 - mae: 2103.8242 - val_loss: 2070.5920 - val_mse: 19317992.0000 - val_mae: 2070.8813 - lr: 7.8125e-06\n",
      "Epoch 249/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2104.8401 - mse: 18932714.0000 - mae: 2105.1375\n",
      "Epoch 249: val_loss did not improve from 2067.32007\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2105.7295 - mse: 18941118.0000 - mae: 2106.0271 - val_loss: 2070.9478 - val_mse: 19328574.0000 - val_mae: 2071.2368 - lr: 7.8125e-06\n",
      "Epoch 250/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2107.8159 - mse: 18991880.0000 - mae: 2108.1152\n",
      "Epoch 250: val_loss improved from 2067.32007 to 2060.24707, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2106.7336 - mse: 18977482.0000 - mae: 2107.0330 - val_loss: 2060.2471 - val_mse: 19147864.0000 - val_mae: 2060.5371 - lr: 7.8125e-06\n",
      "Epoch 251/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2100.0952 - mse: 18834178.0000 - mae: 2100.3953\n",
      "Epoch 251: val_loss did not improve from 2060.24707\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2099.8203 - mse: 18823684.0000 - mae: 2100.1206 - val_loss: 2067.9197 - val_mse: 19133196.0000 - val_mae: 2068.2095 - lr: 7.8125e-06\n",
      "Epoch 252/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2093.2974 - mse: 18716232.0000 - mae: 2093.5940\n",
      "Epoch 252: val_loss improved from 2060.24707 to 2060.22949, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2099.0093 - mse: 18844562.0000 - mae: 2099.3059 - val_loss: 2060.2295 - val_mse: 19150602.0000 - val_mae: 2060.5168 - lr: 7.8125e-06\n",
      "Epoch 253/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2097.5640 - mse: 18835232.0000 - mae: 2097.8594\n",
      "Epoch 253: val_loss did not improve from 2060.22949\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2097.1404 - mse: 18823264.0000 - mae: 2097.4358 - val_loss: 2065.9534 - val_mse: 19237806.0000 - val_mae: 2066.2434 - lr: 7.8125e-06\n",
      "Epoch 254/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2094.0994 - mse: 18804618.0000 - mae: 2094.3992\n",
      "Epoch 254: val_loss did not improve from 2060.22949\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2096.4998 - mse: 18813938.0000 - mae: 2096.7998 - val_loss: 2069.0264 - val_mse: 19251892.0000 - val_mae: 2069.3140 - lr: 7.8125e-06\n",
      "Epoch 255/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2100.9507 - mse: 18814498.0000 - mae: 2101.2488\n",
      "Epoch 255: val_loss did not improve from 2060.22949\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2100.2805 - mse: 18806984.0000 - mae: 2100.5784 - val_loss: 2087.2266 - val_mse: 19577086.0000 - val_mae: 2087.5144 - lr: 7.8125e-06\n",
      "Epoch 256/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2098.5637 - mse: 18726884.0000 - mae: 2098.8613\n",
      "Epoch 256: val_loss did not improve from 2060.22949\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2104.0969 - mse: 18780836.0000 - mae: 2104.3953 - val_loss: 2081.9302 - val_mse: 19261846.0000 - val_mae: 2082.2195 - lr: 7.8125e-06\n",
      "Epoch 257/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2102.5059 - mse: 18771704.0000 - mae: 2102.8049\n",
      "Epoch 257: val_loss did not improve from 2060.22949\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2106.9358 - mse: 18806770.0000 - mae: 2107.2354 - val_loss: 2080.0044 - val_mse: 19203728.0000 - val_mae: 2080.2920 - lr: 7.8125e-06\n",
      "Epoch 258/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2100.0098 - mse: 18846484.0000 - mae: 2100.3083\n",
      "Epoch 258: val_loss did not improve from 2060.22949\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2105.9983 - mse: 18899390.0000 - mae: 2106.2974 - val_loss: 2070.8262 - val_mse: 19256272.0000 - val_mae: 2071.1172 - lr: 7.8125e-06\n",
      "Epoch 259/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2102.4221 - mse: 18831788.0000 - mae: 2102.7195\n",
      "Epoch 259: val_loss did not improve from 2060.22949\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2103.2876 - mse: 18846336.0000 - mae: 2103.5847 - val_loss: 2066.3252 - val_mse: 19214702.0000 - val_mae: 2066.6165 - lr: 7.8125e-06\n",
      "Epoch 260/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2097.8884 - mse: 18813718.0000 - mae: 2098.1853\n",
      "Epoch 260: val_loss did not improve from 2060.22949\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2098.7393 - mse: 18817142.0000 - mae: 2099.0364 - val_loss: 2071.9858 - val_mse: 19183018.0000 - val_mae: 2072.2754 - lr: 7.8125e-06\n",
      "Epoch 261/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2092.4966 - mse: 18789838.0000 - mae: 2092.7942\n",
      "Epoch 261: val_loss improved from 2060.22949 to 2057.78687, saving model to new_stne_lstm_weight.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2095.8799 - mse: 18824746.0000 - mae: 2096.1780 - val_loss: 2057.7869 - val_mse: 19131822.0000 - val_mae: 2058.0767 - lr: 7.8125e-06\n",
      "Epoch 262/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2099.2700 - mse: 18847536.0000 - mae: 2099.5679\n",
      "Epoch 262: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2098.8425 - mse: 18839644.0000 - mae: 2099.1404 - val_loss: 2075.4380 - val_mse: 19394044.0000 - val_mae: 2075.7261 - lr: 7.8125e-06\n",
      "Epoch 263/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2093.1755 - mse: 18700290.0000 - mae: 2093.4712\n",
      "Epoch 263: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2097.8125 - mse: 18760856.0000 - mae: 2098.1084 - val_loss: 2078.3130 - val_mse: 19463068.0000 - val_mae: 2078.6028 - lr: 7.8125e-06\n",
      "Epoch 264/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2096.3862 - mse: 18813828.0000 - mae: 2096.6829\n",
      "Epoch 264: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2098.9653 - mse: 18818350.0000 - mae: 2099.2625 - val_loss: 2074.7498 - val_mse: 19422088.0000 - val_mae: 2075.0386 - lr: 7.8125e-06\n",
      "Epoch 265/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2092.9033 - mse: 18755042.0000 - mae: 2093.2014\n",
      "Epoch 265: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2093.3269 - mse: 18751196.0000 - mae: 2093.6250 - val_loss: 2062.8972 - val_mse: 19224640.0000 - val_mae: 2063.1870 - lr: 7.8125e-06\n",
      "Epoch 266/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2091.3809 - mse: 18731234.0000 - mae: 2091.6794\n",
      "Epoch 266: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2091.4617 - mse: 18733296.0000 - mae: 2091.7605 - val_loss: 2060.3374 - val_mse: 19070594.0000 - val_mae: 2060.6240 - lr: 7.8125e-06\n",
      "Epoch 267/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2096.4893 - mse: 18732266.0000 - mae: 2096.7856\n",
      "Epoch 267: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2095.2766 - mse: 18715798.0000 - mae: 2095.5730 - val_loss: 2064.3831 - val_mse: 19227328.0000 - val_mae: 2064.6709 - lr: 7.8125e-06\n",
      "Epoch 268/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2094.3096 - mse: 18782430.0000 - mae: 2094.6060\n",
      "Epoch 268: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2094.4512 - mse: 18783716.0000 - mae: 2094.7473 - val_loss: 2079.3086 - val_mse: 19550526.0000 - val_mae: 2079.5955 - lr: 7.8125e-06\n",
      "Epoch 269/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2084.4268 - mse: 18605864.0000 - mae: 2084.7231\n",
      "Epoch 269: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2093.1758 - mse: 18744538.0000 - mae: 2093.4729 - val_loss: 2077.4744 - val_mse: 19568664.0000 - val_mae: 2077.7637 - lr: 7.8125e-06\n",
      "Epoch 270/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2091.9971 - mse: 18644396.0000 - mae: 2092.2942\n",
      "Epoch 270: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2094.3416 - mse: 18680680.0000 - mae: 2094.6387 - val_loss: 2083.4675 - val_mse: 19569492.0000 - val_mae: 2083.7563 - lr: 7.8125e-06\n",
      "Epoch 271/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2097.5557 - mse: 18667236.0000 - mae: 2097.8523\n",
      "Epoch 271: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2102.5205 - mse: 18718256.0000 - mae: 2102.8174 - val_loss: 2083.9851 - val_mse: 19568126.0000 - val_mae: 2084.2742 - lr: 7.8125e-06\n",
      "Epoch 272/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2094.7041 - mse: 18734770.0000 - mae: 2095.0029\n",
      "Epoch 272: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2093.9009 - mse: 18696570.0000 - mae: 2094.2002 - val_loss: 2074.4592 - val_mse: 19358442.0000 - val_mae: 2074.7480 - lr: 3.9063e-06\n",
      "Epoch 273/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2085.6726 - mse: 18545036.0000 - mae: 2085.9700\n",
      "Epoch 273: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2089.7651 - mse: 18623014.0000 - mae: 2090.0625 - val_loss: 2071.0552 - val_mse: 19356732.0000 - val_mae: 2071.3420 - lr: 3.9063e-06\n",
      "Epoch 274/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2090.9106 - mse: 18708954.0000 - mae: 2091.2090\n",
      "Epoch 274: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2090.5974 - mse: 18683870.0000 - mae: 2090.8958 - val_loss: 2078.6787 - val_mse: 19522902.0000 - val_mae: 2078.9651 - lr: 3.9063e-06\n",
      "Epoch 275/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2092.6699 - mse: 18680194.0000 - mae: 2092.9678\n",
      "Epoch 275: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2091.3264 - mse: 18651504.0000 - mae: 2091.6243 - val_loss: 2077.3589 - val_mse: 19396068.0000 - val_mae: 2077.6436 - lr: 3.9063e-06\n",
      "Epoch 276/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2077.4937 - mse: 18521530.0000 - mae: 2077.7893\n",
      "Epoch 276: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2088.2112 - mse: 18619982.0000 - mae: 2088.5073 - val_loss: 2077.7722 - val_mse: 19461308.0000 - val_mae: 2078.0571 - lr: 3.9063e-06\n",
      "Epoch 277/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2090.1855 - mse: 18647728.0000 - mae: 2090.4814\n",
      "Epoch 277: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2088.9294 - mse: 18628152.0000 - mae: 2089.2256 - val_loss: 2075.5940 - val_mse: 19406482.0000 - val_mae: 2075.8792 - lr: 3.9063e-06\n",
      "Epoch 278/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2088.2126 - mse: 18613746.0000 - mae: 2088.5098\n",
      "Epoch 278: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2088.6619 - mse: 18626402.0000 - mae: 2088.9587 - val_loss: 2074.2236 - val_mse: 19389376.0000 - val_mae: 2074.5100 - lr: 3.9063e-06\n",
      "Epoch 279/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2083.3787 - mse: 18567518.0000 - mae: 2083.6753\n",
      "Epoch 279: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2087.6440 - mse: 18632920.0000 - mae: 2087.9407 - val_loss: 2071.4692 - val_mse: 19310308.0000 - val_mae: 2071.7551 - lr: 3.9063e-06\n",
      "Epoch 280/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2084.9153 - mse: 18627926.0000 - mae: 2085.2134\n",
      "Epoch 280: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 4s 10ms/step - loss: 2087.2180 - mse: 18632962.0000 - mae: 2087.5166 - val_loss: 2070.7583 - val_mse: 19338290.0000 - val_mae: 2071.0437 - lr: 3.9063e-06\n",
      "Epoch 281/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2083.7656 - mse: 18599874.0000 - mae: 2084.0615\n",
      "Epoch 281: val_loss did not improve from 2057.78687\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2086.3713 - mse: 18616794.0000 - mae: 2086.6675 - val_loss: 2071.5842 - val_mse: 19397916.0000 - val_mae: 2071.8687 - lr: 3.9063e-06\n",
      "Epoch 1/500\n",
      "    436/Unknown - 4s 8ms/step - loss: 2086.7529 - mse: 18664468.0000 - mae: 2087.0503\n",
      "Epoch 1: val_loss improved from inf to 2070.23022, saving model to new_stne_lstm_weight_ns.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2086.7529 - mse: 18664468.0000 - mae: 2087.0503 - val_loss: 2070.2302 - val_mse: 19385802.0000 - val_mae: 2070.5142 - lr: 1.9531e-06\n",
      "Epoch 2/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2076.3906 - mse: 18564694.0000 - mae: 2076.6882\n",
      "Epoch 2: val_loss improved from 2070.23022 to 2069.91162, saving model to new_stne_lstm_weight_ns.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2085.6436 - mse: 18654718.0000 - mae: 2085.9414 - val_loss: 2069.9116 - val_mse: 19380140.0000 - val_mae: 2070.1960 - lr: 1.9531e-06\n",
      "Epoch 3/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2077.6272 - mse: 18552030.0000 - mae: 2077.9221\n",
      "Epoch 3: val_loss improved from 2069.91162 to 2069.75952, saving model to new_stne_lstm_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2085.9636 - mse: 18649780.0000 - mae: 2086.2590 - val_loss: 2069.7595 - val_mse: 19380116.0000 - val_mae: 2070.0435 - lr: 1.9531e-06\n",
      "Epoch 4/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2077.7444 - mse: 18575348.0000 - mae: 2078.0405\n",
      "Epoch 4: val_loss did not improve from 2069.75952\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2084.9231 - mse: 18648538.0000 - mae: 2085.2200 - val_loss: 2073.2510 - val_mse: 19419794.0000 - val_mae: 2073.5339 - lr: 1.9531e-06\n",
      "Epoch 5/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2086.1821 - mse: 18669288.0000 - mae: 2086.4788\n",
      "Epoch 5: val_loss did not improve from 2069.75952\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2086.4214 - mse: 18660298.0000 - mae: 2086.7183 - val_loss: 2073.4956 - val_mse: 19413492.0000 - val_mae: 2073.7798 - lr: 1.9531e-06\n",
      "Epoch 6/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2081.6992 - mse: 18604736.0000 - mae: 2081.9963\n",
      "Epoch 6: val_loss did not improve from 2069.75952\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2086.1201 - mse: 18656898.0000 - mae: 2086.4172 - val_loss: 2071.0891 - val_mse: 19399094.0000 - val_mae: 2071.3728 - lr: 1.9531e-06\n",
      "Epoch 7/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2084.4136 - mse: 18633546.0000 - mae: 2084.7097\n",
      "Epoch 7: val_loss did not improve from 2069.75952\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2084.6504 - mse: 18624570.0000 - mae: 2084.9468 - val_loss: 2071.0420 - val_mse: 19404272.0000 - val_mae: 2071.3247 - lr: 1.9531e-06\n",
      "Epoch 8/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2075.9812 - mse: 18551886.0000 - mae: 2076.2756\n",
      "Epoch 8: val_loss did not improve from 2069.75952\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2085.1436 - mse: 18641382.0000 - mae: 2085.4387 - val_loss: 2072.3018 - val_mse: 19403824.0000 - val_mae: 2072.5864 - lr: 1.9531e-06\n",
      "Epoch 9/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2085.2886 - mse: 18659200.0000 - mae: 2085.5862\n",
      "Epoch 9: val_loss did not improve from 2069.75952\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2085.5261 - mse: 18650188.0000 - mae: 2085.8240 - val_loss: 2071.2869 - val_mse: 19406112.0000 - val_mae: 2071.5703 - lr: 1.9531e-06\n",
      "Epoch 10/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2077.7139 - mse: 18518200.0000 - mae: 2078.0093\n",
      "Epoch 10: val_loss did not improve from 2069.75952\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2082.1882 - mse: 18571188.0000 - mae: 2082.4836 - val_loss: 2070.1877 - val_mse: 19382564.0000 - val_mae: 2070.4712 - lr: 1.9531e-06\n",
      "Epoch 11/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2084.2444 - mse: 18644848.0000 - mae: 2084.5410\n",
      "Epoch 11: val_loss did not improve from 2069.75952\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2084.4795 - mse: 18635828.0000 - mae: 2084.7761 - val_loss: 2070.8823 - val_mse: 19402480.0000 - val_mae: 2071.1655 - lr: 1.9531e-06\n",
      "Epoch 12/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2083.3899 - mse: 18619334.0000 - mae: 2083.6875\n",
      "Epoch 12: val_loss did not improve from 2069.75952\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2083.6245 - mse: 18610336.0000 - mae: 2083.9226 - val_loss: 2070.3606 - val_mse: 19407378.0000 - val_mae: 2070.6438 - lr: 1.9531e-06\n",
      "Epoch 13/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2075.6099 - mse: 18534000.0000 - mae: 2075.9072\n",
      "Epoch 13: val_loss did not improve from 2069.75952\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2083.9180 - mse: 18631770.0000 - mae: 2084.2156 - val_loss: 2070.9719 - val_mse: 19396496.0000 - val_mae: 2071.2561 - lr: 1.9531e-06\n",
      "Epoch 14/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2071.9326 - mse: 18455192.0000 - mae: 2072.2283\n",
      "Epoch 14: val_loss improved from 2069.75952 to 2069.00537, saving model to new_stne_lstm_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2080.4478 - mse: 18555102.0000 - mae: 2080.7434 - val_loss: 2069.0054 - val_mse: 19366192.0000 - val_mae: 2069.2893 - lr: 9.7656e-07\n",
      "Epoch 15/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2075.4097 - mse: 18490908.0000 - mae: 2075.7075\n",
      "Epoch 15: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2080.1838 - mse: 18547448.0000 - mae: 2080.4819 - val_loss: 2069.3152 - val_mse: 19343252.0000 - val_mae: 2069.5984 - lr: 9.7656e-07\n",
      "Epoch 16/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2071.4434 - mse: 18448518.0000 - mae: 2071.7400\n",
      "Epoch 16: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2080.0693 - mse: 18550108.0000 - mae: 2080.3665 - val_loss: 2070.3650 - val_mse: 19353136.0000 - val_mae: 2070.6479 - lr: 9.7656e-07\n",
      "Epoch 17/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2072.4351 - mse: 18472640.0000 - mae: 2072.7336\n",
      "Epoch 17: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2079.9385 - mse: 18550238.0000 - mae: 2080.2373 - val_loss: 2071.3406 - val_mse: 19366392.0000 - val_mae: 2071.6240 - lr: 9.7656e-07\n",
      "Epoch 18/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2078.6758 - mse: 18547212.0000 - mae: 2078.9734\n",
      "Epoch 18: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2079.6216 - mse: 18550060.0000 - mae: 2079.9197 - val_loss: 2071.6455 - val_mse: 19377394.0000 - val_mae: 2071.9285 - lr: 9.7656e-07\n",
      "Epoch 19/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2070.2776 - mse: 18457452.0000 - mae: 2070.5774\n",
      "Epoch 19: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2079.6467 - mse: 18549460.0000 - mae: 2079.9470 - val_loss: 2071.4807 - val_mse: 19373168.0000 - val_mae: 2071.7634 - lr: 9.7656e-07\n",
      "Epoch 20/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2070.2175 - mse: 18457976.0000 - mae: 2070.5134\n",
      "Epoch 20: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2079.4895 - mse: 18549226.0000 - mae: 2079.7861 - val_loss: 2071.0327 - val_mse: 19371784.0000 - val_mae: 2071.3159 - lr: 9.7656e-07\n",
      "Epoch 21/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2070.9470 - mse: 18452104.0000 - mae: 2071.2458\n",
      "Epoch 21: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2079.3757 - mse: 18551262.0000 - mae: 2079.6748 - val_loss: 2070.8359 - val_mse: 19372062.0000 - val_mae: 2071.1187 - lr: 9.7656e-07\n",
      "Epoch 22/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2071.0764 - mse: 18449030.0000 - mae: 2071.3745\n",
      "Epoch 22: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2079.5908 - mse: 18549014.0000 - mae: 2079.8892 - val_loss: 2070.9077 - val_mse: 19370784.0000 - val_mae: 2071.1904 - lr: 9.7656e-07\n",
      "Epoch 23/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2069.8169 - mse: 18449044.0000 - mae: 2070.1130\n",
      "Epoch 23: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2079.3464 - mse: 18543400.0000 - mae: 2079.6428 - val_loss: 2069.3936 - val_mse: 19349308.0000 - val_mae: 2069.6772 - lr: 9.7656e-07\n",
      "Epoch 24/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2077.9250 - mse: 18536284.0000 - mae: 2078.2229\n",
      "Epoch 24: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2079.0088 - mse: 18540968.0000 - mae: 2079.3069 - val_loss: 2069.8157 - val_mse: 19354812.0000 - val_mae: 2070.0991 - lr: 9.7656e-07\n",
      "Epoch 25/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2068.7732 - mse: 18437210.0000 - mae: 2069.0706\n",
      "Epoch 25: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2078.2800 - mse: 18531036.0000 - mae: 2078.5781 - val_loss: 2070.0330 - val_mse: 19356238.0000 - val_mae: 2070.3162 - lr: 4.8828e-07\n",
      "Epoch 26/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2077.7019 - mse: 18538570.0000 - mae: 2077.9990\n",
      "Epoch 26: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2078.1819 - mse: 18531370.0000 - mae: 2078.4790 - val_loss: 2070.6736 - val_mse: 19359540.0000 - val_mae: 2070.9565 - lr: 4.8828e-07\n",
      "Epoch 27/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2078.0239 - mse: 18530336.0000 - mae: 2078.3213\n",
      "Epoch 27: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2078.0239 - mse: 18530336.0000 - mae: 2078.3213 - val_loss: 2070.8086 - val_mse: 19364088.0000 - val_mae: 2071.0903 - lr: 4.8828e-07\n",
      "Epoch 28/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2073.2329 - mse: 18475856.0000 - mae: 2073.5320\n",
      "Epoch 28: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2077.9094 - mse: 18530714.0000 - mae: 2078.2087 - val_loss: 2070.8074 - val_mse: 19363736.0000 - val_mae: 2071.0889 - lr: 4.8828e-07\n",
      "Epoch 29/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2076.8789 - mse: 18526398.0000 - mae: 2077.1775\n",
      "Epoch 29: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2077.9060 - mse: 18530248.0000 - mae: 2078.2046 - val_loss: 2070.7073 - val_mse: 19364492.0000 - val_mae: 2070.9900 - lr: 4.8828e-07\n",
      "Epoch 30/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2077.9106 - mse: 18529686.0000 - mae: 2078.2095\n",
      "Epoch 30: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2077.9106 - mse: 18529686.0000 - mae: 2078.2095 - val_loss: 2070.4443 - val_mse: 19356864.0000 - val_mae: 2070.7266 - lr: 4.8828e-07\n",
      "Epoch 31/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2077.9592 - mse: 18528880.0000 - mae: 2078.2561\n",
      "Epoch 31: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2077.9592 - mse: 18528880.0000 - mae: 2078.2561 - val_loss: 2070.5947 - val_mse: 19361186.0000 - val_mae: 2070.8767 - lr: 4.8828e-07\n",
      "Epoch 32/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2077.3674 - mse: 18535722.0000 - mae: 2077.6643\n",
      "Epoch 32: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2077.8376 - mse: 18528420.0000 - mae: 2078.1345 - val_loss: 2070.5002 - val_mse: 19359032.0000 - val_mae: 2070.7827 - lr: 4.8828e-07\n",
      "Epoch 33/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2070.3962 - mse: 18451442.0000 - mae: 2070.6938\n",
      "Epoch 33: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2077.8679 - mse: 18528596.0000 - mae: 2078.1658 - val_loss: 2070.5229 - val_mse: 19359204.0000 - val_mae: 2070.8064 - lr: 4.8828e-07\n",
      "Epoch 34/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2073.0979 - mse: 18472964.0000 - mae: 2073.3953\n",
      "Epoch 34: val_loss did not improve from 2069.00537\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2077.7964 - mse: 18528160.0000 - mae: 2078.0942 - val_loss: 2070.5134 - val_mse: 19359050.0000 - val_mae: 2070.7952 - lr: 4.8828e-07\n"
     ]
    }
   ],
   "source": [
    "# loss : 모델이 훈련데이터에 대해 얼마나 잘 학습하고 있는지 평가하는 지표 (모델이 훈련데이터에 미치는 오차의 평균을 나타낸다)\n",
    "# val_loss : 검증 데이터(validation data)에 대한 손실 값으로 검증 데이터를 사용해 모델의 일반화 성능을 평가한다 (즉, 훈련 데이터 외의 데이터에 대해서도 얼마나 잘 예측하는지를 판단)\n",
    "# loss와 val_loss가 크지 않은 모델이 overfitting 되지 않고 이상적인 모델이다!\n",
    "\n",
    "lstm_history = lstm_model.fit(train_data, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_lstm])\n",
    "lstm_history_ns = lstm_model.fit(train_data_ns, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_lstm_ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    436/Unknown - 5s 3ms/step - loss: 7603.6187 - mse: 183063280.0000 - mae: 7603.9780\n",
      "Epoch 1: val_loss improved from inf to 7071.09766, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 6s 5ms/step - loss: 7603.6187 - mse: 183063280.0000 - mae: 7603.9780 - val_loss: 7071.0977 - val_mse: 170232816.0000 - val_mae: 7071.5015 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 7501.5840 - mse: 179422336.0000 - mae: 7502.0303\n",
      "Epoch 2: val_loss improved from 7071.09766 to 6941.60693, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 7505.2988 - mse: 179493248.0000 - mae: 7505.7456 - val_loss: 6941.6069 - val_mse: 165693888.0000 - val_mae: 6942.0771 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "423/436 [============================>.] - ETA: 0s - loss: 7295.5791 - mse: 172775232.0000 - mae: 7296.0640\n",
      "Epoch 3: val_loss improved from 6941.60693 to 6732.31787, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 7319.8965 - mse: 173040976.0000 - mae: 7320.3813 - val_loss: 6732.3179 - val_mse: 158177984.0000 - val_mae: 6732.8110 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 7075.7051 - mse: 164302080.0000 - mae: 7076.2012\n",
      "Epoch 4: val_loss improved from 6732.31787 to 6465.63477, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 7069.3252 - mse: 164126096.0000 - mae: 7069.8208 - val_loss: 6465.6348 - val_mse: 149126336.0000 - val_mae: 6466.1279 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 6783.8052 - mse: 154058240.0000 - mae: 6784.2974\n",
      "Epoch 5: val_loss improved from 6465.63477 to 6200.26514, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 6777.9194 - mse: 153812480.0000 - mae: 6778.4121 - val_loss: 6200.2651 - val_mse: 139204192.0000 - val_mae: 6200.7617 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 6496.2876 - mse: 143343072.0000 - mae: 6496.7798\n",
      "Epoch 6: val_loss improved from 6200.26514 to 5908.17676, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 6489.5381 - mse: 143039600.0000 - mae: 6490.0308 - val_loss: 5908.1768 - val_mse: 128887560.0000 - val_mae: 5908.6665 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "422/436 [============================>.] - ETA: 0s - loss: 6151.5859 - mse: 131281712.0000 - mae: 6152.0723\n",
      "Epoch 7: val_loss improved from 5908.17676 to 5604.00098, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 6176.2729 - mse: 131659640.0000 - mae: 6176.7598 - val_loss: 5604.0010 - val_mse: 117951048.0000 - val_mae: 5604.4858 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 5837.1504 - mse: 120150328.0000 - mae: 5837.6284\n",
      "Epoch 8: val_loss improved from 5604.00098 to 5387.79932, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 5829.1235 - mse: 119896120.0000 - mae: 5829.6021 - val_loss: 5387.7993 - val_mse: 107117256.0000 - val_mae: 5388.2827 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 5524.8076 - mse: 108660120.0000 - mae: 5525.2822\n",
      "Epoch 9: val_loss improved from 5387.79932 to 5028.79590, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 5523.1143 - mse: 108589304.0000 - mae: 5523.5884 - val_loss: 5028.7959 - val_mse: 96594304.0000 - val_mae: 5029.2666 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 5229.7178 - mse: 97871576.0000 - mae: 5230.1812\n",
      "Epoch 10: val_loss improved from 5028.79590 to 4793.39795, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 5ms/step - loss: 5239.2144 - mse: 98038184.0000 - mae: 5239.6787 - val_loss: 4793.3979 - val_mse: 87157824.0000 - val_mae: 4793.8589 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "426/436 [============================>.] - ETA: 0s - loss: 5023.6387 - mse: 89077528.0000 - mae: 5024.0933\n",
      "Epoch 11: val_loss improved from 4793.39795 to 4665.99072, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 5ms/step - loss: 5024.6763 - mse: 88856992.0000 - mae: 5025.1323 - val_loss: 4665.9907 - val_mse: 78753184.0000 - val_mae: 4666.4424 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "423/436 [============================>.] - ETA: 0s - loss: 4777.3799 - mse: 80016632.0000 - mae: 4777.8223\n",
      "Epoch 12: val_loss improved from 4665.99072 to 4436.64502, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 4767.6597 - mse: 79625488.0000 - mae: 4768.1021 - val_loss: 4436.6450 - val_mse: 70742264.0000 - val_mae: 4437.0874 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 4573.1982 - mse: 71820496.0000 - mae: 4573.6392\n",
      "Epoch 13: val_loss improved from 4436.64502 to 4303.55420, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 4569.9731 - mse: 71667912.0000 - mae: 4570.4146 - val_loss: 4303.5542 - val_mse: 64843912.0000 - val_mae: 4303.9873 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 4449.6685 - mse: 66231744.0000 - mae: 4450.0962\n",
      "Epoch 14: val_loss improved from 4303.55420 to 4031.59790, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 4447.7598 - mse: 66157144.0000 - mae: 4448.1870 - val_loss: 4031.5979 - val_mse: 56448036.0000 - val_mae: 4032.0234 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 4094.6052 - mse: 57252948.0000 - mae: 4095.0305\n",
      "Epoch 15: val_loss improved from 4031.59790 to 3836.94336, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 4094.6052 - mse: 57252948.0000 - mae: 4095.0305 - val_loss: 3836.9434 - val_mse: 50680348.0000 - val_mae: 3837.3645 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 4021.6631 - mse: 53321404.0000 - mae: 4022.0742\n",
      "Epoch 16: val_loss did not improve from 3836.94336\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 4029.8708 - mse: 53362552.0000 - mae: 4030.2830 - val_loss: 4026.4692 - val_mse: 50007204.0000 - val_mae: 4026.8789 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 4111.8096 - mse: 53393428.0000 - mae: 4112.2114\n",
      "Epoch 17: val_loss did not improve from 3836.94336\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 4117.8916 - mse: 53464824.0000 - mae: 4118.2935 - val_loss: 4139.2480 - val_mse: 50387800.0000 - val_mae: 4139.6377 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 3984.2417 - mse: 50025208.0000 - mae: 3984.6189\n",
      "Epoch 18: val_loss did not improve from 3836.94336\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 3994.7085 - mse: 50177200.0000 - mae: 3995.0859 - val_loss: 4063.6819 - val_mse: 48652792.0000 - val_mae: 4064.0581 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 3703.8562 - mse: 43574544.0000 - mae: 3704.2307\n",
      "Epoch 19: val_loss improved from 3836.94336 to 3562.42383, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 3704.8701 - mse: 43588760.0000 - mae: 3705.2444 - val_loss: 3562.4238 - val_mse: 39867740.0000 - val_mae: 3562.7964 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "419/436 [===========================>..] - ETA: 0s - loss: 3637.1650 - mse: 42103480.0000 - mae: 3637.5398\n",
      "Epoch 20: val_loss improved from 3562.42383 to 3353.04053, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 3634.3167 - mse: 41929956.0000 - mae: 3634.6924 - val_loss: 3353.0405 - val_mse: 36659808.0000 - val_mae: 3353.4043 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 3337.4094 - mse: 36068460.0000 - mae: 3337.7820\n",
      "Epoch 21: val_loss improved from 3353.04053 to 3152.98755, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 3338.7900 - mse: 36054264.0000 - mae: 3339.1631 - val_loss: 3152.9875 - val_mse: 33067978.0000 - val_mae: 3153.3513 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 3171.5190 - mse: 33016848.0000 - mae: 3171.8828\n",
      "Epoch 22: val_loss improved from 3152.98755 to 3077.09985, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 3177.1960 - mse: 33082146.0000 - mae: 3177.5596 - val_loss: 3077.0999 - val_mse: 30768320.0000 - val_mae: 3077.4480 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 3245.3765 - mse: 33856440.0000 - mae: 3245.7246\n",
      "Epoch 23: val_loss improved from 3077.09985 to 3062.36694, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 3243.6228 - mse: 33824000.0000 - mae: 3243.9709 - val_loss: 3062.3669 - val_mse: 30636536.0000 - val_mae: 3062.7014 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "424/436 [============================>.] - ETA: 0s - loss: 3140.1245 - mse: 32479760.0000 - mae: 3140.4678\n",
      "Epoch 24: val_loss did not improve from 3062.36694\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 3155.4160 - mse: 32717548.0000 - mae: 3155.7605 - val_loss: 3074.1726 - val_mse: 31889414.0000 - val_mae: 3074.5068 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 3338.8577 - mse: 35864084.0000 - mae: 3339.2009\n",
      "Epoch 25: val_loss improved from 3062.36694 to 2960.43018, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 3337.3965 - mse: 35825652.0000 - mae: 3337.7400 - val_loss: 2960.4302 - val_mse: 29779642.0000 - val_mae: 2960.7571 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 3351.9924 - mse: 36261604.0000 - mae: 3352.3203\n",
      "Epoch 26: val_loss did not improve from 2960.43018\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 3352.7605 - mse: 36271844.0000 - mae: 3353.0884 - val_loss: 3145.4043 - val_mse: 31249896.0000 - val_mae: 3145.7349 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "423/436 [============================>.] - ETA: 0s - loss: 3142.8782 - mse: 32366878.0000 - mae: 3143.2136\n",
      "Epoch 27: val_loss improved from 2960.43018 to 2902.36914, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 3141.3733 - mse: 32334982.0000 - mae: 3141.7083 - val_loss: 2902.3691 - val_mse: 29023646.0000 - val_mae: 2902.6843 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 3071.4985 - mse: 32150498.0000 - mae: 3071.8264\n",
      "Epoch 28: val_loss did not improve from 2902.36914\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 3070.2532 - mse: 32119912.0000 - mae: 3070.5811 - val_loss: 2938.5681 - val_mse: 30168308.0000 - val_mae: 2938.8889 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "423/436 [============================>.] - ETA: 0s - loss: 3017.1069 - mse: 30959512.0000 - mae: 3017.4399\n",
      "Epoch 29: val_loss did not improve from 2902.36914\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 3036.1521 - mse: 31216040.0000 - mae: 3036.4863 - val_loss: 3074.6453 - val_mse: 31875938.0000 - val_mae: 3074.9541 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 3264.8945 - mse: 36011920.0000 - mae: 3265.2129\n",
      "Epoch 30: val_loss did not improve from 2902.36914\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 3264.3936 - mse: 36001596.0000 - mae: 3264.7119 - val_loss: 3043.0022 - val_mse: 30618784.0000 - val_mae: 3043.3076 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "426/436 [============================>.] - ETA: 0s - loss: 3341.5796 - mse: 37224560.0000 - mae: 3341.8999\n",
      "Epoch 31: val_loss did not improve from 2902.36914\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 3350.9346 - mse: 37429808.0000 - mae: 3351.2559 - val_loss: 3292.2441 - val_mse: 35396140.0000 - val_mae: 3292.5581 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "424/436 [============================>.] - ETA: 0s - loss: 3191.0417 - mse: 34320496.0000 - mae: 3191.3613\n",
      "Epoch 32: val_loss did not improve from 2902.36914\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 3198.0837 - mse: 34479752.0000 - mae: 3198.4038 - val_loss: 3589.8928 - val_mse: 47417748.0000 - val_mae: 3590.1973 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 3133.2578 - mse: 33406768.0000 - mae: 3133.5791\n",
      "Epoch 33: val_loss did not improve from 2902.36914\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 3130.0801 - mse: 33352336.0000 - mae: 3130.4014 - val_loss: 3140.6941 - val_mse: 33586660.0000 - val_mae: 3140.9995 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 3322.3723 - mse: 36639004.0000 - mae: 3322.6892\n",
      "Epoch 34: val_loss did not improve from 2902.36914\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 3316.8748 - mse: 36566500.0000 - mae: 3317.1914 - val_loss: 3152.2964 - val_mse: 35401412.0000 - val_mae: 3152.6069 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 3148.9753 - mse: 32946000.0000 - mae: 3149.3020\n",
      "Epoch 35: val_loss improved from 2902.36914 to 2819.31958, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 3152.1912 - mse: 32995370.0000 - mae: 3152.5181 - val_loss: 2819.3196 - val_mse: 26510224.0000 - val_mae: 2819.6313 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2967.3596 - mse: 29806070.0000 - mae: 2967.6755\n",
      "Epoch 36: val_loss did not improve from 2819.31958\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2974.6904 - mse: 29881348.0000 - mae: 2975.0068 - val_loss: 2837.2424 - val_mse: 28781290.0000 - val_mae: 2837.5515 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2973.7124 - mse: 30597276.0000 - mae: 2974.0239\n",
      "Epoch 37: val_loss did not improve from 2819.31958\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2977.4346 - mse: 30632816.0000 - mae: 2977.7466 - val_loss: 2966.6199 - val_mse: 30903254.0000 - val_mae: 2966.9175 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "426/436 [============================>.] - ETA: 0s - loss: 2941.7947 - mse: 30004558.0000 - mae: 2942.1035\n",
      "Epoch 38: val_loss did not improve from 2819.31958\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2950.9622 - mse: 30208028.0000 - mae: 2951.2725 - val_loss: 2947.8625 - val_mse: 31663240.0000 - val_mae: 2948.1609 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "420/436 [===========================>..] - ETA: 0s - loss: 2977.7183 - mse: 31648022.0000 - mae: 2978.0383\n",
      "Epoch 39: val_loss did not improve from 2819.31958\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 2981.5032 - mse: 31669420.0000 - mae: 2981.8242 - val_loss: 3021.4788 - val_mse: 33449502.0000 - val_mae: 3021.7808 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2946.8586 - mse: 31340890.0000 - mae: 2947.1716\n",
      "Epoch 40: val_loss did not improve from 2819.31958\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2946.8586 - mse: 31340890.0000 - mae: 2947.1716 - val_loss: 2903.1069 - val_mse: 30302142.0000 - val_mae: 2903.4016 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2975.4185 - mse: 32303878.0000 - mae: 2975.7327\n",
      "Epoch 41: val_loss did not improve from 2819.31958\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2977.4707 - mse: 32293894.0000 - mae: 2977.7852 - val_loss: 3045.7368 - val_mse: 31206894.0000 - val_mae: 3046.0276 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "421/436 [===========================>..] - ETA: 0s - loss: 2826.1482 - mse: 29503484.0000 - mae: 2826.4546\n",
      "Epoch 42: val_loss did not improve from 2819.31958\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2833.5859 - mse: 29579906.0000 - mae: 2833.8938 - val_loss: 2846.1943 - val_mse: 30285922.0000 - val_mae: 2846.5027 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2906.1082 - mse: 30506536.0000 - mae: 2906.4272\n",
      "Epoch 43: val_loss did not improve from 2819.31958\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2909.2485 - mse: 30530494.0000 - mae: 2909.5679 - val_loss: 2874.1855 - val_mse: 29909540.0000 - val_mae: 2874.4915 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "427/436 [============================>.] - ETA: 0s - loss: 2875.2961 - mse: 29962488.0000 - mae: 2875.6108\n",
      "Epoch 44: val_loss did not improve from 2819.31958\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2882.8643 - mse: 30036916.0000 - mae: 2883.1799 - val_loss: 2986.5847 - val_mse: 32389372.0000 - val_mae: 2986.8826 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "426/436 [============================>.] - ETA: 0s - loss: 2903.8516 - mse: 30312306.0000 - mae: 2904.1653\n",
      "Epoch 45: val_loss did not improve from 2819.31958\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2930.7986 - mse: 30785574.0000 - mae: 2931.1128 - val_loss: 3543.2935 - val_mse: 48578460.0000 - val_mae: 3543.5884 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2901.7378 - mse: 30357422.0000 - mae: 2902.0530\n",
      "Epoch 46: val_loss did not improve from 2819.31958\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2907.1482 - mse: 30433848.0000 - mae: 2907.4646 - val_loss: 2857.4260 - val_mse: 30073700.0000 - val_mae: 2857.7388 - lr: 5.0000e-04\n",
      "Epoch 47/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2647.1216 - mse: 25985488.0000 - mae: 2647.4456\n",
      "Epoch 47: val_loss improved from 2819.31958 to 2701.38696, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2653.1384 - mse: 26057328.0000 - mae: 2653.4626 - val_loss: 2701.3870 - val_mse: 27288970.0000 - val_mae: 2701.6978 - lr: 5.0000e-04\n",
      "Epoch 48/500\n",
      "425/436 [============================>.] - ETA: 0s - loss: 2588.4089 - mse: 25309760.0000 - mae: 2588.7258\n",
      "Epoch 48: val_loss did not improve from 2701.38696\n",
      "436/436 [==============================] - 2s 5ms/step - loss: 2612.3481 - mse: 25617156.0000 - mae: 2612.6660 - val_loss: 2746.7417 - val_mse: 28422632.0000 - val_mae: 2747.0454 - lr: 5.0000e-04\n",
      "Epoch 49/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2615.0203 - mse: 26197106.0000 - mae: 2615.3379\n",
      "Epoch 49: val_loss improved from 2701.38696 to 2678.24219, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 5ms/step - loss: 2610.7981 - mse: 26194542.0000 - mae: 2611.1162 - val_loss: 2678.2422 - val_mse: 28148602.0000 - val_mae: 2678.5437 - lr: 5.0000e-04\n",
      "Epoch 50/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2591.6790 - mse: 25958178.0000 - mae: 2591.9912\n",
      "Epoch 50: val_loss did not improve from 2678.24219\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2597.3438 - mse: 26006742.0000 - mae: 2597.6560 - val_loss: 2703.3821 - val_mse: 27474144.0000 - val_mae: 2703.6809 - lr: 5.0000e-04\n",
      "Epoch 51/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2617.3892 - mse: 26644506.0000 - mae: 2617.7012\n",
      "Epoch 51: val_loss improved from 2678.24219 to 2540.10547, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2628.9009 - mse: 26866950.0000 - mae: 2629.2136 - val_loss: 2540.1055 - val_mse: 26941392.0000 - val_mae: 2540.4070 - lr: 5.0000e-04\n",
      "Epoch 52/500\n",
      "427/436 [============================>.] - ETA: 0s - loss: 2644.7874 - mse: 26669528.0000 - mae: 2645.0996\n",
      "Epoch 52: val_loss did not improve from 2540.10547\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2650.5945 - mse: 26695370.0000 - mae: 2650.9075 - val_loss: 2865.3010 - val_mse: 29471276.0000 - val_mae: 2865.6055 - lr: 5.0000e-04\n",
      "Epoch 53/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2637.4043 - mse: 26391064.0000 - mae: 2637.7134\n",
      "Epoch 53: val_loss did not improve from 2540.10547\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2644.2498 - mse: 26513762.0000 - mae: 2644.5588 - val_loss: 2649.6111 - val_mse: 26143924.0000 - val_mae: 2649.9072 - lr: 5.0000e-04\n",
      "Epoch 54/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2574.3201 - mse: 25307450.0000 - mae: 2574.6289\n",
      "Epoch 54: val_loss did not improve from 2540.10547\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2574.3201 - mse: 25307450.0000 - mae: 2574.6289 - val_loss: 2565.4531 - val_mse: 24582670.0000 - val_mae: 2565.7458 - lr: 5.0000e-04\n",
      "Epoch 55/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2577.8765 - mse: 25511188.0000 - mae: 2578.1843\n",
      "Epoch 55: val_loss did not improve from 2540.10547\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2576.8325 - mse: 25445464.0000 - mae: 2577.1406 - val_loss: 2703.9255 - val_mse: 27585014.0000 - val_mae: 2704.2234 - lr: 5.0000e-04\n",
      "Epoch 56/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2637.1089 - mse: 26234334.0000 - mae: 2637.4199\n",
      "Epoch 56: val_loss did not improve from 2540.10547\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2632.4055 - mse: 26152490.0000 - mae: 2632.7168 - val_loss: 2572.6924 - val_mse: 25312096.0000 - val_mae: 2572.9912 - lr: 5.0000e-04\n",
      "Epoch 57/500\n",
      "427/436 [============================>.] - ETA: 0s - loss: 2526.7180 - mse: 24812512.0000 - mae: 2527.0249\n",
      "Epoch 57: val_loss did not improve from 2540.10547\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2543.8301 - mse: 25068266.0000 - mae: 2544.1377 - val_loss: 2599.8977 - val_mse: 26198458.0000 - val_mae: 2600.1985 - lr: 5.0000e-04\n",
      "Epoch 58/500\n",
      "426/436 [============================>.] - ETA: 0s - loss: 2682.9487 - mse: 27430244.0000 - mae: 2683.2542\n",
      "Epoch 58: val_loss did not improve from 2540.10547\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2687.0811 - mse: 27509176.0000 - mae: 2687.3872 - val_loss: 2670.9626 - val_mse: 26714602.0000 - val_mae: 2671.2542 - lr: 5.0000e-04\n",
      "Epoch 59/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2560.3716 - mse: 25538914.0000 - mae: 2560.6765\n",
      "Epoch 59: val_loss did not improve from 2540.10547\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2561.3276 - mse: 25625016.0000 - mae: 2561.6328 - val_loss: 2837.6299 - val_mse: 30041474.0000 - val_mae: 2837.9260 - lr: 5.0000e-04\n",
      "Epoch 60/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2621.0393 - mse: 26524790.0000 - mae: 2621.3455\n",
      "Epoch 60: val_loss did not improve from 2540.10547\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2626.1694 - mse: 26635440.0000 - mae: 2626.4761 - val_loss: 2707.5815 - val_mse: 27484440.0000 - val_mae: 2707.8745 - lr: 5.0000e-04\n",
      "Epoch 61/500\n",
      "418/436 [===========================>..] - ETA: 0s - loss: 2577.6348 - mse: 25514082.0000 - mae: 2577.9392\n",
      "Epoch 61: val_loss did not improve from 2540.10547\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 2592.5891 - mse: 25709278.0000 - mae: 2592.8931 - val_loss: 2646.8059 - val_mse: 26792046.0000 - val_mae: 2647.0967 - lr: 5.0000e-04\n",
      "Epoch 62/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2496.0442 - mse: 24687056.0000 - mae: 2496.3506\n",
      "Epoch 62: val_loss improved from 2540.10547 to 2406.70996, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2499.9497 - mse: 24729874.0000 - mae: 2500.2563 - val_loss: 2406.7100 - val_mse: 24459676.0000 - val_mae: 2407.0029 - lr: 2.5000e-04\n",
      "Epoch 63/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2479.7695 - mse: 24520394.0000 - mae: 2480.0745\n",
      "Epoch 63: val_loss did not improve from 2406.70996\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2485.5098 - mse: 24572552.0000 - mae: 2485.8152 - val_loss: 2511.2065 - val_mse: 26519228.0000 - val_mae: 2511.4995 - lr: 2.5000e-04\n",
      "Epoch 64/500\n",
      "424/436 [============================>.] - ETA: 0s - loss: 2470.6709 - mse: 23969626.0000 - mae: 2470.9736\n",
      "Epoch 64: val_loss did not improve from 2406.70996\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2488.3740 - mse: 24265378.0000 - mae: 2488.6772 - val_loss: 2546.4941 - val_mse: 26062840.0000 - val_mae: 2546.7839 - lr: 2.5000e-04\n",
      "Epoch 65/500\n",
      "421/436 [===========================>..] - ETA: 0s - loss: 2411.3794 - mse: 23385036.0000 - mae: 2411.6829\n",
      "Epoch 65: val_loss did not improve from 2406.70996\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2429.1350 - mse: 23677130.0000 - mae: 2429.4390 - val_loss: 2461.2495 - val_mse: 24713578.0000 - val_mae: 2461.5408 - lr: 2.5000e-04\n",
      "Epoch 66/500\n",
      "426/436 [============================>.] - ETA: 0s - loss: 2428.3918 - mse: 23899720.0000 - mae: 2428.6938\n",
      "Epoch 66: val_loss did not improve from 2406.70996\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2441.9216 - mse: 24167988.0000 - mae: 2442.2244 - val_loss: 2467.1760 - val_mse: 24769356.0000 - val_mae: 2467.4673 - lr: 2.5000e-04\n",
      "Epoch 67/500\n",
      "425/436 [============================>.] - ETA: 0s - loss: 2453.5952 - mse: 24181192.0000 - mae: 2453.8982\n",
      "Epoch 67: val_loss improved from 2406.70996 to 2371.31128, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2471.9377 - mse: 24402064.0000 - mae: 2472.2422 - val_loss: 2371.3113 - val_mse: 23436948.0000 - val_mae: 2371.6008 - lr: 2.5000e-04\n",
      "Epoch 68/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2426.4700 - mse: 23937852.0000 - mae: 2426.7751\n",
      "Epoch 68: val_loss did not improve from 2371.31128\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2428.2839 - mse: 23926792.0000 - mae: 2428.5894 - val_loss: 2427.3909 - val_mse: 23763990.0000 - val_mae: 2427.6868 - lr: 2.5000e-04\n",
      "Epoch 69/500\n",
      "423/436 [============================>.] - ETA: 0s - loss: 2428.4624 - mse: 23442400.0000 - mae: 2428.7681\n",
      "Epoch 69: val_loss did not improve from 2371.31128\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2448.7493 - mse: 23872122.0000 - mae: 2449.0552 - val_loss: 2428.0798 - val_mse: 25012454.0000 - val_mae: 2428.3748 - lr: 2.5000e-04\n",
      "Epoch 70/500\n",
      "424/436 [============================>.] - ETA: 0s - loss: 2410.6067 - mse: 23511832.0000 - mae: 2410.9150\n",
      "Epoch 70: val_loss did not improve from 2371.31128\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2431.2700 - mse: 23856866.0000 - mae: 2431.5791 - val_loss: 2399.1077 - val_mse: 24033898.0000 - val_mae: 2399.4021 - lr: 2.5000e-04\n",
      "Epoch 71/500\n",
      "424/436 [============================>.] - ETA: 0s - loss: 2400.3257 - mse: 23411828.0000 - mae: 2400.6301\n",
      "Epoch 71: val_loss did not improve from 2371.31128\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2414.2803 - mse: 23665238.0000 - mae: 2414.5857 - val_loss: 2399.9868 - val_mse: 23968120.0000 - val_mae: 2400.2812 - lr: 2.5000e-04\n",
      "Epoch 72/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2421.7415 - mse: 23560884.0000 - mae: 2422.0444\n",
      "Epoch 72: val_loss improved from 2371.31128 to 2301.95850, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2425.4204 - mse: 23575828.0000 - mae: 2425.7239 - val_loss: 2301.9585 - val_mse: 21673118.0000 - val_mae: 2302.2449 - lr: 2.5000e-04\n",
      "Epoch 73/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2426.1350 - mse: 23212272.0000 - mae: 2426.4365\n",
      "Epoch 73: val_loss did not improve from 2301.95850\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2426.1350 - mse: 23212272.0000 - mae: 2426.4365 - val_loss: 2429.1118 - val_mse: 24873702.0000 - val_mae: 2429.4075 - lr: 2.5000e-04\n",
      "Epoch 74/500\n",
      "417/436 [===========================>..] - ETA: 0s - loss: 2402.2332 - mse: 23046370.0000 - mae: 2402.5374\n",
      "Epoch 74: val_loss did not improve from 2301.95850\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2431.8042 - mse: 23479920.0000 - mae: 2432.1099 - val_loss: 2438.8892 - val_mse: 25319154.0000 - val_mae: 2439.1821 - lr: 2.5000e-04\n",
      "Epoch 75/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2446.0049 - mse: 24144220.0000 - mae: 2446.3088\n",
      "Epoch 75: val_loss improved from 2301.95850 to 2278.10571, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2448.8130 - mse: 24120042.0000 - mae: 2449.1172 - val_loss: 2278.1057 - val_mse: 22575308.0000 - val_mae: 2278.3994 - lr: 2.5000e-04\n",
      "Epoch 76/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2417.0081 - mse: 23496320.0000 - mae: 2417.3120\n",
      "Epoch 76: val_loss did not improve from 2278.10571\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2421.9150 - mse: 23547638.0000 - mae: 2422.2197 - val_loss: 2483.2737 - val_mse: 24418086.0000 - val_mae: 2483.5686 - lr: 2.5000e-04\n",
      "Epoch 77/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2401.8528 - mse: 23085872.0000 - mae: 2402.1558\n",
      "Epoch 77: val_loss did not improve from 2278.10571\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2402.0552 - mse: 23058890.0000 - mae: 2402.3586 - val_loss: 2412.8792 - val_mse: 23357344.0000 - val_mae: 2413.1714 - lr: 2.5000e-04\n",
      "Epoch 78/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2402.6169 - mse: 23157600.0000 - mae: 2402.9207\n",
      "Epoch 78: val_loss improved from 2278.10571 to 2270.80347, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2405.0413 - mse: 23172034.0000 - mae: 2405.3450 - val_loss: 2270.8035 - val_mse: 21749522.0000 - val_mae: 2271.0959 - lr: 2.5000e-04\n",
      "Epoch 79/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2374.8955 - mse: 22529142.0000 - mae: 2375.1968\n",
      "Epoch 79: val_loss did not improve from 2270.80347\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2379.1536 - mse: 22584878.0000 - mae: 2379.4553 - val_loss: 2360.9771 - val_mse: 23050398.0000 - val_mae: 2361.2671 - lr: 2.5000e-04\n",
      "Epoch 80/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2385.0989 - mse: 22889126.0000 - mae: 2385.4019\n",
      "Epoch 80: val_loss did not improve from 2270.80347\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2395.9155 - mse: 23059602.0000 - mae: 2396.2188 - val_loss: 2283.3528 - val_mse: 22084328.0000 - val_mae: 2283.6431 - lr: 2.5000e-04\n",
      "Epoch 81/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2401.6772 - mse: 23005872.0000 - mae: 2401.9810\n",
      "Epoch 81: val_loss did not improve from 2270.80347\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2408.4077 - mse: 23159930.0000 - mae: 2408.7117 - val_loss: 2449.8052 - val_mse: 24256948.0000 - val_mae: 2450.0933 - lr: 2.5000e-04\n",
      "Epoch 82/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2350.9514 - mse: 22340470.0000 - mae: 2351.2542\n",
      "Epoch 82: val_loss did not improve from 2270.80347\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2350.9514 - mse: 22340470.0000 - mae: 2351.2542 - val_loss: 2369.6260 - val_mse: 23357368.0000 - val_mae: 2369.9163 - lr: 2.5000e-04\n",
      "Epoch 83/500\n",
      "425/436 [============================>.] - ETA: 0s - loss: 2382.8962 - mse: 23181350.0000 - mae: 2383.1973\n",
      "Epoch 83: val_loss did not improve from 2270.80347\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2394.0552 - mse: 23323950.0000 - mae: 2394.3572 - val_loss: 2497.0071 - val_mse: 25643442.0000 - val_mae: 2497.2974 - lr: 2.5000e-04\n",
      "Epoch 84/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2390.2598 - mse: 23318682.0000 - mae: 2390.5635\n",
      "Epoch 84: val_loss did not improve from 2270.80347\n",
      "436/436 [==============================] - 2s 5ms/step - loss: 2392.4058 - mse: 23329264.0000 - mae: 2392.7097 - val_loss: 2405.8882 - val_mse: 23609502.0000 - val_mae: 2406.1787 - lr: 2.5000e-04\n",
      "Epoch 85/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2330.9358 - mse: 22155324.0000 - mae: 2331.2388\n",
      "Epoch 85: val_loss did not improve from 2270.80347\n",
      "436/436 [==============================] - 2s 5ms/step - loss: 2336.3853 - mse: 22236164.0000 - mae: 2336.6885 - val_loss: 2433.3704 - val_mse: 23995698.0000 - val_mae: 2433.6582 - lr: 2.5000e-04\n",
      "Epoch 86/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2373.7529 - mse: 22740416.0000 - mae: 2374.0564\n",
      "Epoch 86: val_loss did not improve from 2270.80347\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2374.9897 - mse: 22762984.0000 - mae: 2375.2932 - val_loss: 2403.3340 - val_mse: 22975808.0000 - val_mae: 2403.6201 - lr: 2.5000e-04\n",
      "Epoch 87/500\n",
      "423/436 [============================>.] - ETA: 0s - loss: 2378.6663 - mse: 23055524.0000 - mae: 2378.9673\n",
      "Epoch 87: val_loss did not improve from 2270.80347\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2379.6736 - mse: 22950880.0000 - mae: 2379.9753 - val_loss: 2350.6313 - val_mse: 22440800.0000 - val_mae: 2350.9150 - lr: 2.5000e-04\n",
      "Epoch 88/500\n",
      "416/436 [===========================>..] - ETA: 0s - loss: 2353.9111 - mse: 22712484.0000 - mae: 2354.2102\n",
      "Epoch 88: val_loss did not improve from 2270.80347\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2382.5315 - mse: 23232846.0000 - mae: 2382.8315 - val_loss: 2292.1140 - val_mse: 22420480.0000 - val_mae: 2292.4014 - lr: 2.5000e-04\n",
      "Epoch 89/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2358.0137 - mse: 23112206.0000 - mae: 2358.3147\n",
      "Epoch 89: val_loss did not improve from 2270.80347\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2366.2986 - mse: 23190904.0000 - mae: 2366.6003 - val_loss: 2283.3887 - val_mse: 22391858.0000 - val_mae: 2283.6760 - lr: 1.2500e-04\n",
      "Epoch 90/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2318.5159 - mse: 22136834.0000 - mae: 2318.8176\n",
      "Epoch 90: val_loss did not improve from 2270.80347\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2328.2903 - mse: 22282478.0000 - mae: 2328.5925 - val_loss: 2271.9265 - val_mse: 21782526.0000 - val_mae: 2272.2185 - lr: 1.2500e-04\n",
      "Epoch 91/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2337.8992 - mse: 22318570.0000 - mae: 2338.2029\n",
      "Epoch 91: val_loss improved from 2270.80347 to 2225.17969, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2351.0212 - mse: 22536996.0000 - mae: 2351.3252 - val_loss: 2225.1797 - val_mse: 21807568.0000 - val_mae: 2225.4705 - lr: 1.2500e-04\n",
      "Epoch 92/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2329.9380 - mse: 22397706.0000 - mae: 2330.2432\n",
      "Epoch 92: val_loss did not improve from 2225.17969\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2332.1116 - mse: 22449884.0000 - mae: 2332.4167 - val_loss: 2298.2927 - val_mse: 22723138.0000 - val_mae: 2298.5840 - lr: 1.2500e-04\n",
      "Epoch 93/500\n",
      "426/436 [============================>.] - ETA: 0s - loss: 2326.7976 - mse: 22445662.0000 - mae: 2327.1008\n",
      "Epoch 93: val_loss improved from 2225.17969 to 2202.34717, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2339.9124 - mse: 22591006.0000 - mae: 2340.2161 - val_loss: 2202.3472 - val_mse: 20796970.0000 - val_mae: 2202.6370 - lr: 1.2500e-04\n",
      "Epoch 94/500\n",
      "423/436 [============================>.] - ETA: 0s - loss: 2351.4434 - mse: 22350226.0000 - mae: 2351.7449\n",
      "Epoch 94: val_loss did not improve from 2202.34717\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2358.3708 - mse: 22442802.0000 - mae: 2358.6733 - val_loss: 2224.4102 - val_mse: 21569858.0000 - val_mae: 2224.7007 - lr: 1.2500e-04\n",
      "Epoch 95/500\n",
      "420/436 [===========================>..] - ETA: 0s - loss: 2347.1438 - mse: 22341712.0000 - mae: 2347.4473\n",
      "Epoch 95: val_loss did not improve from 2202.34717\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2364.0977 - mse: 22559808.0000 - mae: 2364.4021 - val_loss: 2275.9927 - val_mse: 22105002.0000 - val_mae: 2276.2847 - lr: 1.2500e-04\n",
      "Epoch 96/500\n",
      "421/436 [===========================>..] - ETA: 0s - loss: 2384.2605 - mse: 23057848.0000 - mae: 2384.5632\n",
      "Epoch 96: val_loss did not improve from 2202.34717\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2397.0615 - mse: 23193954.0000 - mae: 2397.3650 - val_loss: 2274.4246 - val_mse: 22084314.0000 - val_mae: 2274.7131 - lr: 1.2500e-04\n",
      "Epoch 97/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2335.9570 - mse: 22200328.0000 - mae: 2336.2595\n",
      "Epoch 97: val_loss did not improve from 2202.34717\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2339.9302 - mse: 22267044.0000 - mae: 2340.2332 - val_loss: 2216.2117 - val_mse: 21755034.0000 - val_mae: 2216.5034 - lr: 1.2500e-04\n",
      "Epoch 98/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2318.7351 - mse: 21995454.0000 - mae: 2319.0383\n",
      "Epoch 98: val_loss improved from 2202.34717 to 2162.40088, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2329.2737 - mse: 22161250.0000 - mae: 2329.5769 - val_loss: 2162.4009 - val_mse: 20840752.0000 - val_mae: 2162.6892 - lr: 1.2500e-04\n",
      "Epoch 99/500\n",
      "421/436 [===========================>..] - ETA: 0s - loss: 2336.7395 - mse: 22246036.0000 - mae: 2337.0427\n",
      "Epoch 99: val_loss did not improve from 2162.40088\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2354.5327 - mse: 22492846.0000 - mae: 2354.8362 - val_loss: 2214.3289 - val_mse: 21370318.0000 - val_mae: 2214.6206 - lr: 1.2500e-04\n",
      "Epoch 100/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2287.9919 - mse: 21500578.0000 - mae: 2288.2952\n",
      "Epoch 100: val_loss did not improve from 2162.40088\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2289.3445 - mse: 21515220.0000 - mae: 2289.6477 - val_loss: 2171.6670 - val_mse: 20986898.0000 - val_mae: 2171.9575 - lr: 1.2500e-04\n",
      "Epoch 101/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2270.4941 - mse: 21576520.0000 - mae: 2270.7988\n",
      "Epoch 101: val_loss did not improve from 2162.40088\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2272.5000 - mse: 21525356.0000 - mae: 2272.8047 - val_loss: 2187.1631 - val_mse: 21051662.0000 - val_mae: 2187.4556 - lr: 1.2500e-04\n",
      "Epoch 102/500\n",
      "426/436 [============================>.] - ETA: 0s - loss: 2302.9451 - mse: 22138542.0000 - mae: 2303.2502\n",
      "Epoch 102: val_loss did not improve from 2162.40088\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2318.7122 - mse: 22401302.0000 - mae: 2319.0178 - val_loss: 2343.3650 - val_mse: 23037476.0000 - val_mae: 2343.6567 - lr: 1.2500e-04\n",
      "Epoch 103/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2313.4954 - mse: 22351476.0000 - mae: 2313.7998\n",
      "Epoch 103: val_loss did not improve from 2162.40088\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2315.9316 - mse: 22347564.0000 - mae: 2316.2363 - val_loss: 2208.6174 - val_mse: 21796012.0000 - val_mae: 2208.9084 - lr: 1.2500e-04\n",
      "Epoch 104/500\n",
      "423/436 [============================>.] - ETA: 0s - loss: 2286.1987 - mse: 21518760.0000 - mae: 2286.5005\n",
      "Epoch 104: val_loss did not improve from 2162.40088\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2306.7246 - mse: 21791040.0000 - mae: 2307.0278 - val_loss: 2256.9644 - val_mse: 22062338.0000 - val_mae: 2257.2561 - lr: 1.2500e-04\n",
      "Epoch 105/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2312.4216 - mse: 22342188.0000 - mae: 2312.7283\n",
      "Epoch 105: val_loss did not improve from 2162.40088\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2319.8594 - mse: 22420986.0000 - mae: 2320.1663 - val_loss: 2205.6387 - val_mse: 21848516.0000 - val_mae: 2205.9285 - lr: 1.2500e-04\n",
      "Epoch 106/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2317.7588 - mse: 22367656.0000 - mae: 2318.0645\n",
      "Epoch 106: val_loss did not improve from 2162.40088\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2319.1531 - mse: 22402152.0000 - mae: 2319.4587 - val_loss: 2318.9612 - val_mse: 22547662.0000 - val_mae: 2319.2532 - lr: 1.2500e-04\n",
      "Epoch 107/500\n",
      "423/436 [============================>.] - ETA: 0s - loss: 2301.9272 - mse: 21895130.0000 - mae: 2302.2319\n",
      "Epoch 107: val_loss did not improve from 2162.40088\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2312.8386 - mse: 22027518.0000 - mae: 2313.1440 - val_loss: 2203.8040 - val_mse: 21420616.0000 - val_mae: 2204.0957 - lr: 1.2500e-04\n",
      "Epoch 108/500\n",
      "427/436 [============================>.] - ETA: 0s - loss: 2313.8101 - mse: 22132328.0000 - mae: 2314.1147\n",
      "Epoch 108: val_loss did not improve from 2162.40088\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2320.2610 - mse: 22184232.0000 - mae: 2320.5664 - val_loss: 2223.2749 - val_mse: 21435872.0000 - val_mae: 2223.5654 - lr: 1.2500e-04\n",
      "Epoch 109/500\n",
      "424/436 [============================>.] - ETA: 0s - loss: 2324.4712 - mse: 21920248.0000 - mae: 2324.7732\n",
      "Epoch 109: val_loss did not improve from 2162.40088\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2348.3093 - mse: 22215314.0000 - mae: 2348.6125 - val_loss: 2218.8589 - val_mse: 21473776.0000 - val_mae: 2219.1479 - lr: 6.2500e-05\n",
      "Epoch 110/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2343.9924 - mse: 22190398.0000 - mae: 2344.2949\n",
      "Epoch 110: val_loss did not improve from 2162.40088\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2352.5300 - mse: 22324218.0000 - mae: 2352.8328 - val_loss: 2249.8066 - val_mse: 22100816.0000 - val_mae: 2250.0959 - lr: 6.2500e-05\n",
      "Epoch 111/500\n",
      "426/436 [============================>.] - ETA: 0s - loss: 2333.7190 - mse: 22066256.0000 - mae: 2334.0200\n",
      "Epoch 111: val_loss did not improve from 2162.40088\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2348.4348 - mse: 22297836.0000 - mae: 2348.7363 - val_loss: 2259.5176 - val_mse: 22081634.0000 - val_mae: 2259.8059 - lr: 6.2500e-05\n",
      "Epoch 112/500\n",
      "423/436 [============================>.] - ETA: 0s - loss: 2307.8369 - mse: 22096060.0000 - mae: 2308.1379\n",
      "Epoch 112: val_loss did not improve from 2162.40088\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2319.7769 - mse: 22252834.0000 - mae: 2320.0786 - val_loss: 2292.4595 - val_mse: 22397632.0000 - val_mae: 2292.7478 - lr: 6.2500e-05\n",
      "Epoch 113/500\n",
      "422/436 [============================>.] - ETA: 0s - loss: 2358.4824 - mse: 23098224.0000 - mae: 2358.7832\n",
      "Epoch 113: val_loss did not improve from 2162.40088\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2372.9973 - mse: 23312070.0000 - mae: 2373.2996 - val_loss: 2200.9678 - val_mse: 21496772.0000 - val_mae: 2201.2554 - lr: 6.2500e-05\n",
      "Epoch 114/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2317.9741 - mse: 22396500.0000 - mae: 2318.2739\n",
      "Epoch 114: val_loss improved from 2162.40088 to 2161.42554, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2322.0701 - mse: 22491276.0000 - mae: 2322.3699 - val_loss: 2161.4255 - val_mse: 20999396.0000 - val_mae: 2161.7141 - lr: 6.2500e-05\n",
      "Epoch 115/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2299.5198 - mse: 22017010.0000 - mae: 2299.8218\n",
      "Epoch 115: val_loss did not improve from 2161.42554\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2299.6987 - mse: 22012050.0000 - mae: 2300.0010 - val_loss: 2187.8735 - val_mse: 21454672.0000 - val_mae: 2188.1626 - lr: 6.2500e-05\n",
      "Epoch 116/500\n",
      "419/436 [===========================>..] - ETA: 0s - loss: 2269.3269 - mse: 21482440.0000 - mae: 2269.6267\n",
      "Epoch 116: val_loss did not improve from 2161.42554\n",
      "436/436 [==============================] - 1s 3ms/step - loss: 2291.4490 - mse: 21747144.0000 - mae: 2291.7500 - val_loss: 2188.1145 - val_mse: 21119740.0000 - val_mae: 2188.4041 - lr: 6.2500e-05\n",
      "Epoch 117/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2291.6240 - mse: 21901658.0000 - mae: 2291.9255\n",
      "Epoch 117: val_loss did not improve from 2161.42554\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2292.5034 - mse: 21917094.0000 - mae: 2292.8047 - val_loss: 2237.5281 - val_mse: 21781898.0000 - val_mae: 2237.8179 - lr: 6.2500e-05\n",
      "Epoch 118/500\n",
      "424/436 [============================>.] - ETA: 0s - loss: 2299.3792 - mse: 21975752.0000 - mae: 2299.6804\n",
      "Epoch 118: val_loss did not improve from 2161.42554\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2308.4041 - mse: 22077880.0000 - mae: 2308.7058 - val_loss: 2216.0837 - val_mse: 21305004.0000 - val_mae: 2216.3723 - lr: 6.2500e-05\n",
      "Epoch 119/500\n",
      "424/436 [============================>.] - ETA: 0s - loss: 2273.3201 - mse: 21698638.0000 - mae: 2273.6211\n",
      "Epoch 119: val_loss did not improve from 2161.42554\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2283.7349 - mse: 21870168.0000 - mae: 2284.0361 - val_loss: 2239.3889 - val_mse: 21860962.0000 - val_mae: 2239.6792 - lr: 6.2500e-05\n",
      "Epoch 120/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2255.8828 - mse: 21157840.0000 - mae: 2256.1858\n",
      "Epoch 120: val_loss did not improve from 2161.42554\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2266.3672 - mse: 21334832.0000 - mae: 2266.6711 - val_loss: 2238.0264 - val_mse: 21763646.0000 - val_mae: 2238.3169 - lr: 6.2500e-05\n",
      "Epoch 121/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2282.7371 - mse: 21593356.0000 - mae: 2283.0388\n",
      "Epoch 121: val_loss did not improve from 2161.42554\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2292.8416 - mse: 21723898.0000 - mae: 2293.1438 - val_loss: 2184.3235 - val_mse: 20971930.0000 - val_mae: 2184.6145 - lr: 6.2500e-05\n",
      "Epoch 122/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2289.6641 - mse: 21684750.0000 - mae: 2289.9683\n",
      "Epoch 122: val_loss did not improve from 2161.42554\n",
      "436/436 [==============================] - 2s 5ms/step - loss: 2289.6641 - mse: 21684750.0000 - mae: 2289.9683 - val_loss: 2256.0911 - val_mse: 22251076.0000 - val_mae: 2256.3828 - lr: 6.2500e-05\n",
      "Epoch 123/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2275.0085 - mse: 21267130.0000 - mae: 2275.3145\n",
      "Epoch 123: val_loss did not improve from 2161.42554\n",
      "436/436 [==============================] - 2s 5ms/step - loss: 2276.2957 - mse: 21275180.0000 - mae: 2276.6018 - val_loss: 2202.3271 - val_mse: 21398060.0000 - val_mae: 2202.6187 - lr: 6.2500e-05\n",
      "Epoch 124/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2250.1643 - mse: 21081962.0000 - mae: 2250.4656\n",
      "Epoch 124: val_loss did not improve from 2161.42554\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2257.0991 - mse: 21216848.0000 - mae: 2257.4009 - val_loss: 2214.3110 - val_mse: 21327116.0000 - val_mae: 2214.6018 - lr: 6.2500e-05\n",
      "Epoch 125/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2292.0122 - mse: 21972194.0000 - mae: 2292.3149\n",
      "Epoch 125: val_loss did not improve from 2161.42554\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2291.1218 - mse: 21966276.0000 - mae: 2291.4248 - val_loss: 2216.3440 - val_mse: 21553524.0000 - val_mae: 2216.6355 - lr: 3.1250e-05\n",
      "Epoch 126/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2266.5178 - mse: 21496896.0000 - mae: 2266.8215\n",
      "Epoch 126: val_loss did not improve from 2161.42554\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2274.7161 - mse: 21622478.0000 - mae: 2275.0200 - val_loss: 2196.8562 - val_mse: 21357268.0000 - val_mae: 2197.1477 - lr: 3.1250e-05\n",
      "Epoch 127/500\n",
      "424/436 [============================>.] - ETA: 0s - loss: 2262.8701 - mse: 21619144.0000 - mae: 2263.1714\n",
      "Epoch 127: val_loss did not improve from 2161.42554\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2272.8311 - mse: 21680250.0000 - mae: 2273.1328 - val_loss: 2178.1240 - val_mse: 21050652.0000 - val_mae: 2178.4163 - lr: 3.1250e-05\n",
      "Epoch 128/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2262.8010 - mse: 21550224.0000 - mae: 2263.1038\n",
      "Epoch 128: val_loss did not improve from 2161.42554\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2269.7773 - mse: 21611676.0000 - mae: 2270.0806 - val_loss: 2181.5247 - val_mse: 21208136.0000 - val_mae: 2181.8157 - lr: 3.1250e-05\n",
      "Epoch 129/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2265.4832 - mse: 21497746.0000 - mae: 2265.7869\n",
      "Epoch 129: val_loss did not improve from 2161.42554\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2268.0662 - mse: 21552104.0000 - mae: 2268.3704 - val_loss: 2171.9663 - val_mse: 20931134.0000 - val_mae: 2172.2576 - lr: 3.1250e-05\n",
      "Epoch 130/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2245.5859 - mse: 21170722.0000 - mae: 2245.8892\n",
      "Epoch 130: val_loss did not improve from 2161.42554\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2247.0952 - mse: 21218890.0000 - mae: 2247.3979 - val_loss: 2172.0598 - val_mse: 20909518.0000 - val_mae: 2172.3499 - lr: 3.1250e-05\n",
      "Epoch 131/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2245.9565 - mse: 21235526.0000 - mae: 2246.2603\n",
      "Epoch 131: val_loss improved from 2161.42554 to 2161.30884, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2245.3835 - mse: 21225868.0000 - mae: 2245.6870 - val_loss: 2161.3088 - val_mse: 20686086.0000 - val_mae: 2161.5989 - lr: 3.1250e-05\n",
      "Epoch 132/500\n",
      "427/436 [============================>.] - ETA: 0s - loss: 2230.3755 - mse: 20896794.0000 - mae: 2230.6797\n",
      "Epoch 132: val_loss improved from 2161.30884 to 2156.41309, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2238.4487 - mse: 20997400.0000 - mae: 2238.7534 - val_loss: 2156.4131 - val_mse: 20763710.0000 - val_mae: 2156.7036 - lr: 3.1250e-05\n",
      "Epoch 133/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2226.5901 - mse: 20795278.0000 - mae: 2226.8936\n",
      "Epoch 133: val_loss improved from 2156.41309 to 2152.90430, saving model to new_stne_rnn_weight.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2229.0476 - mse: 20843056.0000 - mae: 2229.3508 - val_loss: 2152.9043 - val_mse: 20765880.0000 - val_mae: 2153.1929 - lr: 3.1250e-05\n",
      "Epoch 134/500\n",
      "427/436 [============================>.] - ETA: 0s - loss: 2226.9292 - mse: 20844558.0000 - mae: 2227.2319\n",
      "Epoch 134: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2234.3765 - mse: 20941960.0000 - mae: 2234.6797 - val_loss: 2155.7227 - val_mse: 20790378.0000 - val_mae: 2156.0137 - lr: 3.1250e-05\n",
      "Epoch 135/500\n",
      "418/436 [===========================>..] - ETA: 0s - loss: 2211.8784 - mse: 20601046.0000 - mae: 2212.1799\n",
      "Epoch 135: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2226.5903 - mse: 20703704.0000 - mae: 2226.8936 - val_loss: 2178.2046 - val_mse: 21150348.0000 - val_mae: 2178.4954 - lr: 3.1250e-05\n",
      "Epoch 136/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2211.5259 - mse: 20434740.0000 - mae: 2211.8293\n",
      "Epoch 136: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2211.5259 - mse: 20434740.0000 - mae: 2211.8293 - val_loss: 2187.7087 - val_mse: 21052012.0000 - val_mae: 2187.9995 - lr: 3.1250e-05\n",
      "Epoch 137/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2207.3633 - mse: 20502492.0000 - mae: 2207.6653\n",
      "Epoch 137: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2210.9795 - mse: 20505856.0000 - mae: 2211.2820 - val_loss: 2188.5989 - val_mse: 21056842.0000 - val_mae: 2188.8901 - lr: 3.1250e-05\n",
      "Epoch 138/500\n",
      "426/436 [============================>.] - ETA: 0s - loss: 2204.6602 - mse: 20446508.0000 - mae: 2204.9634\n",
      "Epoch 138: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2216.9912 - mse: 20623320.0000 - mae: 2217.2954 - val_loss: 2185.9822 - val_mse: 21096306.0000 - val_mae: 2186.2739 - lr: 3.1250e-05\n",
      "Epoch 139/500\n",
      "427/436 [============================>.] - ETA: 0s - loss: 2209.0527 - mse: 20611384.0000 - mae: 2209.3564\n",
      "Epoch 139: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2221.5886 - mse: 20733164.0000 - mae: 2221.8931 - val_loss: 2214.0542 - val_mse: 21428486.0000 - val_mae: 2214.3457 - lr: 3.1250e-05\n",
      "Epoch 140/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2237.5334 - mse: 20802962.0000 - mae: 2237.8374\n",
      "Epoch 140: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2243.5208 - mse: 20862424.0000 - mae: 2243.8250 - val_loss: 2195.7986 - val_mse: 20834634.0000 - val_mae: 2196.0898 - lr: 3.1250e-05\n",
      "Epoch 141/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2241.4202 - mse: 20897386.0000 - mae: 2241.7256\n",
      "Epoch 141: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2246.7222 - mse: 20976948.0000 - mae: 2247.0276 - val_loss: 2195.5845 - val_mse: 21339690.0000 - val_mae: 2195.8755 - lr: 3.1250e-05\n",
      "Epoch 142/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2221.2100 - mse: 20734180.0000 - mae: 2221.5129\n",
      "Epoch 142: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2221.2336 - mse: 20734028.0000 - mae: 2221.5364 - val_loss: 2221.3848 - val_mse: 21593610.0000 - val_mae: 2221.6758 - lr: 3.1250e-05\n",
      "Epoch 143/500\n",
      "421/436 [===========================>..] - ETA: 0s - loss: 2217.5298 - mse: 20475238.0000 - mae: 2217.8337\n",
      "Epoch 143: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2234.0447 - mse: 20724240.0000 - mae: 2234.3496 - val_loss: 2230.7183 - val_mse: 21876016.0000 - val_mae: 2231.0095 - lr: 3.1250e-05\n",
      "Epoch 144/500\n",
      "421/436 [===========================>..] - ETA: 0s - loss: 2231.5706 - mse: 20692590.0000 - mae: 2231.8745\n",
      "Epoch 144: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2244.8118 - mse: 20884398.0000 - mae: 2245.1162 - val_loss: 2208.7271 - val_mse: 21337148.0000 - val_mae: 2209.0183 - lr: 1.5625e-05\n",
      "Epoch 145/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2232.4031 - mse: 20748966.0000 - mae: 2232.7065\n",
      "Epoch 145: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2238.6274 - mse: 20781140.0000 - mae: 2238.9314 - val_loss: 2182.9390 - val_mse: 20878522.0000 - val_mae: 2183.2300 - lr: 1.5625e-05\n",
      "Epoch 146/500\n",
      "416/436 [===========================>..] - ETA: 0s - loss: 2219.2009 - mse: 20594732.0000 - mae: 2219.5068\n",
      "Epoch 146: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2238.2021 - mse: 20821536.0000 - mae: 2238.5090 - val_loss: 2191.6082 - val_mse: 21161386.0000 - val_mae: 2191.8997 - lr: 1.5625e-05\n",
      "Epoch 147/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2236.5994 - mse: 20800668.0000 - mae: 2236.9028\n",
      "Epoch 147: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2244.1467 - mse: 20919120.0000 - mae: 2244.4509 - val_loss: 2202.1785 - val_mse: 21271038.0000 - val_mae: 2202.4695 - lr: 1.5625e-05\n",
      "Epoch 148/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2240.0725 - mse: 20928378.0000 - mae: 2240.3760\n",
      "Epoch 148: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2245.3220 - mse: 20957140.0000 - mae: 2245.6257 - val_loss: 2183.8201 - val_mse: 21101912.0000 - val_mae: 2184.1118 - lr: 1.5625e-05\n",
      "Epoch 149/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2229.9556 - mse: 20796760.0000 - mae: 2230.2600\n",
      "Epoch 149: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2240.6506 - mse: 20930976.0000 - mae: 2240.9556 - val_loss: 2189.0200 - val_mse: 21136016.0000 - val_mae: 2189.3113 - lr: 1.5625e-05\n",
      "Epoch 150/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2226.5701 - mse: 20701096.0000 - mae: 2226.8735\n",
      "Epoch 150: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2238.9114 - mse: 20870960.0000 - mae: 2239.2151 - val_loss: 2204.8289 - val_mse: 21358410.0000 - val_mae: 2205.1204 - lr: 1.5625e-05\n",
      "Epoch 151/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2236.6409 - mse: 20820212.0000 - mae: 2236.9438\n",
      "Epoch 151: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2237.4387 - mse: 20829012.0000 - mae: 2237.7415 - val_loss: 2191.6509 - val_mse: 21150756.0000 - val_mae: 2191.9434 - lr: 1.5625e-05\n",
      "Epoch 152/500\n",
      "418/436 [===========================>..] - ETA: 0s - loss: 2219.7617 - mse: 20626528.0000 - mae: 2220.0667\n",
      "Epoch 152: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 3ms/step - loss: 2243.9324 - mse: 20938206.0000 - mae: 2244.2388 - val_loss: 2205.9734 - val_mse: 21470938.0000 - val_mae: 2206.2656 - lr: 1.5625e-05\n",
      "Epoch 153/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2225.0422 - mse: 20649424.0000 - mae: 2225.3447\n",
      "Epoch 153: val_loss did not improve from 2152.90430\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2229.9673 - mse: 20746060.0000 - mae: 2230.2698 - val_loss: 2193.5376 - val_mse: 21309512.0000 - val_mae: 2193.8293 - lr: 1.5625e-05\n",
      "Epoch 1/500\n",
      "    428/Unknown - 1s 3ms/step - loss: 2222.8159 - mse: 20688248.0000 - mae: 2223.1201\n",
      "Epoch 1: val_loss improved from inf to 2165.98682, saving model to new_stne_rnn_weight_ns.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2234.4458 - mse: 20842240.0000 - mae: 2234.7507 - val_loss: 2165.9868 - val_mse: 20842806.0000 - val_mae: 2166.2798 - lr: 7.8125e-06\n",
      "Epoch 2/500\n",
      "425/436 [============================>.] - ETA: 0s - loss: 2212.7285 - mse: 20560528.0000 - mae: 2213.0322\n",
      "Epoch 2: val_loss improved from 2165.98682 to 2160.68457, saving model to new_stne_rnn_weight_ns.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2230.0852 - mse: 20769768.0000 - mae: 2230.3899 - val_loss: 2160.6846 - val_mse: 20686852.0000 - val_mae: 2160.9761 - lr: 7.8125e-06\n",
      "Epoch 3/500\n",
      "425/436 [============================>.] - ETA: 0s - loss: 2209.0520 - mse: 20483134.0000 - mae: 2209.3545\n",
      "Epoch 3: val_loss improved from 2160.68457 to 2159.90161, saving model to new_stne_rnn_weight_ns.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2226.4919 - mse: 20693768.0000 - mae: 2226.7952 - val_loss: 2159.9016 - val_mse: 20727162.0000 - val_mae: 2160.1938 - lr: 7.8125e-06\n",
      "Epoch 4/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2226.0725 - mse: 20714536.0000 - mae: 2226.3752\n",
      "Epoch 4: val_loss improved from 2159.90161 to 2159.55225, saving model to new_stne_rnn_weight_ns.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2227.6692 - mse: 20720620.0000 - mae: 2227.9722 - val_loss: 2159.5522 - val_mse: 20679928.0000 - val_mae: 2159.8440 - lr: 7.8125e-06\n",
      "Epoch 5/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2224.9419 - mse: 20669106.0000 - mae: 2225.2458\n",
      "Epoch 5: val_loss did not improve from 2159.55225\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2224.9419 - mse: 20669106.0000 - mae: 2225.2458 - val_loss: 2173.2490 - val_mse: 20967592.0000 - val_mae: 2173.5410 - lr: 7.8125e-06\n",
      "Epoch 6/500\n",
      "424/436 [============================>.] - ETA: 0s - loss: 2208.5820 - mse: 20431896.0000 - mae: 2208.8862\n",
      "Epoch 6: val_loss did not improve from 2159.55225\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2228.1963 - mse: 20681066.0000 - mae: 2228.5015 - val_loss: 2175.4031 - val_mse: 20927372.0000 - val_mae: 2175.6956 - lr: 7.8125e-06\n",
      "Epoch 7/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2220.8748 - mse: 20655520.0000 - mae: 2221.1794\n",
      "Epoch 7: val_loss improved from 2159.55225 to 2158.36255, saving model to new_stne_rnn_weight_ns.h5\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2229.3638 - mse: 20746688.0000 - mae: 2229.6687 - val_loss: 2158.3625 - val_mse: 20596746.0000 - val_mae: 2158.6550 - lr: 7.8125e-06\n",
      "Epoch 8/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2225.1895 - mse: 20696846.0000 - mae: 2225.4939\n",
      "Epoch 8: val_loss improved from 2158.36255 to 2155.01001, saving model to new_stne_rnn_weight_ns.h5\n",
      "436/436 [==============================] - 2s 5ms/step - loss: 2225.6265 - mse: 20689326.0000 - mae: 2225.9309 - val_loss: 2155.0100 - val_mse: 20596904.0000 - val_mae: 2155.3025 - lr: 7.8125e-06\n",
      "Epoch 9/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2217.9709 - mse: 20559896.0000 - mae: 2218.2754\n",
      "Epoch 9: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 5ms/step - loss: 2222.8806 - mse: 20612468.0000 - mae: 2223.1855 - val_loss: 2155.3713 - val_mse: 20619754.0000 - val_mae: 2155.6638 - lr: 7.8125e-06\n",
      "Epoch 10/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2216.3545 - mse: 20577432.0000 - mae: 2216.6580\n",
      "Epoch 10: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2226.8174 - mse: 20712678.0000 - mae: 2227.1211 - val_loss: 2177.4041 - val_mse: 20995828.0000 - val_mae: 2177.6965 - lr: 7.8125e-06\n",
      "Epoch 11/500\n",
      "426/436 [============================>.] - ETA: 0s - loss: 2208.3477 - mse: 20481984.0000 - mae: 2208.6506\n",
      "Epoch 11: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2225.0420 - mse: 20681212.0000 - mae: 2225.3459 - val_loss: 2172.5088 - val_mse: 20894184.0000 - val_mae: 2172.8003 - lr: 7.8125e-06\n",
      "Epoch 12/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2214.1445 - mse: 20552768.0000 - mae: 2214.4490\n",
      "Epoch 12: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2222.6770 - mse: 20642672.0000 - mae: 2222.9822 - val_loss: 2174.6094 - val_mse: 20914500.0000 - val_mae: 2174.9014 - lr: 7.8125e-06\n",
      "Epoch 13/500\n",
      "424/436 [============================>.] - ETA: 0s - loss: 2198.9038 - mse: 20337498.0000 - mae: 2199.2058\n",
      "Epoch 13: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2218.6655 - mse: 20586220.0000 - mae: 2218.9680 - val_loss: 2173.1704 - val_mse: 20893492.0000 - val_mae: 2173.4614 - lr: 7.8125e-06\n",
      "Epoch 14/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2208.4565 - mse: 20448890.0000 - mae: 2208.7615\n",
      "Epoch 14: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2217.1128 - mse: 20541440.0000 - mae: 2217.4177 - val_loss: 2170.0256 - val_mse: 20820810.0000 - val_mae: 2170.3184 - lr: 7.8125e-06\n",
      "Epoch 15/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2206.8125 - mse: 20414772.0000 - mae: 2207.1157\n",
      "Epoch 15: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2218.2568 - mse: 20538986.0000 - mae: 2218.5605 - val_loss: 2168.5581 - val_mse: 20661116.0000 - val_mae: 2168.8508 - lr: 7.8125e-06\n",
      "Epoch 16/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2218.5505 - mse: 20633694.0000 - mae: 2218.8552\n",
      "Epoch 16: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2220.3528 - mse: 20644572.0000 - mae: 2220.6575 - val_loss: 2166.0471 - val_mse: 20692226.0000 - val_mae: 2166.3394 - lr: 7.8125e-06\n",
      "Epoch 17/500\n",
      "427/436 [============================>.] - ETA: 0s - loss: 2205.5068 - mse: 20441036.0000 - mae: 2205.8113\n",
      "Epoch 17: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2219.7358 - mse: 20621280.0000 - mae: 2220.0410 - val_loss: 2170.3750 - val_mse: 20709540.0000 - val_mae: 2170.6675 - lr: 7.8125e-06\n",
      "Epoch 18/500\n",
      "419/436 [===========================>..] - ETA: 0s - loss: 2196.0320 - mse: 20314742.0000 - mae: 2196.3357\n",
      "Epoch 18: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2217.8411 - mse: 20565424.0000 - mae: 2218.1465 - val_loss: 2157.5884 - val_mse: 20444336.0000 - val_mae: 2157.8809 - lr: 7.8125e-06\n",
      "Epoch 19/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2218.8582 - mse: 20642792.0000 - mae: 2219.1628\n",
      "Epoch 19: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2220.8110 - mse: 20656510.0000 - mae: 2221.1157 - val_loss: 2166.9590 - val_mse: 20678646.0000 - val_mae: 2167.2520 - lr: 3.9063e-06\n",
      "Epoch 20/500\n",
      "426/436 [============================>.] - ETA: 0s - loss: 2198.7446 - mse: 20372100.0000 - mae: 2199.0493\n",
      "Epoch 20: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2215.8494 - mse: 20581860.0000 - mae: 2216.1545 - val_loss: 2164.5664 - val_mse: 20662544.0000 - val_mae: 2164.8582 - lr: 3.9063e-06\n",
      "Epoch 21/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2203.1284 - mse: 20412702.0000 - mae: 2203.4326\n",
      "Epoch 21: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2212.6841 - mse: 20525338.0000 - mae: 2212.9885 - val_loss: 2160.9001 - val_mse: 20613342.0000 - val_mae: 2161.1921 - lr: 3.9063e-06\n",
      "Epoch 22/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2209.1855 - mse: 20480838.0000 - mae: 2209.4905\n",
      "Epoch 22: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2211.1675 - mse: 20495056.0000 - mae: 2211.4724 - val_loss: 2159.4502 - val_mse: 20589926.0000 - val_mae: 2159.7422 - lr: 3.9063e-06\n",
      "Epoch 23/500\n",
      "420/436 [===========================>..] - ETA: 0s - loss: 2185.7837 - mse: 20196194.0000 - mae: 2186.0857\n",
      "Epoch 23: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2209.7195 - mse: 20481886.0000 - mae: 2210.0227 - val_loss: 2160.2725 - val_mse: 20579188.0000 - val_mae: 2160.5642 - lr: 3.9063e-06\n",
      "Epoch 24/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2203.0354 - mse: 20375746.0000 - mae: 2203.3413\n",
      "Epoch 24: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2208.0740 - mse: 20430940.0000 - mae: 2208.3801 - val_loss: 2160.0459 - val_mse: 20569676.0000 - val_mae: 2160.3394 - lr: 3.9063e-06\n",
      "Epoch 25/500\n",
      "423/436 [============================>.] - ETA: 0s - loss: 2189.4163 - mse: 20205048.0000 - mae: 2189.7222\n",
      "Epoch 25: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2209.6345 - mse: 20453264.0000 - mae: 2209.9412 - val_loss: 2160.5046 - val_mse: 20570272.0000 - val_mae: 2160.7974 - lr: 3.9063e-06\n",
      "Epoch 26/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2204.5706 - mse: 20396244.0000 - mae: 2204.8752\n",
      "Epoch 26: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2209.5813 - mse: 20450960.0000 - mae: 2209.8862 - val_loss: 2158.8958 - val_mse: 20560668.0000 - val_mae: 2159.1875 - lr: 3.9063e-06\n",
      "Epoch 27/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2195.7808 - mse: 20269612.0000 - mae: 2196.0850\n",
      "Epoch 27: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2207.7483 - mse: 20426724.0000 - mae: 2208.0530 - val_loss: 2157.9946 - val_mse: 20548578.0000 - val_mae: 2158.2871 - lr: 3.9063e-06\n",
      "Epoch 28/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2209.0518 - mse: 20424860.0000 - mae: 2209.3557\n",
      "Epoch 28: val_loss did not improve from 2155.01001\n",
      "436/436 [==============================] - 2s 4ms/step - loss: 2209.0518 - mse: 20424860.0000 - mae: 2209.3557 - val_loss: 2156.9673 - val_mse: 20527218.0000 - val_mae: 2157.2595 - lr: 3.9063e-06\n"
     ]
    }
   ],
   "source": [
    "rnn_history = rnn_model.fit(train_data, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_rnn])\n",
    "rnn_history_ns = rnn_model.fit(train_data_ns, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_rnn_ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    435/Unknown - 12s 6ms/step - loss: 7615.9390 - mse: 183480832.0000 - mae: 7616.2651\n",
      "Epoch 1: val_loss improved from inf to 7106.72412, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 15s 12ms/step - loss: 7619.9600 - mse: 183658496.0000 - mae: 7620.2852 - val_loss: 7106.7241 - val_mse: 171538432.0000 - val_mae: 7107.0107 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 7563.5996 - mse: 181821344.0000 - mae: 7563.9058\n",
      "Epoch 2: val_loss improved from 7106.72412 to 7043.36133, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 7576.6865 - mse: 182088352.0000 - mae: 7576.9932 - val_loss: 7043.3613 - val_mse: 169202864.0000 - val_mae: 7043.6621 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 7482.7051 - mse: 178742720.0000 - mae: 7483.0117\n",
      "Epoch 3: val_loss improved from 7043.36133 to 6927.76514, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 7478.0898 - mse: 178624800.0000 - mae: 7478.3965 - val_loss: 6927.7651 - val_mse: 165256320.0000 - val_mae: 6928.0493 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 7342.4595 - mse: 173801920.0000 - mae: 7342.7681\n",
      "Epoch 4: val_loss improved from 6927.76514 to 6796.52148, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 7342.4595 - mse: 173801920.0000 - mae: 7342.7681 - val_loss: 6796.5215 - val_mse: 160240784.0000 - val_mae: 6796.8276 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 7174.6445 - mse: 168040368.0000 - mae: 7174.9507\n",
      "Epoch 5: val_loss improved from 6796.52148 to 6622.09961, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 7174.6445 - mse: 168040368.0000 - mae: 7174.9507 - val_loss: 6622.0996 - val_mse: 154617296.0000 - val_mae: 6622.4458 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 7011.9077 - mse: 161786640.0000 - mae: 7012.2231\n",
      "Epoch 6: val_loss improved from 6622.09961 to 6448.95703, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 7018.6509 - mse: 161890528.0000 - mae: 7018.9658 - val_loss: 6448.9570 - val_mse: 148472720.0000 - val_mae: 6449.2798 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 6790.3140 - mse: 154495024.0000 - mae: 6790.6270\n",
      "Epoch 7: val_loss improved from 6448.95703 to 6260.43848, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 6798.9902 - mse: 154758720.0000 - mae: 6799.3042 - val_loss: 6260.4385 - val_mse: 141590640.0000 - val_mae: 6260.7686 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 6589.0737 - mse: 147613536.0000 - mae: 6589.3789\n",
      "Epoch 8: val_loss improved from 6260.43848 to 6149.08008, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 6580.4536 - mse: 147288112.0000 - mae: 6580.7588 - val_loss: 6149.0801 - val_mse: 135697616.0000 - val_mae: 6149.4292 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 6497.6025 - mse: 142604912.0000 - mae: 6497.9370\n",
      "Epoch 9: val_loss improved from 6149.08008 to 5861.16211, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 6497.6025 - mse: 142604912.0000 - mae: 6497.9370 - val_loss: 5861.1621 - val_mse: 127537064.0000 - val_mae: 5861.5059 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 6155.2915 - mse: 132132920.0000 - mae: 6155.5981\n",
      "Epoch 10: val_loss improved from 5861.16211 to 5663.61865, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 6154.9365 - mse: 132105440.0000 - mae: 6155.2432 - val_loss: 5663.6187 - val_mse: 120102152.0000 - val_mae: 5663.8677 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 5970.2861 - mse: 124582008.0000 - mae: 5970.5947\n",
      "Epoch 11: val_loss improved from 5663.61865 to 5501.59814, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 5973.6489 - mse: 124621984.0000 - mae: 5973.9570 - val_loss: 5501.5981 - val_mse: 113425696.0000 - val_mae: 5501.8716 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 5755.9209 - mse: 117061832.0000 - mae: 5756.2256\n",
      "Epoch 12: val_loss improved from 5501.59814 to 5272.87695, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 5750.1851 - mse: 116943240.0000 - mae: 5750.4902 - val_loss: 5272.8770 - val_mse: 106148904.0000 - val_mae: 5273.1445 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 5557.4917 - mse: 109580152.0000 - mae: 5557.7891\n",
      "Epoch 13: val_loss did not improve from 5272.87695\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 5568.4062 - mse: 109647568.0000 - mae: 5568.7046 - val_loss: 5285.9604 - val_mse: 100327816.0000 - val_mae: 5286.2544 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 5470.8442 - mse: 104641968.0000 - mae: 5471.1514\n",
      "Epoch 14: val_loss improved from 5272.87695 to 4928.33545, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 5474.9995 - mse: 104746000.0000 - mae: 5475.3066 - val_loss: 4928.3354 - val_mse: 93031656.0000 - val_mae: 4928.5938 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 5190.3398 - mse: 95915320.0000 - mae: 5190.6748\n",
      "Epoch 15: val_loss improved from 4928.33545 to 4818.76270, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 5191.9707 - mse: 95984832.0000 - mae: 5192.3057 - val_loss: 4818.7627 - val_mse: 87639872.0000 - val_mae: 4819.0645 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 5014.0488 - mse: 89184848.0000 - mae: 5014.3682\n",
      "Epoch 16: val_loss improved from 4818.76270 to 4648.96533, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 5012.3467 - mse: 89090016.0000 - mae: 5012.6655 - val_loss: 4648.9653 - val_mse: 80192976.0000 - val_mae: 4649.2593 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 4862.3730 - mse: 82935384.0000 - mae: 4862.7090\n",
      "Epoch 17: val_loss improved from 4648.96533 to 4446.92383, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 4868.0361 - mse: 82983896.0000 - mae: 4868.3721 - val_loss: 4446.9238 - val_mse: 74143112.0000 - val_mae: 4447.2871 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 4711.1191 - mse: 77176784.0000 - mae: 4711.4331\n",
      "Epoch 18: val_loss improved from 4446.92383 to 4371.72705, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 4714.8301 - mse: 77199032.0000 - mae: 4715.1440 - val_loss: 4371.7271 - val_mse: 70370712.0000 - val_mae: 4372.0186 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 4514.5010 - mse: 70840704.0000 - mae: 4514.8330\n",
      "Epoch 19: val_loss improved from 4371.72705 to 4149.35254, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 4505.1089 - mse: 70628400.0000 - mae: 4505.4419 - val_loss: 4149.3525 - val_mse: 63520464.0000 - val_mae: 4149.7905 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 4312.0781 - mse: 64958724.0000 - mae: 4312.4180\n",
      "Epoch 20: val_loss improved from 4149.35254 to 4024.53198, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 4317.3350 - mse: 65005660.0000 - mae: 4317.6753 - val_loss: 4024.5320 - val_mse: 58642100.0000 - val_mae: 4024.8154 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 4200.4463 - mse: 60632020.0000 - mae: 4200.7520\n",
      "Epoch 21: val_loss improved from 4024.53198 to 3967.41187, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 4211.5215 - mse: 60688780.0000 - mae: 4211.8281 - val_loss: 3967.4119 - val_mse: 54240040.0000 - val_mae: 3967.6936 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 4110.8066 - mse: 56693512.0000 - mae: 4111.1138\n",
      "Epoch 22: val_loss did not improve from 3967.41187\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 4109.1123 - mse: 56606824.0000 - mae: 4109.4199 - val_loss: 4046.6526 - val_mse: 53334216.0000 - val_mae: 4046.9968 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 3947.8191 - mse: 53157644.0000 - mae: 3948.1536\n",
      "Epoch 23: val_loss improved from 3967.41187 to 3798.65259, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3952.5227 - mse: 53202836.0000 - mae: 3952.8572 - val_loss: 3798.6526 - val_mse: 48553088.0000 - val_mae: 3798.9414 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 3788.0149 - mse: 48151772.0000 - mae: 3788.3411\n",
      "Epoch 24: val_loss improved from 3798.65259 to 3635.78198, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 3790.1499 - mse: 48207256.0000 - mae: 3790.4761 - val_loss: 3635.7820 - val_mse: 44844096.0000 - val_mae: 3636.0781 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 3663.6038 - mse: 45152440.0000 - mae: 3663.9124\n",
      "Epoch 25: val_loss improved from 3635.78198 to 3511.62109, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 3667.4370 - mse: 45188220.0000 - mae: 3667.7466 - val_loss: 3511.6211 - val_mse: 41805288.0000 - val_mae: 3511.9622 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 3571.4509 - mse: 42150212.0000 - mae: 3571.7656\n",
      "Epoch 26: val_loss improved from 3511.62109 to 3436.72144, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3574.4644 - mse: 42160352.0000 - mae: 3574.7791 - val_loss: 3436.7214 - val_mse: 39260016.0000 - val_mae: 3437.0149 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 3457.7378 - mse: 39756352.0000 - mae: 3458.0635\n",
      "Epoch 27: val_loss improved from 3436.72144 to 3401.21118, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3458.8215 - mse: 39771168.0000 - mae: 3459.1472 - val_loss: 3401.2112 - val_mse: 37398852.0000 - val_mae: 3401.4841 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 3452.9719 - mse: 38904960.0000 - mae: 3453.2827\n",
      "Epoch 28: val_loss improved from 3401.21118 to 3270.02661, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3452.9719 - mse: 38904960.0000 - mae: 3453.2827 - val_loss: 3270.0266 - val_mse: 35610376.0000 - val_mae: 3270.3296 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 3371.3923 - mse: 37464812.0000 - mae: 3371.7122\n",
      "Epoch 29: val_loss did not improve from 3270.02661\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3377.4338 - mse: 37539784.0000 - mae: 3377.7539 - val_loss: 3318.2241 - val_mse: 35287696.0000 - val_mae: 3318.5701 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 3480.9077 - mse: 38708812.0000 - mae: 3481.2168\n",
      "Epoch 30: val_loss did not improve from 3270.02661\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3483.9263 - mse: 38733444.0000 - mae: 3484.2356 - val_loss: 3516.2705 - val_mse: 38555248.0000 - val_mae: 3516.5701 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 3247.3074 - mse: 34448616.0000 - mae: 3247.6206\n",
      "Epoch 31: val_loss improved from 3270.02661 to 3136.58984, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3243.2439 - mse: 34380808.0000 - mae: 3243.5571 - val_loss: 3136.5898 - val_mse: 32473420.0000 - val_mae: 3136.8586 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 3163.6536 - mse: 33197350.0000 - mae: 3163.9648\n",
      "Epoch 32: val_loss improved from 3136.58984 to 3083.47681, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 3162.4343 - mse: 33177344.0000 - mae: 3162.7458 - val_loss: 3083.4768 - val_mse: 31480704.0000 - val_mae: 3083.7493 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 3226.5251 - mse: 34162276.0000 - mae: 3226.8384\n",
      "Epoch 33: val_loss did not improve from 3083.47681\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3228.8391 - mse: 34203400.0000 - mae: 3229.1526 - val_loss: 3114.0044 - val_mse: 32586744.0000 - val_mae: 3114.3352 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 3104.2439 - mse: 32278752.0000 - mae: 3104.5593\n",
      "Epoch 34: val_loss did not improve from 3083.47681\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3112.4919 - mse: 32446688.0000 - mae: 3112.8071 - val_loss: 3285.9490 - val_mse: 34095828.0000 - val_mae: 3286.2490 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 3121.6729 - mse: 32721874.0000 - mae: 3121.9934\n",
      "Epoch 35: val_loss did not improve from 3083.47681\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3125.5840 - mse: 32792466.0000 - mae: 3125.9043 - val_loss: 3387.9729 - val_mse: 37697060.0000 - val_mae: 3388.2788 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 3145.1379 - mse: 32988612.0000 - mae: 3145.4580\n",
      "Epoch 36: val_loss improved from 3083.47681 to 3066.10962, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 3143.7476 - mse: 32951354.0000 - mae: 3144.0674 - val_loss: 3066.1096 - val_mse: 32182074.0000 - val_mae: 3066.4116 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 3239.8367 - mse: 35293508.0000 - mae: 3240.1484\n",
      "Epoch 37: val_loss did not improve from 3066.10962\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3239.8367 - mse: 35293508.0000 - mae: 3240.1484 - val_loss: 3105.9329 - val_mse: 31915604.0000 - val_mae: 3106.2266 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 3078.9839 - mse: 32188136.0000 - mae: 3079.2957\n",
      "Epoch 38: val_loss improved from 3066.10962 to 2916.98047, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3078.9839 - mse: 32188136.0000 - mae: 3079.2957 - val_loss: 2916.9805 - val_mse: 29564496.0000 - val_mae: 2917.2815 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 3071.8740 - mse: 32355326.0000 - mae: 3072.1843\n",
      "Epoch 39: val_loss did not improve from 2916.98047\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3076.3396 - mse: 32440698.0000 - mae: 3076.6509 - val_loss: 3038.9580 - val_mse: 32218384.0000 - val_mae: 3039.2947 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2996.9822 - mse: 30993998.0000 - mae: 2997.2908\n",
      "Epoch 40: val_loss did not improve from 2916.98047\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2996.3137 - mse: 30981512.0000 - mae: 2996.6226 - val_loss: 2924.2324 - val_mse: 29733566.0000 - val_mae: 2924.4783 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2972.5842 - mse: 30454824.0000 - mae: 2972.8911\n",
      "Epoch 41: val_loss improved from 2916.98047 to 2910.15112, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2971.3123 - mse: 30449350.0000 - mae: 2971.6191 - val_loss: 2910.1511 - val_mse: 30136022.0000 - val_mae: 2910.4573 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "427/436 [============================>.] - ETA: 0s - loss: 2931.2410 - mse: 30046764.0000 - mae: 2931.5486\n",
      "Epoch 42: val_loss improved from 2910.15112 to 2868.06543, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2942.7180 - mse: 30235538.0000 - mae: 2943.0256 - val_loss: 2868.0654 - val_mse: 30026868.0000 - val_mae: 2868.3276 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2991.1213 - mse: 30770572.0000 - mae: 2991.4285\n",
      "Epoch 43: val_loss did not improve from 2868.06543\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2995.1755 - mse: 30853454.0000 - mae: 2995.4827 - val_loss: 3219.2217 - val_mse: 34433064.0000 - val_mae: 3219.4995 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2983.3047 - mse: 31155696.0000 - mae: 2983.6099\n",
      "Epoch 44: val_loss did not improve from 2868.06543\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2983.7290 - mse: 31148564.0000 - mae: 2984.0339 - val_loss: 2986.7153 - val_mse: 31494318.0000 - val_mae: 2986.9675 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 3021.3958 - mse: 31224718.0000 - mae: 3021.6990\n",
      "Epoch 45: val_loss did not improve from 2868.06543\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3020.5620 - mse: 31216562.0000 - mae: 3020.8657 - val_loss: 2872.9070 - val_mse: 29836718.0000 - val_mae: 2873.1997 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2904.5476 - mse: 29977414.0000 - mae: 2904.8518\n",
      "Epoch 46: val_loss improved from 2868.06543 to 2857.80225, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2906.5095 - mse: 30019836.0000 - mae: 2906.8137 - val_loss: 2857.8022 - val_mse: 30800884.0000 - val_mae: 2858.0745 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2907.1545 - mse: 30468360.0000 - mae: 2907.4719\n",
      "Epoch 47: val_loss improved from 2857.80225 to 2833.65820, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2910.6558 - mse: 30517262.0000 - mae: 2910.9736 - val_loss: 2833.6582 - val_mse: 28947934.0000 - val_mae: 2833.9885 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2912.6833 - mse: 29861286.0000 - mae: 2912.9944\n",
      "Epoch 48: val_loss did not improve from 2833.65820\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2921.4236 - mse: 30004012.0000 - mae: 2921.7356 - val_loss: 2834.3430 - val_mse: 30218150.0000 - val_mae: 2834.6304 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 3027.2227 - mse: 31710276.0000 - mae: 3027.5320\n",
      "Epoch 49: val_loss did not improve from 2833.65820\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3030.1177 - mse: 31766024.0000 - mae: 3030.4268 - val_loss: 3022.1021 - val_mse: 33815496.0000 - val_mae: 3022.3936 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 3332.3582 - mse: 38553940.0000 - mae: 3332.6812\n",
      "Epoch 50: val_loss did not improve from 2833.65820\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3338.6648 - mse: 38637840.0000 - mae: 3338.9878 - val_loss: 3351.6519 - val_mse: 37040564.0000 - val_mae: 3351.9109 - lr: 0.0010\n",
      "Epoch 51/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 3291.2444 - mse: 37009232.0000 - mae: 3291.5542\n",
      "Epoch 51: val_loss improved from 2833.65820 to 2807.87451, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3292.7319 - mse: 37008972.0000 - mae: 3293.0420 - val_loss: 2807.8745 - val_mse: 29059444.0000 - val_mae: 2808.1731 - lr: 0.0010\n",
      "Epoch 52/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2925.8333 - mse: 30313938.0000 - mae: 2926.1375\n",
      "Epoch 52: val_loss did not improve from 2807.87451\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2925.6272 - mse: 30311382.0000 - mae: 2925.9324 - val_loss: 2850.7668 - val_mse: 29120284.0000 - val_mae: 2851.0728 - lr: 0.0010\n",
      "Epoch 53/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2967.7932 - mse: 30556304.0000 - mae: 2968.1013\n",
      "Epoch 53: val_loss did not improve from 2807.87451\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2970.9082 - mse: 30619476.0000 - mae: 2971.2166 - val_loss: 3746.4875 - val_mse: 43423088.0000 - val_mae: 3746.7864 - lr: 0.0010\n",
      "Epoch 54/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 3256.4099 - mse: 35944860.0000 - mae: 3256.7136\n",
      "Epoch 54: val_loss did not improve from 2807.87451\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3257.1948 - mse: 35958508.0000 - mae: 3257.4985 - val_loss: 3028.3220 - val_mse: 32227566.0000 - val_mae: 3028.6338 - lr: 0.0010\n",
      "Epoch 55/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 3018.4353 - mse: 32076902.0000 - mae: 3018.7444\n",
      "Epoch 55: val_loss did not improve from 2807.87451\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3018.4353 - mse: 32076902.0000 - mae: 3018.7444 - val_loss: 3203.4705 - val_mse: 35964688.0000 - val_mae: 3203.7759 - lr: 0.0010\n",
      "Epoch 56/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2974.7773 - mse: 30811738.0000 - mae: 2975.0784\n",
      "Epoch 56: val_loss did not improve from 2807.87451\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2979.1040 - mse: 30879532.0000 - mae: 2979.4050 - val_loss: 2991.3584 - val_mse: 32182950.0000 - val_mae: 2991.6836 - lr: 0.0010\n",
      "Epoch 57/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2978.1904 - mse: 30884142.0000 - mae: 2978.4966\n",
      "Epoch 57: val_loss did not improve from 2807.87451\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2985.2773 - mse: 30973602.0000 - mae: 2985.5842 - val_loss: 3053.8088 - val_mse: 30679190.0000 - val_mae: 3054.1155 - lr: 0.0010\n",
      "Epoch 58/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2926.9175 - mse: 30267596.0000 - mae: 2927.2207\n",
      "Epoch 58: val_loss did not improve from 2807.87451\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2937.8643 - mse: 30388366.0000 - mae: 2938.1682 - val_loss: 2846.1206 - val_mse: 28883072.0000 - val_mae: 2846.4099 - lr: 0.0010\n",
      "Epoch 59/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2905.9583 - mse: 30307938.0000 - mae: 2906.2629\n",
      "Epoch 59: val_loss did not improve from 2807.87451\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2903.7144 - mse: 30259464.0000 - mae: 2904.0190 - val_loss: 2833.6667 - val_mse: 29412604.0000 - val_mae: 2833.9263 - lr: 0.0010\n",
      "Epoch 60/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2818.6218 - mse: 29017998.0000 - mae: 2818.9319\n",
      "Epoch 60: val_loss improved from 2807.87451 to 2678.18066, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2820.8708 - mse: 29054154.0000 - mae: 2821.1809 - val_loss: 2678.1807 - val_mse: 27406786.0000 - val_mae: 2678.4636 - lr: 0.0010\n",
      "Epoch 61/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2959.0908 - mse: 31073482.0000 - mae: 2959.4136\n",
      "Epoch 61: val_loss did not improve from 2678.18066\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2965.9106 - mse: 31227018.0000 - mae: 2966.2334 - val_loss: 2961.1313 - val_mse: 34080140.0000 - val_mae: 2961.4468 - lr: 0.0010\n",
      "Epoch 62/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2989.6211 - mse: 32432596.0000 - mae: 2989.9353\n",
      "Epoch 62: val_loss did not improve from 2678.18066\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2990.2124 - mse: 32446658.0000 - mae: 2990.5269 - val_loss: 2905.2119 - val_mse: 31140270.0000 - val_mae: 2905.4761 - lr: 0.0010\n",
      "Epoch 63/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2958.6516 - mse: 31762036.0000 - mae: 2958.9561\n",
      "Epoch 63: val_loss did not improve from 2678.18066\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2964.4609 - mse: 31828212.0000 - mae: 2964.7656 - val_loss: 2918.6155 - val_mse: 30480996.0000 - val_mae: 2918.8855 - lr: 0.0010\n",
      "Epoch 64/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 3165.1318 - mse: 34620344.0000 - mae: 3165.4475\n",
      "Epoch 64: val_loss did not improve from 2678.18066\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 3163.1692 - mse: 34588144.0000 - mae: 3163.4851 - val_loss: 3316.0435 - val_mse: 36703592.0000 - val_mae: 3316.3635 - lr: 0.0010\n",
      "Epoch 65/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 3335.3167 - mse: 37914008.0000 - mae: 3335.6262\n",
      "Epoch 65: val_loss did not improve from 2678.18066\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 3334.6069 - mse: 37899960.0000 - mae: 3334.9163 - val_loss: 3139.6707 - val_mse: 33634028.0000 - val_mae: 3139.9368 - lr: 0.0010\n",
      "Epoch 66/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 3090.3420 - mse: 33128552.0000 - mae: 3090.6545\n",
      "Epoch 66: val_loss did not improve from 2678.18066\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3093.7222 - mse: 33215638.0000 - mae: 3094.0361 - val_loss: 3026.9929 - val_mse: 32748028.0000 - val_mae: 3027.3066 - lr: 0.0010\n",
      "Epoch 67/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 3008.9463 - mse: 31901570.0000 - mae: 3009.2595\n",
      "Epoch 67: val_loss did not improve from 2678.18066\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3005.1606 - mse: 31834108.0000 - mae: 3005.4739 - val_loss: 3101.9419 - val_mse: 33249668.0000 - val_mae: 3102.2234 - lr: 0.0010\n",
      "Epoch 68/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 3011.0813 - mse: 32178508.0000 - mae: 3011.3955\n",
      "Epoch 68: val_loss did not improve from 2678.18066\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3014.5120 - mse: 32240098.0000 - mae: 3014.8262 - val_loss: 2985.4041 - val_mse: 32268274.0000 - val_mae: 2985.6904 - lr: 0.0010\n",
      "Epoch 69/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 3034.3811 - mse: 32795986.0000 - mae: 3034.6973\n",
      "Epoch 69: val_loss did not improve from 2678.18066\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3036.7375 - mse: 32854322.0000 - mae: 3037.0535 - val_loss: 2980.7427 - val_mse: 32204756.0000 - val_mae: 2981.0388 - lr: 0.0010\n",
      "Epoch 70/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 3096.4910 - mse: 33290536.0000 - mae: 3096.8027\n",
      "Epoch 70: val_loss did not improve from 2678.18066\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 3100.2834 - mse: 33346204.0000 - mae: 3100.5955 - val_loss: 2918.7515 - val_mse: 30217700.0000 - val_mae: 2919.0498 - lr: 0.0010\n",
      "Epoch 71/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 3057.8105 - mse: 32266642.0000 - mae: 3058.1182\n",
      "Epoch 71: val_loss did not improve from 2678.18066\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 3059.7278 - mse: 32319898.0000 - mae: 3060.0359 - val_loss: 2751.3665 - val_mse: 28566870.0000 - val_mae: 2751.6765 - lr: 5.0000e-04\n",
      "Epoch 72/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2904.9873 - mse: 30005340.0000 - mae: 2905.2971\n",
      "Epoch 72: val_loss did not improve from 2678.18066\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2909.0852 - mse: 30078230.0000 - mae: 2909.3960 - val_loss: 2797.5417 - val_mse: 28921228.0000 - val_mae: 2797.8926 - lr: 5.0000e-04\n",
      "Epoch 73/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2851.1975 - mse: 29760258.0000 - mae: 2851.5115\n",
      "Epoch 73: val_loss did not improve from 2678.18066\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2850.4905 - mse: 29723974.0000 - mae: 2850.8047 - val_loss: 2790.4675 - val_mse: 28385986.0000 - val_mae: 2790.7625 - lr: 5.0000e-04\n",
      "Epoch 74/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2794.1365 - mse: 28597534.0000 - mae: 2794.4514\n",
      "Epoch 74: val_loss did not improve from 2678.18066\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2799.4138 - mse: 28653286.0000 - mae: 2799.7288 - val_loss: 2691.3821 - val_mse: 26658446.0000 - val_mae: 2691.6626 - lr: 5.0000e-04\n",
      "Epoch 75/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2831.9043 - mse: 28814722.0000 - mae: 2832.2178\n",
      "Epoch 75: val_loss improved from 2678.18066 to 2622.16724, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2833.0737 - mse: 28759816.0000 - mae: 2833.3875 - val_loss: 2622.1672 - val_mse: 26448040.0000 - val_mae: 2622.4465 - lr: 5.0000e-04\n",
      "Epoch 76/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2750.7610 - mse: 27610074.0000 - mae: 2751.0791\n",
      "Epoch 76: val_loss did not improve from 2622.16724\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2752.9512 - mse: 27639634.0000 - mae: 2753.2695 - val_loss: 2662.9038 - val_mse: 26854178.0000 - val_mae: 2663.2131 - lr: 5.0000e-04\n",
      "Epoch 77/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2692.0667 - mse: 26684900.0000 - mae: 2692.3857\n",
      "Epoch 77: val_loss did not improve from 2622.16724\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2698.6721 - mse: 26785116.0000 - mae: 2698.9912 - val_loss: 2625.9385 - val_mse: 25898610.0000 - val_mae: 2626.2432 - lr: 5.0000e-04\n",
      "Epoch 78/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2703.6143 - mse: 26728746.0000 - mae: 2703.9297\n",
      "Epoch 78: val_loss did not improve from 2622.16724\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2705.5891 - mse: 26770866.0000 - mae: 2705.9048 - val_loss: 2623.6221 - val_mse: 26518896.0000 - val_mae: 2623.9290 - lr: 5.0000e-04\n",
      "Epoch 79/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2777.7437 - mse: 28333660.0000 - mae: 2778.0540\n",
      "Epoch 79: val_loss did not improve from 2622.16724\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2777.7437 - mse: 28333660.0000 - mae: 2778.0540 - val_loss: 2643.5364 - val_mse: 26141248.0000 - val_mae: 2643.8140 - lr: 5.0000e-04\n",
      "Epoch 80/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2780.2998 - mse: 27942388.0000 - mae: 2780.6052\n",
      "Epoch 80: val_loss did not improve from 2622.16724\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2785.6633 - mse: 28083028.0000 - mae: 2785.9692 - val_loss: 2680.8970 - val_mse: 26970302.0000 - val_mae: 2681.2039 - lr: 5.0000e-04\n",
      "Epoch 81/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2801.5996 - mse: 28162812.0000 - mae: 2801.9058\n",
      "Epoch 81: val_loss improved from 2622.16724 to 2555.65210, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2801.5996 - mse: 28162812.0000 - mae: 2801.9058 - val_loss: 2555.6521 - val_mse: 25637638.0000 - val_mae: 2555.9551 - lr: 5.0000e-04\n",
      "Epoch 82/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2737.3511 - mse: 27876828.0000 - mae: 2737.6560\n",
      "Epoch 82: val_loss did not improve from 2555.65210\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2745.3228 - mse: 28018796.0000 - mae: 2745.6282 - val_loss: 2683.9165 - val_mse: 28493258.0000 - val_mae: 2684.2034 - lr: 5.0000e-04\n",
      "Epoch 83/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2740.2690 - mse: 27958756.0000 - mae: 2740.5728\n",
      "Epoch 83: val_loss did not improve from 2555.65210\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2740.2690 - mse: 27958756.0000 - mae: 2740.5728 - val_loss: 2581.1162 - val_mse: 25436578.0000 - val_mae: 2581.4126 - lr: 5.0000e-04\n",
      "Epoch 84/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2713.6990 - mse: 27197596.0000 - mae: 2713.9983\n",
      "Epoch 84: val_loss did not improve from 2555.65210\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2717.2283 - mse: 27216604.0000 - mae: 2717.5281 - val_loss: 2635.9023 - val_mse: 25572524.0000 - val_mae: 2636.2122 - lr: 5.0000e-04\n",
      "Epoch 85/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2669.8616 - mse: 26605186.0000 - mae: 2670.1694\n",
      "Epoch 85: val_loss did not improve from 2555.65210\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2680.4043 - mse: 26734558.0000 - mae: 2680.7124 - val_loss: 2624.5151 - val_mse: 27421274.0000 - val_mae: 2624.8154 - lr: 5.0000e-04\n",
      "Epoch 86/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2717.7749 - mse: 27465070.0000 - mae: 2718.0916\n",
      "Epoch 86: val_loss did not improve from 2555.65210\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2725.2439 - mse: 27638596.0000 - mae: 2725.5608 - val_loss: 2610.2747 - val_mse: 27327232.0000 - val_mae: 2610.5723 - lr: 5.0000e-04\n",
      "Epoch 87/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2708.7295 - mse: 27615768.0000 - mae: 2709.0415\n",
      "Epoch 87: val_loss did not improve from 2555.65210\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2716.1272 - mse: 27721626.0000 - mae: 2716.4395 - val_loss: 2573.5393 - val_mse: 26303794.0000 - val_mae: 2573.8596 - lr: 5.0000e-04\n",
      "Epoch 88/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2654.2300 - mse: 26383902.0000 - mae: 2654.5532\n",
      "Epoch 88: val_loss did not improve from 2555.65210\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2655.0305 - mse: 26382952.0000 - mae: 2655.3538 - val_loss: 2611.4885 - val_mse: 26183256.0000 - val_mae: 2611.7932 - lr: 5.0000e-04\n",
      "Epoch 89/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2623.2351 - mse: 25834584.0000 - mae: 2623.5483\n",
      "Epoch 89: val_loss did not improve from 2555.65210\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2635.8054 - mse: 26095194.0000 - mae: 2636.1189 - val_loss: 2689.5227 - val_mse: 28695930.0000 - val_mae: 2689.8088 - lr: 5.0000e-04\n",
      "Epoch 90/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2657.1555 - mse: 26878462.0000 - mae: 2657.4629\n",
      "Epoch 90: val_loss improved from 2555.65210 to 2545.00269, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2662.5061 - mse: 26921756.0000 - mae: 2662.8137 - val_loss: 2545.0027 - val_mse: 25089952.0000 - val_mae: 2545.3164 - lr: 5.0000e-04\n",
      "Epoch 91/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2655.8374 - mse: 26867868.0000 - mae: 2656.1516\n",
      "Epoch 91: val_loss did not improve from 2545.00269\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2661.2820 - mse: 26921842.0000 - mae: 2661.5964 - val_loss: 2655.5229 - val_mse: 27867460.0000 - val_mae: 2655.8035 - lr: 5.0000e-04\n",
      "Epoch 92/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2645.3459 - mse: 26721810.0000 - mae: 2645.6609\n",
      "Epoch 92: val_loss improved from 2545.00269 to 2543.78174, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2646.8630 - mse: 26734378.0000 - mae: 2647.1782 - val_loss: 2543.7817 - val_mse: 25548588.0000 - val_mae: 2544.0964 - lr: 5.0000e-04\n",
      "Epoch 93/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2603.0176 - mse: 25614420.0000 - mae: 2603.3262\n",
      "Epoch 93: val_loss improved from 2543.78174 to 2527.81958, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2605.5662 - mse: 25660188.0000 - mae: 2605.8757 - val_loss: 2527.8196 - val_mse: 25688484.0000 - val_mae: 2528.1433 - lr: 5.0000e-04\n",
      "Epoch 94/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2662.5342 - mse: 27196442.0000 - mae: 2662.8452\n",
      "Epoch 94: val_loss did not improve from 2527.81958\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2666.4834 - mse: 27259984.0000 - mae: 2666.7947 - val_loss: 2561.3518 - val_mse: 26050918.0000 - val_mae: 2561.6650 - lr: 5.0000e-04\n",
      "Epoch 95/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2635.8308 - mse: 26392218.0000 - mae: 2636.1450\n",
      "Epoch 95: val_loss did not improve from 2527.81958\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2640.2871 - mse: 26457220.0000 - mae: 2640.6021 - val_loss: 2729.5129 - val_mse: 27582130.0000 - val_mae: 2729.7981 - lr: 5.0000e-04\n",
      "Epoch 96/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2671.8772 - mse: 26504696.0000 - mae: 2672.1968\n",
      "Epoch 96: val_loss did not improve from 2527.81958\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2672.5305 - mse: 26503796.0000 - mae: 2672.8501 - val_loss: 2562.1912 - val_mse: 26038588.0000 - val_mae: 2562.5273 - lr: 5.0000e-04\n",
      "Epoch 97/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2613.3242 - mse: 25690694.0000 - mae: 2613.6326\n",
      "Epoch 97: val_loss did not improve from 2527.81958\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2612.4492 - mse: 25681086.0000 - mae: 2612.7576 - val_loss: 2565.8779 - val_mse: 25597400.0000 - val_mae: 2566.1641 - lr: 5.0000e-04\n",
      "Epoch 98/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2557.9592 - mse: 24647638.0000 - mae: 2558.2664\n",
      "Epoch 98: val_loss improved from 2527.81958 to 2486.47217, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2557.9592 - mse: 24647638.0000 - mae: 2558.2664 - val_loss: 2486.4722 - val_mse: 23821674.0000 - val_mae: 2486.7603 - lr: 5.0000e-04\n",
      "Epoch 99/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2518.9668 - mse: 23852838.0000 - mae: 2519.2698\n",
      "Epoch 99: val_loss did not improve from 2486.47217\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2522.9688 - mse: 23903362.0000 - mae: 2523.2725 - val_loss: 2496.8914 - val_mse: 23913510.0000 - val_mae: 2497.2417 - lr: 5.0000e-04\n",
      "Epoch 100/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2541.3071 - mse: 24216728.0000 - mae: 2541.6167\n",
      "Epoch 100: val_loss did not improve from 2486.47217\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2540.5767 - mse: 24200344.0000 - mae: 2540.8865 - val_loss: 2672.5981 - val_mse: 26602280.0000 - val_mae: 2672.9375 - lr: 5.0000e-04\n",
      "Epoch 101/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2515.8979 - mse: 24060900.0000 - mae: 2516.2039\n",
      "Epoch 101: val_loss did not improve from 2486.47217\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2520.2747 - mse: 24118130.0000 - mae: 2520.5811 - val_loss: 2509.9590 - val_mse: 24130258.0000 - val_mae: 2510.2832 - lr: 5.0000e-04\n",
      "Epoch 102/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2518.4177 - mse: 24253414.0000 - mae: 2518.7241\n",
      "Epoch 102: val_loss did not improve from 2486.47217\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2520.9402 - mse: 24309818.0000 - mae: 2521.2471 - val_loss: 2571.9658 - val_mse: 24857662.0000 - val_mae: 2572.2800 - lr: 5.0000e-04\n",
      "Epoch 103/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2535.8440 - mse: 24068022.0000 - mae: 2536.1470\n",
      "Epoch 103: val_loss did not improve from 2486.47217\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2535.8018 - mse: 24076196.0000 - mae: 2536.1042 - val_loss: 2547.3398 - val_mse: 24292472.0000 - val_mae: 2547.6138 - lr: 5.0000e-04\n",
      "Epoch 104/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2561.7898 - mse: 24771894.0000 - mae: 2562.0950\n",
      "Epoch 104: val_loss did not improve from 2486.47217\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2564.2183 - mse: 24774002.0000 - mae: 2564.5237 - val_loss: 2571.3357 - val_mse: 25040614.0000 - val_mae: 2571.6414 - lr: 5.0000e-04\n",
      "Epoch 105/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2542.3005 - mse: 24425722.0000 - mae: 2542.6091\n",
      "Epoch 105: val_loss did not improve from 2486.47217\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2542.8398 - mse: 24432406.0000 - mae: 2543.1489 - val_loss: 2575.3271 - val_mse: 25633596.0000 - val_mae: 2575.6011 - lr: 5.0000e-04\n",
      "Epoch 106/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2555.6575 - mse: 24971214.0000 - mae: 2555.9595\n",
      "Epoch 106: val_loss improved from 2486.47217 to 2480.43262, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2558.2175 - mse: 24999232.0000 - mae: 2558.5195 - val_loss: 2480.4326 - val_mse: 24369642.0000 - val_mae: 2480.7573 - lr: 5.0000e-04\n",
      "Epoch 107/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2500.8943 - mse: 23857526.0000 - mae: 2501.1970\n",
      "Epoch 107: val_loss did not improve from 2480.43262\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2505.5369 - mse: 23910424.0000 - mae: 2505.8403 - val_loss: 2504.8799 - val_mse: 24471940.0000 - val_mae: 2505.1887 - lr: 5.0000e-04\n",
      "Epoch 108/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2497.8403 - mse: 23848418.0000 - mae: 2498.1406\n",
      "Epoch 108: val_loss did not improve from 2480.43262\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2502.9827 - mse: 23911078.0000 - mae: 2503.2832 - val_loss: 2595.5344 - val_mse: 24702474.0000 - val_mae: 2595.8320 - lr: 5.0000e-04\n",
      "Epoch 109/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2473.6409 - mse: 23298430.0000 - mae: 2473.9419\n",
      "Epoch 109: val_loss improved from 2480.43262 to 2475.12329, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2473.7144 - mse: 23305044.0000 - mae: 2474.0154 - val_loss: 2475.1233 - val_mse: 24350036.0000 - val_mae: 2475.4124 - lr: 5.0000e-04\n",
      "Epoch 110/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2485.3977 - mse: 23650562.0000 - mae: 2485.6992\n",
      "Epoch 110: val_loss did not improve from 2475.12329\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2479.4512 - mse: 23556630.0000 - mae: 2479.7529 - val_loss: 2476.7534 - val_mse: 24003666.0000 - val_mae: 2477.0608 - lr: 5.0000e-04\n",
      "Epoch 111/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2439.5461 - mse: 22876098.0000 - mae: 2439.8452\n",
      "Epoch 111: val_loss did not improve from 2475.12329\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2443.6909 - mse: 22926106.0000 - mae: 2443.9905 - val_loss: 2484.4849 - val_mse: 24015672.0000 - val_mae: 2484.7856 - lr: 5.0000e-04\n",
      "Epoch 112/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2448.9763 - mse: 23062154.0000 - mae: 2449.2781\n",
      "Epoch 112: val_loss did not improve from 2475.12329\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2449.6609 - mse: 23048222.0000 - mae: 2449.9629 - val_loss: 2684.0408 - val_mse: 27148680.0000 - val_mae: 2684.3293 - lr: 5.0000e-04\n",
      "Epoch 113/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2486.3953 - mse: 23486270.0000 - mae: 2486.6956\n",
      "Epoch 113: val_loss did not improve from 2475.12329\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2487.1243 - mse: 23486360.0000 - mae: 2487.4243 - val_loss: 2536.4778 - val_mse: 25700642.0000 - val_mae: 2536.7864 - lr: 5.0000e-04\n",
      "Epoch 114/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2548.8806 - mse: 24791706.0000 - mae: 2549.1807\n",
      "Epoch 114: val_loss did not improve from 2475.12329\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2554.3401 - mse: 24896172.0000 - mae: 2554.6411 - val_loss: 2607.4204 - val_mse: 25881138.0000 - val_mae: 2607.7209 - lr: 5.0000e-04\n",
      "Epoch 115/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2587.0623 - mse: 25400970.0000 - mae: 2587.3655\n",
      "Epoch 115: val_loss did not improve from 2475.12329\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2599.2944 - mse: 25560696.0000 - mae: 2599.5984 - val_loss: 2624.8289 - val_mse: 26693124.0000 - val_mae: 2625.1597 - lr: 5.0000e-04\n",
      "Epoch 116/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2611.4314 - mse: 25895106.0000 - mae: 2611.7349\n",
      "Epoch 116: val_loss did not improve from 2475.12329\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2611.3647 - mse: 25895062.0000 - mae: 2611.6682 - val_loss: 2649.3682 - val_mse: 26704844.0000 - val_mae: 2649.6370 - lr: 5.0000e-04\n",
      "Epoch 117/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2553.6809 - mse: 25306740.0000 - mae: 2553.9785\n",
      "Epoch 117: val_loss did not improve from 2475.12329\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2554.9890 - mse: 25329546.0000 - mae: 2555.2869 - val_loss: 2558.4543 - val_mse: 24804650.0000 - val_mae: 2558.7888 - lr: 5.0000e-04\n",
      "Epoch 118/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2546.9644 - mse: 24915612.0000 - mae: 2547.2668\n",
      "Epoch 118: val_loss did not improve from 2475.12329\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2550.9858 - mse: 24940810.0000 - mae: 2551.2886 - val_loss: 2594.7512 - val_mse: 26722796.0000 - val_mae: 2595.0527 - lr: 5.0000e-04\n",
      "Epoch 119/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2534.8242 - mse: 24172438.0000 - mae: 2535.1284\n",
      "Epoch 119: val_loss did not improve from 2475.12329\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2541.0288 - mse: 24252688.0000 - mae: 2541.3328 - val_loss: 2556.8469 - val_mse: 24552730.0000 - val_mae: 2557.1211 - lr: 5.0000e-04\n",
      "Epoch 120/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2555.4753 - mse: 24955276.0000 - mae: 2555.7781\n",
      "Epoch 120: val_loss did not improve from 2475.12329\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2555.4753 - mse: 24955276.0000 - mae: 2555.7781 - val_loss: 2511.1738 - val_mse: 25052992.0000 - val_mae: 2511.4998 - lr: 2.5000e-04\n",
      "Epoch 121/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2511.0466 - mse: 24311884.0000 - mae: 2511.3479\n",
      "Epoch 121: val_loss did not improve from 2475.12329\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2512.7891 - mse: 24325350.0000 - mae: 2513.0908 - val_loss: 2613.6987 - val_mse: 26903852.0000 - val_mae: 2613.9851 - lr: 2.5000e-04\n",
      "Epoch 122/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2520.6777 - mse: 24966864.0000 - mae: 2520.9824\n",
      "Epoch 122: val_loss did not improve from 2475.12329\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2519.7322 - mse: 24952374.0000 - mae: 2520.0371 - val_loss: 2476.4548 - val_mse: 24619518.0000 - val_mae: 2476.7529 - lr: 2.5000e-04\n",
      "Epoch 123/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2491.0806 - mse: 24530106.0000 - mae: 2491.3816\n",
      "Epoch 123: val_loss did not improve from 2475.12329\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2491.8716 - mse: 24514620.0000 - mae: 2492.1729 - val_loss: 2475.9102 - val_mse: 24556228.0000 - val_mae: 2476.2227 - lr: 2.5000e-04\n",
      "Epoch 124/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2483.4243 - mse: 23640452.0000 - mae: 2483.7253\n",
      "Epoch 124: val_loss improved from 2475.12329 to 2437.97510, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2484.6313 - mse: 23649826.0000 - mae: 2484.9321 - val_loss: 2437.9751 - val_mse: 23238622.0000 - val_mae: 2438.2583 - lr: 2.5000e-04\n",
      "Epoch 125/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2514.6562 - mse: 24320228.0000 - mae: 2514.9558\n",
      "Epoch 125: val_loss did not improve from 2437.97510\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2520.1152 - mse: 24393488.0000 - mae: 2520.4153 - val_loss: 2509.6416 - val_mse: 24346742.0000 - val_mae: 2509.9399 - lr: 2.5000e-04\n",
      "Epoch 126/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2486.5093 - mse: 24497020.0000 - mae: 2486.8103\n",
      "Epoch 126: val_loss improved from 2437.97510 to 2421.71729, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2488.9734 - mse: 24531796.0000 - mae: 2489.2744 - val_loss: 2421.7173 - val_mse: 23796320.0000 - val_mae: 2422.0098 - lr: 2.5000e-04\n",
      "Epoch 127/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2464.3809 - mse: 23971718.0000 - mae: 2464.6794\n",
      "Epoch 127: val_loss improved from 2421.71729 to 2410.34326, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2463.9424 - mse: 23959142.0000 - mae: 2464.2405 - val_loss: 2410.3433 - val_mse: 24099250.0000 - val_mae: 2410.6338 - lr: 2.5000e-04\n",
      "Epoch 128/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2500.0454 - mse: 24716108.0000 - mae: 2500.3450\n",
      "Epoch 128: val_loss did not improve from 2410.34326\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2502.1692 - mse: 24759288.0000 - mae: 2502.4688 - val_loss: 2427.0605 - val_mse: 24043550.0000 - val_mae: 2427.3459 - lr: 2.5000e-04\n",
      "Epoch 129/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2467.8704 - mse: 23938072.0000 - mae: 2468.1697\n",
      "Epoch 129: val_loss improved from 2410.34326 to 2401.06323, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2476.3457 - mse: 24051236.0000 - mae: 2476.6460 - val_loss: 2401.0632 - val_mse: 23824186.0000 - val_mae: 2401.3674 - lr: 2.5000e-04\n",
      "Epoch 130/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2454.2197 - mse: 24006340.0000 - mae: 2454.5215\n",
      "Epoch 130: val_loss improved from 2401.06323 to 2336.99585, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2460.7659 - mse: 24083692.0000 - mae: 2461.0674 - val_loss: 2336.9958 - val_mse: 23380614.0000 - val_mae: 2337.2529 - lr: 2.5000e-04\n",
      "Epoch 131/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2435.8992 - mse: 24043018.0000 - mae: 2436.1990\n",
      "Epoch 131: val_loss did not improve from 2336.99585\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2438.5198 - mse: 24062862.0000 - mae: 2438.8196 - val_loss: 2394.0247 - val_mse: 23991008.0000 - val_mae: 2394.3201 - lr: 2.5000e-04\n",
      "Epoch 132/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2446.5388 - mse: 23983686.0000 - mae: 2446.8420\n",
      "Epoch 132: val_loss did not improve from 2336.99585\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2452.7827 - mse: 24032830.0000 - mae: 2453.0867 - val_loss: 2421.6011 - val_mse: 23597494.0000 - val_mae: 2421.9231 - lr: 2.5000e-04\n",
      "Epoch 133/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2461.2456 - mse: 23782028.0000 - mae: 2461.5481\n",
      "Epoch 133: val_loss did not improve from 2336.99585\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2463.2000 - mse: 23812428.0000 - mae: 2463.5024 - val_loss: 2418.8484 - val_mse: 24450426.0000 - val_mae: 2419.1533 - lr: 2.5000e-04\n",
      "Epoch 134/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2474.8442 - mse: 23975562.0000 - mae: 2475.1465\n",
      "Epoch 134: val_loss did not improve from 2336.99585\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2475.0840 - mse: 23938764.0000 - mae: 2475.3860 - val_loss: 2388.8452 - val_mse: 23730686.0000 - val_mae: 2389.1479 - lr: 2.5000e-04\n",
      "Epoch 135/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2459.8372 - mse: 23944752.0000 - mae: 2460.1416\n",
      "Epoch 135: val_loss improved from 2336.99585 to 2287.56494, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2460.0793 - mse: 23951122.0000 - mae: 2460.3838 - val_loss: 2287.5649 - val_mse: 22152422.0000 - val_mae: 2287.8792 - lr: 2.5000e-04\n",
      "Epoch 136/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2437.0374 - mse: 23700160.0000 - mae: 2437.3379\n",
      "Epoch 136: val_loss did not improve from 2287.56494\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2448.8623 - mse: 23804328.0000 - mae: 2449.1638 - val_loss: 2343.4424 - val_mse: 22965046.0000 - val_mae: 2343.7344 - lr: 2.5000e-04\n",
      "Epoch 137/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2438.3357 - mse: 23913228.0000 - mae: 2438.6392\n",
      "Epoch 137: val_loss did not improve from 2287.56494\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2441.2844 - mse: 23921352.0000 - mae: 2441.5879 - val_loss: 2401.6526 - val_mse: 24140752.0000 - val_mae: 2401.9600 - lr: 2.5000e-04\n",
      "Epoch 138/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2404.5366 - mse: 22894944.0000 - mae: 2404.8362\n",
      "Epoch 138: val_loss did not improve from 2287.56494\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2404.5366 - mse: 22894944.0000 - mae: 2404.8362 - val_loss: 2368.9768 - val_mse: 23353910.0000 - val_mae: 2369.3022 - lr: 2.5000e-04\n",
      "Epoch 139/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2398.1284 - mse: 22819314.0000 - mae: 2398.4299\n",
      "Epoch 139: val_loss did not improve from 2287.56494\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2404.9727 - mse: 22900306.0000 - mae: 2405.2744 - val_loss: 2342.8008 - val_mse: 23305858.0000 - val_mae: 2343.0974 - lr: 2.5000e-04\n",
      "Epoch 140/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2415.3408 - mse: 23197854.0000 - mae: 2415.6416\n",
      "Epoch 140: val_loss did not improve from 2287.56494\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2414.3198 - mse: 23179346.0000 - mae: 2414.6206 - val_loss: 2329.5337 - val_mse: 22334260.0000 - val_mae: 2329.8367 - lr: 2.5000e-04\n",
      "Epoch 141/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2359.4387 - mse: 22324576.0000 - mae: 2359.7400\n",
      "Epoch 141: val_loss did not improve from 2287.56494\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2359.4387 - mse: 22324576.0000 - mae: 2359.7400 - val_loss: 2366.1504 - val_mse: 22965854.0000 - val_mae: 2366.4741 - lr: 2.5000e-04\n",
      "Epoch 142/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2366.5227 - mse: 22209052.0000 - mae: 2366.8252\n",
      "Epoch 142: val_loss did not improve from 2287.56494\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2369.4265 - mse: 22231548.0000 - mae: 2369.7295 - val_loss: 2374.1721 - val_mse: 22491096.0000 - val_mae: 2374.4629 - lr: 2.5000e-04\n",
      "Epoch 143/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2360.5417 - mse: 22258254.0000 - mae: 2360.8418\n",
      "Epoch 143: val_loss did not improve from 2287.56494\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2361.9155 - mse: 22256022.0000 - mae: 2362.2161 - val_loss: 2325.1533 - val_mse: 22002260.0000 - val_mae: 2325.4600 - lr: 2.5000e-04\n",
      "Epoch 144/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2348.9246 - mse: 21803422.0000 - mae: 2349.2273\n",
      "Epoch 144: val_loss did not improve from 2287.56494\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2348.7993 - mse: 21771354.0000 - mae: 2349.1023 - val_loss: 2344.9636 - val_mse: 23198374.0000 - val_mae: 2345.2600 - lr: 2.5000e-04\n",
      "Epoch 145/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2354.7639 - mse: 22160054.0000 - mae: 2355.0667\n",
      "Epoch 145: val_loss did not improve from 2287.56494\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2354.7639 - mse: 22160054.0000 - mae: 2355.0667 - val_loss: 2357.0847 - val_mse: 23006254.0000 - val_mae: 2357.3735 - lr: 2.5000e-04\n",
      "Epoch 146/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2352.6978 - mse: 22365002.0000 - mae: 2353.0000\n",
      "Epoch 146: val_loss did not improve from 2287.56494\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2353.8452 - mse: 22358758.0000 - mae: 2354.1482 - val_loss: 2310.0645 - val_mse: 22573838.0000 - val_mae: 2310.3569 - lr: 1.2500e-04\n",
      "Epoch 147/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2357.5901 - mse: 22399234.0000 - mae: 2357.8923\n",
      "Epoch 147: val_loss did not improve from 2287.56494\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2362.0012 - mse: 22478076.0000 - mae: 2362.3035 - val_loss: 2314.2571 - val_mse: 22205982.0000 - val_mae: 2314.5486 - lr: 1.2500e-04\n",
      "Epoch 148/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2341.7896 - mse: 22310980.0000 - mae: 2342.0906\n",
      "Epoch 148: val_loss did not improve from 2287.56494\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2344.8894 - mse: 22367612.0000 - mae: 2345.1907 - val_loss: 2337.4255 - val_mse: 22796016.0000 - val_mae: 2337.7239 - lr: 1.2500e-04\n",
      "Epoch 149/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2352.1809 - mse: 22269738.0000 - mae: 2352.4800\n",
      "Epoch 149: val_loss did not improve from 2287.56494\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2351.7358 - mse: 22217762.0000 - mae: 2352.0349 - val_loss: 2309.2742 - val_mse: 22336020.0000 - val_mae: 2309.5569 - lr: 1.2500e-04\n",
      "Epoch 150/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2350.8289 - mse: 22154676.0000 - mae: 2351.1309\n",
      "Epoch 150: val_loss did not improve from 2287.56494\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2355.6692 - mse: 22224610.0000 - mae: 2355.9717 - val_loss: 2308.8557 - val_mse: 22687206.0000 - val_mae: 2309.1450 - lr: 1.2500e-04\n",
      "Epoch 151/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2356.7888 - mse: 22611220.0000 - mae: 2357.0874\n",
      "Epoch 151: val_loss did not improve from 2287.56494\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2358.9814 - mse: 22659334.0000 - mae: 2359.2800 - val_loss: 2338.2444 - val_mse: 23129636.0000 - val_mae: 2338.5498 - lr: 1.2500e-04\n",
      "Epoch 152/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2337.0837 - mse: 22137682.0000 - mae: 2337.3850\n",
      "Epoch 152: val_loss did not improve from 2287.56494\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2339.0493 - mse: 22168760.0000 - mae: 2339.3511 - val_loss: 2361.3848 - val_mse: 23164028.0000 - val_mae: 2361.6863 - lr: 1.2500e-04\n",
      "Epoch 153/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2317.5530 - mse: 21704966.0000 - mae: 2317.8535\n",
      "Epoch 153: val_loss did not improve from 2287.56494\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2327.3262 - mse: 21785372.0000 - mae: 2327.6277 - val_loss: 2295.6777 - val_mse: 22322658.0000 - val_mae: 2295.9734 - lr: 1.2500e-04\n",
      "Epoch 154/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2308.5515 - mse: 21761298.0000 - mae: 2308.8496\n",
      "Epoch 154: val_loss improved from 2287.56494 to 2283.71313, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2314.9263 - mse: 21875436.0000 - mae: 2315.2246 - val_loss: 2283.7131 - val_mse: 22478432.0000 - val_mae: 2284.0125 - lr: 1.2500e-04\n",
      "Epoch 155/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2346.7659 - mse: 21915612.0000 - mae: 2347.0649\n",
      "Epoch 155: val_loss improved from 2283.71313 to 2270.52637, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2349.8943 - mse: 21956004.0000 - mae: 2350.1936 - val_loss: 2270.5264 - val_mse: 21174920.0000 - val_mae: 2270.8245 - lr: 1.2500e-04\n",
      "Epoch 156/500\n",
      "427/436 [============================>.] - ETA: 0s - loss: 2320.0867 - mse: 21420662.0000 - mae: 2320.3860\n",
      "Epoch 156: val_loss did not improve from 2270.52637\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2326.3562 - mse: 21508526.0000 - mae: 2326.6565 - val_loss: 2348.5876 - val_mse: 22443376.0000 - val_mae: 2348.8845 - lr: 1.2500e-04\n",
      "Epoch 157/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2306.5676 - mse: 21399498.0000 - mae: 2306.8677\n",
      "Epoch 157: val_loss did not improve from 2270.52637\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2317.8713 - mse: 21575846.0000 - mae: 2318.1716 - val_loss: 2281.0151 - val_mse: 22062674.0000 - val_mae: 2281.3022 - lr: 1.2500e-04\n",
      "Epoch 158/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2291.7217 - mse: 21502758.0000 - mae: 2292.0249\n",
      "Epoch 158: val_loss did not improve from 2270.52637\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2291.7217 - mse: 21502758.0000 - mae: 2292.0249 - val_loss: 2324.1931 - val_mse: 22176622.0000 - val_mae: 2324.4827 - lr: 1.2500e-04\n",
      "Epoch 159/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2288.8486 - mse: 21177748.0000 - mae: 2289.1460\n",
      "Epoch 159: val_loss improved from 2270.52637 to 2249.50366, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2292.3704 - mse: 21200380.0000 - mae: 2292.6682 - val_loss: 2249.5037 - val_mse: 21500416.0000 - val_mae: 2249.7925 - lr: 1.2500e-04\n",
      "Epoch 160/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2277.1167 - mse: 21131592.0000 - mae: 2277.4160\n",
      "Epoch 160: val_loss did not improve from 2249.50366\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2284.4851 - mse: 21267088.0000 - mae: 2284.7849 - val_loss: 2262.2041 - val_mse: 21655076.0000 - val_mae: 2262.4980 - lr: 1.2500e-04\n",
      "Epoch 161/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2300.1926 - mse: 21585796.0000 - mae: 2300.4932\n",
      "Epoch 161: val_loss did not improve from 2249.50366\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2305.9807 - mse: 21659874.0000 - mae: 2306.2815 - val_loss: 2277.7747 - val_mse: 22271820.0000 - val_mae: 2278.0605 - lr: 1.2500e-04\n",
      "Epoch 162/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2311.7146 - mse: 21655202.0000 - mae: 2312.0144\n",
      "Epoch 162: val_loss did not improve from 2249.50366\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2310.9580 - mse: 21592990.0000 - mae: 2311.2585 - val_loss: 2276.8123 - val_mse: 21595782.0000 - val_mae: 2277.1128 - lr: 1.2500e-04\n",
      "Epoch 163/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2286.8699 - mse: 21323726.0000 - mae: 2287.1721\n",
      "Epoch 163: val_loss improved from 2249.50366 to 2241.96924, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2287.0635 - mse: 21317334.0000 - mae: 2287.3657 - val_loss: 2241.9692 - val_mse: 21616050.0000 - val_mae: 2242.2617 - lr: 1.2500e-04\n",
      "Epoch 164/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2286.1655 - mse: 21233310.0000 - mae: 2286.4668\n",
      "Epoch 164: val_loss did not improve from 2241.96924\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2290.8804 - mse: 21302396.0000 - mae: 2291.1821 - val_loss: 2253.9402 - val_mse: 21702244.0000 - val_mae: 2254.2478 - lr: 1.2500e-04\n",
      "Epoch 165/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2307.5728 - mse: 21361018.0000 - mae: 2307.8784\n",
      "Epoch 165: val_loss did not improve from 2241.96924\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2315.8994 - mse: 21484132.0000 - mae: 2316.2056 - val_loss: 2303.8799 - val_mse: 22524606.0000 - val_mae: 2304.1926 - lr: 1.2500e-04\n",
      "Epoch 166/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2318.9082 - mse: 21913150.0000 - mae: 2319.2109\n",
      "Epoch 166: val_loss did not improve from 2241.96924\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2326.1809 - mse: 21952074.0000 - mae: 2326.4841 - val_loss: 2255.3220 - val_mse: 21585394.0000 - val_mae: 2255.6206 - lr: 1.2500e-04\n",
      "Epoch 167/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2261.4885 - mse: 20605178.0000 - mae: 2261.7888\n",
      "Epoch 167: val_loss did not improve from 2241.96924\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2263.1016 - mse: 20640340.0000 - mae: 2263.4019 - val_loss: 2282.2876 - val_mse: 22016032.0000 - val_mae: 2282.5786 - lr: 1.2500e-04\n",
      "Epoch 168/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2257.2332 - mse: 20657018.0000 - mae: 2257.5352\n",
      "Epoch 168: val_loss did not improve from 2241.96924\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2263.8193 - mse: 20737490.0000 - mae: 2264.1216 - val_loss: 2316.2773 - val_mse: 22854638.0000 - val_mae: 2316.5737 - lr: 1.2500e-04\n",
      "Epoch 169/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2289.8367 - mse: 21310836.0000 - mae: 2290.1367\n",
      "Epoch 169: val_loss did not improve from 2241.96924\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2294.2915 - mse: 21354102.0000 - mae: 2294.5920 - val_loss: 2291.6833 - val_mse: 22615380.0000 - val_mae: 2291.9824 - lr: 1.2500e-04\n",
      "Epoch 170/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2291.3423 - mse: 21259908.0000 - mae: 2291.6460\n",
      "Epoch 170: val_loss did not improve from 2241.96924\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2291.3423 - mse: 21259908.0000 - mae: 2291.6460 - val_loss: 2260.5889 - val_mse: 21784542.0000 - val_mae: 2260.8745 - lr: 1.2500e-04\n",
      "Epoch 171/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2279.2451 - mse: 21079854.0000 - mae: 2279.5459\n",
      "Epoch 171: val_loss did not improve from 2241.96924\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2279.2451 - mse: 21079854.0000 - mae: 2279.5459 - val_loss: 2250.0334 - val_mse: 22181106.0000 - val_mae: 2250.3203 - lr: 1.2500e-04\n",
      "Epoch 172/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2262.5771 - mse: 20881756.0000 - mae: 2262.8767\n",
      "Epoch 172: val_loss improved from 2241.96924 to 2215.64575, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2268.2505 - mse: 20985386.0000 - mae: 2268.5505 - val_loss: 2215.6458 - val_mse: 21480466.0000 - val_mae: 2215.9565 - lr: 1.2500e-04\n",
      "Epoch 173/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2268.7573 - mse: 21204270.0000 - mae: 2269.0598\n",
      "Epoch 173: val_loss improved from 2215.64575 to 2208.09961, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2272.5674 - mse: 21200624.0000 - mae: 2272.8706 - val_loss: 2208.0996 - val_mse: 21192166.0000 - val_mae: 2208.3960 - lr: 1.2500e-04\n",
      "Epoch 174/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2254.3025 - mse: 20744434.0000 - mae: 2254.6023\n",
      "Epoch 174: val_loss did not improve from 2208.09961\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2254.1606 - mse: 20733944.0000 - mae: 2254.4609 - val_loss: 2279.2683 - val_mse: 21625760.0000 - val_mae: 2279.5581 - lr: 1.2500e-04\n",
      "Epoch 175/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2258.6992 - mse: 20628332.0000 - mae: 2258.9988\n",
      "Epoch 175: val_loss did not improve from 2208.09961\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2255.8945 - mse: 20591874.0000 - mae: 2256.1941 - val_loss: 2251.2910 - val_mse: 21884716.0000 - val_mae: 2251.5898 - lr: 1.2500e-04\n",
      "Epoch 176/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2276.4783 - mse: 21279020.0000 - mae: 2276.7783\n",
      "Epoch 176: val_loss did not improve from 2208.09961\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2286.2151 - mse: 21389618.0000 - mae: 2286.5156 - val_loss: 2304.0908 - val_mse: 23117686.0000 - val_mae: 2304.4033 - lr: 1.2500e-04\n",
      "Epoch 177/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2265.0264 - mse: 21040284.0000 - mae: 2265.3257\n",
      "Epoch 177: val_loss did not improve from 2208.09961\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2269.5815 - mse: 21081116.0000 - mae: 2269.8813 - val_loss: 2261.8225 - val_mse: 22114962.0000 - val_mae: 2262.1133 - lr: 1.2500e-04\n",
      "Epoch 178/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2253.1724 - mse: 20811522.0000 - mae: 2253.4736\n",
      "Epoch 178: val_loss did not improve from 2208.09961\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2253.1724 - mse: 20811522.0000 - mae: 2253.4736 - val_loss: 2229.0403 - val_mse: 22178808.0000 - val_mae: 2229.3333 - lr: 1.2500e-04\n",
      "Epoch 179/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2276.9827 - mse: 21244322.0000 - mae: 2277.2805\n",
      "Epoch 179: val_loss did not improve from 2208.09961\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2273.8660 - mse: 21208792.0000 - mae: 2274.1638 - val_loss: 2242.0027 - val_mse: 21795082.0000 - val_mae: 2242.2996 - lr: 1.2500e-04\n",
      "Epoch 180/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2279.6416 - mse: 21070590.0000 - mae: 2279.9414\n",
      "Epoch 180: val_loss did not improve from 2208.09961\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2279.6416 - mse: 21070590.0000 - mae: 2279.9414 - val_loss: 2221.2681 - val_mse: 21446130.0000 - val_mae: 2221.5720 - lr: 1.2500e-04\n",
      "Epoch 181/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2235.0681 - mse: 20419278.0000 - mae: 2235.3684\n",
      "Epoch 181: val_loss improved from 2208.09961 to 2205.99390, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2241.3503 - mse: 20488724.0000 - mae: 2241.6516 - val_loss: 2205.9939 - val_mse: 20936776.0000 - val_mae: 2206.2927 - lr: 1.2500e-04\n",
      "Epoch 182/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2254.3164 - mse: 20562476.0000 - mae: 2254.6150\n",
      "Epoch 182: val_loss did not improve from 2205.99390\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2255.2505 - mse: 20568554.0000 - mae: 2255.5491 - val_loss: 2215.5498 - val_mse: 20702542.0000 - val_mae: 2215.8337 - lr: 1.2500e-04\n",
      "Epoch 183/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2223.1946 - mse: 20029476.0000 - mae: 2223.4927\n",
      "Epoch 183: val_loss did not improve from 2205.99390\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2230.7993 - mse: 20149650.0000 - mae: 2231.0977 - val_loss: 2224.1636 - val_mse: 21029742.0000 - val_mae: 2224.4580 - lr: 1.2500e-04\n",
      "Epoch 184/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2241.1455 - mse: 20243528.0000 - mae: 2241.4438\n",
      "Epoch 184: val_loss did not improve from 2205.99390\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2248.6812 - mse: 20352512.0000 - mae: 2248.9802 - val_loss: 2227.3848 - val_mse: 20872266.0000 - val_mae: 2227.6838 - lr: 1.2500e-04\n",
      "Epoch 185/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2245.2124 - mse: 20541424.0000 - mae: 2245.5120\n",
      "Epoch 185: val_loss did not improve from 2205.99390\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2246.0271 - mse: 20555950.0000 - mae: 2246.3267 - val_loss: 2251.3767 - val_mse: 20986514.0000 - val_mae: 2251.6738 - lr: 1.2500e-04\n",
      "Epoch 186/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2247.0974 - mse: 20420352.0000 - mae: 2247.3972\n",
      "Epoch 186: val_loss did not improve from 2205.99390\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2248.7744 - mse: 20449318.0000 - mae: 2249.0745 - val_loss: 2230.9761 - val_mse: 21290700.0000 - val_mae: 2231.2705 - lr: 1.2500e-04\n",
      "Epoch 187/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2231.9419 - mse: 20193406.0000 - mae: 2232.2441\n",
      "Epoch 187: val_loss did not improve from 2205.99390\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2243.6624 - mse: 20344118.0000 - mae: 2243.9648 - val_loss: 2274.9814 - val_mse: 21668612.0000 - val_mae: 2275.2734 - lr: 1.2500e-04\n",
      "Epoch 188/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2213.8699 - mse: 19958126.0000 - mae: 2214.1721\n",
      "Epoch 188: val_loss did not improve from 2205.99390\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2212.2209 - mse: 19925728.0000 - mae: 2212.5229 - val_loss: 2245.3262 - val_mse: 21335448.0000 - val_mae: 2245.6194 - lr: 1.2500e-04\n",
      "Epoch 189/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2212.6194 - mse: 19959938.0000 - mae: 2212.9167\n",
      "Epoch 189: val_loss improved from 2205.99390 to 2150.06567, saving model to new_stne_gru_weight.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2216.4863 - mse: 19991218.0000 - mae: 2216.7842 - val_loss: 2150.0657 - val_mse: 19680178.0000 - val_mae: 2150.3630 - lr: 1.2500e-04\n",
      "Epoch 190/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 2194.8340 - mse: 19537280.0000 - mae: 2195.1372\n",
      "Epoch 190: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2205.7979 - mse: 19730826.0000 - mae: 2206.1011 - val_loss: 2308.9729 - val_mse: 21952504.0000 - val_mae: 2309.2712 - lr: 1.2500e-04\n",
      "Epoch 191/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2285.7515 - mse: 20993232.0000 - mae: 2286.0527\n",
      "Epoch 191: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2286.5237 - mse: 20985194.0000 - mae: 2286.8254 - val_loss: 2228.1392 - val_mse: 20555502.0000 - val_mae: 2228.4451 - lr: 1.2500e-04\n",
      "Epoch 192/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2257.2944 - mse: 20313018.0000 - mae: 2257.5991\n",
      "Epoch 192: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2257.5525 - mse: 20298522.0000 - mae: 2257.8574 - val_loss: 2271.0105 - val_mse: 21505780.0000 - val_mae: 2271.3130 - lr: 1.2500e-04\n",
      "Epoch 193/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2240.2063 - mse: 20164398.0000 - mae: 2240.5098\n",
      "Epoch 193: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2240.4070 - mse: 20190654.0000 - mae: 2240.7107 - val_loss: 2237.5884 - val_mse: 21221656.0000 - val_mae: 2237.8730 - lr: 1.2500e-04\n",
      "Epoch 194/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2221.1672 - mse: 20103884.0000 - mae: 2221.4688\n",
      "Epoch 194: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2218.1277 - mse: 20031630.0000 - mae: 2218.4294 - val_loss: 2250.8975 - val_mse: 20707372.0000 - val_mae: 2251.1929 - lr: 1.2500e-04\n",
      "Epoch 195/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2247.2649 - mse: 20073850.0000 - mae: 2247.5652\n",
      "Epoch 195: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2254.4900 - mse: 20194100.0000 - mae: 2254.7905 - val_loss: 2253.5574 - val_mse: 21056886.0000 - val_mae: 2253.8547 - lr: 1.2500e-04\n",
      "Epoch 196/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2254.9946 - mse: 20394090.0000 - mae: 2255.2959\n",
      "Epoch 196: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2254.9946 - mse: 20394090.0000 - mae: 2255.2959 - val_loss: 2194.8362 - val_mse: 20541550.0000 - val_mae: 2195.1135 - lr: 1.2500e-04\n",
      "Epoch 197/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2232.4492 - mse: 19863168.0000 - mae: 2232.7480\n",
      "Epoch 197: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2233.3450 - mse: 19869980.0000 - mae: 2233.6440 - val_loss: 2212.0730 - val_mse: 20490230.0000 - val_mae: 2212.3647 - lr: 1.2500e-04\n",
      "Epoch 198/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2245.8125 - mse: 19982820.0000 - mae: 2246.1130\n",
      "Epoch 198: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2244.3796 - mse: 19964872.0000 - mae: 2244.6799 - val_loss: 2191.8018 - val_mse: 20399546.0000 - val_mae: 2192.0981 - lr: 1.2500e-04\n",
      "Epoch 199/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2283.2573 - mse: 20458956.0000 - mae: 2283.5574\n",
      "Epoch 199: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2285.9683 - mse: 20491916.0000 - mae: 2286.2688 - val_loss: 2256.0051 - val_mse: 21535994.0000 - val_mae: 2256.3052 - lr: 1.2500e-04\n",
      "Epoch 200/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2260.4709 - mse: 20559680.0000 - mae: 2260.7712\n",
      "Epoch 200: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2267.8894 - mse: 20663042.0000 - mae: 2268.1904 - val_loss: 2271.8699 - val_mse: 21853800.0000 - val_mae: 2272.1616 - lr: 6.2500e-05\n",
      "Epoch 201/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2250.9429 - mse: 20270304.0000 - mae: 2251.2432\n",
      "Epoch 201: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2250.7642 - mse: 20248068.0000 - mae: 2251.0647 - val_loss: 2183.7534 - val_mse: 20278654.0000 - val_mae: 2184.0483 - lr: 6.2500e-05\n",
      "Epoch 202/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2244.3171 - mse: 20346114.0000 - mae: 2244.6157\n",
      "Epoch 202: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2244.3171 - mse: 20346114.0000 - mae: 2244.6157 - val_loss: 2199.7827 - val_mse: 20624672.0000 - val_mae: 2200.0715 - lr: 6.2500e-05\n",
      "Epoch 203/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2234.3484 - mse: 20384808.0000 - mae: 2234.6467\n",
      "Epoch 203: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2233.9084 - mse: 20380190.0000 - mae: 2234.2068 - val_loss: 2189.6406 - val_mse: 20599694.0000 - val_mae: 2189.9268 - lr: 6.2500e-05\n",
      "Epoch 204/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2221.2744 - mse: 20024008.0000 - mae: 2221.5715\n",
      "Epoch 204: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2220.6167 - mse: 19996482.0000 - mae: 2220.9143 - val_loss: 2184.6218 - val_mse: 20231958.0000 - val_mae: 2184.9150 - lr: 6.2500e-05\n",
      "Epoch 205/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2207.5820 - mse: 19740028.0000 - mae: 2207.8831\n",
      "Epoch 205: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2212.5830 - mse: 19811462.0000 - mae: 2212.8843 - val_loss: 2199.0891 - val_mse: 20718494.0000 - val_mae: 2199.3784 - lr: 6.2500e-05\n",
      "Epoch 206/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2193.5090 - mse: 19475024.0000 - mae: 2193.8076\n",
      "Epoch 206: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2196.1921 - mse: 19504298.0000 - mae: 2196.4910 - val_loss: 2208.9692 - val_mse: 20414920.0000 - val_mae: 2209.2578 - lr: 6.2500e-05\n",
      "Epoch 207/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2188.3838 - mse: 19356894.0000 - mae: 2188.6829\n",
      "Epoch 207: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2187.7415 - mse: 19348552.0000 - mae: 2188.0403 - val_loss: 2196.5735 - val_mse: 20429792.0000 - val_mae: 2196.8589 - lr: 6.2500e-05\n",
      "Epoch 208/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2187.7581 - mse: 19129068.0000 - mae: 2188.0588\n",
      "Epoch 208: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2188.7400 - mse: 19141870.0000 - mae: 2189.0405 - val_loss: 2180.2478 - val_mse: 20022436.0000 - val_mae: 2180.5459 - lr: 6.2500e-05\n",
      "Epoch 209/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2166.8096 - mse: 18822180.0000 - mae: 2167.1104\n",
      "Epoch 209: val_loss did not improve from 2150.06567\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2171.5667 - mse: 18881532.0000 - mae: 2171.8679 - val_loss: 2162.2419 - val_mse: 19924408.0000 - val_mae: 2162.5364 - lr: 6.2500e-05\n",
      "Epoch 1/500\n",
      "    434/Unknown - 3s 7ms/step - loss: 2174.1555 - mse: 19098472.0000 - mae: 2174.4556\n",
      "Epoch 1: val_loss improved from inf to 2169.98340, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2174.4790 - mse: 19093514.0000 - mae: 2174.7793 - val_loss: 2169.9834 - val_mse: 19813942.0000 - val_mae: 2170.2727 - lr: 3.1250e-05\n",
      "Epoch 2/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2170.7917 - mse: 18976590.0000 - mae: 2171.0925\n",
      "Epoch 2: val_loss did not improve from 2169.98340\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2179.7231 - mse: 19074150.0000 - mae: 2180.0247 - val_loss: 2180.2268 - val_mse: 19898584.0000 - val_mae: 2180.5166 - lr: 3.1250e-05\n",
      "Epoch 3/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2156.1580 - mse: 18658786.0000 - mae: 2156.4580\n",
      "Epoch 3: val_loss improved from 2169.98340 to 2150.03369, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2156.5496 - mse: 18654240.0000 - mae: 2156.8496 - val_loss: 2150.0337 - val_mse: 19466036.0000 - val_mae: 2150.3252 - lr: 3.1250e-05\n",
      "Epoch 4/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2141.9358 - mse: 18415260.0000 - mae: 2142.2361\n",
      "Epoch 4: val_loss did not improve from 2150.03369\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2153.7927 - mse: 18592018.0000 - mae: 2154.0933 - val_loss: 2155.0901 - val_mse: 19597340.0000 - val_mae: 2155.3821 - lr: 3.1250e-05\n",
      "Epoch 5/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2154.2000 - mse: 18590052.0000 - mae: 2154.4998\n",
      "Epoch 5: val_loss improved from 2150.03369 to 2142.82275, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2158.7161 - mse: 18636558.0000 - mae: 2159.0164 - val_loss: 2142.8228 - val_mse: 19121216.0000 - val_mae: 2143.1169 - lr: 3.1250e-05\n",
      "Epoch 6/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 2144.1960 - mse: 18397632.0000 - mae: 2144.4951\n",
      "Epoch 6: val_loss did not improve from 2142.82275\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2144.3513 - mse: 18388234.0000 - mae: 2144.6509 - val_loss: 2146.5464 - val_mse: 19156594.0000 - val_mae: 2146.8374 - lr: 3.1250e-05\n",
      "Epoch 7/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2139.8325 - mse: 18293082.0000 - mae: 2140.1326\n",
      "Epoch 7: val_loss did not improve from 2142.82275\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2139.8325 - mse: 18293082.0000 - mae: 2140.1326 - val_loss: 2146.7673 - val_mse: 18976732.0000 - val_mae: 2147.0596 - lr: 3.1250e-05\n",
      "Epoch 8/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2122.7871 - mse: 18074648.0000 - mae: 2123.0879\n",
      "Epoch 8: val_loss did not improve from 2142.82275\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2132.4663 - mse: 18180558.0000 - mae: 2132.7671 - val_loss: 2154.6821 - val_mse: 18962052.0000 - val_mae: 2154.9724 - lr: 3.1250e-05\n",
      "Epoch 9/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2117.6729 - mse: 17830686.0000 - mae: 2117.9734\n",
      "Epoch 9: val_loss improved from 2142.82275 to 2122.10303, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2117.6729 - mse: 17830686.0000 - mae: 2117.9734 - val_loss: 2122.1030 - val_mse: 18308324.0000 - val_mae: 2122.3950 - lr: 3.1250e-05\n",
      "Epoch 10/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 2113.4314 - mse: 17799486.0000 - mae: 2113.7302\n",
      "Epoch 10: val_loss did not improve from 2122.10303\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2113.4314 - mse: 17799486.0000 - mae: 2113.7302 - val_loss: 2153.4585 - val_mse: 18804500.0000 - val_mae: 2153.7485 - lr: 3.1250e-05\n",
      "Epoch 11/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2094.3552 - mse: 17301532.0000 - mae: 2094.6548\n",
      "Epoch 11: val_loss did not improve from 2122.10303\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2103.0698 - mse: 17397034.0000 - mae: 2103.3694 - val_loss: 2134.5071 - val_mse: 18527250.0000 - val_mae: 2134.7993 - lr: 3.1250e-05\n",
      "Epoch 12/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2078.4348 - mse: 17142022.0000 - mae: 2078.7346\n",
      "Epoch 12: val_loss did not improve from 2122.10303\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2087.3486 - mse: 17231636.0000 - mae: 2087.6487 - val_loss: 2134.6421 - val_mse: 18467732.0000 - val_mae: 2134.9319 - lr: 3.1250e-05\n",
      "Epoch 13/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 2081.6370 - mse: 17076162.0000 - mae: 2081.9341\n",
      "Epoch 13: val_loss did not improve from 2122.10303\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 2092.3750 - mse: 17212480.0000 - mae: 2092.6729 - val_loss: 2205.1370 - val_mse: 19842230.0000 - val_mae: 2205.4280 - lr: 3.1250e-05\n",
      "Epoch 14/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2082.7532 - mse: 17104254.0000 - mae: 2083.0525\n",
      "Epoch 14: val_loss improved from 2122.10303 to 2119.37476, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2084.2419 - mse: 17110650.0000 - mae: 2084.5415 - val_loss: 2119.3748 - val_mse: 18065290.0000 - val_mae: 2119.6648 - lr: 3.1250e-05\n",
      "Epoch 15/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2059.8201 - mse: 16672429.0000 - mae: 2060.1174\n",
      "Epoch 15: val_loss improved from 2119.37476 to 2116.32031, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2061.7222 - mse: 16683386.0000 - mae: 2062.0195 - val_loss: 2116.3203 - val_mse: 18165054.0000 - val_mae: 2116.6160 - lr: 3.1250e-05\n",
      "Epoch 16/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 2051.2644 - mse: 16547695.0000 - mae: 2051.5613\n",
      "Epoch 16: val_loss did not improve from 2116.32031\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2060.7676 - mse: 16638121.0000 - mae: 2061.0649 - val_loss: 2119.1875 - val_mse: 18221514.0000 - val_mae: 2119.4771 - lr: 3.1250e-05\n",
      "Epoch 17/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2062.1716 - mse: 16617992.0000 - mae: 2062.4690\n",
      "Epoch 17: val_loss improved from 2116.32031 to 2092.82227, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 2067.6223 - mse: 16671687.0000 - mae: 2067.9199 - val_loss: 2092.8223 - val_mse: 17765742.0000 - val_mae: 2093.1162 - lr: 3.1250e-05\n",
      "Epoch 18/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2054.4353 - mse: 16501255.0000 - mae: 2054.7324\n",
      "Epoch 18: val_loss improved from 2092.82227 to 2087.21509, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2062.4158 - mse: 16588427.0000 - mae: 2062.7129 - val_loss: 2087.2151 - val_mse: 17629242.0000 - val_mae: 2087.5054 - lr: 3.1250e-05\n",
      "Epoch 19/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 2038.7557 - mse: 16278800.0000 - mae: 2039.0531\n",
      "Epoch 19: val_loss did not improve from 2087.21509\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 2043.7903 - mse: 16330295.0000 - mae: 2044.0879 - val_loss: 2089.8582 - val_mse: 17834894.0000 - val_mae: 2090.1509 - lr: 3.1250e-05\n",
      "Epoch 20/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 2032.3440 - mse: 16206231.0000 - mae: 2032.6421\n",
      "Epoch 20: val_loss did not improve from 2087.21509\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2040.3590 - mse: 16289843.0000 - mae: 2040.6573 - val_loss: 2091.3621 - val_mse: 17837302.0000 - val_mae: 2091.6548 - lr: 3.1250e-05\n",
      "Epoch 21/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 2016.8485 - mse: 15886908.0000 - mae: 2017.1455\n",
      "Epoch 21: val_loss improved from 2087.21509 to 2074.33447, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2025.0586 - mse: 15972913.0000 - mae: 2025.3562 - val_loss: 2074.3345 - val_mse: 17613898.0000 - val_mae: 2074.6296 - lr: 3.1250e-05\n",
      "Epoch 22/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2008.3232 - mse: 15658011.0000 - mae: 2008.6235\n",
      "Epoch 22: val_loss improved from 2074.33447 to 2068.61694, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2009.9803 - mse: 15665661.0000 - mae: 2010.2806 - val_loss: 2068.6169 - val_mse: 17309350.0000 - val_mae: 2068.9111 - lr: 3.1250e-05\n",
      "Epoch 23/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 2005.0258 - mse: 15658554.0000 - mae: 2005.3248\n",
      "Epoch 23: val_loss improved from 2068.61694 to 2055.36279, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 2007.1953 - mse: 15678292.0000 - mae: 2007.4946 - val_loss: 2055.3628 - val_mse: 17233896.0000 - val_mae: 2055.6604 - lr: 3.1250e-05\n",
      "Epoch 24/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1981.3755 - mse: 15405454.0000 - mae: 1981.6748\n",
      "Epoch 24: val_loss did not improve from 2055.36279\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1990.8662 - mse: 15510413.0000 - mae: 1991.1659 - val_loss: 2076.8635 - val_mse: 17506008.0000 - val_mae: 2077.1587 - lr: 3.1250e-05\n",
      "Epoch 25/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 1978.4854 - mse: 15341454.0000 - mae: 1978.7847\n",
      "Epoch 25: val_loss did not improve from 2055.36279\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1986.8593 - mse: 15431359.0000 - mae: 1987.1592 - val_loss: 2081.3884 - val_mse: 17610258.0000 - val_mae: 2081.6833 - lr: 3.1250e-05\n",
      "Epoch 26/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1976.5554 - mse: 15414674.0000 - mae: 1976.8544\n",
      "Epoch 26: val_loss improved from 2055.36279 to 2041.35730, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1985.9222 - mse: 15511536.0000 - mae: 1986.2216 - val_loss: 2041.3573 - val_mse: 17107526.0000 - val_mae: 2041.6514 - lr: 3.1250e-05\n",
      "Epoch 27/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1976.5714 - mse: 15276639.0000 - mae: 1976.8730\n",
      "Epoch 27: val_loss improved from 2041.35730 to 2027.68225, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1976.4170 - mse: 15266003.0000 - mae: 1976.7186 - val_loss: 2027.6823 - val_mse: 16812296.0000 - val_mae: 2027.9781 - lr: 3.1250e-05\n",
      "Epoch 28/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1964.9694 - mse: 15173305.0000 - mae: 1965.2690\n",
      "Epoch 28: val_loss did not improve from 2027.68225\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1966.3234 - mse: 15188000.0000 - mae: 1966.6230 - val_loss: 2034.2246 - val_mse: 17054444.0000 - val_mae: 2034.5205 - lr: 3.1250e-05\n",
      "Epoch 29/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1965.8794 - mse: 15189859.0000 - mae: 1966.1835\n",
      "Epoch 29: val_loss improved from 2027.68225 to 2019.30615, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1965.7056 - mse: 15179330.0000 - mae: 1966.0099 - val_loss: 2019.3062 - val_mse: 16687155.0000 - val_mae: 2019.6053 - lr: 3.1250e-05\n",
      "Epoch 30/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1963.0903 - mse: 15039272.0000 - mae: 1963.3911\n",
      "Epoch 30: val_loss did not improve from 2019.30615\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1968.2369 - mse: 15096117.0000 - mae: 1968.5380 - val_loss: 2022.8876 - val_mse: 16576707.0000 - val_mae: 2023.1843 - lr: 3.1250e-05\n",
      "Epoch 31/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 1959.6309 - mse: 14977733.0000 - mae: 1959.9294\n",
      "Epoch 31: val_loss did not improve from 2019.30615\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1969.6715 - mse: 15093253.0000 - mae: 1969.9707 - val_loss: 2029.2948 - val_mse: 17224846.0000 - val_mae: 2029.5889 - lr: 3.1250e-05\n",
      "Epoch 32/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1933.2310 - mse: 14778939.0000 - mae: 1933.5314\n",
      "Epoch 32: val_loss did not improve from 2019.30615\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1942.4650 - mse: 14890082.0000 - mae: 1942.7655 - val_loss: 2024.7527 - val_mse: 16862574.0000 - val_mae: 2025.0471 - lr: 3.1250e-05\n",
      "Epoch 33/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1913.6194 - mse: 14389704.0000 - mae: 1913.9188\n",
      "Epoch 33: val_loss improved from 2019.30615 to 1994.05933, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1919.7382 - mse: 14452326.0000 - mae: 1920.0378 - val_loss: 1994.0593 - val_mse: 16158132.0000 - val_mae: 1994.3512 - lr: 3.1250e-05\n",
      "Epoch 34/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1903.4470 - mse: 14221236.0000 - mae: 1903.7451\n",
      "Epoch 34: val_loss did not improve from 1994.05933\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1905.6018 - mse: 14240161.0000 - mae: 1905.9001 - val_loss: 2000.0067 - val_mse: 16154828.0000 - val_mae: 2000.2987 - lr: 3.1250e-05\n",
      "Epoch 35/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1913.6820 - mse: 14347264.0000 - mae: 1913.9813\n",
      "Epoch 35: val_loss did not improve from 1994.05933\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1913.4442 - mse: 14336747.0000 - mae: 1913.7437 - val_loss: 2007.2900 - val_mse: 16430170.0000 - val_mae: 2007.5850 - lr: 3.1250e-05\n",
      "Epoch 36/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1916.0680 - mse: 14407332.0000 - mae: 1916.3701\n",
      "Epoch 36: val_loss improved from 1994.05933 to 1991.52783, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1925.0074 - mse: 14516735.0000 - mae: 1925.3099 - val_loss: 1991.5278 - val_mse: 16459350.0000 - val_mae: 1991.8231 - lr: 3.1250e-05\n",
      "Epoch 37/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1901.8755 - mse: 14311649.0000 - mae: 1902.1759\n",
      "Epoch 37: val_loss did not improve from 1991.52783\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1910.8538 - mse: 14421178.0000 - mae: 1911.1545 - val_loss: 1999.8536 - val_mse: 16271452.0000 - val_mae: 2000.1479 - lr: 3.1250e-05\n",
      "Epoch 38/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1898.8276 - mse: 14226550.0000 - mae: 1899.1288\n",
      "Epoch 38: val_loss improved from 1991.52783 to 1973.97449, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1909.1862 - mse: 14341284.0000 - mae: 1909.4879 - val_loss: 1973.9745 - val_mse: 15859732.0000 - val_mae: 1974.2694 - lr: 3.1250e-05\n",
      "Epoch 39/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1911.1536 - mse: 14342197.0000 - mae: 1911.4531\n",
      "Epoch 39: val_loss did not improve from 1973.97449\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1915.6385 - mse: 14394149.0000 - mae: 1915.9382 - val_loss: 1975.5397 - val_mse: 16131642.0000 - val_mae: 1975.8354 - lr: 3.1250e-05\n",
      "Epoch 40/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1901.3485 - mse: 14199863.0000 - mae: 1901.6487\n",
      "Epoch 40: val_loss did not improve from 1973.97449\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1909.6515 - mse: 14301652.0000 - mae: 1909.9520 - val_loss: 1977.5585 - val_mse: 15974718.0000 - val_mae: 1977.8550 - lr: 3.1250e-05\n",
      "Epoch 41/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1900.2479 - mse: 14274349.0000 - mae: 1900.5490\n",
      "Epoch 41: val_loss did not improve from 1973.97449\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1908.6914 - mse: 14378940.0000 - mae: 1908.9927 - val_loss: 1993.8228 - val_mse: 16385916.0000 - val_mae: 1994.1176 - lr: 3.1250e-05\n",
      "Epoch 42/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1925.3519 - mse: 14522659.0000 - mae: 1925.6528\n",
      "Epoch 42: val_loss did not improve from 1973.97449\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1927.2092 - mse: 14547632.0000 - mae: 1927.5103 - val_loss: 1991.8635 - val_mse: 16373994.0000 - val_mae: 1992.1598 - lr: 3.1250e-05\n",
      "Epoch 43/500\n",
      "428/436 [============================>.] - ETA: 0s - loss: 1896.2914 - mse: 14104284.0000 - mae: 1896.5902\n",
      "Epoch 43: val_loss did not improve from 1973.97449\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1903.9974 - mse: 14186045.0000 - mae: 1904.2969 - val_loss: 1987.3060 - val_mse: 16114304.0000 - val_mae: 1987.6012 - lr: 3.1250e-05\n",
      "Epoch 44/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1910.5979 - mse: 14224475.0000 - mae: 1910.8997\n",
      "Epoch 44: val_loss improved from 1973.97449 to 1954.32275, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1910.1417 - mse: 14213639.0000 - mae: 1910.4438 - val_loss: 1954.3228 - val_mse: 15609468.0000 - val_mae: 1954.6213 - lr: 3.1250e-05\n",
      "Epoch 45/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1878.5164 - mse: 13862536.0000 - mae: 1878.8165\n",
      "Epoch 45: val_loss did not improve from 1954.32275\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1883.8909 - mse: 13923500.0000 - mae: 1884.1913 - val_loss: 1960.7078 - val_mse: 15746507.0000 - val_mae: 1961.0040 - lr: 3.1250e-05\n",
      "Epoch 46/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1866.7998 - mse: 13755226.0000 - mae: 1867.0996\n",
      "Epoch 46: val_loss did not improve from 1954.32275\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1875.6023 - mse: 13844404.0000 - mae: 1875.9026 - val_loss: 1967.9919 - val_mse: 15844497.0000 - val_mae: 1968.2881 - lr: 3.1250e-05\n",
      "Epoch 47/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1897.8275 - mse: 14112688.0000 - mae: 1898.1259\n",
      "Epoch 47: val_loss did not improve from 1954.32275\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1897.8275 - mse: 14112688.0000 - mae: 1898.1259 - val_loss: 1999.1123 - val_mse: 16088455.0000 - val_mae: 1999.4054 - lr: 3.1250e-05\n",
      "Epoch 48/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1902.4614 - mse: 14220656.0000 - mae: 1902.7599\n",
      "Epoch 48: val_loss did not improve from 1954.32275\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1904.7389 - mse: 14243940.0000 - mae: 1905.0375 - val_loss: 1966.2694 - val_mse: 16005179.0000 - val_mae: 1966.5614 - lr: 3.1250e-05\n",
      "Epoch 49/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1872.9121 - mse: 13843403.0000 - mae: 1873.2125\n",
      "Epoch 49: val_loss did not improve from 1954.32275\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1879.6526 - mse: 13920684.0000 - mae: 1879.9532 - val_loss: 1967.4576 - val_mse: 16023125.0000 - val_mae: 1967.7534 - lr: 3.1250e-05\n",
      "Epoch 50/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1879.6589 - mse: 13835756.0000 - mae: 1879.9568\n",
      "Epoch 50: val_loss improved from 1954.32275 to 1953.96179, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1889.2675 - mse: 13949268.0000 - mae: 1889.5657 - val_loss: 1953.9618 - val_mse: 15724633.0000 - val_mae: 1954.2555 - lr: 3.1250e-05\n",
      "Epoch 51/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1872.0671 - mse: 13673066.0000 - mae: 1872.3656\n",
      "Epoch 51: val_loss improved from 1953.96179 to 1933.18884, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1872.4514 - mse: 13666891.0000 - mae: 1872.7502 - val_loss: 1933.1888 - val_mse: 15320962.0000 - val_mae: 1933.4835 - lr: 3.1250e-05\n",
      "Epoch 52/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1862.1218 - mse: 13508869.0000 - mae: 1862.4188\n",
      "Epoch 52: val_loss did not improve from 1933.18884\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1864.7183 - mse: 13533259.0000 - mae: 1865.0154 - val_loss: 1949.6312 - val_mse: 15648293.0000 - val_mae: 1949.9248 - lr: 3.1250e-05\n",
      "Epoch 53/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1864.3347 - mse: 13573878.0000 - mae: 1864.6328\n",
      "Epoch 53: val_loss did not improve from 1933.18884\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1864.3347 - mse: 13573878.0000 - mae: 1864.6328 - val_loss: 1950.4221 - val_mse: 15684651.0000 - val_mae: 1950.7130 - lr: 3.1250e-05\n",
      "Epoch 54/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1849.6125 - mse: 13447098.0000 - mae: 1849.9121\n",
      "Epoch 54: val_loss did not improve from 1933.18884\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1861.3423 - mse: 13583014.0000 - mae: 1861.6423 - val_loss: 1944.8462 - val_mse: 15612976.0000 - val_mae: 1945.1414 - lr: 3.1250e-05\n",
      "Epoch 55/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1864.2716 - mse: 13562146.0000 - mae: 1864.5720\n",
      "Epoch 55: val_loss improved from 1933.18884 to 1924.44189, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1874.6931 - mse: 13693767.0000 - mae: 1874.9935 - val_loss: 1924.4419 - val_mse: 15418696.0000 - val_mae: 1924.7313 - lr: 3.1250e-05\n",
      "Epoch 56/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1858.2887 - mse: 13514036.0000 - mae: 1858.5902\n",
      "Epoch 56: val_loss did not improve from 1924.44189\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1858.2887 - mse: 13514036.0000 - mae: 1858.5902 - val_loss: 1928.7635 - val_mse: 15191475.0000 - val_mae: 1929.0571 - lr: 3.1250e-05\n",
      "Epoch 57/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1857.6796 - mse: 13566633.0000 - mae: 1857.9761\n",
      "Epoch 57: val_loss improved from 1924.44189 to 1910.63123, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1866.6509 - mse: 13670360.0000 - mae: 1866.9480 - val_loss: 1910.6312 - val_mse: 15006722.0000 - val_mae: 1910.9249 - lr: 3.1250e-05\n",
      "Epoch 58/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 1841.8748 - mse: 13399578.0000 - mae: 1842.1725\n",
      "Epoch 58: val_loss improved from 1910.63123 to 1888.55103, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1850.0029 - mse: 13482971.0000 - mae: 1850.3013 - val_loss: 1888.5510 - val_mse: 14742237.0000 - val_mae: 1888.8451 - lr: 3.1250e-05\n",
      "Epoch 59/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1848.5807 - mse: 13477402.0000 - mae: 1848.8800\n",
      "Epoch 59: val_loss did not improve from 1888.55103\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1857.6642 - mse: 13584966.0000 - mae: 1857.9637 - val_loss: 1911.6514 - val_mse: 15064902.0000 - val_mae: 1911.9440 - lr: 3.1250e-05\n",
      "Epoch 60/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1843.6670 - mse: 13402672.0000 - mae: 1843.9656\n",
      "Epoch 60: val_loss did not improve from 1888.55103\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1854.4580 - mse: 13521007.0000 - mae: 1854.7573 - val_loss: 1929.7731 - val_mse: 15247226.0000 - val_mae: 1930.0616 - lr: 3.1250e-05\n",
      "Epoch 61/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1843.1481 - mse: 13324586.0000 - mae: 1843.4459\n",
      "Epoch 61: val_loss did not improve from 1888.55103\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1843.3640 - mse: 13317102.0000 - mae: 1843.6620 - val_loss: 1917.4962 - val_mse: 15073307.0000 - val_mae: 1917.7906 - lr: 3.1250e-05\n",
      "Epoch 62/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1831.9293 - mse: 13225866.0000 - mae: 1832.2295\n",
      "Epoch 62: val_loss did not improve from 1888.55103\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1831.9293 - mse: 13225866.0000 - mae: 1832.2295 - val_loss: 1911.3845 - val_mse: 14968503.0000 - val_mae: 1911.6794 - lr: 3.1250e-05\n",
      "Epoch 63/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1823.1757 - mse: 13151256.0000 - mae: 1823.4753\n",
      "Epoch 63: val_loss did not improve from 1888.55103\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1832.6334 - mse: 13263450.0000 - mae: 1832.9333 - val_loss: 1909.9025 - val_mse: 15024381.0000 - val_mae: 1910.1978 - lr: 3.1250e-05\n",
      "Epoch 64/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1819.7943 - mse: 13118107.0000 - mae: 1820.0933\n",
      "Epoch 64: val_loss did not improve from 1888.55103\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1819.7943 - mse: 13118107.0000 - mae: 1820.0933 - val_loss: 1898.4879 - val_mse: 14794897.0000 - val_mae: 1898.7836 - lr: 3.1250e-05\n",
      "Epoch 65/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1827.1398 - mse: 13261575.0000 - mae: 1827.4381\n",
      "Epoch 65: val_loss improved from 1888.55103 to 1886.71912, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1827.1398 - mse: 13261575.0000 - mae: 1827.4381 - val_loss: 1886.7191 - val_mse: 14754768.0000 - val_mae: 1887.0149 - lr: 3.1250e-05\n",
      "Epoch 66/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1824.3763 - mse: 13209467.0000 - mae: 1824.6750\n",
      "Epoch 66: val_loss improved from 1886.71912 to 1881.36707, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1824.3687 - mse: 13201183.0000 - mae: 1824.6676 - val_loss: 1881.3671 - val_mse: 14608286.0000 - val_mae: 1881.6619 - lr: 3.1250e-05\n",
      "Epoch 67/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1813.6298 - mse: 13113624.0000 - mae: 1813.9280\n",
      "Epoch 67: val_loss did not improve from 1881.36707\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1819.6627 - mse: 13183331.0000 - mae: 1819.9611 - val_loss: 1883.9381 - val_mse: 14760438.0000 - val_mae: 1884.2311 - lr: 3.1250e-05\n",
      "Epoch 68/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1810.7571 - mse: 12894281.0000 - mae: 1811.0558\n",
      "Epoch 68: val_loss did not improve from 1881.36707\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1810.7443 - mse: 12886368.0000 - mae: 1811.0432 - val_loss: 1899.9796 - val_mse: 14769354.0000 - val_mae: 1900.2762 - lr: 3.1250e-05\n",
      "Epoch 69/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1810.6155 - mse: 13008901.0000 - mae: 1810.9125\n",
      "Epoch 69: val_loss improved from 1881.36707 to 1861.95752, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1816.1949 - mse: 13071585.0000 - mae: 1816.4922 - val_loss: 1861.9575 - val_mse: 14341174.0000 - val_mae: 1862.2471 - lr: 3.1250e-05\n",
      "Epoch 70/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1799.9136 - mse: 12948659.0000 - mae: 1800.2141\n",
      "Epoch 70: val_loss improved from 1861.95752 to 1851.21643, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1808.8359 - mse: 13058689.0000 - mae: 1809.1370 - val_loss: 1851.2164 - val_mse: 14163687.0000 - val_mae: 1851.5112 - lr: 3.1250e-05\n",
      "Epoch 71/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1803.5830 - mse: 12979292.0000 - mae: 1803.8821\n",
      "Epoch 71: val_loss did not improve from 1851.21643\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1812.7905 - mse: 13096488.0000 - mae: 1813.0898 - val_loss: 1852.5725 - val_mse: 14196695.0000 - val_mae: 1852.8650 - lr: 3.1250e-05\n",
      "Epoch 72/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 1789.2002 - mse: 12804098.0000 - mae: 1789.4984\n",
      "Epoch 72: val_loss improved from 1851.21643 to 1850.33765, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1797.0989 - mse: 12895690.0000 - mae: 1797.3977 - val_loss: 1850.3376 - val_mse: 14268719.0000 - val_mae: 1850.6287 - lr: 3.1250e-05\n",
      "Epoch 73/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 1805.1677 - mse: 12970264.0000 - mae: 1805.4647\n",
      "Epoch 73: val_loss did not improve from 1850.33765\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1812.7314 - mse: 13061846.0000 - mae: 1813.0291 - val_loss: 1850.5559 - val_mse: 14195655.0000 - val_mae: 1850.8461 - lr: 3.1250e-05\n",
      "Epoch 74/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1806.6588 - mse: 12967265.0000 - mae: 1806.9561\n",
      "Epoch 74: val_loss did not improve from 1850.33765\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1806.5519 - mse: 12959141.0000 - mae: 1806.8492 - val_loss: 1868.5040 - val_mse: 14369971.0000 - val_mae: 1868.7975 - lr: 3.1250e-05\n",
      "Epoch 75/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1791.1069 - mse: 12648565.0000 - mae: 1791.4039\n",
      "Epoch 75: val_loss did not improve from 1850.33765\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1791.0768 - mse: 12641087.0000 - mae: 1791.3739 - val_loss: 1867.2036 - val_mse: 14326419.0000 - val_mae: 1867.4966 - lr: 3.1250e-05\n",
      "Epoch 76/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1782.1179 - mse: 12536301.0000 - mae: 1782.4147\n",
      "Epoch 76: val_loss improved from 1850.33765 to 1845.45679, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1792.2365 - mse: 12665816.0000 - mae: 1792.5336 - val_loss: 1845.4568 - val_mse: 13979828.0000 - val_mae: 1845.7466 - lr: 3.1250e-05\n",
      "Epoch 77/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1775.1783 - mse: 12499451.0000 - mae: 1775.4734\n",
      "Epoch 77: val_loss did not improve from 1845.45679\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1784.5959 - mse: 12607420.0000 - mae: 1784.8915 - val_loss: 1858.0989 - val_mse: 14262566.0000 - val_mae: 1858.3928 - lr: 3.1250e-05\n",
      "Epoch 78/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1767.4714 - mse: 12404185.0000 - mae: 1767.7693\n",
      "Epoch 78: val_loss improved from 1845.45679 to 1840.64465, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1773.3406 - mse: 12464859.0000 - mae: 1773.6389 - val_loss: 1840.6447 - val_mse: 13961070.0000 - val_mae: 1840.9349 - lr: 3.1250e-05\n",
      "Epoch 79/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1778.2262 - mse: 12536269.0000 - mae: 1778.5239\n",
      "Epoch 79: val_loss improved from 1840.64465 to 1837.14075, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1786.7756 - mse: 12641472.0000 - mae: 1787.0740 - val_loss: 1837.1407 - val_mse: 14005009.0000 - val_mae: 1837.4326 - lr: 3.1250e-05\n",
      "Epoch 80/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1783.5322 - mse: 12609464.0000 - mae: 1783.8304\n",
      "Epoch 80: val_loss did not improve from 1837.14075\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1785.6394 - mse: 12631627.0000 - mae: 1785.9377 - val_loss: 1850.3665 - val_mse: 14133476.0000 - val_mae: 1850.6575 - lr: 3.1250e-05\n",
      "Epoch 81/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1803.7003 - mse: 12905322.0000 - mae: 1803.9984\n",
      "Epoch 81: val_loss did not improve from 1837.14075\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1809.4240 - mse: 12966961.0000 - mae: 1809.7223 - val_loss: 1844.0548 - val_mse: 14023988.0000 - val_mae: 1844.3472 - lr: 3.1250e-05\n",
      "Epoch 82/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1772.0046 - mse: 12638655.0000 - mae: 1772.3047\n",
      "Epoch 82: val_loss improved from 1837.14075 to 1826.82800, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1774.2174 - mse: 12660472.0000 - mae: 1774.5177 - val_loss: 1826.8280 - val_mse: 13812458.0000 - val_mae: 1827.1157 - lr: 3.1250e-05\n",
      "Epoch 83/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1769.5411 - mse: 12373406.0000 - mae: 1769.8394\n",
      "Epoch 83: val_loss did not improve from 1826.82800\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1779.6843 - mse: 12516789.0000 - mae: 1779.9828 - val_loss: 1853.9037 - val_mse: 14055790.0000 - val_mae: 1854.1947 - lr: 3.1250e-05\n",
      "Epoch 84/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1775.1438 - mse: 12568030.0000 - mae: 1775.4424\n",
      "Epoch 84: val_loss improved from 1826.82800 to 1823.61755, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1781.0039 - mse: 12635036.0000 - mae: 1781.3027 - val_loss: 1823.6176 - val_mse: 13688022.0000 - val_mae: 1823.9073 - lr: 3.1250e-05\n",
      "Epoch 85/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1763.5612 - mse: 12414714.0000 - mae: 1763.8599\n",
      "Epoch 85: val_loss improved from 1823.61755 to 1789.36572, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1763.5720 - mse: 12407159.0000 - mae: 1763.8708 - val_loss: 1789.3657 - val_mse: 13302847.0000 - val_mae: 1789.6554 - lr: 3.1250e-05\n",
      "Epoch 86/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1769.9893 - mse: 12507609.0000 - mae: 1770.2866\n",
      "Epoch 86: val_loss did not improve from 1789.36572\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1779.6046 - mse: 12627912.0000 - mae: 1779.9022 - val_loss: 1806.3235 - val_mse: 13472517.0000 - val_mae: 1806.6179 - lr: 3.1250e-05\n",
      "Epoch 87/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1762.6975 - mse: 12351773.0000 - mae: 1762.9984\n",
      "Epoch 87: val_loss did not improve from 1789.36572\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1768.1394 - mse: 12410915.0000 - mae: 1768.4408 - val_loss: 1862.2728 - val_mse: 13916773.0000 - val_mae: 1862.5692 - lr: 3.1250e-05\n",
      "Epoch 88/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1747.1226 - mse: 12195391.0000 - mae: 1747.4200\n",
      "Epoch 88: val_loss did not improve from 1789.36572\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1749.3511 - mse: 12215337.0000 - mae: 1749.6488 - val_loss: 1792.5221 - val_mse: 13482342.0000 - val_mae: 1792.8141 - lr: 3.1250e-05\n",
      "Epoch 89/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1759.1849 - mse: 12271967.0000 - mae: 1759.4832\n",
      "Epoch 89: val_loss did not improve from 1789.36572\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1765.0553 - mse: 12332359.0000 - mae: 1765.3536 - val_loss: 1810.9746 - val_mse: 13527508.0000 - val_mae: 1811.2646 - lr: 3.1250e-05\n",
      "Epoch 90/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1754.2948 - mse: 12129803.0000 - mae: 1754.5924\n",
      "Epoch 90: val_loss did not improve from 1789.36572\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1755.9203 - mse: 12145930.0000 - mae: 1756.2180 - val_loss: 1824.6115 - val_mse: 13677624.0000 - val_mae: 1824.9017 - lr: 3.1250e-05\n",
      "Epoch 91/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1754.5562 - mse: 12114210.0000 - mae: 1754.8542\n",
      "Epoch 91: val_loss did not improve from 1789.36572\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1764.0930 - mse: 12247120.0000 - mae: 1764.3914 - val_loss: 1843.1980 - val_mse: 13697480.0000 - val_mae: 1843.4891 - lr: 3.1250e-05\n",
      "Epoch 92/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1757.9465 - mse: 12151708.0000 - mae: 1758.2451\n",
      "Epoch 92: val_loss did not improve from 1789.36572\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1767.5249 - mse: 12287670.0000 - mae: 1767.8237 - val_loss: 1872.8932 - val_mse: 14281510.0000 - val_mae: 1873.1904 - lr: 3.1250e-05\n",
      "Epoch 93/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1771.2363 - mse: 12374973.0000 - mae: 1771.5341\n",
      "Epoch 93: val_loss did not improve from 1789.36572\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1781.1443 - mse: 12517048.0000 - mae: 1781.4425 - val_loss: 1806.5032 - val_mse: 13487732.0000 - val_mae: 1806.8020 - lr: 3.1250e-05\n",
      "Epoch 94/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1762.9902 - mse: 12238213.0000 - mae: 1763.2920\n",
      "Epoch 94: val_loss did not improve from 1789.36572\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1762.9902 - mse: 12238213.0000 - mae: 1763.2920 - val_loss: 1808.1383 - val_mse: 13681815.0000 - val_mae: 1808.4388 - lr: 3.1250e-05\n",
      "Epoch 95/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1740.4236 - mse: 12035806.0000 - mae: 1740.7284\n",
      "Epoch 95: val_loss did not improve from 1789.36572\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1749.4835 - mse: 12143103.0000 - mae: 1749.7888 - val_loss: 1819.1215 - val_mse: 13713662.0000 - val_mae: 1819.4171 - lr: 3.1250e-05\n",
      "Epoch 96/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1748.2557 - mse: 12045166.0000 - mae: 1748.5591\n",
      "Epoch 96: val_loss did not improve from 1789.36572\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1748.1368 - mse: 12037180.0000 - mae: 1748.4403 - val_loss: 1809.9030 - val_mse: 13463212.0000 - val_mae: 1810.1971 - lr: 1.5625e-05\n",
      "Epoch 97/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1733.2960 - mse: 11926859.0000 - mae: 1733.5984\n",
      "Epoch 97: val_loss did not improve from 1789.36572\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1733.2924 - mse: 11919318.0000 - mae: 1733.5950 - val_loss: 1811.6150 - val_mse: 13506607.0000 - val_mae: 1811.9115 - lr: 1.5625e-05\n",
      "Epoch 98/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1741.4310 - mse: 12061019.0000 - mae: 1741.7346\n",
      "Epoch 98: val_loss did not improve from 1789.36572\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1741.3585 - mse: 12053215.0000 - mae: 1741.6622 - val_loss: 1802.7418 - val_mse: 13419589.0000 - val_mae: 1803.0370 - lr: 1.5625e-05\n",
      "Epoch 99/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1724.1686 - mse: 11828374.0000 - mae: 1724.4730\n",
      "Epoch 99: val_loss did not improve from 1789.36572\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1726.2863 - mse: 11847767.0000 - mae: 1726.5908 - val_loss: 1797.3521 - val_mse: 13400029.0000 - val_mae: 1797.6475 - lr: 1.5625e-05\n",
      "Epoch 100/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1721.4352 - mse: 11855803.0000 - mae: 1721.7377\n",
      "Epoch 100: val_loss did not improve from 1789.36572\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1730.6115 - mse: 11965274.0000 - mae: 1730.9146 - val_loss: 1794.3955 - val_mse: 13330867.0000 - val_mae: 1794.6919 - lr: 1.5625e-05\n",
      "Epoch 101/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1717.5198 - mse: 11803919.0000 - mae: 1717.8237\n",
      "Epoch 101: val_loss did not improve from 1789.36572\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1727.1533 - mse: 11916931.0000 - mae: 1727.4576 - val_loss: 1808.0925 - val_mse: 13513846.0000 - val_mae: 1808.3877 - lr: 1.5625e-05\n",
      "Epoch 102/500\n",
      "427/436 [============================>.] - ETA: 0s - loss: 1716.4742 - mse: 11732663.0000 - mae: 1716.7771\n",
      "Epoch 102: val_loss did not improve from 1789.36572\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1728.3296 - mse: 11868765.0000 - mae: 1728.6333 - val_loss: 1791.6444 - val_mse: 13423308.0000 - val_mae: 1791.9398 - lr: 1.5625e-05\n",
      "Epoch 103/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1726.1523 - mse: 11891611.0000 - mae: 1726.4561\n",
      "Epoch 103: val_loss did not improve from 1789.36572\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1728.1475 - mse: 11904426.0000 - mae: 1728.4512 - val_loss: 1794.9025 - val_mse: 13389639.0000 - val_mae: 1795.1971 - lr: 1.5625e-05\n",
      "Epoch 104/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1727.9536 - mse: 11905450.0000 - mae: 1728.2579\n",
      "Epoch 104: val_loss improved from 1789.36572 to 1789.02063, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1727.9536 - mse: 11905450.0000 - mae: 1728.2579 - val_loss: 1789.0206 - val_mse: 13423027.0000 - val_mae: 1789.3168 - lr: 1.5625e-05\n",
      "Epoch 105/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1712.5638 - mse: 11730444.0000 - mae: 1712.8683\n",
      "Epoch 105: val_loss did not improve from 1789.02063\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1722.2190 - mse: 11839131.0000 - mae: 1722.5240 - val_loss: 1798.2766 - val_mse: 13535181.0000 - val_mae: 1798.5708 - lr: 1.5625e-05\n",
      "Epoch 106/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1715.0071 - mse: 11721476.0000 - mae: 1715.3101\n",
      "Epoch 106: val_loss did not improve from 1789.02063\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1716.9043 - mse: 11733140.0000 - mae: 1717.2074 - val_loss: 1795.4110 - val_mse: 13373988.0000 - val_mae: 1795.7054 - lr: 1.5625e-05\n",
      "Epoch 107/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1709.5524 - mse: 11661149.0000 - mae: 1709.8557\n",
      "Epoch 107: val_loss improved from 1789.02063 to 1781.96936, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1719.0599 - mse: 11779077.0000 - mae: 1719.3635 - val_loss: 1781.9694 - val_mse: 13200348.0000 - val_mae: 1782.2648 - lr: 1.5625e-05\n",
      "Epoch 108/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1708.3433 - mse: 11711637.0000 - mae: 1708.6464\n",
      "Epoch 108: val_loss did not improve from 1781.96936\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1714.0815 - mse: 11763217.0000 - mae: 1714.3850 - val_loss: 1786.8002 - val_mse: 13304930.0000 - val_mae: 1787.0947 - lr: 1.5625e-05\n",
      "Epoch 109/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1715.2738 - mse: 11708447.0000 - mae: 1715.5769\n",
      "Epoch 109: val_loss improved from 1781.96936 to 1773.94043, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1715.2738 - mse: 11708447.0000 - mae: 1715.5769 - val_loss: 1773.9404 - val_mse: 13081372.0000 - val_mae: 1774.2345 - lr: 1.5625e-05\n",
      "Epoch 110/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1703.8479 - mse: 11616318.0000 - mae: 1704.1510\n",
      "Epoch 110: val_loss did not improve from 1773.94043\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1703.8956 - mse: 11609411.0000 - mae: 1704.1990 - val_loss: 1792.4814 - val_mse: 13233123.0000 - val_mae: 1792.7754 - lr: 1.5625e-05\n",
      "Epoch 111/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1711.5476 - mse: 11705597.0000 - mae: 1711.8503\n",
      "Epoch 111: val_loss did not improve from 1773.94043\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1717.1998 - mse: 11756050.0000 - mae: 1717.5027 - val_loss: 1820.2875 - val_mse: 13394262.0000 - val_mae: 1820.5853 - lr: 1.5625e-05\n",
      "Epoch 112/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1705.1641 - mse: 11743109.0000 - mae: 1705.4675\n",
      "Epoch 112: val_loss did not improve from 1773.94043\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1711.3129 - mse: 11801132.0000 - mae: 1711.6166 - val_loss: 1783.2728 - val_mse: 13272995.0000 - val_mae: 1783.5673 - lr: 1.5625e-05\n",
      "Epoch 113/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1710.2123 - mse: 11729004.0000 - mae: 1710.5154\n",
      "Epoch 113: val_loss improved from 1773.94043 to 1769.95020, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1710.2123 - mse: 11729004.0000 - mae: 1710.5154 - val_loss: 1769.9502 - val_mse: 13109050.0000 - val_mae: 1770.2446 - lr: 1.5625e-05\n",
      "Epoch 114/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1698.8505 - mse: 11632259.0000 - mae: 1699.1533\n",
      "Epoch 114: val_loss did not improve from 1769.95020\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1708.6730 - mse: 11754356.0000 - mae: 1708.9762 - val_loss: 1785.7222 - val_mse: 13368761.0000 - val_mae: 1786.0170 - lr: 1.5625e-05\n",
      "Epoch 115/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1704.3595 - mse: 11646668.0000 - mae: 1704.6627\n",
      "Epoch 115: val_loss did not improve from 1769.95020\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1704.3595 - mse: 11646668.0000 - mae: 1704.6627 - val_loss: 1777.7856 - val_mse: 13133802.0000 - val_mae: 1778.0812 - lr: 1.5625e-05\n",
      "Epoch 116/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1702.2554 - mse: 11653362.0000 - mae: 1702.5586\n",
      "Epoch 116: val_loss improved from 1769.95020 to 1767.11963, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1707.8503 - mse: 11703366.0000 - mae: 1708.1541 - val_loss: 1767.1196 - val_mse: 13090420.0000 - val_mae: 1767.4139 - lr: 1.5625e-05\n",
      "Epoch 117/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1706.5109 - mse: 11724256.0000 - mae: 1706.8138\n",
      "Epoch 117: val_loss improved from 1767.11963 to 1760.43176, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1712.0088 - mse: 11772665.0000 - mae: 1712.3119 - val_loss: 1760.4318 - val_mse: 12753437.0000 - val_mae: 1760.7266 - lr: 1.5625e-05\n",
      "Epoch 118/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1699.5957 - mse: 11627075.0000 - mae: 1699.8987\n",
      "Epoch 118: val_loss did not improve from 1760.43176\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1704.9774 - mse: 11676456.0000 - mae: 1705.2806 - val_loss: 1769.2534 - val_mse: 13037933.0000 - val_mae: 1769.5483 - lr: 1.5625e-05\n",
      "Epoch 119/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1693.6016 - mse: 11508423.0000 - mae: 1693.9048\n",
      "Epoch 119: val_loss did not improve from 1760.43176\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1703.1725 - mse: 11620893.0000 - mae: 1703.4760 - val_loss: 1766.6521 - val_mse: 12970758.0000 - val_mae: 1766.9449 - lr: 1.5625e-05\n",
      "Epoch 120/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1693.1239 - mse: 11521606.0000 - mae: 1693.4271\n",
      "Epoch 120: val_loss did not improve from 1760.43176\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1693.1239 - mse: 11521606.0000 - mae: 1693.4271 - val_loss: 1769.8099 - val_mse: 12979957.0000 - val_mae: 1770.1050 - lr: 1.5625e-05\n",
      "Epoch 121/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1698.5411 - mse: 11559316.0000 - mae: 1698.8451\n",
      "Epoch 121: val_loss did not improve from 1760.43176\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1704.2594 - mse: 11617501.0000 - mae: 1704.5635 - val_loss: 1771.5494 - val_mse: 12995408.0000 - val_mae: 1771.8444 - lr: 1.5625e-05\n",
      "Epoch 122/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1711.1508 - mse: 11728750.0000 - mae: 1711.4543\n",
      "Epoch 122: val_loss did not improve from 1760.43176\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1711.4767 - mse: 11722759.0000 - mae: 1711.7804 - val_loss: 1773.3234 - val_mse: 12984951.0000 - val_mae: 1773.6191 - lr: 1.5625e-05\n",
      "Epoch 123/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1693.9821 - mse: 11540999.0000 - mae: 1694.2872\n",
      "Epoch 123: val_loss did not improve from 1760.43176\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1703.7120 - mse: 11655671.0000 - mae: 1704.0177 - val_loss: 1770.1028 - val_mse: 12917919.0000 - val_mae: 1770.3972 - lr: 1.5625e-05\n",
      "Epoch 124/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1687.2673 - mse: 11414342.0000 - mae: 1687.5713\n",
      "Epoch 124: val_loss did not improve from 1760.43176\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1697.2666 - mse: 11530067.0000 - mae: 1697.5709 - val_loss: 1767.4104 - val_mse: 13121117.0000 - val_mae: 1767.7054 - lr: 1.5625e-05\n",
      "Epoch 125/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1687.3707 - mse: 11451212.0000 - mae: 1687.6755\n",
      "Epoch 125: val_loss did not improve from 1760.43176\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1693.2655 - mse: 11509856.0000 - mae: 1693.5707 - val_loss: 1763.2019 - val_mse: 12866382.0000 - val_mae: 1763.4961 - lr: 1.5625e-05\n",
      "Epoch 126/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1686.7047 - mse: 11454483.0000 - mae: 1687.0067\n",
      "Epoch 126: val_loss improved from 1760.43176 to 1757.98108, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1696.5665 - mse: 11577202.0000 - mae: 1696.8688 - val_loss: 1757.9811 - val_mse: 12814480.0000 - val_mae: 1758.2744 - lr: 1.5625e-05\n",
      "Epoch 127/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1695.1575 - mse: 11546350.0000 - mae: 1695.4625\n",
      "Epoch 127: val_loss did not improve from 1757.98108\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1695.2451 - mse: 11539605.0000 - mae: 1695.5503 - val_loss: 1771.1367 - val_mse: 12897788.0000 - val_mae: 1771.4308 - lr: 1.5625e-05\n",
      "Epoch 128/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1695.9357 - mse: 11590748.0000 - mae: 1696.2377\n",
      "Epoch 128: val_loss improved from 1757.98108 to 1756.60413, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1695.9357 - mse: 11590748.0000 - mae: 1696.2377 - val_loss: 1756.6041 - val_mse: 12912169.0000 - val_mae: 1756.8982 - lr: 1.5625e-05\n",
      "Epoch 129/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1686.2251 - mse: 11472051.0000 - mae: 1686.5271\n",
      "Epoch 129: val_loss did not improve from 1756.60413\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1695.7345 - mse: 11582006.0000 - mae: 1696.0369 - val_loss: 1768.3323 - val_mse: 13031622.0000 - val_mae: 1768.6279 - lr: 1.5625e-05\n",
      "Epoch 130/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1686.3527 - mse: 11412699.0000 - mae: 1686.6560\n",
      "Epoch 130: val_loss improved from 1756.60413 to 1745.68579, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1696.4468 - mse: 11545322.0000 - mae: 1696.7505 - val_loss: 1745.6858 - val_mse: 12737877.0000 - val_mae: 1745.9803 - lr: 1.5625e-05\n",
      "Epoch 131/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1693.4130 - mse: 11536283.0000 - mae: 1693.7157\n",
      "Epoch 131: val_loss did not improve from 1745.68579\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1693.7961 - mse: 11532323.0000 - mae: 1694.0991 - val_loss: 1749.6302 - val_mse: 12873302.0000 - val_mae: 1749.9243 - lr: 1.5625e-05\n",
      "Epoch 132/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1707.2113 - mse: 11686882.0000 - mae: 1707.5149\n",
      "Epoch 132: val_loss did not improve from 1745.68579\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1707.2113 - mse: 11686882.0000 - mae: 1707.5149 - val_loss: 1754.2197 - val_mse: 12961812.0000 - val_mae: 1754.5132 - lr: 1.5625e-05\n",
      "Epoch 133/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1701.4382 - mse: 11594941.0000 - mae: 1701.7405\n",
      "Epoch 133: val_loss did not improve from 1745.68579\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1701.4382 - mse: 11594941.0000 - mae: 1701.7405 - val_loss: 1758.4448 - val_mse: 13039367.0000 - val_mae: 1758.7400 - lr: 1.5625e-05\n",
      "Epoch 134/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1688.5864 - mse: 11451917.0000 - mae: 1688.8901\n",
      "Epoch 134: val_loss did not improve from 1745.68579\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1698.1619 - mse: 11568457.0000 - mae: 1698.4659 - val_loss: 1745.8577 - val_mse: 12789844.0000 - val_mae: 1746.1514 - lr: 1.5625e-05\n",
      "Epoch 135/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1689.8636 - mse: 11427832.0000 - mae: 1690.1660\n",
      "Epoch 135: val_loss did not improve from 1745.68579\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1699.4366 - mse: 11541818.0000 - mae: 1699.7393 - val_loss: 1751.8414 - val_mse: 12912352.0000 - val_mae: 1752.1361 - lr: 1.5625e-05\n",
      "Epoch 136/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1684.3645 - mse: 11395825.0000 - mae: 1684.6683\n",
      "Epoch 136: val_loss did not improve from 1745.68579\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1694.1121 - mse: 11510859.0000 - mae: 1694.4165 - val_loss: 1753.4656 - val_mse: 12860551.0000 - val_mae: 1753.7598 - lr: 1.5625e-05\n",
      "Epoch 137/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1684.6331 - mse: 11378434.0000 - mae: 1684.9357\n",
      "Epoch 137: val_loss did not improve from 1745.68579\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1685.0793 - mse: 11375300.0000 - mae: 1685.3821 - val_loss: 1747.6521 - val_mse: 12903565.0000 - val_mae: 1747.9454 - lr: 1.5625e-05\n",
      "Epoch 138/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1677.9130 - mse: 11335886.0000 - mae: 1678.2155\n",
      "Epoch 138: val_loss did not improve from 1745.68579\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1683.9363 - mse: 11396658.0000 - mae: 1684.2390 - val_loss: 1745.9905 - val_mse: 12767301.0000 - val_mae: 1746.2849 - lr: 1.5625e-05\n",
      "Epoch 139/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1676.1343 - mse: 11336335.0000 - mae: 1676.4373\n",
      "Epoch 139: val_loss did not improve from 1745.68579\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1677.9869 - mse: 11349690.0000 - mae: 1678.2900 - val_loss: 1756.0751 - val_mse: 12798158.0000 - val_mae: 1756.3691 - lr: 1.5625e-05\n",
      "Epoch 140/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1679.1016 - mse: 11340284.0000 - mae: 1679.4037\n",
      "Epoch 140: val_loss did not improve from 1745.68579\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1680.6803 - mse: 11350048.0000 - mae: 1680.9827 - val_loss: 1762.8268 - val_mse: 12977622.0000 - val_mae: 1763.1215 - lr: 1.5625e-05\n",
      "Epoch 141/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1677.4241 - mse: 11293688.0000 - mae: 1677.7269\n",
      "Epoch 141: val_loss improved from 1745.68579 to 1736.95435, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1687.0945 - mse: 11411004.0000 - mae: 1687.3978 - val_loss: 1736.9543 - val_mse: 12614151.0000 - val_mae: 1737.2473 - lr: 7.8125e-06\n",
      "Epoch 142/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1676.8433 - mse: 11317369.0000 - mae: 1677.1469\n",
      "Epoch 142: val_loss improved from 1736.95435 to 1726.94214, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1676.8433 - mse: 11317369.0000 - mae: 1677.1469 - val_loss: 1726.9421 - val_mse: 12506518.0000 - val_mae: 1727.2339 - lr: 7.8125e-06\n",
      "Epoch 143/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1679.9564 - mse: 11351638.0000 - mae: 1680.2601\n",
      "Epoch 143: val_loss did not improve from 1726.94214\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1681.8492 - mse: 11366503.0000 - mae: 1682.1532 - val_loss: 1730.8003 - val_mse: 12575725.0000 - val_mae: 1731.0930 - lr: 7.8125e-06\n",
      "Epoch 144/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1671.8478 - mse: 11264750.0000 - mae: 1672.1511\n",
      "Epoch 144: val_loss did not improve from 1726.94214\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1682.0081 - mse: 11393498.0000 - mae: 1682.3118 - val_loss: 1727.8403 - val_mse: 12540772.0000 - val_mae: 1728.1324 - lr: 7.8125e-06\n",
      "Epoch 145/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1667.9608 - mse: 11245531.0000 - mae: 1668.2623\n",
      "Epoch 145: val_loss improved from 1726.94214 to 1725.39429, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1677.5118 - mse: 11360446.0000 - mae: 1677.8136 - val_loss: 1725.3943 - val_mse: 12485048.0000 - val_mae: 1725.6868 - lr: 7.8125e-06\n",
      "Epoch 146/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1664.5308 - mse: 11188622.0000 - mae: 1664.8323\n",
      "Epoch 146: val_loss did not improve from 1725.39429\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1674.0466 - mse: 11308277.0000 - mae: 1674.3486 - val_loss: 1729.6023 - val_mse: 12577149.0000 - val_mae: 1729.8943 - lr: 7.8125e-06\n",
      "Epoch 147/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1665.3850 - mse: 11181385.0000 - mae: 1665.6875\n",
      "Epoch 147: val_loss did not improve from 1725.39429\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1671.3602 - mse: 11242123.0000 - mae: 1671.6631 - val_loss: 1728.9869 - val_mse: 12519430.0000 - val_mae: 1729.2788 - lr: 7.8125e-06\n",
      "Epoch 148/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1669.1698 - mse: 11247562.0000 - mae: 1669.4725\n",
      "Epoch 148: val_loss did not improve from 1725.39429\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1669.1698 - mse: 11247562.0000 - mae: 1669.4725 - val_loss: 1727.3386 - val_mse: 12534755.0000 - val_mae: 1727.6311 - lr: 7.8125e-06\n",
      "Epoch 149/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1668.4441 - mse: 11239784.0000 - mae: 1668.7482\n",
      "Epoch 149: val_loss improved from 1725.39429 to 1723.87769, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1668.7177 - mse: 11233599.0000 - mae: 1669.0220 - val_loss: 1723.8777 - val_mse: 12505795.0000 - val_mae: 1724.1700 - lr: 7.8125e-06\n",
      "Epoch 150/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1655.8595 - mse: 11088755.0000 - mae: 1656.1631\n",
      "Epoch 150: val_loss did not improve from 1723.87769\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1665.4197 - mse: 11203050.0000 - mae: 1665.7239 - val_loss: 1729.3813 - val_mse: 12550707.0000 - val_mae: 1729.6742 - lr: 7.8125e-06\n",
      "Epoch 151/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1653.7487 - mse: 11056795.0000 - mae: 1654.0508\n",
      "Epoch 151: val_loss did not improve from 1723.87769\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1663.4514 - mse: 11172570.0000 - mae: 1663.7538 - val_loss: 1729.5173 - val_mse: 12557562.0000 - val_mae: 1729.8099 - lr: 7.8125e-06\n",
      "Epoch 152/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1653.1199 - mse: 11061509.0000 - mae: 1653.4235\n",
      "Epoch 152: val_loss did not improve from 1723.87769\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1662.9407 - mse: 11179972.0000 - mae: 1663.2446 - val_loss: 1727.2972 - val_mse: 12545140.0000 - val_mae: 1727.5892 - lr: 7.8125e-06\n",
      "Epoch 153/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1664.0754 - mse: 11221076.0000 - mae: 1664.3783\n",
      "Epoch 153: val_loss did not improve from 1723.87769\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1664.4031 - mse: 11215207.0000 - mae: 1664.7061 - val_loss: 1728.9926 - val_mse: 12577382.0000 - val_mae: 1729.2834 - lr: 7.8125e-06\n",
      "Epoch 154/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1661.7743 - mse: 11170220.0000 - mae: 1662.0748\n",
      "Epoch 154: val_loss did not improve from 1723.87769\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1663.6580 - mse: 11184158.0000 - mae: 1663.9585 - val_loss: 1729.7992 - val_mse: 12586609.0000 - val_mae: 1730.0897 - lr: 7.8125e-06\n",
      "Epoch 155/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1655.9341 - mse: 11105328.0000 - mae: 1656.2356\n",
      "Epoch 155: val_loss did not improve from 1723.87769\n",
      "436/436 [==============================] - 3s 7ms/step - loss: 1661.9324 - mse: 11165627.0000 - mae: 1662.2343 - val_loss: 1727.1019 - val_mse: 12575273.0000 - val_mae: 1727.3922 - lr: 7.8125e-06\n",
      "Epoch 156/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1660.3809 - mse: 11172225.0000 - mae: 1660.6825\n",
      "Epoch 156: val_loss did not improve from 1723.87769\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1662.3021 - mse: 11186566.0000 - mae: 1662.6039 - val_loss: 1725.3228 - val_mse: 12545292.0000 - val_mae: 1725.6135 - lr: 7.8125e-06\n",
      "Epoch 157/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1648.8409 - mse: 11012513.0000 - mae: 1649.1431\n",
      "Epoch 157: val_loss did not improve from 1723.87769\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1658.6744 - mse: 11133945.0000 - mae: 1658.9769 - val_loss: 1727.3442 - val_mse: 12582457.0000 - val_mae: 1727.6343 - lr: 7.8125e-06\n",
      "Epoch 158/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1647.4260 - mse: 11010675.0000 - mae: 1647.7283\n",
      "Epoch 158: val_loss did not improve from 1723.87769\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1657.1785 - mse: 11130910.0000 - mae: 1657.4810 - val_loss: 1730.7690 - val_mse: 12624331.0000 - val_mae: 1731.0602 - lr: 7.8125e-06\n",
      "Epoch 159/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1652.4244 - mse: 11086505.0000 - mae: 1652.7260\n",
      "Epoch 159: val_loss did not improve from 1723.87769\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1662.2814 - mse: 11204737.0000 - mae: 1662.5835 - val_loss: 1730.4813 - val_mse: 12568664.0000 - val_mae: 1730.7733 - lr: 7.8125e-06\n",
      "Epoch 160/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1663.2166 - mse: 11169304.0000 - mae: 1663.5206\n",
      "Epoch 160: val_loss improved from 1723.87769 to 1714.14319, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1663.6367 - mse: 11163986.0000 - mae: 1663.9410 - val_loss: 1714.1432 - val_mse: 12393104.0000 - val_mae: 1714.4319 - lr: 3.9063e-06\n",
      "Epoch 161/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1649.1226 - mse: 11004349.0000 - mae: 1649.4250\n",
      "Epoch 161: val_loss improved from 1714.14319 to 1711.91846, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1658.7704 - mse: 11122470.0000 - mae: 1659.0730 - val_loss: 1711.9185 - val_mse: 12401729.0000 - val_mae: 1712.2087 - lr: 3.9063e-06\n",
      "Epoch 162/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1650.1978 - mse: 11039025.0000 - mae: 1650.4993\n",
      "Epoch 162: val_loss did not improve from 1711.91846\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1656.2294 - mse: 11100621.0000 - mae: 1656.5312 - val_loss: 1713.0233 - val_mse: 12359139.0000 - val_mae: 1713.3129 - lr: 3.9063e-06\n",
      "Epoch 163/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1655.6929 - mse: 11088731.0000 - mae: 1655.9951\n",
      "Epoch 163: val_loss improved from 1711.91846 to 1711.38416, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1657.7357 - mse: 11104618.0000 - mae: 1658.0381 - val_loss: 1711.3842 - val_mse: 12371729.0000 - val_mae: 1711.6746 - lr: 3.9063e-06\n",
      "Epoch 164/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1645.4832 - mse: 10964811.0000 - mae: 1645.7847\n",
      "Epoch 164: val_loss improved from 1711.38416 to 1711.27954, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1655.3844 - mse: 11086433.0000 - mae: 1655.6860 - val_loss: 1711.2795 - val_mse: 12346377.0000 - val_mae: 1711.5698 - lr: 3.9063e-06\n",
      "Epoch 165/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1648.6140 - mse: 11013450.0000 - mae: 1648.9166\n",
      "Epoch 165: val_loss did not improve from 1711.27954\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1654.7723 - mse: 11076787.0000 - mae: 1655.0750 - val_loss: 1712.1359 - val_mse: 12362289.0000 - val_mae: 1712.4259 - lr: 3.9063e-06\n",
      "Epoch 166/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1654.1248 - mse: 11079586.0000 - mae: 1654.4264\n",
      "Epoch 166: val_loss improved from 1711.27954 to 1710.46997, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1654.5719 - mse: 11074406.0000 - mae: 1654.8738 - val_loss: 1710.4700 - val_mse: 12336026.0000 - val_mae: 1710.7598 - lr: 3.9063e-06\n",
      "Epoch 167/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1653.7350 - mse: 11051617.0000 - mae: 1654.0385\n",
      "Epoch 167: val_loss did not improve from 1710.46997\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1653.7350 - mse: 11051617.0000 - mae: 1654.0385 - val_loss: 1712.1094 - val_mse: 12365822.0000 - val_mae: 1712.3999 - lr: 3.9063e-06\n",
      "Epoch 168/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1653.0773 - mse: 11063054.0000 - mae: 1653.3807\n",
      "Epoch 168: val_loss did not improve from 1710.46997\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1653.5219 - mse: 11057865.0000 - mae: 1653.8254 - val_loss: 1710.7559 - val_mse: 12332249.0000 - val_mae: 1711.0464 - lr: 3.9063e-06\n",
      "Epoch 169/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1646.7808 - mse: 10979799.0000 - mae: 1647.0824\n",
      "Epoch 169: val_loss did not improve from 1710.46997\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1652.9412 - mse: 11043236.0000 - mae: 1653.2432 - val_loss: 1711.9680 - val_mse: 12359595.0000 - val_mae: 1712.2583 - lr: 3.9063e-06\n",
      "Epoch 170/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1642.3877 - mse: 10923590.0000 - mae: 1642.6899\n",
      "Epoch 170: val_loss did not improve from 1710.46997\n",
      "436/436 [==============================] - 4s 10ms/step - loss: 1652.3925 - mse: 11043329.0000 - mae: 1652.6949 - val_loss: 1713.2323 - val_mse: 12357390.0000 - val_mae: 1713.5222 - lr: 3.9063e-06\n",
      "Epoch 171/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1658.8505 - mse: 11111955.0000 - mae: 1659.1536\n",
      "Epoch 171: val_loss did not improve from 1710.46997\n",
      "436/436 [==============================] - 4s 10ms/step - loss: 1659.2965 - mse: 11106748.0000 - mae: 1659.5999 - val_loss: 1713.8967 - val_mse: 12405085.0000 - val_mae: 1714.1871 - lr: 3.9063e-06\n",
      "Epoch 172/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1644.0094 - mse: 10943113.0000 - mae: 1644.3125\n",
      "Epoch 172: val_loss did not improve from 1710.46997\n",
      "436/436 [==============================] - 4s 10ms/step - loss: 1654.0031 - mse: 11062556.0000 - mae: 1654.3064 - val_loss: 1712.0955 - val_mse: 12345476.0000 - val_mae: 1712.3857 - lr: 3.9063e-06\n",
      "Epoch 173/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1647.1677 - mse: 11003503.0000 - mae: 1647.4705\n",
      "Epoch 173: val_loss did not improve from 1710.46997\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1653.3389 - mse: 11066995.0000 - mae: 1653.6418 - val_loss: 1712.0475 - val_mse: 12353408.0000 - val_mae: 1712.3372 - lr: 3.9063e-06\n",
      "Epoch 174/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1643.6057 - mse: 10938540.0000 - mae: 1643.9073\n",
      "Epoch 174: val_loss did not improve from 1710.46997\n",
      "436/436 [==============================] - 4s 10ms/step - loss: 1653.5863 - mse: 11057707.0000 - mae: 1653.8883 - val_loss: 1716.1775 - val_mse: 12385057.0000 - val_mae: 1716.4667 - lr: 3.9063e-06\n",
      "Epoch 175/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1644.4891 - mse: 10963136.0000 - mae: 1644.7911\n",
      "Epoch 175: val_loss did not improve from 1710.46997\n",
      "436/436 [==============================] - 4s 10ms/step - loss: 1654.5342 - mse: 11083225.0000 - mae: 1654.8368 - val_loss: 1714.1737 - val_mse: 12372413.0000 - val_mae: 1714.4640 - lr: 3.9063e-06\n",
      "Epoch 176/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1651.8452 - mse: 11066001.0000 - mae: 1652.1493\n",
      "Epoch 176: val_loss did not improve from 1710.46997\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1653.9478 - mse: 11082537.0000 - mae: 1654.2520 - val_loss: 1714.1027 - val_mse: 12388047.0000 - val_mae: 1714.3922 - lr: 3.9063e-06\n",
      "Epoch 177/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1644.5195 - mse: 10945562.0000 - mae: 1644.8212\n",
      "Epoch 177: val_loss improved from 1710.46997 to 1706.71899, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1654.4799 - mse: 11067846.0000 - mae: 1654.7817 - val_loss: 1706.7190 - val_mse: 12274438.0000 - val_mae: 1707.0071 - lr: 1.9531e-06\n",
      "Epoch 178/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1650.6682 - mse: 11038854.0000 - mae: 1650.9698\n",
      "Epoch 178: val_loss improved from 1706.71899 to 1704.61023, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1652.8070 - mse: 11056065.0000 - mae: 1653.1086 - val_loss: 1704.6102 - val_mse: 12243176.0000 - val_mae: 1704.8995 - lr: 1.9531e-06\n",
      "Epoch 179/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1650.8195 - mse: 11033226.0000 - mae: 1651.1218\n",
      "Epoch 179: val_loss did not improve from 1704.61023\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1650.8195 - mse: 11033226.0000 - mae: 1651.1218 - val_loss: 1706.2902 - val_mse: 12253790.0000 - val_mae: 1706.5792 - lr: 1.9531e-06\n",
      "Epoch 180/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 1640.6414 - mse: 10904691.0000 - mae: 1640.9441\n",
      "Epoch 180: val_loss improved from 1704.61023 to 1704.60779, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1650.1299 - mse: 11013591.0000 - mae: 1650.4333 - val_loss: 1704.6078 - val_mse: 12244748.0000 - val_mae: 1704.8972 - lr: 1.9531e-06\n",
      "Epoch 181/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1640.7518 - mse: 10895846.0000 - mae: 1641.0541\n",
      "Epoch 181: val_loss did not improve from 1704.60779\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1650.6356 - mse: 11015848.0000 - mae: 1650.9381 - val_loss: 1705.4872 - val_mse: 12255991.0000 - val_mae: 1705.7762 - lr: 1.9531e-06\n",
      "Epoch 182/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1638.7244 - mse: 10879211.0000 - mae: 1639.0259\n",
      "Epoch 182: val_loss did not improve from 1704.60779\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1648.8694 - mse: 11001464.0000 - mae: 1649.1711 - val_loss: 1705.9536 - val_mse: 12256417.0000 - val_mae: 1706.2433 - lr: 1.9531e-06\n",
      "Epoch 183/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1643.6711 - mse: 10946198.0000 - mae: 1643.9736\n",
      "Epoch 183: val_loss did not improve from 1704.60779\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1649.8876 - mse: 11010849.0000 - mae: 1650.1903 - val_loss: 1705.7272 - val_mse: 12251668.0000 - val_mae: 1706.0168 - lr: 1.9531e-06\n",
      "Epoch 184/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1638.9758 - mse: 10876870.0000 - mae: 1639.2760\n",
      "Epoch 184: val_loss did not improve from 1704.60779\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1649.0327 - mse: 11000576.0000 - mae: 1649.3330 - val_loss: 1706.5516 - val_mse: 12269155.0000 - val_mae: 1706.8406 - lr: 1.9531e-06\n",
      "Epoch 185/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1639.9136 - mse: 10887897.0000 - mae: 1640.2159\n",
      "Epoch 185: val_loss did not improve from 1704.60779\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1649.9202 - mse: 11011210.0000 - mae: 1650.2228 - val_loss: 1706.1748 - val_mse: 12262730.0000 - val_mae: 1706.4628 - lr: 1.9531e-06\n",
      "Epoch 186/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1648.2167 - mse: 11003649.0000 - mae: 1648.5193\n",
      "Epoch 186: val_loss did not improve from 1704.60779\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1648.7283 - mse: 10998945.0000 - mae: 1649.0310 - val_loss: 1705.4235 - val_mse: 12239373.0000 - val_mae: 1705.7119 - lr: 1.9531e-06\n",
      "Epoch 187/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1637.9362 - mse: 10871930.0000 - mae: 1638.2383\n",
      "Epoch 187: val_loss did not improve from 1704.60779\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1648.0781 - mse: 10994281.0000 - mae: 1648.3804 - val_loss: 1705.8533 - val_mse: 12267888.0000 - val_mae: 1706.1420 - lr: 1.9531e-06\n",
      "Epoch 188/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1649.0295 - mse: 11032391.0000 - mae: 1649.3318\n",
      "Epoch 188: val_loss improved from 1704.60779 to 1704.49512, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1651.1837 - mse: 11049756.0000 - mae: 1651.4860 - val_loss: 1704.4951 - val_mse: 12238615.0000 - val_mae: 1704.7833 - lr: 1.9531e-06\n",
      "Epoch 189/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 1639.8055 - mse: 10916603.0000 - mae: 1640.1071\n",
      "Epoch 189: val_loss did not improve from 1704.49512\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1649.4185 - mse: 11026586.0000 - mae: 1649.7207 - val_loss: 1705.5579 - val_mse: 12247571.0000 - val_mae: 1705.8472 - lr: 1.9531e-06\n",
      "Epoch 190/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1648.6230 - mse: 11029739.0000 - mae: 1648.9264\n",
      "Epoch 190: val_loss did not improve from 1704.49512\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1649.1279 - mse: 11024955.0000 - mae: 1649.4315 - val_loss: 1705.3975 - val_mse: 12258321.0000 - val_mae: 1705.6863 - lr: 1.9531e-06\n",
      "Epoch 191/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1638.2078 - mse: 10875996.0000 - mae: 1638.5085\n",
      "Epoch 191: val_loss did not improve from 1704.49512\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1648.1187 - mse: 10996386.0000 - mae: 1648.4204 - val_loss: 1704.8354 - val_mse: 12247168.0000 - val_mae: 1705.1244 - lr: 1.9531e-06\n",
      "Epoch 192/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1637.7848 - mse: 10873046.0000 - mae: 1638.0857\n",
      "Epoch 192: val_loss did not improve from 1704.49512\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1647.8167 - mse: 10996547.0000 - mae: 1648.1182 - val_loss: 1704.5475 - val_mse: 12239253.0000 - val_mae: 1704.8362 - lr: 1.9531e-06\n",
      "Epoch 193/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1646.7118 - mse: 10985535.0000 - mae: 1647.0142\n",
      "Epoch 193: val_loss did not improve from 1704.49512\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1648.8630 - mse: 11002841.0000 - mae: 1649.1654 - val_loss: 1705.4615 - val_mse: 12261029.0000 - val_mae: 1705.7500 - lr: 1.9531e-06\n",
      "Epoch 194/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1638.3186 - mse: 10880030.0000 - mae: 1638.6195\n",
      "Epoch 194: val_loss did not improve from 1704.49512\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1648.5154 - mse: 11003315.0000 - mae: 1648.8167 - val_loss: 1705.0404 - val_mse: 12252625.0000 - val_mae: 1705.3284 - lr: 1.9531e-06\n",
      "Epoch 195/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1646.9325 - mse: 10991315.0000 - mae: 1647.2355\n",
      "Epoch 195: val_loss did not improve from 1704.49512\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1647.4327 - mse: 10986530.0000 - mae: 1647.7358 - val_loss: 1705.2451 - val_mse: 12254825.0000 - val_mae: 1705.5339 - lr: 1.9531e-06\n",
      "Epoch 196/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1641.7727 - mse: 10933661.0000 - mae: 1642.0753\n",
      "Epoch 196: val_loss improved from 1704.49512 to 1704.40015, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1647.9794 - mse: 10998203.0000 - mae: 1648.2821 - val_loss: 1704.4001 - val_mse: 12234019.0000 - val_mae: 1704.6886 - lr: 1.9531e-06\n",
      "Epoch 197/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1637.7964 - mse: 10867835.0000 - mae: 1638.0988\n",
      "Epoch 197: val_loss did not improve from 1704.40015\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1647.9553 - mse: 10990777.0000 - mae: 1648.2581 - val_loss: 1705.6262 - val_mse: 12259029.0000 - val_mae: 1705.9138 - lr: 1.9531e-06\n",
      "Epoch 198/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1646.8828 - mse: 10993919.0000 - mae: 1647.1844\n",
      "Epoch 198: val_loss did not improve from 1704.40015\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1647.3914 - mse: 10989204.0000 - mae: 1647.6932 - val_loss: 1704.5109 - val_mse: 12233286.0000 - val_mae: 1704.7992 - lr: 1.9531e-06\n",
      "Epoch 199/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1646.7566 - mse: 10995380.0000 - mae: 1647.0594\n",
      "Epoch 199: val_loss did not improve from 1704.40015\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1648.9141 - mse: 11012828.0000 - mae: 1649.2170 - val_loss: 1705.5663 - val_mse: 12261592.0000 - val_mae: 1705.8551 - lr: 1.9531e-06\n",
      "Epoch 200/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1646.0448 - mse: 10987625.0000 - mae: 1646.3455\n",
      "Epoch 200: val_loss did not improve from 1704.40015\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1646.5532 - mse: 10982912.0000 - mae: 1646.8539 - val_loss: 1705.0963 - val_mse: 12243703.0000 - val_mae: 1705.3854 - lr: 1.9531e-06\n",
      "Epoch 201/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1643.3413 - mse: 10960840.0000 - mae: 1643.6426\n",
      "Epoch 201: val_loss did not improve from 1704.40015\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1649.5378 - mse: 11025435.0000 - mae: 1649.8392 - val_loss: 1706.6670 - val_mse: 12272668.0000 - val_mae: 1706.9550 - lr: 1.9531e-06\n",
      "Epoch 202/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1647.8644 - mse: 11010104.0000 - mae: 1648.1664\n",
      "Epoch 202: val_loss did not improve from 1704.40015\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1647.8644 - mse: 11010104.0000 - mae: 1648.1664 - val_loss: 1705.1154 - val_mse: 12242262.0000 - val_mae: 1705.4038 - lr: 1.9531e-06\n",
      "Epoch 203/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1640.8737 - mse: 10936409.0000 - mae: 1641.1732\n",
      "Epoch 203: val_loss did not improve from 1704.40015\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1647.0720 - mse: 11000818.0000 - mae: 1647.3717 - val_loss: 1705.1561 - val_mse: 12265201.0000 - val_mae: 1705.4438 - lr: 1.9531e-06\n",
      "Epoch 204/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1637.8470 - mse: 10879879.0000 - mae: 1638.1483\n",
      "Epoch 204: val_loss did not improve from 1704.40015\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1647.7678 - mse: 11000352.0000 - mae: 1648.0691 - val_loss: 1704.6078 - val_mse: 12239303.0000 - val_mae: 1704.8965 - lr: 1.9531e-06\n",
      "Epoch 205/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1646.1936 - mse: 10976786.0000 - mae: 1646.4948\n",
      "Epoch 205: val_loss did not improve from 1704.40015\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1646.1936 - mse: 10976786.0000 - mae: 1646.4948 - val_loss: 1705.6338 - val_mse: 12262835.0000 - val_mae: 1705.9221 - lr: 1.9531e-06\n",
      "Epoch 206/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1646.9054 - mse: 10979254.0000 - mae: 1647.2083\n",
      "Epoch 206: val_loss did not improve from 1704.40015\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1646.9054 - mse: 10979254.0000 - mae: 1647.2083 - val_loss: 1705.5132 - val_mse: 12258845.0000 - val_mae: 1705.8015 - lr: 1.9531e-06\n",
      "Epoch 207/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1635.6115 - mse: 10845514.0000 - mae: 1635.9111\n",
      "Epoch 207: val_loss improved from 1704.40015 to 1703.98389, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1645.6107 - mse: 10967064.0000 - mae: 1645.9111 - val_loss: 1703.9839 - val_mse: 12219796.0000 - val_mae: 1704.2712 - lr: 9.7656e-07\n",
      "Epoch 208/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1645.1106 - mse: 10971058.0000 - mae: 1645.4124\n",
      "Epoch 208: val_loss improved from 1703.98389 to 1703.46887, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1645.6301 - mse: 10966427.0000 - mae: 1645.9320 - val_loss: 1703.4689 - val_mse: 12222089.0000 - val_mae: 1703.7560 - lr: 9.7656e-07\n",
      "Epoch 209/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1643.2278 - mse: 10946934.0000 - mae: 1643.5297\n",
      "Epoch 209: val_loss improved from 1703.46887 to 1703.12427, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1645.4259 - mse: 10965217.0000 - mae: 1645.7279 - val_loss: 1703.1243 - val_mse: 12211457.0000 - val_mae: 1703.4126 - lr: 9.7656e-07\n",
      "Epoch 210/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1635.0618 - mse: 10840158.0000 - mae: 1635.3633\n",
      "Epoch 210: val_loss did not improve from 1703.12427\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1645.0293 - mse: 10961380.0000 - mae: 1645.3314 - val_loss: 1703.2639 - val_mse: 12224277.0000 - val_mae: 1703.5516 - lr: 9.7656e-07\n",
      "Epoch 211/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1642.8484 - mse: 10943401.0000 - mae: 1643.1498\n",
      "Epoch 211: val_loss did not improve from 1703.12427\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1645.0389 - mse: 10961512.0000 - mae: 1645.3403 - val_loss: 1703.1583 - val_mse: 12216541.0000 - val_mae: 1703.4463 - lr: 9.7656e-07\n",
      "Epoch 212/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 1635.3304 - mse: 10851685.0000 - mae: 1635.6312\n",
      "Epoch 212: val_loss did not improve from 1703.12427\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1645.0018 - mse: 10962529.0000 - mae: 1645.3033 - val_loss: 1703.6597 - val_mse: 12227960.0000 - val_mae: 1703.9479 - lr: 9.7656e-07\n",
      "Epoch 213/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1644.4279 - mse: 10969511.0000 - mae: 1644.7300\n",
      "Epoch 213: val_loss did not improve from 1703.12427\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1644.9510 - mse: 10964894.0000 - mae: 1645.2535 - val_loss: 1703.4200 - val_mse: 12219411.0000 - val_mae: 1703.7081 - lr: 9.7656e-07\n",
      "Epoch 214/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1642.7903 - mse: 10947976.0000 - mae: 1643.0907\n",
      "Epoch 214: val_loss did not improve from 1703.12427\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1644.9878 - mse: 10966100.0000 - mae: 1645.2882 - val_loss: 1703.4633 - val_mse: 12228404.0000 - val_mae: 1703.7509 - lr: 9.7656e-07\n",
      "Epoch 215/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1634.6016 - mse: 10835506.0000 - mae: 1634.9041\n",
      "Epoch 215: val_loss did not improve from 1703.12427\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1644.8865 - mse: 10960426.0000 - mae: 1645.1892 - val_loss: 1703.1851 - val_mse: 12214136.0000 - val_mae: 1703.4724 - lr: 9.7656e-07\n",
      "Epoch 216/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1638.3737 - mse: 10894233.0000 - mae: 1638.6747\n",
      "Epoch 216: val_loss did not improve from 1703.12427\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1644.6206 - mse: 10959785.0000 - mae: 1644.9218 - val_loss: 1703.7849 - val_mse: 12229303.0000 - val_mae: 1704.0728 - lr: 9.7656e-07\n",
      "Epoch 217/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1644.2648 - mse: 10969007.0000 - mae: 1644.5675\n",
      "Epoch 217: val_loss did not improve from 1703.12427\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1644.7881 - mse: 10964389.0000 - mae: 1645.0912 - val_loss: 1703.5853 - val_mse: 12223873.0000 - val_mae: 1703.8728 - lr: 9.7656e-07\n",
      "Epoch 218/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 1634.8444 - mse: 10849434.0000 - mae: 1635.1445\n",
      "Epoch 218: val_loss did not improve from 1703.12427\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1644.5264 - mse: 10960504.0000 - mae: 1644.8270 - val_loss: 1703.5370 - val_mse: 12217258.0000 - val_mae: 1703.8247 - lr: 9.7656e-07\n",
      "Epoch 219/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1634.8181 - mse: 10843382.0000 - mae: 1635.1201\n",
      "Epoch 219: val_loss did not improve from 1703.12427\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1644.7969 - mse: 10964759.0000 - mae: 1645.0994 - val_loss: 1703.5090 - val_mse: 12226159.0000 - val_mae: 1703.7966 - lr: 9.7656e-07\n",
      "Epoch 220/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1633.9218 - mse: 10825992.0000 - mae: 1634.2233\n",
      "Epoch 220: val_loss did not improve from 1703.12427\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1643.9038 - mse: 10947636.0000 - mae: 1644.2057 - val_loss: 1703.3646 - val_mse: 12215861.0000 - val_mae: 1703.6509 - lr: 4.8828e-07\n",
      "Epoch 221/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1633.4398 - mse: 10820230.0000 - mae: 1633.7406\n",
      "Epoch 221: val_loss did not improve from 1703.12427\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1643.5581 - mse: 10945370.0000 - mae: 1643.8590 - val_loss: 1703.2433 - val_mse: 12220135.0000 - val_mae: 1703.5308 - lr: 4.8828e-07\n",
      "Epoch 222/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1633.3993 - mse: 10823944.0000 - mae: 1633.7007\n",
      "Epoch 222: val_loss improved from 1703.12427 to 1703.02832, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1643.3813 - mse: 10945555.0000 - mae: 1643.6832 - val_loss: 1703.0283 - val_mse: 12215653.0000 - val_mae: 1703.3153 - lr: 4.8828e-07\n",
      "Epoch 223/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1643.0106 - mse: 10950696.0000 - mae: 1643.3131\n",
      "Epoch 223: val_loss improved from 1703.02832 to 1703.01160, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1643.5360 - mse: 10946106.0000 - mae: 1643.8386 - val_loss: 1703.0116 - val_mse: 12219469.0000 - val_mae: 1703.2994 - lr: 4.8828e-07\n",
      "Epoch 224/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1633.4449 - mse: 10824574.0000 - mae: 1633.7460\n",
      "Epoch 224: val_loss improved from 1703.01160 to 1702.75500, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1643.4187 - mse: 10946110.0000 - mae: 1643.7202 - val_loss: 1702.7550 - val_mse: 12214097.0000 - val_mae: 1703.0425 - lr: 4.8828e-07\n",
      "Epoch 225/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1641.2131 - mse: 10927058.0000 - mae: 1641.5157\n",
      "Epoch 225: val_loss did not improve from 1702.75500\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1643.4147 - mse: 10945477.0000 - mae: 1643.7174 - val_loss: 1703.1292 - val_mse: 12221016.0000 - val_mae: 1703.4167 - lr: 4.8828e-07\n",
      "Epoch 226/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1642.8005 - mse: 10950251.0000 - mae: 1643.1000\n",
      "Epoch 226: val_loss did not improve from 1702.75500\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1643.3259 - mse: 10945664.0000 - mae: 1643.6256 - val_loss: 1702.7982 - val_mse: 12215371.0000 - val_mae: 1703.0857 - lr: 4.8828e-07\n",
      "Epoch 227/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1642.8683 - mse: 10950454.0000 - mae: 1643.1698\n",
      "Epoch 227: val_loss did not improve from 1702.75500\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1643.3925 - mse: 10945855.0000 - mae: 1643.6942 - val_loss: 1702.8607 - val_mse: 12219215.0000 - val_mae: 1703.1483 - lr: 4.8828e-07\n",
      "Epoch 228/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1632.9214 - mse: 10820564.0000 - mae: 1633.2233\n",
      "Epoch 228: val_loss improved from 1702.75500 to 1702.58069, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1643.2067 - mse: 10945795.0000 - mae: 1643.5088 - val_loss: 1702.5807 - val_mse: 12214425.0000 - val_mae: 1702.8682 - lr: 4.8828e-07\n",
      "Epoch 229/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1640.9697 - mse: 10927195.0000 - mae: 1641.2729\n",
      "Epoch 229: val_loss did not improve from 1702.58069\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1643.1674 - mse: 10945535.0000 - mae: 1643.4707 - val_loss: 1702.6383 - val_mse: 12218610.0000 - val_mae: 1702.9258 - lr: 4.8828e-07\n",
      "Epoch 230/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1643.2092 - mse: 10945857.0000 - mae: 1643.5107\n",
      "Epoch 230: val_loss did not improve from 1702.58069\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1643.2092 - mse: 10945857.0000 - mae: 1643.5107 - val_loss: 1702.6115 - val_mse: 12215462.0000 - val_mae: 1702.8988 - lr: 4.8828e-07\n",
      "Epoch 231/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1641.0858 - mse: 10927439.0000 - mae: 1641.3872\n",
      "Epoch 231: val_loss did not improve from 1702.58069\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1643.2854 - mse: 10945822.0000 - mae: 1643.5869 - val_loss: 1702.7152 - val_mse: 12213476.0000 - val_mae: 1703.0026 - lr: 4.8828e-07\n",
      "Epoch 232/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1633.2186 - mse: 10823816.0000 - mae: 1633.5197\n",
      "Epoch 232: val_loss improved from 1702.58069 to 1702.50659, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1643.1798 - mse: 10945270.0000 - mae: 1643.4811 - val_loss: 1702.5066 - val_mse: 12214812.0000 - val_mae: 1702.7937 - lr: 4.8828e-07\n",
      "Epoch 233/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1640.8591 - mse: 10926458.0000 - mae: 1641.1611\n",
      "Epoch 233: val_loss improved from 1702.50659 to 1702.50391, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1643.0582 - mse: 10944842.0000 - mae: 1643.3605 - val_loss: 1702.5039 - val_mse: 12210836.0000 - val_mae: 1702.7910 - lr: 4.8828e-07\n",
      "Epoch 234/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1633.1638 - mse: 10823482.0000 - mae: 1633.4640\n",
      "Epoch 234: val_loss did not improve from 1702.50391\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1643.1262 - mse: 10944989.0000 - mae: 1643.4268 - val_loss: 1702.6418 - val_mse: 12217679.0000 - val_mae: 1702.9281 - lr: 4.8828e-07\n",
      "Epoch 235/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1632.7206 - mse: 10819327.0000 - mae: 1633.0227\n",
      "Epoch 235: val_loss improved from 1702.50391 to 1702.49048, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1643.0149 - mse: 10944695.0000 - mae: 1643.3175 - val_loss: 1702.4905 - val_mse: 12212702.0000 - val_mae: 1702.7783 - lr: 4.8828e-07\n",
      "Epoch 236/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1632.9240 - mse: 10821889.0000 - mae: 1633.2262\n",
      "Epoch 236: val_loss did not improve from 1702.49048\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1642.8928 - mse: 10943424.0000 - mae: 1643.1957 - val_loss: 1702.5009 - val_mse: 12215853.0000 - val_mae: 1702.7877 - lr: 4.8828e-07\n",
      "Epoch 237/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1643.0009 - mse: 10944678.0000 - mae: 1643.3022\n",
      "Epoch 237: val_loss did not improve from 1702.49048\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1643.0009 - mse: 10944678.0000 - mae: 1643.3022 - val_loss: 1702.5083 - val_mse: 12213720.0000 - val_mae: 1702.7961 - lr: 4.8828e-07\n",
      "Epoch 238/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1636.6093 - mse: 10877291.0000 - mae: 1636.9097\n",
      "Epoch 238: val_loss did not improve from 1702.49048\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1642.8684 - mse: 10943166.0000 - mae: 1643.1689 - val_loss: 1702.7084 - val_mse: 12219108.0000 - val_mae: 1702.9968 - lr: 4.8828e-07\n",
      "Epoch 239/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1642.9502 - mse: 10944357.0000 - mae: 1643.2526\n",
      "Epoch 239: val_loss did not improve from 1702.49048\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1642.9502 - mse: 10944357.0000 - mae: 1643.2526 - val_loss: 1702.6267 - val_mse: 12215553.0000 - val_mae: 1702.9132 - lr: 4.8828e-07\n",
      "Epoch 240/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1632.8580 - mse: 10821886.0000 - mae: 1633.1603\n",
      "Epoch 240: val_loss did not improve from 1702.49048\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1642.8269 - mse: 10943415.0000 - mae: 1643.1295 - val_loss: 1702.5536 - val_mse: 12217846.0000 - val_mae: 1702.8418 - lr: 4.8828e-07\n",
      "Epoch 241/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1640.4802 - mse: 10923817.0000 - mae: 1640.7828\n",
      "Epoch 241: val_loss improved from 1702.49048 to 1702.41211, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1642.6774 - mse: 10942116.0000 - mae: 1642.9799 - val_loss: 1702.4121 - val_mse: 12213276.0000 - val_mae: 1702.6992 - lr: 4.8828e-07\n",
      "Epoch 242/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1642.6476 - mse: 10941883.0000 - mae: 1642.9503\n",
      "Epoch 242: val_loss did not improve from 1702.41211\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1642.6476 - mse: 10941883.0000 - mae: 1642.9503 - val_loss: 1702.7883 - val_mse: 12220434.0000 - val_mae: 1703.0759 - lr: 4.8828e-07\n",
      "Epoch 243/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1632.7200 - mse: 10817728.0000 - mae: 1633.0216\n",
      "Epoch 243: val_loss did not improve from 1702.41211\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1642.8351 - mse: 10942905.0000 - mae: 1643.1370 - val_loss: 1702.7502 - val_mse: 12217680.0000 - val_mae: 1703.0370 - lr: 4.8828e-07\n",
      "Epoch 244/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1640.3779 - mse: 10922870.0000 - mae: 1640.6809\n",
      "Epoch 244: val_loss did not improve from 1702.41211\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1642.5756 - mse: 10941174.0000 - mae: 1642.8785 - val_loss: 1702.5959 - val_mse: 12218286.0000 - val_mae: 1702.8831 - lr: 4.8828e-07\n",
      "Epoch 245/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1636.3375 - mse: 10875503.0000 - mae: 1636.6393\n",
      "Epoch 245: val_loss did not improve from 1702.41211\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1642.5985 - mse: 10941389.0000 - mae: 1642.9006 - val_loss: 1702.5098 - val_mse: 12214410.0000 - val_mae: 1702.7972 - lr: 4.8828e-07\n",
      "Epoch 246/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1640.3344 - mse: 10922783.0000 - mae: 1640.6367\n",
      "Epoch 246: val_loss improved from 1702.41211 to 1702.40308, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1642.5328 - mse: 10941093.0000 - mae: 1642.8351 - val_loss: 1702.4031 - val_mse: 12210477.0000 - val_mae: 1702.6907 - lr: 4.8828e-07\n",
      "Epoch 247/500\n",
      "430/436 [============================>.] - ETA: 0s - loss: 1632.6515 - mse: 10819383.0000 - mae: 1632.9521\n",
      "Epoch 247: val_loss did not improve from 1702.40308\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1642.6130 - mse: 10940873.0000 - mae: 1642.9144 - val_loss: 1702.6223 - val_mse: 12217721.0000 - val_mae: 1702.9095 - lr: 4.8828e-07\n",
      "Epoch 248/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1631.9844 - mse: 10813521.0000 - mae: 1632.2866\n",
      "Epoch 248: val_loss did not improve from 1702.40308\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1642.2915 - mse: 10939073.0000 - mae: 1642.5940 - val_loss: 1702.4055 - val_mse: 12211041.0000 - val_mae: 1702.6925 - lr: 4.8828e-07\n",
      "Epoch 249/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1636.0322 - mse: 10873396.0000 - mae: 1636.3330\n",
      "Epoch 249: val_loss did not improve from 1702.40308\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1642.2971 - mse: 10939294.0000 - mae: 1642.5981 - val_loss: 1702.7009 - val_mse: 12217514.0000 - val_mae: 1702.9885 - lr: 4.8828e-07\n",
      "Epoch 250/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1640.2876 - mse: 10922634.0000 - mae: 1640.5891\n",
      "Epoch 250: val_loss did not improve from 1702.40308\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1642.4873 - mse: 10940937.0000 - mae: 1642.7888 - val_loss: 1702.4153 - val_mse: 12212700.0000 - val_mae: 1702.7025 - lr: 4.8828e-07\n",
      "Epoch 251/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1639.8082 - mse: 10919625.0000 - mae: 1640.1101\n",
      "Epoch 251: val_loss did not improve from 1702.40308\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1642.0077 - mse: 10937920.0000 - mae: 1642.3099 - val_loss: 1702.6652 - val_mse: 12219469.0000 - val_mae: 1702.9535 - lr: 4.8828e-07\n",
      "Epoch 252/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1631.8741 - mse: 10813832.0000 - mae: 1632.1752\n",
      "Epoch 252: val_loss did not improve from 1702.40308\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1642.1740 - mse: 10939315.0000 - mae: 1642.4757 - val_loss: 1702.4502 - val_mse: 12212839.0000 - val_mae: 1702.7372 - lr: 4.8828e-07\n",
      "Epoch 253/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1641.6962 - mse: 10944120.0000 - mae: 1641.9973\n",
      "Epoch 253: val_loss did not improve from 1702.40308\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1642.2227 - mse: 10939536.0000 - mae: 1642.5239 - val_loss: 1702.5642 - val_mse: 12218628.0000 - val_mae: 1702.8524 - lr: 4.8828e-07\n",
      "Epoch 254/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1632.0400 - mse: 10813234.0000 - mae: 1632.3416\n",
      "Epoch 254: val_loss did not improve from 1702.40308\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1642.1624 - mse: 10938471.0000 - mae: 1642.4639 - val_loss: 1702.6680 - val_mse: 12216892.0000 - val_mae: 1702.9562 - lr: 4.8828e-07\n",
      "Epoch 255/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1639.7893 - mse: 10919122.0000 - mae: 1640.0900\n",
      "Epoch 255: val_loss did not improve from 1702.40308\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1641.9894 - mse: 10937424.0000 - mae: 1642.2903 - val_loss: 1702.8368 - val_mse: 12221798.0000 - val_mae: 1703.1238 - lr: 4.8828e-07\n",
      "Epoch 256/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1642.0947 - mse: 10938966.0000 - mae: 1642.3965\n",
      "Epoch 256: val_loss did not improve from 1702.40308\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1642.0947 - mse: 10938966.0000 - mae: 1642.3965 - val_loss: 1702.5120 - val_mse: 12215044.0000 - val_mae: 1702.7997 - lr: 4.8828e-07\n",
      "Epoch 257/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1635.2515 - mse: 10863486.0000 - mae: 1635.5522\n",
      "Epoch 257: val_loss improved from 1702.40308 to 1702.25952, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1641.5199 - mse: 10929443.0000 - mae: 1641.8210 - val_loss: 1702.2595 - val_mse: 12210997.0000 - val_mae: 1702.5459 - lr: 2.4414e-07\n",
      "Epoch 258/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1641.4175 - mse: 10928925.0000 - mae: 1641.7194\n",
      "Epoch 258: val_loss did not improve from 1702.25952\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1641.4175 - mse: 10928925.0000 - mae: 1641.7194 - val_loss: 1702.3993 - val_mse: 12214316.0000 - val_mae: 1702.6868 - lr: 2.4414e-07\n",
      "Epoch 259/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1635.1550 - mse: 10863769.0000 - mae: 1635.4562\n",
      "Epoch 259: val_loss improved from 1702.25952 to 1702.16589, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1641.4238 - mse: 10929735.0000 - mae: 1641.7251 - val_loss: 1702.1659 - val_mse: 12210956.0000 - val_mae: 1702.4528 - lr: 2.4414e-07\n",
      "Epoch 260/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1640.8173 - mse: 10933539.0000 - mae: 1641.1191\n",
      "Epoch 260: val_loss did not improve from 1702.16589\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1641.3455 - mse: 10928971.0000 - mae: 1641.6475 - val_loss: 1702.2826 - val_mse: 12214163.0000 - val_mae: 1702.5698 - lr: 2.4414e-07\n",
      "Epoch 261/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1639.1736 - mse: 10911138.0000 - mae: 1639.4744\n",
      "Epoch 261: val_loss improved from 1702.16589 to 1702.03906, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1641.3711 - mse: 10929436.0000 - mae: 1641.6721 - val_loss: 1702.0391 - val_mse: 12209858.0000 - val_mae: 1702.3258 - lr: 2.4414e-07\n",
      "Epoch 262/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1631.2286 - mse: 10804244.0000 - mae: 1631.5292\n",
      "Epoch 262: val_loss did not improve from 1702.03906\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1641.3597 - mse: 10929552.0000 - mae: 1641.6604 - val_loss: 1702.0863 - val_mse: 12212259.0000 - val_mae: 1702.3723 - lr: 2.4414e-07\n",
      "Epoch 263/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1639.0907 - mse: 10911190.0000 - mae: 1639.3912\n",
      "Epoch 263: val_loss did not improve from 1702.03906\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1641.2872 - mse: 10929474.0000 - mae: 1641.5878 - val_loss: 1702.0964 - val_mse: 12211318.0000 - val_mae: 1702.3831 - lr: 2.4414e-07\n",
      "Epoch 264/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1631.0250 - mse: 10804107.0000 - mae: 1631.3240\n",
      "Epoch 264: val_loss did not improve from 1702.03906\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1641.3334 - mse: 10929762.0000 - mae: 1641.6324 - val_loss: 1702.0551 - val_mse: 12212725.0000 - val_mae: 1702.3409 - lr: 2.4414e-07\n",
      "Epoch 265/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1640.7551 - mse: 10933566.0000 - mae: 1641.0553\n",
      "Epoch 265: val_loss improved from 1702.03906 to 1701.99121, saving model to new_stne_gru_weight_ns.h5\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1641.2839 - mse: 10929002.0000 - mae: 1641.5842 - val_loss: 1701.9912 - val_mse: 12210208.0000 - val_mae: 1702.2770 - lr: 2.4414e-07\n",
      "Epoch 266/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1631.1232 - mse: 10803460.0000 - mae: 1631.4243\n",
      "Epoch 266: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1641.2440 - mse: 10928657.0000 - mae: 1641.5453 - val_loss: 1702.0496 - val_mse: 12212392.0000 - val_mae: 1702.3362 - lr: 2.4414e-07\n",
      "Epoch 267/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1641.2773 - mse: 10929099.0000 - mae: 1641.5790\n",
      "Epoch 267: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1641.2773 - mse: 10929099.0000 - mae: 1641.5790 - val_loss: 1702.1436 - val_mse: 12211513.0000 - val_mae: 1702.4303 - lr: 2.4414e-07\n",
      "Epoch 268/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1640.7128 - mse: 10933403.0000 - mae: 1641.0129\n",
      "Epoch 268: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1641.2424 - mse: 10928846.0000 - mae: 1641.5427 - val_loss: 1702.1051 - val_mse: 12213154.0000 - val_mae: 1702.3925 - lr: 2.4414e-07\n",
      "Epoch 269/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 1631.5427 - mse: 10817091.0000 - mae: 1631.8427\n",
      "Epoch 269: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1641.1978 - mse: 10928349.0000 - mae: 1641.4982 - val_loss: 1702.0388 - val_mse: 12210527.0000 - val_mae: 1702.3270 - lr: 2.4414e-07\n",
      "Epoch 270/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1634.9512 - mse: 10863150.0000 - mae: 1635.2532\n",
      "Epoch 270: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1641.2186 - mse: 10929092.0000 - mae: 1641.5208 - val_loss: 1702.0868 - val_mse: 12212906.0000 - val_mae: 1702.3738 - lr: 2.4414e-07\n",
      "Epoch 271/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1630.8701 - mse: 10802619.0000 - mae: 1631.1714\n",
      "Epoch 271: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1641.1848 - mse: 10928370.0000 - mae: 1641.4865 - val_loss: 1702.0798 - val_mse: 12211202.0000 - val_mae: 1702.3657 - lr: 2.4414e-07\n",
      "Epoch 272/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 1631.5017 - mse: 10817591.0000 - mae: 1631.8022\n",
      "Epoch 272: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1641.1509 - mse: 10928691.0000 - mae: 1641.4521 - val_loss: 1702.2012 - val_mse: 12214266.0000 - val_mae: 1702.4886 - lr: 2.4414e-07\n",
      "Epoch 273/500\n",
      "429/436 [============================>.] - ETA: 0s - loss: 1631.5099 - mse: 10817189.0000 - mae: 1631.8105\n",
      "Epoch 273: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1641.1594 - mse: 10928268.0000 - mae: 1641.4607 - val_loss: 1702.0721 - val_mse: 12210738.0000 - val_mae: 1702.3586 - lr: 2.4414e-07\n",
      "Epoch 274/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1640.5869 - mse: 10932489.0000 - mae: 1640.8887\n",
      "Epoch 274: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1641.1158 - mse: 10927925.0000 - mae: 1641.4178 - val_loss: 1702.0576 - val_mse: 12211403.0000 - val_mae: 1702.3446 - lr: 2.4414e-07\n",
      "Epoch 275/500\n",
      "436/436 [==============================] - ETA: 0s - loss: 1641.1234 - mse: 10927414.0000 - mae: 1641.4242\n",
      "Epoch 275: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1641.1234 - mse: 10927414.0000 - mae: 1641.4242 - val_loss: 1702.0586 - val_mse: 12209682.0000 - val_mae: 1702.3450 - lr: 2.4414e-07\n",
      "Epoch 276/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1634.4675 - mse: 10855890.0000 - mae: 1634.7683\n",
      "Epoch 276: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1640.7389 - mse: 10921883.0000 - mae: 1641.0399 - val_loss: 1702.0767 - val_mse: 12210758.0000 - val_mae: 1702.3625 - lr: 1.2207e-07\n",
      "Epoch 277/500\n",
      "435/436 [============================>.] - ETA: 0s - loss: 1640.1777 - mse: 10926729.0000 - mae: 1640.4806\n",
      "Epoch 277: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1640.7072 - mse: 10922170.0000 - mae: 1641.0101 - val_loss: 1702.1160 - val_mse: 12211996.0000 - val_mae: 1702.4033 - lr: 1.2207e-07\n",
      "Epoch 278/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1634.4341 - mse: 10856079.0000 - mae: 1634.7349\n",
      "Epoch 278: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1640.7076 - mse: 10922117.0000 - mae: 1641.0087 - val_loss: 1702.1483 - val_mse: 12211328.0000 - val_mae: 1702.4348 - lr: 1.2207e-07\n",
      "Epoch 279/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1638.4574 - mse: 10903460.0000 - mae: 1638.7577\n",
      "Epoch 279: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1640.6566 - mse: 10921773.0000 - mae: 1640.9573 - val_loss: 1702.1499 - val_mse: 12212375.0000 - val_mae: 1702.4368 - lr: 1.2207e-07\n",
      "Epoch 280/500\n",
      "432/436 [============================>.] - ETA: 0s - loss: 1630.3640 - mse: 10796486.0000 - mae: 1630.6643\n",
      "Epoch 280: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1640.6799 - mse: 10922284.0000 - mae: 1640.9807 - val_loss: 1702.0815 - val_mse: 12211329.0000 - val_mae: 1702.3680 - lr: 1.2207e-07\n",
      "Epoch 281/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1638.4292 - mse: 10903500.0000 - mae: 1638.7292\n",
      "Epoch 281: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1640.6285 - mse: 10921800.0000 - mae: 1640.9287 - val_loss: 1702.0400 - val_mse: 12209896.0000 - val_mae: 1702.3267 - lr: 1.2207e-07\n",
      "Epoch 282/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1630.5450 - mse: 10797469.0000 - mae: 1630.8452\n",
      "Epoch 282: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1640.6278 - mse: 10921906.0000 - mae: 1640.9282 - val_loss: 1702.0803 - val_mse: 12211243.0000 - val_mae: 1702.3663 - lr: 1.2207e-07\n",
      "Epoch 283/500\n",
      "433/436 [============================>.] - ETA: 0s - loss: 1634.3380 - mse: 10855647.0000 - mae: 1634.6377\n",
      "Epoch 283: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 3s 8ms/step - loss: 1640.6129 - mse: 10921693.0000 - mae: 1640.9127 - val_loss: 1702.1317 - val_mse: 12210677.0000 - val_mae: 1702.4185 - lr: 1.2207e-07\n",
      "Epoch 284/500\n",
      "434/436 [============================>.] - ETA: 0s - loss: 1638.3761 - mse: 10903218.0000 - mae: 1638.6765\n",
      "Epoch 284: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 4s 9ms/step - loss: 1640.5757 - mse: 10921527.0000 - mae: 1640.8761 - val_loss: 1702.1501 - val_mse: 12211876.0000 - val_mae: 1702.4362 - lr: 1.2207e-07\n",
      "Epoch 285/500\n",
      "431/436 [============================>.] - ETA: 0s - loss: 1630.4952 - mse: 10798122.0000 - mae: 1630.7954\n",
      "Epoch 285: val_loss did not improve from 1701.99121\n",
      "436/436 [==============================] - 4s 8ms/step - loss: 1640.5668 - mse: 10922346.0000 - mae: 1640.8672 - val_loss: 1702.0632 - val_mse: 12210479.0000 - val_mae: 1702.3501 - lr: 1.2207e-07\n"
     ]
    }
   ],
   "source": [
    "gru_history = gru_model.fit(train_data, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_gru])\n",
    "gru_history_ns = gru_model.fit(train_data_ns, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_gru_ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------lstm_history-------------\n",
      "lstm_history Validation Loss: 2057.786865234375\n",
      "lstm_history Validation MSE: 19070594.0\n",
      "lstm_history Validation MAE: 2058.07666015625\n",
      "-------------lstm_history_ns-------------\n",
      "lstm_history_ns Validation Loss: 2069.00537109375\n",
      "lstm_history_ns Validation MSE: 19343252.0\n",
      "lstm_history_ns Validation MAE: 2069.289306640625\n",
      "-------------rnn_history-------------\n",
      "rnn_history Validation Loss: 2152.904296875\n",
      "rnn_history Validation MSE: 20686086.0\n",
      "rnn_history Validation MAE: 2153.19287109375\n",
      "-------------rnn_history_ns-------------\n",
      "rnn_history_ns Validation Loss: 2155.010009765625\n",
      "rnn_history_ns Validation MSE: 20444336.0\n",
      "rnn_history_ns Validation MAE: 2155.302490234375\n",
      "-------------gru_history-------------\n",
      "gru_history Validation Loss: 2150.065673828125\n",
      "gru_history Validation MSE: 19680178.0\n",
      "gru_history Validation MAE: 2150.363037109375\n",
      "-------------gru_history_ns-------------\n",
      "gru_history_ns Validation Loss: 1701.9912109375\n",
      "gru_history_ns Validation MSE: 12209682.0\n",
      "gru_history_ns Validation MAE: 1702.2769775390625\n"
     ]
    }
   ],
   "source": [
    "# 종합 결과\n",
    "\n",
    "history_list = [\"lstm_history\", \"rnn_history\", \"gru_history\", \"lstm_history_ns\", \"rnn_history_ns\", \"gru_history_ns\"]\n",
    "def result(historys) :\n",
    "  for name, history in globals().items() :\n",
    "    if name in history_list :\n",
    "      print(f\"-------------{name}-------------\")\n",
    "      val_loss = min(history.history['val_loss'])\n",
    "      val_mse = min(history.history['val_mse'])\n",
    "      val_mae = min(history.history['val_mae'])\n",
    "      print(f\"{name} Validation Loss:\", val_loss)\n",
    "      print(f\"{name} Validation MSE:\", val_mse)\n",
    "      print(f\"{name} Validation MAE:\", val_mae)\n",
    "\n",
    "result(history_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/lstm_model_stne_only\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/lstm_model_stne_only\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/rnn_model_stne_only\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/rnn_model_stne_only\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/gru_model_stne_only\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/gru_model_stne_only\\assets\n"
     ]
    }
   ],
   "source": [
    "lstm_save_path = f\"./Models/lstm_model_stne_only\"\n",
    "rnn_save_path = f\"./Models/rnn_model_stne_only\"\n",
    "gru_save_path = f\"./Models/gru_model_stne_only\"\n",
    "\n",
    "save_model(lstm_model, lstm_save_path, overwrite=True)\n",
    "save_model(rnn_model, rnn_save_path, overwrite=True)\n",
    "save_model(gru_model, gru_save_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52578, 9)\n"
     ]
    }
   ],
   "source": [
    "St_NotEncode_Basic_data = pd.read_pickle(\"Basic_StandardScalar_final_data\")\n",
    "  \n",
    "print(St_NotEncode_Basic_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler Not Encode Basic Data\n",
      "(52578, 8) (52578,)\n",
      "(42062, 8) (10516, 8) (42062,) (10516,)\n",
      "=======================================\n"
     ]
    }
   ],
   "source": [
    "# Feature와 Label 분리하기\n",
    "def Feature_Label(datafile) :\n",
    "    X = datafile.iloc[:,:-1]\n",
    "    y = datafile.iloc[:,-1]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "print(\"StandardScaler Not Encode Basic Data\")\n",
    "SB_X, SB_y = Feature_Label(St_NotEncode_Basic_data)\n",
    "print(SB_X.shape, SB_y.shape)\n",
    "SB_X_train, SB_X_test, SB_y_train, SB_y_test = train_test_split(SB_X, SB_y, test_size=0.2, random_state=10, shuffle=False)\n",
    "print(SB_X_train.shape, SB_X_test.shape, SB_y_train.shape, SB_y_test.shape)\n",
    "print(\"=======================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = windowed_dataset(SB_y_train, WINDOW_SIZE, BATCH_SIZE, True)\n",
    "test_data = windowed_dataset(SB_y_test, WINDOW_SIZE, BATCH_SIZE, False)\n",
    "train_data_ns = windowed_dataset(SB_y_train, WINDOW_SIZE, BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 1)\n",
      "(32, 1)\n"
     ]
    }
   ],
   "source": [
    "for data in train_data.take(1) :\n",
    "  print(f'{data[0].shape}')\n",
    "  print(f'{data[1].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential([\n",
    "  Conv1D(filters=32, kernel_size=30,\n",
    "         padding='causal',\n",
    "         activation='relu',\n",
    "         input_shape=[WINDOW_SIZE, 1]),\n",
    "  LSTM(128, activation='tanh', return_sequences=True),  \n",
    "  LSTM(64, activation='tanh', return_sequences=True),\n",
    "  LSTM(32, activation='tanh'),\n",
    "  Dense(8, activation='relu'),\n",
    "  Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = Sequential([\n",
    "  Conv1D(filters=32, kernel_size=30,\n",
    "         padding='causal', \n",
    "         activation='relu',\n",
    "         input_shape=[WINDOW_SIZE, 1]),\n",
    "  SimpleRNN(128, activation='tanh', return_sequences=True),  \n",
    "  SimpleRNN(64, activation='tanh', return_sequences=True),\n",
    "  SimpleRNN(32, activation='tanh'),\n",
    "  Dense(8, activation='relu'),\n",
    "  Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = Sequential([\n",
    "  Conv1D(filters=32, kernel_size=30,\n",
    "         padding='causal',\n",
    "         activation='relu',\n",
    "         input_shape=[WINDOW_SIZE, 1]),\n",
    "  GRU(128, activation='tanh', return_sequences=True),  \n",
    "  GRU(64, activation='tanh', return_sequences=True),\n",
    "  GRU(32, activation='tanh'),\n",
    "  Dense(8, activation='relu'),\n",
    "  Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = Huber()\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "lstm_model.compile(loss=loss, optimizer=optimizer, metrics=['mse', 'mae'])\n",
    "rnn_model.compile(loss=loss, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), metrics=['mse', 'mae'])\n",
    "gru_model.compile(loss=loss, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10)\n",
    "            \n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "mc_lstm = ModelCheckpoint('base_stne_lstm_weight.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_lstm_ns = ModelCheckpoint('base_stne_lstm_weight_ns.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_rnn = ModelCheckpoint('base_stne_rnn_weight.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_rnn_ns = ModelCheckpoint('base_stne_rnn_weight_ns.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_gru = ModelCheckpoint('base_stne_gru_weight.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_gru_ns = ModelCheckpoint('base_stne_gru_weight_ns.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1311/Unknown - 36s 10ms/step - loss: 2.0998 - mse: 28.0403 - mae: 2.4257\n",
      "Epoch 1: val_loss improved from inf to 1.89622, saving model to base_stne_lstm_weight.h5\n",
      "1315/1315 [==============================] - 39s 12ms/step - loss: 2.0991 - mse: 28.0213 - mae: 2.4250 - val_loss: 1.8962 - val_mse: 15.1975 - val_mae: 2.2502 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 1.0017 - mse: 6.1665 - mae: 1.2983\n",
      "Epoch 2: val_loss improved from 1.89622 to 1.53876, saving model to base_stne_lstm_weight.h5\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 1.0026 - mse: 6.1743 - mae: 1.2993 - val_loss: 1.5388 - val_mse: 11.2410 - val_mae: 1.9197 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.9729 - mse: 5.9796 - mae: 1.2647\n",
      "Epoch 3: val_loss improved from 1.53876 to 1.52194, saving model to base_stne_lstm_weight.h5\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 0.9729 - mse: 5.9796 - mae: 1.2647 - val_loss: 1.5219 - val_mse: 11.0460 - val_mae: 1.8818 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.9613 - mse: 5.9361 - mae: 1.2506\n",
      "Epoch 4: val_loss improved from 1.52194 to 1.50095, saving model to base_stne_lstm_weight.h5\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.9620 - mse: 5.9414 - mae: 1.2513 - val_loss: 1.5009 - val_mse: 10.8846 - val_mae: 1.8348 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.9563 - mse: 5.8934 - mae: 1.2442\n",
      "Epoch 5: val_loss did not improve from 1.50095\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 0.9579 - mse: 5.9077 - mae: 1.2459 - val_loss: 1.6084 - val_mse: 12.5728 - val_mae: 1.9379 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.9420 - mse: 5.7983 - mae: 1.2276\n",
      "Epoch 6: val_loss improved from 1.50095 to 1.37214, saving model to base_stne_lstm_weight.h5\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.9428 - mse: 5.8034 - mae: 1.2285 - val_loss: 1.3721 - val_mse: 9.9162 - val_mae: 1.6974 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "1307/1315 [============================>.] - ETA: 0s - loss: 0.9412 - mse: 5.7785 - mae: 1.2252\n",
      "Epoch 7: val_loss did not improve from 1.37214\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.9440 - mse: 5.8026 - mae: 1.2283 - val_loss: 1.5141 - val_mse: 11.0292 - val_mae: 1.8399 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.9296 - mse: 5.7180 - mae: 1.2134\n",
      "Epoch 8: val_loss did not improve from 1.37214\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.9331 - mse: 5.7490 - mae: 1.2170 - val_loss: 1.4588 - val_mse: 10.5325 - val_mae: 1.7745 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.9243 - mse: 5.6994 - mae: 1.2056\n",
      "Epoch 9: val_loss did not improve from 1.37214\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.9243 - mse: 5.6996 - mae: 1.2057 - val_loss: 1.4893 - val_mse: 10.6629 - val_mae: 1.8016 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.9246 - mse: 5.6771 - mae: 1.2072\n",
      "Epoch 10: val_loss did not improve from 1.37214\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.9248 - mse: 5.6762 - mae: 1.2076 - val_loss: 1.4856 - val_mse: 10.9370 - val_mae: 1.8130 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.9323 - mse: 5.7739 - mae: 1.2157\n",
      "Epoch 11: val_loss did not improve from 1.37214\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.9322 - mse: 5.7729 - mae: 1.2156 - val_loss: 1.4640 - val_mse: 10.8483 - val_mae: 1.7803 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.9186 - mse: 5.6532 - mae: 1.1996\n",
      "Epoch 12: val_loss did not improve from 1.37214\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 0.9191 - mse: 5.6572 - mae: 1.2001 - val_loss: 1.5393 - val_mse: 11.0690 - val_mae: 1.8508 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.9153 - mse: 5.6277 - mae: 1.1966\n",
      "Epoch 13: val_loss did not improve from 1.37214\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.9187 - mse: 5.6691 - mae: 1.2001 - val_loss: 1.4997 - val_mse: 10.7044 - val_mae: 1.8191 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.9167 - mse: 5.6794 - mae: 1.1968\n",
      "Epoch 14: val_loss did not improve from 1.37214\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.9171 - mse: 5.6829 - mae: 1.1973 - val_loss: 1.4346 - val_mse: 10.5882 - val_mae: 1.7509 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.9112 - mse: 5.6034 - mae: 1.1922\n",
      "Epoch 15: val_loss did not improve from 1.37214\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.9112 - mse: 5.6034 - mae: 1.1922 - val_loss: 1.4844 - val_mse: 10.6609 - val_mae: 1.7974 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.9108 - mse: 5.6288 - mae: 1.1899\n",
      "Epoch 16: val_loss did not improve from 1.37214\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.9107 - mse: 5.6279 - mae: 1.1898 - val_loss: 1.5416 - val_mse: 10.9588 - val_mae: 1.8602 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8996 - mse: 5.5264 - mae: 1.1783\n",
      "Epoch 17: val_loss did not improve from 1.37214\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8999 - mse: 5.5291 - mae: 1.1786 - val_loss: 1.3839 - val_mse: 9.8237 - val_mae: 1.7026 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8907 - mse: 5.4780 - mae: 1.1688\n",
      "Epoch 18: val_loss improved from 1.37214 to 1.34227, saving model to base_stne_lstm_weight.h5\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 0.8922 - mse: 5.4888 - mae: 1.1705 - val_loss: 1.3423 - val_mse: 9.7007 - val_mae: 1.6549 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8879 - mse: 5.4376 - mae: 1.1669\n",
      "Epoch 19: val_loss did not improve from 1.34227\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8883 - mse: 5.4406 - mae: 1.1672 - val_loss: 1.4277 - val_mse: 10.1117 - val_mae: 1.7428 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8856 - mse: 5.4377 - mae: 1.1629\n",
      "Epoch 20: val_loss did not improve from 1.34227\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 0.8864 - mse: 5.4468 - mae: 1.1637 - val_loss: 1.4352 - val_mse: 10.3931 - val_mae: 1.7497 - lr: 5.0000e-04\n",
      "Epoch 21/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8854 - mse: 5.4418 - mae: 1.1626\n",
      "Epoch 21: val_loss did not improve from 1.34227\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8865 - mse: 5.4514 - mae: 1.1639 - val_loss: 1.3875 - val_mse: 9.8974 - val_mae: 1.7024 - lr: 5.0000e-04\n",
      "Epoch 22/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8881 - mse: 5.4562 - mae: 1.1653\n",
      "Epoch 22: val_loss improved from 1.34227 to 1.32328, saving model to base_stne_lstm_weight.h5\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8888 - mse: 5.4656 - mae: 1.1661 - val_loss: 1.3233 - val_mse: 9.5477 - val_mae: 1.6379 - lr: 5.0000e-04\n",
      "Epoch 23/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8795 - mse: 5.4140 - mae: 1.1560\n",
      "Epoch 23: val_loss did not improve from 1.32328\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8809 - mse: 5.4254 - mae: 1.1575 - val_loss: 1.4107 - val_mse: 10.0150 - val_mae: 1.7266 - lr: 5.0000e-04\n",
      "Epoch 24/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8861 - mse: 5.4538 - mae: 1.1635\n",
      "Epoch 24: val_loss improved from 1.32328 to 1.31865, saving model to base_stne_lstm_weight.h5\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8861 - mse: 5.4504 - mae: 1.1635 - val_loss: 1.3187 - val_mse: 9.4540 - val_mae: 1.6326 - lr: 5.0000e-04\n",
      "Epoch 25/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8839 - mse: 5.4429 - mae: 1.1607\n",
      "Epoch 25: val_loss did not improve from 1.31865\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8858 - mse: 5.4641 - mae: 1.1627 - val_loss: 1.3634 - val_mse: 9.6732 - val_mae: 1.6766 - lr: 5.0000e-04\n",
      "Epoch 26/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8857 - mse: 5.4418 - mae: 1.1624\n",
      "Epoch 26: val_loss did not improve from 1.31865\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8857 - mse: 5.4421 - mae: 1.1624 - val_loss: 1.3843 - val_mse: 9.9220 - val_mae: 1.6999 - lr: 5.0000e-04\n",
      "Epoch 27/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8851 - mse: 5.4430 - mae: 1.1617\n",
      "Epoch 27: val_loss did not improve from 1.31865\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8858 - mse: 5.4496 - mae: 1.1624 - val_loss: 1.3586 - val_mse: 9.7091 - val_mae: 1.6728 - lr: 5.0000e-04\n",
      "Epoch 28/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8823 - mse: 5.4003 - mae: 1.1593\n",
      "Epoch 28: val_loss did not improve from 1.31865\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8842 - mse: 5.4364 - mae: 1.1613 - val_loss: 1.4184 - val_mse: 10.0389 - val_mae: 1.7458 - lr: 5.0000e-04\n",
      "Epoch 29/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8794 - mse: 5.3987 - mae: 1.1559\n",
      "Epoch 29: val_loss did not improve from 1.31865\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8793 - mse: 5.3979 - mae: 1.1558 - val_loss: 1.3492 - val_mse: 9.6171 - val_mae: 1.6619 - lr: 5.0000e-04\n",
      "Epoch 30/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8811 - mse: 5.4128 - mae: 1.1577\n",
      "Epoch 30: val_loss did not improve from 1.31865\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8814 - mse: 5.4149 - mae: 1.1579 - val_loss: 1.3436 - val_mse: 9.6047 - val_mae: 1.6588 - lr: 5.0000e-04\n",
      "Epoch 31/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8785 - mse: 5.3997 - mae: 1.1546\n",
      "Epoch 31: val_loss did not improve from 1.31865\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8794 - mse: 5.4063 - mae: 1.1556 - val_loss: 1.3442 - val_mse: 9.4782 - val_mae: 1.6626 - lr: 5.0000e-04\n",
      "Epoch 32/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8811 - mse: 5.4047 - mae: 1.1575\n",
      "Epoch 32: val_loss did not improve from 1.31865\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8811 - mse: 5.4047 - mae: 1.1575 - val_loss: 1.4327 - val_mse: 10.1306 - val_mae: 1.7500 - lr: 5.0000e-04\n",
      "Epoch 33/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8782 - mse: 5.4214 - mae: 1.1534\n",
      "Epoch 33: val_loss did not improve from 1.31865\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8785 - mse: 5.4219 - mae: 1.1537 - val_loss: 1.3290 - val_mse: 9.5101 - val_mae: 1.6434 - lr: 5.0000e-04\n",
      "Epoch 34/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8752 - mse: 5.3612 - mae: 1.1511\n",
      "Epoch 34: val_loss did not improve from 1.31865\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8767 - mse: 5.3723 - mae: 1.1527 - val_loss: 1.3427 - val_mse: 9.6587 - val_mae: 1.6578 - lr: 5.0000e-04\n",
      "Epoch 35/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8780 - mse: 5.3389 - mae: 1.1546\n",
      "Epoch 35: val_loss did not improve from 1.31865\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8795 - mse: 5.3749 - mae: 1.1562 - val_loss: 1.3220 - val_mse: 9.3432 - val_mae: 1.6374 - lr: 2.5000e-04\n",
      "Epoch 36/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8746 - mse: 5.3552 - mae: 1.1514\n",
      "Epoch 36: val_loss did not improve from 1.31865\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8753 - mse: 5.3601 - mae: 1.1522 - val_loss: 1.3278 - val_mse: 9.3743 - val_mae: 1.6450 - lr: 2.5000e-04\n",
      "Epoch 37/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8726 - mse: 5.3477 - mae: 1.1484\n",
      "Epoch 37: val_loss did not improve from 1.31865\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8726 - mse: 5.3513 - mae: 1.1485 - val_loss: 1.3193 - val_mse: 9.3476 - val_mae: 1.6352 - lr: 2.5000e-04\n",
      "Epoch 38/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8692 - mse: 5.3203 - mae: 1.1448\n",
      "Epoch 38: val_loss improved from 1.31865 to 1.30910, saving model to base_stne_lstm_weight.h5\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 0.8721 - mse: 5.3480 - mae: 1.1480 - val_loss: 1.3091 - val_mse: 9.2249 - val_mae: 1.6255 - lr: 2.5000e-04\n",
      "Epoch 39/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8715 - mse: 5.3439 - mae: 1.1471\n",
      "Epoch 39: val_loss did not improve from 1.30910\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8715 - mse: 5.3439 - mae: 1.1471 - val_loss: 1.3108 - val_mse: 9.3393 - val_mae: 1.6253 - lr: 2.5000e-04\n",
      "Epoch 40/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8695 - mse: 5.3315 - mae: 1.1447\n",
      "Epoch 40: val_loss did not improve from 1.30910\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8713 - mse: 5.3514 - mae: 1.1467 - val_loss: 1.3224 - val_mse: 9.3662 - val_mae: 1.6399 - lr: 2.5000e-04\n",
      "Epoch 41/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8684 - mse: 5.3089 - mae: 1.1444\n",
      "Epoch 41: val_loss improved from 1.30910 to 1.30236, saving model to base_stne_lstm_weight.h5\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8703 - mse: 5.3307 - mae: 1.1463 - val_loss: 1.3024 - val_mse: 9.3372 - val_mae: 1.6167 - lr: 2.5000e-04\n",
      "Epoch 42/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8684 - mse: 5.3078 - mae: 1.1441\n",
      "Epoch 42: val_loss did not improve from 1.30236\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8704 - mse: 5.3283 - mae: 1.1463 - val_loss: 1.3250 - val_mse: 9.3586 - val_mae: 1.6417 - lr: 2.5000e-04\n",
      "Epoch 43/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8671 - mse: 5.3184 - mae: 1.1424\n",
      "Epoch 43: val_loss did not improve from 1.30236\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8678 - mse: 5.3266 - mae: 1.1431 - val_loss: 1.3337 - val_mse: 9.4695 - val_mae: 1.6480 - lr: 2.5000e-04\n",
      "Epoch 44/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8691 - mse: 5.3250 - mae: 1.1447\n",
      "Epoch 44: val_loss did not improve from 1.30236\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8703 - mse: 5.3348 - mae: 1.1459 - val_loss: 1.3068 - val_mse: 9.3243 - val_mae: 1.6201 - lr: 2.5000e-04\n",
      "Epoch 45/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8685 - mse: 5.3170 - mae: 1.1438\n",
      "Epoch 45: val_loss did not improve from 1.30236\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8686 - mse: 5.3172 - mae: 1.1439 - val_loss: 1.3191 - val_mse: 9.3707 - val_mae: 1.6344 - lr: 2.5000e-04\n",
      "Epoch 46/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8692 - mse: 5.3258 - mae: 1.1455\n",
      "Epoch 46: val_loss improved from 1.30236 to 1.29593, saving model to base_stne_lstm_weight.h5\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8704 - mse: 5.3371 - mae: 1.1468 - val_loss: 1.2959 - val_mse: 9.2586 - val_mae: 1.6119 - lr: 2.5000e-04\n",
      "Epoch 47/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8706 - mse: 5.3273 - mae: 1.1456\n",
      "Epoch 47: val_loss did not improve from 1.29593\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8707 - mse: 5.3289 - mae: 1.1457 - val_loss: 1.3269 - val_mse: 9.3838 - val_mae: 1.6432 - lr: 2.5000e-04\n",
      "Epoch 48/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8704 - mse: 5.3276 - mae: 1.1463\n",
      "Epoch 48: val_loss did not improve from 1.29593\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8709 - mse: 5.3337 - mae: 1.1467 - val_loss: 1.2991 - val_mse: 9.2652 - val_mae: 1.6133 - lr: 2.5000e-04\n",
      "Epoch 49/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8646 - mse: 5.2983 - mae: 1.1401\n",
      "Epoch 49: val_loss did not improve from 1.29593\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8646 - mse: 5.2983 - mae: 1.1401 - val_loss: 1.3047 - val_mse: 9.2328 - val_mae: 1.6194 - lr: 2.5000e-04\n",
      "Epoch 50/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8635 - mse: 5.2892 - mae: 1.1386\n",
      "Epoch 50: val_loss did not improve from 1.29593\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8654 - mse: 5.3077 - mae: 1.1407 - val_loss: 1.3280 - val_mse: 9.3541 - val_mae: 1.6440 - lr: 2.5000e-04\n",
      "Epoch 51/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8646 - mse: 5.2814 - mae: 1.1403\n",
      "Epoch 51: val_loss did not improve from 1.29593\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8656 - mse: 5.2966 - mae: 1.1414 - val_loss: 1.3186 - val_mse: 9.3683 - val_mae: 1.6332 - lr: 2.5000e-04\n",
      "Epoch 52/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8624 - mse: 5.2758 - mae: 1.1370\n",
      "Epoch 52: val_loss did not improve from 1.29593\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8646 - mse: 5.2985 - mae: 1.1394 - val_loss: 1.3171 - val_mse: 9.3836 - val_mae: 1.6321 - lr: 2.5000e-04\n",
      "Epoch 53/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8636 - mse: 5.2893 - mae: 1.1392\n",
      "Epoch 53: val_loss did not improve from 1.29593\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8644 - mse: 5.2964 - mae: 1.1400 - val_loss: 1.3007 - val_mse: 9.2352 - val_mae: 1.6157 - lr: 2.5000e-04\n",
      "Epoch 54/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8605 - mse: 5.2610 - mae: 1.1351\n",
      "Epoch 54: val_loss did not improve from 1.29593\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8624 - mse: 5.2843 - mae: 1.1372 - val_loss: 1.3396 - val_mse: 9.4785 - val_mae: 1.6567 - lr: 2.5000e-04\n",
      "Epoch 55/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8630 - mse: 5.2931 - mae: 1.1379\n",
      "Epoch 55: val_loss did not improve from 1.29593\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8630 - mse: 5.2931 - mae: 1.1379 - val_loss: 1.3595 - val_mse: 9.5270 - val_mae: 1.6780 - lr: 2.5000e-04\n",
      "Epoch 56/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8638 - mse: 5.2991 - mae: 1.1388\n",
      "Epoch 56: val_loss did not improve from 1.29593\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8642 - mse: 5.2996 - mae: 1.1392 - val_loss: 1.3299 - val_mse: 9.4550 - val_mae: 1.6457 - lr: 2.5000e-04\n",
      "Epoch 57/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8688 - mse: 5.2999 - mae: 1.1457\n",
      "Epoch 57: val_loss did not improve from 1.29593\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8702 - mse: 5.3126 - mae: 1.1471 - val_loss: 1.3053 - val_mse: 9.2537 - val_mae: 1.6181 - lr: 1.2500e-04\n",
      "Epoch 58/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8657 - mse: 5.2943 - mae: 1.1422\n",
      "Epoch 58: val_loss did not improve from 1.29593\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8657 - mse: 5.2943 - mae: 1.1422 - val_loss: 1.3028 - val_mse: 9.2689 - val_mae: 1.6145 - lr: 1.2500e-04\n",
      "Epoch 59/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8637 - mse: 5.2696 - mae: 1.1406\n",
      "Epoch 59: val_loss improved from 1.29593 to 1.29006, saving model to base_stne_lstm_weight.h5\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8661 - mse: 5.2892 - mae: 1.1432 - val_loss: 1.2901 - val_mse: 9.1972 - val_mae: 1.6000 - lr: 1.2500e-04\n",
      "Epoch 60/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8659 - mse: 5.3022 - mae: 1.1422\n",
      "Epoch 60: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8660 - mse: 5.3022 - mae: 1.1422 - val_loss: 1.3075 - val_mse: 9.2492 - val_mae: 1.6197 - lr: 1.2500e-04\n",
      "Epoch 61/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8643 - mse: 5.2738 - mae: 1.1412\n",
      "Epoch 61: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8658 - mse: 5.2886 - mae: 1.1428 - val_loss: 1.3064 - val_mse: 9.2667 - val_mae: 1.6173 - lr: 1.2500e-04\n",
      "Epoch 62/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8632 - mse: 5.2670 - mae: 1.1396\n",
      "Epoch 62: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8646 - mse: 5.2860 - mae: 1.1410 - val_loss: 1.3133 - val_mse: 9.3308 - val_mae: 1.6255 - lr: 1.2500e-04\n",
      "Epoch 63/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8621 - mse: 5.2558 - mae: 1.1389\n",
      "Epoch 63: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8635 - mse: 5.2632 - mae: 1.1404 - val_loss: 1.3110 - val_mse: 9.2935 - val_mae: 1.6257 - lr: 1.2500e-04\n",
      "Epoch 64/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8645 - mse: 5.2799 - mae: 1.1414\n",
      "Epoch 64: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8644 - mse: 5.2792 - mae: 1.1414 - val_loss: 1.3131 - val_mse: 9.3432 - val_mae: 1.6276 - lr: 1.2500e-04\n",
      "Epoch 65/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8632 - mse: 5.2832 - mae: 1.1390\n",
      "Epoch 65: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8635 - mse: 5.2862 - mae: 1.1393 - val_loss: 1.3097 - val_mse: 9.2878 - val_mae: 1.6206 - lr: 1.2500e-04\n",
      "Epoch 66/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8606 - mse: 5.2607 - mae: 1.1361\n",
      "Epoch 66: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8621 - mse: 5.2870 - mae: 1.1377 - val_loss: 1.2925 - val_mse: 9.2400 - val_mae: 1.6048 - lr: 1.2500e-04\n",
      "Epoch 67/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8611 - mse: 5.2622 - mae: 1.1371\n",
      "Epoch 67: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8611 - mse: 5.2622 - mae: 1.1371 - val_loss: 1.3192 - val_mse: 9.4189 - val_mae: 1.6309 - lr: 1.2500e-04\n",
      "Epoch 68/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8612 - mse: 5.2663 - mae: 1.1370\n",
      "Epoch 68: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8612 - mse: 5.2659 - mae: 1.1370 - val_loss: 1.3176 - val_mse: 9.3558 - val_mae: 1.6307 - lr: 1.2500e-04\n",
      "Epoch 69/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8589 - mse: 5.2384 - mae: 1.1348\n",
      "Epoch 69: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8617 - mse: 5.2678 - mae: 1.1378 - val_loss: 1.3070 - val_mse: 9.3122 - val_mae: 1.6219 - lr: 1.2500e-04\n",
      "Epoch 70/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8711 - mse: 5.2913 - mae: 1.1491\n",
      "Epoch 70: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8716 - mse: 5.2959 - mae: 1.1497 - val_loss: 1.2974 - val_mse: 9.2181 - val_mae: 1.6078 - lr: 6.2500e-05\n",
      "Epoch 71/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8682 - mse: 5.2762 - mae: 1.1459\n",
      "Epoch 71: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 0.8695 - mse: 5.2892 - mae: 1.1472 - val_loss: 1.2975 - val_mse: 9.2345 - val_mae: 1.6082 - lr: 6.2500e-05\n",
      "Epoch 72/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8673 - mse: 5.2713 - mae: 1.1449\n",
      "Epoch 72: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 0.8682 - mse: 5.2805 - mae: 1.1459 - val_loss: 1.2991 - val_mse: 9.2239 - val_mae: 1.6098 - lr: 6.2500e-05\n",
      "Epoch 73/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8670 - mse: 5.2616 - mae: 1.1442\n",
      "Epoch 73: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8684 - mse: 5.2777 - mae: 1.1458 - val_loss: 1.3059 - val_mse: 9.2709 - val_mae: 1.6163 - lr: 6.2500e-05\n",
      "Epoch 74/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8667 - mse: 5.2678 - mae: 1.1439\n",
      "Epoch 74: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8682 - mse: 5.2778 - mae: 1.1454 - val_loss: 1.3001 - val_mse: 9.2346 - val_mae: 1.6102 - lr: 6.2500e-05\n",
      "Epoch 75/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8652 - mse: 5.2488 - mae: 1.1423\n",
      "Epoch 75: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8674 - mse: 5.2728 - mae: 1.1447 - val_loss: 1.2991 - val_mse: 9.2251 - val_mae: 1.6092 - lr: 6.2500e-05\n",
      "Epoch 76/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8670 - mse: 5.2739 - mae: 1.1441\n",
      "Epoch 76: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8670 - mse: 5.2739 - mae: 1.1441 - val_loss: 1.2988 - val_mse: 9.2374 - val_mae: 1.6088 - lr: 6.2500e-05\n",
      "Epoch 77/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8650 - mse: 5.2568 - mae: 1.1421\n",
      "Epoch 77: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8666 - mse: 5.2754 - mae: 1.1437 - val_loss: 1.2986 - val_mse: 9.2391 - val_mae: 1.6086 - lr: 6.2500e-05\n",
      "Epoch 78/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8648 - mse: 5.2625 - mae: 1.1419\n",
      "Epoch 78: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8660 - mse: 5.2742 - mae: 1.1431 - val_loss: 1.2961 - val_mse: 9.2260 - val_mae: 1.6060 - lr: 6.2500e-05\n",
      "Epoch 79/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8650 - mse: 5.2576 - mae: 1.1421\n",
      "Epoch 79: val_loss did not improve from 1.29006\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8667 - mse: 5.2762 - mae: 1.1438 - val_loss: 1.3064 - val_mse: 9.2613 - val_mae: 1.6168 - lr: 6.2500e-05\n",
      "Epoch 1/500\n",
      "   1307/Unknown - 10s 7ms/step - loss: 0.8701 - mse: 5.2703 - mae: 1.1482\n",
      "Epoch 1: val_loss improved from inf to 1.29937, saving model to base_stne_lstm_weight_ns.h5\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8712 - mse: 5.2802 - mae: 1.1493 - val_loss: 1.2994 - val_mse: 9.2520 - val_mae: 1.6082 - lr: 3.1250e-05\n",
      "Epoch 2/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8691 - mse: 5.2732 - mae: 1.1462\n",
      "Epoch 2: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8688 - mse: 5.2703 - mae: 1.1459 - val_loss: 1.3003 - val_mse: 9.2540 - val_mae: 1.6092 - lr: 3.1250e-05\n",
      "Epoch 3/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8678 - mse: 5.2664 - mae: 1.1448\n",
      "Epoch 3: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8678 - mse: 5.2664 - mae: 1.1448 - val_loss: 1.3008 - val_mse: 9.2548 - val_mae: 1.6098 - lr: 3.1250e-05\n",
      "Epoch 4/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8676 - mse: 5.2673 - mae: 1.1444\n",
      "Epoch 4: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8673 - mse: 5.2645 - mae: 1.1442 - val_loss: 1.3012 - val_mse: 9.2551 - val_mae: 1.6101 - lr: 3.1250e-05\n",
      "Epoch 5/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8671 - mse: 5.2661 - mae: 1.1439\n",
      "Epoch 5: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8670 - mse: 5.2631 - mae: 1.1438 - val_loss: 1.3014 - val_mse: 9.2552 - val_mae: 1.6104 - lr: 3.1250e-05\n",
      "Epoch 6/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8671 - mse: 5.2651 - mae: 1.1439\n",
      "Epoch 6: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8667 - mse: 5.2620 - mae: 1.1435 - val_loss: 1.3017 - val_mse: 9.2561 - val_mae: 1.6108 - lr: 3.1250e-05\n",
      "Epoch 7/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8666 - mse: 5.2621 - mae: 1.1434\n",
      "Epoch 7: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8665 - mse: 5.2610 - mae: 1.1432 - val_loss: 1.3020 - val_mse: 9.2568 - val_mae: 1.6110 - lr: 3.1250e-05\n",
      "Epoch 8/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8663 - mse: 5.2600 - mae: 1.1430\n",
      "Epoch 8: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 0.8663 - mse: 5.2600 - mae: 1.1430 - val_loss: 1.3023 - val_mse: 9.2582 - val_mae: 1.6114 - lr: 3.1250e-05\n",
      "Epoch 9/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8663 - mse: 5.2618 - mae: 1.1429\n",
      "Epoch 9: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8661 - mse: 5.2591 - mae: 1.1427 - val_loss: 1.3025 - val_mse: 9.2594 - val_mae: 1.6117 - lr: 3.1250e-05\n",
      "Epoch 10/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8662 - mse: 5.2612 - mae: 1.1428\n",
      "Epoch 10: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8659 - mse: 5.2581 - mae: 1.1425 - val_loss: 1.3028 - val_mse: 9.2607 - val_mae: 1.6119 - lr: 3.1250e-05\n",
      "Epoch 11/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8660 - mse: 5.2604 - mae: 1.1426\n",
      "Epoch 11: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8657 - mse: 5.2572 - mae: 1.1423 - val_loss: 1.3030 - val_mse: 9.2621 - val_mae: 1.6122 - lr: 3.1250e-05\n",
      "Epoch 12/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8810 - mse: 5.3273 - mae: 1.1600\n",
      "Epoch 12: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8810 - mse: 5.3273 - mae: 1.1600 - val_loss: 1.3124 - val_mse: 9.3688 - val_mae: 1.6197 - lr: 1.5625e-05\n",
      "Epoch 13/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8791 - mse: 5.3194 - mae: 1.1571\n",
      "Epoch 13: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8791 - mse: 5.3194 - mae: 1.1571 - val_loss: 1.3140 - val_mse: 9.3897 - val_mae: 1.6212 - lr: 1.5625e-05\n",
      "Epoch 14/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8783 - mse: 5.3173 - mae: 1.1560\n",
      "Epoch 14: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8781 - mse: 5.3162 - mae: 1.1558 - val_loss: 1.3147 - val_mse: 9.3965 - val_mae: 1.6218 - lr: 1.5625e-05\n",
      "Epoch 15/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8779 - mse: 5.3177 - mae: 1.1555\n",
      "Epoch 15: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8775 - mse: 5.3145 - mae: 1.1551 - val_loss: 1.3148 - val_mse: 9.3987 - val_mae: 1.6219 - lr: 1.5625e-05\n",
      "Epoch 16/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8773 - mse: 5.3168 - mae: 1.1548\n",
      "Epoch 16: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8771 - mse: 5.3135 - mae: 1.1547 - val_loss: 1.3149 - val_mse: 9.3996 - val_mae: 1.6220 - lr: 1.5625e-05\n",
      "Epoch 17/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8766 - mse: 5.3106 - mae: 1.1540\n",
      "Epoch 17: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8768 - mse: 5.3126 - mae: 1.1543 - val_loss: 1.3149 - val_mse: 9.4004 - val_mae: 1.6220 - lr: 1.5625e-05\n",
      "Epoch 18/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8770 - mse: 5.3165 - mae: 1.1544\n",
      "Epoch 18: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8766 - mse: 5.3119 - mae: 1.1540 - val_loss: 1.3149 - val_mse: 9.4010 - val_mae: 1.6220 - lr: 1.5625e-05\n",
      "Epoch 19/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8764 - mse: 5.3113 - mae: 1.1537\n",
      "Epoch 19: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 0.8764 - mse: 5.3113 - mae: 1.1537 - val_loss: 1.3149 - val_mse: 9.4016 - val_mae: 1.6220 - lr: 1.5625e-05\n",
      "Epoch 20/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8765 - mse: 5.3134 - mae: 1.1538\n",
      "Epoch 20: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8762 - mse: 5.3107 - mae: 1.1535 - val_loss: 1.3149 - val_mse: 9.4021 - val_mae: 1.6220 - lr: 1.5625e-05\n",
      "Epoch 21/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8763 - mse: 5.3128 - mae: 1.1535\n",
      "Epoch 21: val_loss did not improve from 1.29937\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8760 - mse: 5.3102 - mae: 1.1533 - val_loss: 1.3149 - val_mse: 9.4029 - val_mae: 1.6220 - lr: 1.5625e-05\n"
     ]
    }
   ],
   "source": [
    "lstm_history = lstm_model.fit(train_data, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_lstm])\n",
    "lstm_history_ns = lstm_model.fit(train_data_ns, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_lstm_ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1306/Unknown - 10s 4ms/step - loss: 2.1244 - mse: 27.4820 - mae: 2.4669\n",
      "Epoch 1: val_loss improved from inf to 1.90630, saving model to base_stne_rnn_weight.h5\n",
      "1315/1315 [==============================] - 11s 5ms/step - loss: 2.1210 - mse: 27.3790 - mae: 2.4636 - val_loss: 1.9063 - val_mse: 15.3951 - val_mae: 2.3099 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "1303/1315 [============================>.] - ETA: 0s - loss: 1.0212 - mse: 6.3036 - mae: 1.3363\n",
      "Epoch 2: val_loss improved from 1.90630 to 1.88747, saving model to base_stne_rnn_weight.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 1.0238 - mse: 6.3458 - mae: 1.3389 - val_loss: 1.8875 - val_mse: 15.2383 - val_mae: 2.2271 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.9927 - mse: 6.1130 - mae: 1.2985\n",
      "Epoch 3: val_loss improved from 1.88747 to 1.65241, saving model to base_stne_rnn_weight.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9967 - mse: 6.1504 - mae: 1.3027 - val_loss: 1.6524 - val_mse: 12.6733 - val_mae: 2.0038 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.9829 - mse: 6.0593 - mae: 1.2852\n",
      "Epoch 4: val_loss improved from 1.65241 to 1.63779, saving model to base_stne_rnn_weight.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9840 - mse: 6.0711 - mae: 1.2863 - val_loss: 1.6378 - val_mse: 12.4636 - val_mae: 1.9752 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.9834 - mse: 6.0973 - mae: 1.2865\n",
      "Epoch 5: val_loss improved from 1.63779 to 1.43415, saving model to base_stne_rnn_weight.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.9834 - mse: 6.0973 - mae: 1.2865 - val_loss: 1.4341 - val_mse: 10.6424 - val_mae: 1.7577 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "1298/1315 [============================>.] - ETA: 0s - loss: 0.9733 - mse: 6.0038 - mae: 1.2750\n",
      "Epoch 6: val_loss did not improve from 1.43415\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9790 - mse: 6.0491 - mae: 1.2811 - val_loss: 1.7206 - val_mse: 13.3761 - val_mae: 2.0387 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.9721 - mse: 6.0135 - mae: 1.2694\n",
      "Epoch 7: val_loss did not improve from 1.43415\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9756 - mse: 6.0554 - mae: 1.2731 - val_loss: 1.6784 - val_mse: 12.5775 - val_mae: 2.0214 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.9734 - mse: 6.0258 - mae: 1.2718\n",
      "Epoch 8: val_loss did not improve from 1.43415\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9746 - mse: 6.0348 - mae: 1.2730 - val_loss: 1.5070 - val_mse: 10.9578 - val_mae: 1.8284 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.9683 - mse: 5.9703 - mae: 1.2658\n",
      "Epoch 9: val_loss did not improve from 1.43415\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9706 - mse: 5.9946 - mae: 1.2684 - val_loss: 1.5010 - val_mse: 11.0916 - val_mae: 1.8079 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.9571 - mse: 5.9255 - mae: 1.2499\n",
      "Epoch 10: val_loss did not improve from 1.43415\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9586 - mse: 5.9389 - mae: 1.2516 - val_loss: 1.4843 - val_mse: 10.9020 - val_mae: 1.7995 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "1300/1315 [============================>.] - ETA: 0s - loss: 0.9611 - mse: 5.9544 - mae: 1.2553\n",
      "Epoch 11: val_loss did not improve from 1.43415\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9659 - mse: 6.0011 - mae: 1.2603 - val_loss: 1.5706 - val_mse: 11.9860 - val_mae: 1.9030 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.9600 - mse: 5.9355 - mae: 1.2546\n",
      "Epoch 12: val_loss did not improve from 1.43415\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9646 - mse: 5.9954 - mae: 1.2594 - val_loss: 1.5633 - val_mse: 11.4568 - val_mae: 1.9176 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.9553 - mse: 5.9558 - mae: 1.2495\n",
      "Epoch 13: val_loss did not improve from 1.43415\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9555 - mse: 5.9589 - mae: 1.2497 - val_loss: 1.5730 - val_mse: 11.8979 - val_mae: 1.9438 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.9572 - mse: 5.9514 - mae: 1.2540\n",
      "Epoch 14: val_loss did not improve from 1.43415\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.9583 - mse: 5.9589 - mae: 1.2551 - val_loss: 1.5652 - val_mse: 11.6994 - val_mae: 1.8739 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.9642 - mse: 5.9973 - mae: 1.2593\n",
      "Epoch 15: val_loss did not improve from 1.43415\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.9662 - mse: 6.0266 - mae: 1.2614 - val_loss: 1.4672 - val_mse: 10.6387 - val_mae: 1.7999 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.9188 - mse: 5.6718 - mae: 1.2047\n",
      "Epoch 16: val_loss did not improve from 1.43415\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.9188 - mse: 5.6727 - mae: 1.2047 - val_loss: 1.4702 - val_mse: 10.4489 - val_mae: 1.7783 - lr: 5.0000e-04\n",
      "Epoch 17/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.9132 - mse: 5.6302 - mae: 1.1981\n",
      "Epoch 17: val_loss improved from 1.43415 to 1.43299, saving model to base_stne_rnn_weight.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9133 - mse: 5.6329 - mae: 1.1983 - val_loss: 1.4330 - val_mse: 10.5346 - val_mae: 1.7453 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.9116 - mse: 5.6404 - mae: 1.1974\n",
      "Epoch 18: val_loss improved from 1.43299 to 1.39177, saving model to base_stne_rnn_weight.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9124 - mse: 5.6481 - mae: 1.1983 - val_loss: 1.3918 - val_mse: 10.1578 - val_mae: 1.7029 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8974 - mse: 5.5192 - mae: 1.1818\n",
      "Epoch 19: val_loss did not improve from 1.39177\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9030 - mse: 5.5697 - mae: 1.1875 - val_loss: 1.4739 - val_mse: 10.7308 - val_mae: 1.7771 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.9063 - mse: 5.5996 - mae: 1.1916\n",
      "Epoch 20: val_loss did not improve from 1.39177\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9068 - mse: 5.6056 - mae: 1.1922 - val_loss: 1.4230 - val_mse: 10.1800 - val_mae: 1.7444 - lr: 5.0000e-04\n",
      "Epoch 21/500\n",
      "1302/1315 [============================>.] - ETA: 0s - loss: 0.9027 - mse: 5.5195 - mae: 1.1883\n",
      "Epoch 21: val_loss did not improve from 1.39177\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9068 - mse: 5.5669 - mae: 1.1924 - val_loss: 1.4184 - val_mse: 10.3026 - val_mae: 1.7304 - lr: 5.0000e-04\n",
      "Epoch 22/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8991 - mse: 5.5508 - mae: 1.1829\n",
      "Epoch 22: val_loss did not improve from 1.39177\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9012 - mse: 5.5864 - mae: 1.1851 - val_loss: 1.5033 - val_mse: 10.5085 - val_mae: 1.8691 - lr: 5.0000e-04\n",
      "Epoch 23/500\n",
      "1300/1315 [============================>.] - ETA: 0s - loss: 0.8968 - mse: 5.5276 - mae: 1.1814\n",
      "Epoch 23: val_loss did not improve from 1.39177\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8996 - mse: 5.5488 - mae: 1.1845 - val_loss: 1.4510 - val_mse: 10.3912 - val_mae: 1.7695 - lr: 5.0000e-04\n",
      "Epoch 24/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.9051 - mse: 5.5846 - mae: 1.1910\n",
      "Epoch 24: val_loss did not improve from 1.39177\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.9057 - mse: 5.5885 - mae: 1.1917 - val_loss: 1.4171 - val_mse: 10.2710 - val_mae: 1.7231 - lr: 5.0000e-04\n",
      "Epoch 25/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.9004 - mse: 5.5265 - mae: 1.1845\n",
      "Epoch 25: val_loss improved from 1.39177 to 1.37816, saving model to base_stne_rnn_weight.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9014 - mse: 5.5371 - mae: 1.1856 - val_loss: 1.3782 - val_mse: 9.9753 - val_mae: 1.7043 - lr: 5.0000e-04\n",
      "Epoch 26/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.9016 - mse: 5.5459 - mae: 1.1852\n",
      "Epoch 26: val_loss did not improve from 1.37816\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9017 - mse: 5.5460 - mae: 1.1853 - val_loss: 1.4158 - val_mse: 10.3164 - val_mae: 1.7301 - lr: 5.0000e-04\n",
      "Epoch 27/500\n",
      "1300/1315 [============================>.] - ETA: 0s - loss: 0.9014 - mse: 5.5360 - mae: 1.1861\n",
      "Epoch 27: val_loss did not improve from 1.37816\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9049 - mse: 5.5662 - mae: 1.1897 - val_loss: 1.4450 - val_mse: 10.3190 - val_mae: 1.7688 - lr: 5.0000e-04\n",
      "Epoch 28/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8989 - mse: 5.5306 - mae: 1.1821\n",
      "Epoch 28: val_loss did not improve from 1.37816\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8989 - mse: 5.5303 - mae: 1.1821 - val_loss: 1.3932 - val_mse: 10.1379 - val_mae: 1.7029 - lr: 5.0000e-04\n",
      "Epoch 29/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.9008 - mse: 5.5525 - mae: 1.1854\n",
      "Epoch 29: val_loss did not improve from 1.37816\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.9009 - mse: 5.5530 - mae: 1.1855 - val_loss: 1.4234 - val_mse: 10.3343 - val_mae: 1.7393 - lr: 5.0000e-04\n",
      "Epoch 30/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8938 - mse: 5.4914 - mae: 1.1772\n",
      "Epoch 30: val_loss did not improve from 1.37816\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8967 - mse: 5.5163 - mae: 1.1803 - val_loss: 1.4236 - val_mse: 10.1781 - val_mae: 1.7461 - lr: 5.0000e-04\n",
      "Epoch 31/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8904 - mse: 5.4787 - mae: 1.1732\n",
      "Epoch 31: val_loss did not improve from 1.37816\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8937 - mse: 5.5099 - mae: 1.1768 - val_loss: 1.4478 - val_mse: 10.2437 - val_mae: 1.7848 - lr: 5.0000e-04\n",
      "Epoch 32/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8928 - mse: 5.4899 - mae: 1.1772\n",
      "Epoch 32: val_loss did not improve from 1.37816\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8960 - mse: 5.5310 - mae: 1.1805 - val_loss: 1.4365 - val_mse: 10.5369 - val_mae: 1.7586 - lr: 5.0000e-04\n",
      "Epoch 33/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8955 - mse: 5.5062 - mae: 1.1814\n",
      "Epoch 33: val_loss did not improve from 1.37816\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8968 - mse: 5.5279 - mae: 1.1827 - val_loss: 1.4228 - val_mse: 10.1273 - val_mae: 1.7363 - lr: 5.0000e-04\n",
      "Epoch 34/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.9009 - mse: 5.5439 - mae: 1.1848\n",
      "Epoch 34: val_loss did not improve from 1.37816\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.9009 - mse: 5.5439 - mae: 1.1848 - val_loss: 1.3982 - val_mse: 10.0450 - val_mae: 1.7332 - lr: 5.0000e-04\n",
      "Epoch 35/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8909 - mse: 5.4643 - mae: 1.1742\n",
      "Epoch 35: val_loss did not improve from 1.37816\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8942 - mse: 5.4958 - mae: 1.1777 - val_loss: 1.3883 - val_mse: 9.9762 - val_mae: 1.7273 - lr: 5.0000e-04\n",
      "Epoch 36/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8818 - mse: 5.4120 - mae: 1.1618\n",
      "Epoch 36: val_loss did not improve from 1.37816\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8841 - mse: 5.4389 - mae: 1.1642 - val_loss: 1.3928 - val_mse: 9.8692 - val_mae: 1.7127 - lr: 2.5000e-04\n",
      "Epoch 37/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8776 - mse: 5.3928 - mae: 1.1576\n",
      "Epoch 37: val_loss did not improve from 1.37816\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8803 - mse: 5.4266 - mae: 1.1604 - val_loss: 1.4007 - val_mse: 9.9301 - val_mae: 1.7348 - lr: 2.5000e-04\n",
      "Epoch 38/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8768 - mse: 5.3892 - mae: 1.1558\n",
      "Epoch 38: val_loss did not improve from 1.37816\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8788 - mse: 5.4062 - mae: 1.1580 - val_loss: 1.3830 - val_mse: 9.8881 - val_mae: 1.7005 - lr: 2.5000e-04\n",
      "Epoch 39/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8764 - mse: 5.4012 - mae: 1.1556\n",
      "Epoch 39: val_loss did not improve from 1.37816\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8772 - mse: 5.4079 - mae: 1.1565 - val_loss: 1.4051 - val_mse: 9.9649 - val_mae: 1.7293 - lr: 2.5000e-04\n",
      "Epoch 40/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8720 - mse: 5.3472 - mae: 1.1501\n",
      "Epoch 40: val_loss did not improve from 1.37816\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8761 - mse: 5.3890 - mae: 1.1543 - val_loss: 1.4095 - val_mse: 10.0226 - val_mae: 1.7133 - lr: 2.5000e-04\n",
      "Epoch 41/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8712 - mse: 5.3568 - mae: 1.1502\n",
      "Epoch 41: val_loss did not improve from 1.37816\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8748 - mse: 5.3994 - mae: 1.1540 - val_loss: 1.4394 - val_mse: 10.2556 - val_mae: 1.7556 - lr: 2.5000e-04\n",
      "Epoch 42/500\n",
      "1300/1315 [============================>.] - ETA: 0s - loss: 0.8700 - mse: 5.3308 - mae: 1.1481\n",
      "Epoch 42: val_loss improved from 1.37816 to 1.36214, saving model to base_stne_rnn_weight.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8750 - mse: 5.3801 - mae: 1.1534 - val_loss: 1.3621 - val_mse: 9.7294 - val_mae: 1.6746 - lr: 2.5000e-04\n",
      "Epoch 43/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8725 - mse: 5.3529 - mae: 1.1512\n",
      "Epoch 43: val_loss did not improve from 1.36214\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8744 - mse: 5.3692 - mae: 1.1533 - val_loss: 1.4317 - val_mse: 10.1167 - val_mae: 1.7382 - lr: 2.5000e-04\n",
      "Epoch 44/500\n",
      "1299/1315 [============================>.] - ETA: 0s - loss: 0.8671 - mse: 5.2886 - mae: 1.1452\n",
      "Epoch 44: val_loss did not improve from 1.36214\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8741 - mse: 5.3837 - mae: 1.1525 - val_loss: 1.4009 - val_mse: 9.8894 - val_mae: 1.7180 - lr: 2.5000e-04\n",
      "Epoch 45/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8721 - mse: 5.3747 - mae: 1.1501\n",
      "Epoch 45: val_loss did not improve from 1.36214\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8721 - mse: 5.3747 - mae: 1.1501 - val_loss: 1.3629 - val_mse: 9.6897 - val_mae: 1.6878 - lr: 2.5000e-04\n",
      "Epoch 46/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8687 - mse: 5.3504 - mae: 1.1474\n",
      "Epoch 46: val_loss did not improve from 1.36214\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8700 - mse: 5.3634 - mae: 1.1487 - val_loss: 1.3787 - val_mse: 9.7548 - val_mae: 1.7082 - lr: 2.5000e-04\n",
      "Epoch 47/500\n",
      "1302/1315 [============================>.] - ETA: 0s - loss: 0.8663 - mse: 5.3076 - mae: 1.1456\n",
      "Epoch 47: val_loss did not improve from 1.36214\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8701 - mse: 5.3499 - mae: 1.1496 - val_loss: 1.3803 - val_mse: 9.8922 - val_mae: 1.6936 - lr: 2.5000e-04\n",
      "Epoch 48/500\n",
      "1302/1315 [============================>.] - ETA: 0s - loss: 0.8671 - mse: 5.3216 - mae: 1.1450\n",
      "Epoch 48: val_loss did not improve from 1.36214\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8705 - mse: 5.3555 - mae: 1.1487 - val_loss: 1.3937 - val_mse: 9.8809 - val_mae: 1.7201 - lr: 2.5000e-04\n",
      "Epoch 49/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8664 - mse: 5.3205 - mae: 1.1446\n",
      "Epoch 49: val_loss improved from 1.36214 to 1.35188, saving model to base_stne_rnn_weight.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8690 - mse: 5.3430 - mae: 1.1473 - val_loss: 1.3519 - val_mse: 9.7064 - val_mae: 1.6671 - lr: 2.5000e-04\n",
      "Epoch 50/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8697 - mse: 5.3423 - mae: 1.1480\n",
      "Epoch 50: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8707 - mse: 5.3525 - mae: 1.1490 - val_loss: 1.3688 - val_mse: 9.7222 - val_mae: 1.6796 - lr: 2.5000e-04\n",
      "Epoch 51/500\n",
      "1307/1315 [============================>.] - ETA: 0s - loss: 0.8705 - mse: 5.3735 - mae: 1.1483\n",
      "Epoch 51: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8709 - mse: 5.3768 - mae: 1.1487 - val_loss: 1.3798 - val_mse: 9.8058 - val_mae: 1.7107 - lr: 2.5000e-04\n",
      "Epoch 52/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8704 - mse: 5.3525 - mae: 1.1491\n",
      "Epoch 52: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8704 - mse: 5.3525 - mae: 1.1491 - val_loss: 1.3929 - val_mse: 9.8660 - val_mae: 1.7180 - lr: 2.5000e-04\n",
      "Epoch 53/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8714 - mse: 5.3486 - mae: 1.1503\n",
      "Epoch 53: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8714 - mse: 5.3486 - mae: 1.1503 - val_loss: 1.3909 - val_mse: 9.8397 - val_mae: 1.7114 - lr: 2.5000e-04\n",
      "Epoch 54/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8641 - mse: 5.3111 - mae: 1.1421\n",
      "Epoch 54: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8666 - mse: 5.3302 - mae: 1.1448 - val_loss: 1.3702 - val_mse: 9.7642 - val_mae: 1.6839 - lr: 2.5000e-04\n",
      "Epoch 55/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8679 - mse: 5.3407 - mae: 1.1463\n",
      "Epoch 55: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8678 - mse: 5.3387 - mae: 1.1462 - val_loss: 1.3971 - val_mse: 9.8800 - val_mae: 1.7030 - lr: 2.5000e-04\n",
      "Epoch 56/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8676 - mse: 5.3491 - mae: 1.1445\n",
      "Epoch 56: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8675 - mse: 5.3476 - mae: 1.1444 - val_loss: 1.3646 - val_mse: 9.7259 - val_mae: 1.6766 - lr: 2.5000e-04\n",
      "Epoch 57/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8670 - mse: 5.3228 - mae: 1.1447\n",
      "Epoch 57: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8670 - mse: 5.3228 - mae: 1.1447 - val_loss: 1.3762 - val_mse: 9.7941 - val_mae: 1.6829 - lr: 2.5000e-04\n",
      "Epoch 58/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8639 - mse: 5.2995 - mae: 1.1417\n",
      "Epoch 58: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8642 - mse: 5.3021 - mae: 1.1419 - val_loss: 1.3933 - val_mse: 9.8580 - val_mae: 1.7159 - lr: 2.5000e-04\n",
      "Epoch 59/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8667 - mse: 5.3262 - mae: 1.1447\n",
      "Epoch 59: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8667 - mse: 5.3262 - mae: 1.1447 - val_loss: 1.3976 - val_mse: 9.8943 - val_mae: 1.7137 - lr: 2.5000e-04\n",
      "Epoch 60/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8646 - mse: 5.2747 - mae: 1.1429\n",
      "Epoch 60: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8682 - mse: 5.3118 - mae: 1.1466 - val_loss: 1.3886 - val_mse: 9.8140 - val_mae: 1.7069 - lr: 1.2500e-04\n",
      "Epoch 61/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8641 - mse: 5.2859 - mae: 1.1418\n",
      "Epoch 61: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8645 - mse: 5.2908 - mae: 1.1422 - val_loss: 1.3836 - val_mse: 9.7911 - val_mae: 1.7074 - lr: 1.2500e-04\n",
      "Epoch 62/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8621 - mse: 5.2712 - mae: 1.1398\n",
      "Epoch 62: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8648 - mse: 5.2999 - mae: 1.1427 - val_loss: 1.3887 - val_mse: 9.8403 - val_mae: 1.7013 - lr: 1.2500e-04\n",
      "Epoch 63/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8638 - mse: 5.2839 - mae: 1.1410\n",
      "Epoch 63: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8637 - mse: 5.2832 - mae: 1.1410 - val_loss: 1.3710 - val_mse: 9.7025 - val_mae: 1.6904 - lr: 1.2500e-04\n",
      "Epoch 64/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8603 - mse: 5.2591 - mae: 1.1378\n",
      "Epoch 64: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8636 - mse: 5.2939 - mae: 1.1412 - val_loss: 1.3742 - val_mse: 9.7324 - val_mae: 1.6889 - lr: 1.2500e-04\n",
      "Epoch 65/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8584 - mse: 5.2549 - mae: 1.1354\n",
      "Epoch 65: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8613 - mse: 5.2841 - mae: 1.1384 - val_loss: 1.3922 - val_mse: 9.8517 - val_mae: 1.7141 - lr: 1.2500e-04\n",
      "Epoch 66/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8608 - mse: 5.2679 - mae: 1.1387\n",
      "Epoch 66: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8620 - mse: 5.2797 - mae: 1.1401 - val_loss: 1.3666 - val_mse: 9.6769 - val_mae: 1.6837 - lr: 1.2500e-04\n",
      "Epoch 67/500\n",
      "1302/1315 [============================>.] - ETA: 0s - loss: 0.8583 - mse: 5.2415 - mae: 1.1355\n",
      "Epoch 67: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8611 - mse: 5.2658 - mae: 1.1387 - val_loss: 1.3740 - val_mse: 9.7212 - val_mae: 1.6996 - lr: 1.2500e-04\n",
      "Epoch 68/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8620 - mse: 5.2771 - mae: 1.1392\n",
      "Epoch 68: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8638 - mse: 5.2960 - mae: 1.1410 - val_loss: 1.3554 - val_mse: 9.6084 - val_mae: 1.6763 - lr: 1.2500e-04\n",
      "Epoch 69/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8564 - mse: 5.2000 - mae: 1.1338\n",
      "Epoch 69: val_loss did not improve from 1.35188\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8603 - mse: 5.2559 - mae: 1.1378 - val_loss: 1.3787 - val_mse: 9.7206 - val_mae: 1.7018 - lr: 1.2500e-04\n",
      "Epoch 1/500\n",
      "   1301/Unknown - 4s 3ms/step - loss: 0.8607 - mse: 5.2487 - mae: 1.1410\n",
      "Epoch 1: val_loss improved from inf to 1.38507, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8616 - mse: 5.2603 - mae: 1.1420 - val_loss: 1.3851 - val_mse: 9.7491 - val_mae: 1.7062 - lr: 6.2500e-05\n",
      "Epoch 2/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8594 - mse: 5.2556 - mae: 1.1387\n",
      "Epoch 2: val_loss did not improve from 1.38507\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8594 - mse: 5.2537 - mae: 1.1388 - val_loss: 1.3908 - val_mse: 9.7912 - val_mae: 1.7126 - lr: 6.2500e-05\n",
      "Epoch 3/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8585 - mse: 5.2488 - mae: 1.1378\n",
      "Epoch 3: val_loss did not improve from 1.38507\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8587 - mse: 5.2505 - mae: 1.1381 - val_loss: 1.3942 - val_mse: 9.8164 - val_mae: 1.7164 - lr: 6.2500e-05\n",
      "Epoch 4/500\n",
      "1301/1315 [============================>.] - ETA: 0s - loss: 0.8574 - mse: 5.2363 - mae: 1.1366\n",
      "Epoch 4: val_loss did not improve from 1.38507\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8583 - mse: 5.2480 - mae: 1.1376 - val_loss: 1.3968 - val_mse: 9.8369 - val_mae: 1.7195 - lr: 6.2500e-05\n",
      "Epoch 5/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8556 - mse: 5.2221 - mae: 1.1346\n",
      "Epoch 5: val_loss did not improve from 1.38507\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8580 - mse: 5.2461 - mae: 1.1372 - val_loss: 1.3997 - val_mse: 9.8589 - val_mae: 1.7222 - lr: 6.2500e-05\n",
      "Epoch 6/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8576 - mse: 5.2439 - mae: 1.1367\n",
      "Epoch 6: val_loss did not improve from 1.38507\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8576 - mse: 5.2439 - mae: 1.1367 - val_loss: 1.4017 - val_mse: 9.8750 - val_mae: 1.7243 - lr: 6.2500e-05\n",
      "Epoch 7/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8573 - mse: 5.2453 - mae: 1.1363\n",
      "Epoch 7: val_loss did not improve from 1.38507\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8573 - mse: 5.2419 - mae: 1.1364 - val_loss: 1.4033 - val_mse: 9.8877 - val_mae: 1.7262 - lr: 6.2500e-05\n",
      "Epoch 8/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8571 - mse: 5.2413 - mae: 1.1360\n",
      "Epoch 8: val_loss did not improve from 1.38507\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8571 - mse: 5.2404 - mae: 1.1360 - val_loss: 1.4051 - val_mse: 9.9015 - val_mae: 1.7278 - lr: 6.2500e-05\n",
      "Epoch 9/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8564 - mse: 5.2383 - mae: 1.1351\n",
      "Epoch 9: val_loss did not improve from 1.38507\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8568 - mse: 5.2384 - mae: 1.1356 - val_loss: 1.4065 - val_mse: 9.9134 - val_mae: 1.7293 - lr: 6.2500e-05\n",
      "Epoch 10/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8565 - mse: 5.2368 - mae: 1.1353\n",
      "Epoch 10: val_loss did not improve from 1.38507\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8565 - mse: 5.2368 - mae: 1.1353 - val_loss: 1.4076 - val_mse: 9.9230 - val_mae: 1.7307 - lr: 6.2500e-05\n",
      "Epoch 11/500\n",
      "1303/1315 [============================>.] - ETA: 0s - loss: 0.8546 - mse: 5.2173 - mae: 1.1331\n",
      "Epoch 11: val_loss did not improve from 1.38507\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8563 - mse: 5.2354 - mae: 1.1349 - val_loss: 1.4088 - val_mse: 9.9334 - val_mae: 1.7318 - lr: 6.2500e-05\n",
      "Epoch 12/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8720 - mse: 5.2812 - mae: 1.1534\n",
      "Epoch 12: val_loss improved from 1.38507 to 1.37348, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8720 - mse: 5.2812 - mae: 1.1534 - val_loss: 1.3735 - val_mse: 9.7074 - val_mae: 1.6896 - lr: 3.1250e-05\n",
      "Epoch 13/500\n",
      "1302/1315 [============================>.] - ETA: 0s - loss: 0.8673 - mse: 5.2549 - mae: 1.1481\n",
      "Epoch 13: val_loss improved from 1.37348 to 1.37059, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8684 - mse: 5.2690 - mae: 1.1493 - val_loss: 1.3706 - val_mse: 9.6891 - val_mae: 1.6866 - lr: 3.1250e-05\n",
      "Epoch 14/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8655 - mse: 5.2434 - mae: 1.1461\n",
      "Epoch 14: val_loss improved from 1.37059 to 1.36910, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8675 - mse: 5.2658 - mae: 1.1483 - val_loss: 1.3691 - val_mse: 9.6793 - val_mae: 1.6852 - lr: 3.1250e-05\n",
      "Epoch 15/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8666 - mse: 5.2618 - mae: 1.1473\n",
      "Epoch 15: val_loss improved from 1.36910 to 1.36799, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8669 - mse: 5.2635 - mae: 1.1475 - val_loss: 1.3680 - val_mse: 9.6719 - val_mae: 1.6841 - lr: 3.1250e-05\n",
      "Epoch 16/500\n",
      "1303/1315 [============================>.] - ETA: 0s - loss: 0.8650 - mse: 5.2449 - mae: 1.1455\n",
      "Epoch 16: val_loss improved from 1.36799 to 1.36706, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8664 - mse: 5.2615 - mae: 1.1469 - val_loss: 1.3671 - val_mse: 9.6659 - val_mae: 1.6833 - lr: 3.1250e-05\n",
      "Epoch 17/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8654 - mse: 5.2571 - mae: 1.1458\n",
      "Epoch 17: val_loss improved from 1.36706 to 1.36632, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8659 - mse: 5.2595 - mae: 1.1464 - val_loss: 1.3663 - val_mse: 9.6611 - val_mae: 1.6825 - lr: 3.1250e-05\n",
      "Epoch 18/500\n",
      "1303/1315 [============================>.] - ETA: 0s - loss: 0.8642 - mse: 5.2412 - mae: 1.1445\n",
      "Epoch 18: val_loss improved from 1.36632 to 1.36568, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8655 - mse: 5.2578 - mae: 1.1460 - val_loss: 1.3657 - val_mse: 9.6570 - val_mae: 1.6819 - lr: 3.1250e-05\n",
      "Epoch 19/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8637 - mse: 5.2426 - mae: 1.1439\n",
      "Epoch 19: val_loss improved from 1.36568 to 1.36512, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8652 - mse: 5.2560 - mae: 1.1455 - val_loss: 1.3651 - val_mse: 9.6535 - val_mae: 1.6813 - lr: 3.1250e-05\n",
      "Epoch 20/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8643 - mse: 5.2520 - mae: 1.1444\n",
      "Epoch 20: val_loss improved from 1.36512 to 1.36465, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8648 - mse: 5.2544 - mae: 1.1451 - val_loss: 1.3647 - val_mse: 9.6507 - val_mae: 1.6809 - lr: 3.1250e-05\n",
      "Epoch 21/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8644 - mse: 5.2542 - mae: 1.1445\n",
      "Epoch 21: val_loss improved from 1.36465 to 1.36425, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8645 - mse: 5.2528 - mae: 1.1447 - val_loss: 1.3643 - val_mse: 9.6483 - val_mae: 1.6805 - lr: 3.1250e-05\n",
      "Epoch 22/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8640 - mse: 5.2496 - mae: 1.1441\n",
      "Epoch 22: val_loss improved from 1.36425 to 1.36389, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8642 - mse: 5.2513 - mae: 1.1443 - val_loss: 1.3639 - val_mse: 9.6463 - val_mae: 1.6802 - lr: 3.1250e-05\n",
      "Epoch 23/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8622 - mse: 5.2301 - mae: 1.1421\n",
      "Epoch 23: val_loss improved from 1.36389 to 1.36360, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8639 - mse: 5.2498 - mae: 1.1440 - val_loss: 1.3636 - val_mse: 9.6447 - val_mae: 1.6799 - lr: 3.1250e-05\n",
      "Epoch 24/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8636 - mse: 5.2483 - mae: 1.1436\n",
      "Epoch 24: val_loss improved from 1.36360 to 1.36333, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8636 - mse: 5.2483 - mae: 1.1436 - val_loss: 1.3633 - val_mse: 9.6434 - val_mae: 1.6797 - lr: 3.1250e-05\n",
      "Epoch 25/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8635 - mse: 5.2496 - mae: 1.1434\n",
      "Epoch 25: val_loss improved from 1.36333 to 1.36307, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8634 - mse: 5.2469 - mae: 1.1433 - val_loss: 1.3631 - val_mse: 9.6422 - val_mae: 1.6795 - lr: 3.1250e-05\n",
      "Epoch 26/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8626 - mse: 5.2432 - mae: 1.1424\n",
      "Epoch 26: val_loss improved from 1.36307 to 1.36287, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8631 - mse: 5.2456 - mae: 1.1430 - val_loss: 1.3629 - val_mse: 9.6415 - val_mae: 1.6794 - lr: 3.1250e-05\n",
      "Epoch 27/500\n",
      "1303/1315 [============================>.] - ETA: 0s - loss: 0.8615 - mse: 5.2275 - mae: 1.1412\n",
      "Epoch 27: val_loss improved from 1.36287 to 1.36263, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8629 - mse: 5.2442 - mae: 1.1427 - val_loss: 1.3626 - val_mse: 9.6404 - val_mae: 1.6792 - lr: 3.1250e-05\n",
      "Epoch 28/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8626 - mse: 5.2443 - mae: 1.1422\n",
      "Epoch 28: val_loss improved from 1.36263 to 1.36244, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8626 - mse: 5.2429 - mae: 1.1424 - val_loss: 1.3624 - val_mse: 9.6397 - val_mae: 1.6791 - lr: 3.1250e-05\n",
      "Epoch 29/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8607 - mse: 5.2219 - mae: 1.1403\n",
      "Epoch 29: val_loss improved from 1.36244 to 1.36231, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8624 - mse: 5.2416 - mae: 1.1421 - val_loss: 1.3623 - val_mse: 9.6394 - val_mae: 1.6790 - lr: 3.1250e-05\n",
      "Epoch 30/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8623 - mse: 5.2431 - mae: 1.1420\n",
      "Epoch 30: val_loss improved from 1.36231 to 1.36217, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8622 - mse: 5.2403 - mae: 1.1418 - val_loss: 1.3622 - val_mse: 9.6391 - val_mae: 1.6789 - lr: 3.1250e-05\n",
      "Epoch 31/500\n",
      "1298/1315 [============================>.] - ETA: 0s - loss: 0.8604 - mse: 5.2211 - mae: 1.1399\n",
      "Epoch 31: val_loss improved from 1.36217 to 1.36209, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8620 - mse: 5.2391 - mae: 1.1416 - val_loss: 1.3621 - val_mse: 9.6391 - val_mae: 1.6788 - lr: 3.1250e-05\n",
      "Epoch 32/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8603 - mse: 5.2244 - mae: 1.1396\n",
      "Epoch 32: val_loss improved from 1.36209 to 1.36193, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8617 - mse: 5.2379 - mae: 1.1413 - val_loss: 1.3619 - val_mse: 9.6386 - val_mae: 1.6787 - lr: 3.1250e-05\n",
      "Epoch 33/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8598 - mse: 5.2170 - mae: 1.1391\n",
      "Epoch 33: val_loss improved from 1.36193 to 1.36182, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8615 - mse: 5.2367 - mae: 1.1410 - val_loss: 1.3618 - val_mse: 9.6384 - val_mae: 1.6786 - lr: 3.1250e-05\n",
      "Epoch 34/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8614 - mse: 5.2367 - mae: 1.1408\n",
      "Epoch 34: val_loss improved from 1.36182 to 1.36171, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8613 - mse: 5.2356 - mae: 1.1407 - val_loss: 1.3617 - val_mse: 9.6382 - val_mae: 1.6785 - lr: 3.1250e-05\n",
      "Epoch 35/500\n",
      "1301/1315 [============================>.] - ETA: 0s - loss: 0.8604 - mse: 5.2236 - mae: 1.1396\n",
      "Epoch 35: val_loss improved from 1.36171 to 1.36161, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8611 - mse: 5.2345 - mae: 1.1405 - val_loss: 1.3616 - val_mse: 9.6380 - val_mae: 1.6785 - lr: 3.1250e-05\n",
      "Epoch 36/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8608 - mse: 5.2348 - mae: 1.1400\n",
      "Epoch 36: val_loss improved from 1.36161 to 1.36154, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8609 - mse: 5.2334 - mae: 1.1402 - val_loss: 1.3615 - val_mse: 9.6380 - val_mae: 1.6784 - lr: 3.1250e-05\n",
      "Epoch 37/500\n",
      "1302/1315 [============================>.] - ETA: 0s - loss: 0.8595 - mse: 5.2180 - mae: 1.1386\n",
      "Epoch 37: val_loss improved from 1.36154 to 1.36148, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8607 - mse: 5.2323 - mae: 1.1400 - val_loss: 1.3615 - val_mse: 9.6381 - val_mae: 1.6784 - lr: 3.1250e-05\n",
      "Epoch 38/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8590 - mse: 5.2178 - mae: 1.1381\n",
      "Epoch 38: val_loss improved from 1.36148 to 1.36144, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8605 - mse: 5.2313 - mae: 1.1397 - val_loss: 1.3614 - val_mse: 9.6383 - val_mae: 1.6783 - lr: 3.1250e-05\n",
      "Epoch 39/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8604 - mse: 5.2323 - mae: 1.1395\n",
      "Epoch 39: val_loss improved from 1.36144 to 1.36134, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8603 - mse: 5.2303 - mae: 1.1395 - val_loss: 1.3613 - val_mse: 9.6382 - val_mae: 1.6783 - lr: 3.1250e-05\n",
      "Epoch 40/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8602 - mse: 5.2304 - mae: 1.1393\n",
      "Epoch 40: val_loss improved from 1.36134 to 1.36127, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8602 - mse: 5.2293 - mae: 1.1393 - val_loss: 1.3613 - val_mse: 9.6382 - val_mae: 1.6782 - lr: 3.1250e-05\n",
      "Epoch 41/500\n",
      "1301/1315 [============================>.] - ETA: 0s - loss: 0.8592 - mse: 5.2174 - mae: 1.1382\n",
      "Epoch 41: val_loss improved from 1.36127 to 1.36121, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8600 - mse: 5.2283 - mae: 1.1390 - val_loss: 1.3612 - val_mse: 9.6382 - val_mae: 1.6781 - lr: 3.1250e-05\n",
      "Epoch 42/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8598 - mse: 5.2273 - mae: 1.1388\n",
      "Epoch 42: val_loss improved from 1.36121 to 1.36116, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8598 - mse: 5.2273 - mae: 1.1388 - val_loss: 1.3612 - val_mse: 9.6384 - val_mae: 1.6781 - lr: 3.1250e-05\n",
      "Epoch 43/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8597 - mse: 5.2275 - mae: 1.1387\n",
      "Epoch 43: val_loss improved from 1.36116 to 1.36110, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8596 - mse: 5.2264 - mae: 1.1386 - val_loss: 1.3611 - val_mse: 9.6385 - val_mae: 1.6780 - lr: 3.1250e-05\n",
      "Epoch 44/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8577 - mse: 5.2057 - mae: 1.1365\n",
      "Epoch 44: val_loss improved from 1.36110 to 1.36102, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8594 - mse: 5.2255 - mae: 1.1384 - val_loss: 1.3610 - val_mse: 9.6385 - val_mae: 1.6779 - lr: 3.1250e-05\n",
      "Epoch 45/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8578 - mse: 5.2111 - mae: 1.1366\n",
      "Epoch 45: val_loss improved from 1.36102 to 1.36097, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 7s 5ms/step - loss: 0.8593 - mse: 5.2246 - mae: 1.1382 - val_loss: 1.3610 - val_mse: 9.6387 - val_mae: 1.6778 - lr: 3.1250e-05\n",
      "Epoch 46/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8589 - mse: 5.2220 - mae: 1.1377\n",
      "Epoch 46: val_loss improved from 1.36097 to 1.36093, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8591 - mse: 5.2237 - mae: 1.1380 - val_loss: 1.3609 - val_mse: 9.6389 - val_mae: 1.6778 - lr: 3.1250e-05\n",
      "Epoch 47/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8592 - mse: 5.2267 - mae: 1.1379\n",
      "Epoch 47: val_loss improved from 1.36093 to 1.36088, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 7s 5ms/step - loss: 0.8589 - mse: 5.2228 - mae: 1.1378 - val_loss: 1.3609 - val_mse: 9.6390 - val_mae: 1.6777 - lr: 3.1250e-05\n",
      "Epoch 48/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8590 - mse: 5.2247 - mae: 1.1377\n",
      "Epoch 48: val_loss improved from 1.36088 to 1.36085, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8588 - mse: 5.2219 - mae: 1.1376 - val_loss: 1.3608 - val_mse: 9.6392 - val_mae: 1.6777 - lr: 3.1250e-05\n",
      "Epoch 49/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8566 - mse: 5.1987 - mae: 1.1352\n",
      "Epoch 49: val_loss improved from 1.36085 to 1.36080, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8586 - mse: 5.2211 - mae: 1.1374 - val_loss: 1.3608 - val_mse: 9.6393 - val_mae: 1.6776 - lr: 3.1250e-05\n",
      "Epoch 50/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8582 - mse: 5.2186 - mae: 1.1369\n",
      "Epoch 50: val_loss did not improve from 1.36080\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8585 - mse: 5.2202 - mae: 1.1372 - val_loss: 1.3608 - val_mse: 9.6398 - val_mae: 1.6776 - lr: 3.1250e-05\n",
      "Epoch 51/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8562 - mse: 5.1970 - mae: 1.1348\n",
      "Epoch 51: val_loss improved from 1.36080 to 1.36077, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8583 - mse: 5.2194 - mae: 1.1370 - val_loss: 1.3608 - val_mse: 9.6400 - val_mae: 1.6776 - lr: 3.1250e-05\n",
      "Epoch 52/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8582 - mse: 5.2197 - mae: 1.1369\n",
      "Epoch 52: val_loss improved from 1.36077 to 1.36074, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8581 - mse: 5.2186 - mae: 1.1368 - val_loss: 1.3607 - val_mse: 9.6402 - val_mae: 1.6775 - lr: 3.1250e-05\n",
      "Epoch 53/500\n",
      "1307/1315 [============================>.] - ETA: 0s - loss: 0.8570 - mse: 5.2087 - mae: 1.1355\n",
      "Epoch 53: val_loss improved from 1.36074 to 1.36069, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8580 - mse: 5.2179 - mae: 1.1367 - val_loss: 1.3607 - val_mse: 9.6404 - val_mae: 1.6775 - lr: 3.1250e-05\n",
      "Epoch 54/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8576 - mse: 5.2154 - mae: 1.1362\n",
      "Epoch 54: val_loss improved from 1.36069 to 1.36063, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8578 - mse: 5.2171 - mae: 1.1365 - val_loss: 1.3606 - val_mse: 9.6405 - val_mae: 1.6774 - lr: 3.1250e-05\n",
      "Epoch 55/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8572 - mse: 5.2140 - mae: 1.1357\n",
      "Epoch 55: val_loss improved from 1.36063 to 1.36055, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8577 - mse: 5.2163 - mae: 1.1363 - val_loss: 1.3606 - val_mse: 9.6405 - val_mae: 1.6773 - lr: 3.1250e-05\n",
      "Epoch 56/500\n",
      "1303/1315 [============================>.] - ETA: 0s - loss: 0.8561 - mse: 5.1986 - mae: 1.1346\n",
      "Epoch 56: val_loss improved from 1.36055 to 1.36048, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8575 - mse: 5.2155 - mae: 1.1361 - val_loss: 1.3605 - val_mse: 9.6405 - val_mae: 1.6772 - lr: 3.1250e-05\n",
      "Epoch 57/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8575 - mse: 5.2166 - mae: 1.1359\n",
      "Epoch 57: val_loss improved from 1.36048 to 1.36040, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8574 - mse: 5.2147 - mae: 1.1359 - val_loss: 1.3604 - val_mse: 9.6405 - val_mae: 1.6771 - lr: 3.1250e-05\n",
      "Epoch 58/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8571 - mse: 5.2153 - mae: 1.1356\n",
      "Epoch 58: val_loss improved from 1.36040 to 1.36030, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8572 - mse: 5.2139 - mae: 1.1357 - val_loss: 1.3603 - val_mse: 9.6403 - val_mae: 1.6770 - lr: 3.1250e-05\n",
      "Epoch 59/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8565 - mse: 5.2108 - mae: 1.1349\n",
      "Epoch 59: val_loss improved from 1.36030 to 1.36022, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8571 - mse: 5.2131 - mae: 1.1356 - val_loss: 1.3602 - val_mse: 9.6402 - val_mae: 1.6769 - lr: 3.1250e-05\n",
      "Epoch 60/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8549 - mse: 5.1899 - mae: 1.1331\n",
      "Epoch 60: val_loss improved from 1.36022 to 1.36013, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8569 - mse: 5.2124 - mae: 1.1354 - val_loss: 1.3601 - val_mse: 9.6400 - val_mae: 1.6767 - lr: 3.1250e-05\n",
      "Epoch 61/500\n",
      "1307/1315 [============================>.] - ETA: 0s - loss: 0.8558 - mse: 5.2025 - mae: 1.1341\n",
      "Epoch 61: val_loss improved from 1.36013 to 1.36002, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8568 - mse: 5.2116 - mae: 1.1352 - val_loss: 1.3600 - val_mse: 9.6397 - val_mae: 1.6766 - lr: 3.1250e-05\n",
      "Epoch 62/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8561 - mse: 5.2086 - mae: 1.1344\n",
      "Epoch 62: val_loss improved from 1.36002 to 1.35993, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8566 - mse: 5.2109 - mae: 1.1350 - val_loss: 1.3599 - val_mse: 9.6395 - val_mae: 1.6765 - lr: 3.1250e-05\n",
      "Epoch 63/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8566 - mse: 5.2113 - mae: 1.1349\n",
      "Epoch 63: val_loss improved from 1.35993 to 1.35986, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8565 - mse: 5.2102 - mae: 1.1348 - val_loss: 1.3599 - val_mse: 9.6395 - val_mae: 1.6764 - lr: 3.1250e-05\n",
      "Epoch 64/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8562 - mse: 5.2109 - mae: 1.1345\n",
      "Epoch 64: val_loss improved from 1.35986 to 1.35979, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8563 - mse: 5.2094 - mae: 1.1347 - val_loss: 1.3598 - val_mse: 9.6393 - val_mae: 1.6764 - lr: 3.1250e-05\n",
      "Epoch 65/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8541 - mse: 5.1863 - mae: 1.1323\n",
      "Epoch 65: val_loss improved from 1.35979 to 1.35970, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8562 - mse: 5.2087 - mae: 1.1345 - val_loss: 1.3597 - val_mse: 9.6391 - val_mae: 1.6763 - lr: 3.1250e-05\n",
      "Epoch 66/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8546 - mse: 5.1945 - mae: 1.1327\n",
      "Epoch 66: val_loss improved from 1.35970 to 1.35962, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8560 - mse: 5.2080 - mae: 1.1344 - val_loss: 1.3596 - val_mse: 9.6388 - val_mae: 1.6762 - lr: 3.1250e-05\n",
      "Epoch 67/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8559 - mse: 5.2073 - mae: 1.1342\n",
      "Epoch 67: val_loss improved from 1.35962 to 1.35954, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8559 - mse: 5.2073 - mae: 1.1342 - val_loss: 1.3595 - val_mse: 9.6386 - val_mae: 1.6761 - lr: 3.1250e-05\n",
      "Epoch 68/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8559 - mse: 5.2093 - mae: 1.1342\n",
      "Epoch 68: val_loss improved from 1.35954 to 1.35947, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8558 - mse: 5.2066 - mae: 1.1340 - val_loss: 1.3595 - val_mse: 9.6386 - val_mae: 1.6760 - lr: 3.1250e-05\n",
      "Epoch 69/500\n",
      "1307/1315 [============================>.] - ETA: 0s - loss: 0.8546 - mse: 5.1967 - mae: 1.1327\n",
      "Epoch 69: val_loss improved from 1.35947 to 1.35938, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8556 - mse: 5.2059 - mae: 1.1339 - val_loss: 1.3594 - val_mse: 9.6384 - val_mae: 1.6759 - lr: 3.1250e-05\n",
      "Epoch 70/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8534 - mse: 5.1827 - mae: 1.1315\n",
      "Epoch 70: val_loss improved from 1.35938 to 1.35933, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8555 - mse: 5.2052 - mae: 1.1337 - val_loss: 1.3593 - val_mse: 9.6385 - val_mae: 1.6759 - lr: 3.1250e-05\n",
      "Epoch 71/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8556 - mse: 5.2083 - mae: 1.1337\n",
      "Epoch 71: val_loss improved from 1.35933 to 1.35923, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8554 - mse: 5.2045 - mae: 1.1335 - val_loss: 1.3592 - val_mse: 9.6382 - val_mae: 1.6757 - lr: 3.1250e-05\n",
      "Epoch 72/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8553 - mse: 5.2057 - mae: 1.1334\n",
      "Epoch 72: val_loss improved from 1.35923 to 1.35916, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8552 - mse: 5.2038 - mae: 1.1334 - val_loss: 1.3592 - val_mse: 9.6381 - val_mae: 1.6757 - lr: 3.1250e-05\n",
      "Epoch 73/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8530 - mse: 5.1806 - mae: 1.1310\n",
      "Epoch 73: val_loss improved from 1.35916 to 1.35910, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8551 - mse: 5.2031 - mae: 1.1332 - val_loss: 1.3591 - val_mse: 9.6381 - val_mae: 1.6756 - lr: 3.1250e-05\n",
      "Epoch 74/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8547 - mse: 5.2007 - mae: 1.1328\n",
      "Epoch 74: val_loss improved from 1.35910 to 1.35905, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8550 - mse: 5.2023 - mae: 1.1331 - val_loss: 1.3590 - val_mse: 9.6383 - val_mae: 1.6756 - lr: 3.1250e-05\n",
      "Epoch 75/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8549 - mse: 5.2036 - mae: 1.1329\n",
      "Epoch 75: val_loss improved from 1.35905 to 1.35894, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8548 - mse: 5.2017 - mae: 1.1329 - val_loss: 1.3589 - val_mse: 9.6380 - val_mae: 1.6754 - lr: 3.1250e-05\n",
      "Epoch 76/500\n",
      "1301/1315 [============================>.] - ETA: 0s - loss: 0.8539 - mse: 5.1899 - mae: 1.1319\n",
      "Epoch 76: val_loss improved from 1.35894 to 1.35881, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8547 - mse: 5.2010 - mae: 1.1328 - val_loss: 1.3588 - val_mse: 9.6377 - val_mae: 1.6753 - lr: 3.1250e-05\n",
      "Epoch 77/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8546 - mse: 5.2014 - mae: 1.1327\n",
      "Epoch 77: val_loss improved from 1.35881 to 1.35871, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8546 - mse: 5.2003 - mae: 1.1326 - val_loss: 1.3587 - val_mse: 9.6374 - val_mae: 1.6752 - lr: 3.1250e-05\n",
      "Epoch 78/500\n",
      "1303/1315 [============================>.] - ETA: 0s - loss: 0.8530 - mse: 5.1827 - mae: 1.1309\n",
      "Epoch 78: val_loss improved from 1.35871 to 1.35860, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8544 - mse: 5.1996 - mae: 1.1325 - val_loss: 1.3586 - val_mse: 9.6371 - val_mae: 1.6751 - lr: 3.1250e-05\n",
      "Epoch 79/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8538 - mse: 5.1966 - mae: 1.1317\n",
      "Epoch 79: val_loss improved from 1.35860 to 1.35850, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8543 - mse: 5.1989 - mae: 1.1323 - val_loss: 1.3585 - val_mse: 9.6369 - val_mae: 1.6750 - lr: 3.1250e-05\n",
      "Epoch 80/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8541 - mse: 5.1997 - mae: 1.1320\n",
      "Epoch 80: val_loss improved from 1.35850 to 1.35839, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8542 - mse: 5.1982 - mae: 1.1322 - val_loss: 1.3584 - val_mse: 9.6365 - val_mae: 1.6749 - lr: 3.1250e-05\n",
      "Epoch 81/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8540 - mse: 5.1991 - mae: 1.1318\n",
      "Epoch 81: val_loss improved from 1.35839 to 1.35829, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8541 - mse: 5.1976 - mae: 1.1320 - val_loss: 1.3583 - val_mse: 9.6363 - val_mae: 1.6749 - lr: 3.1250e-05\n",
      "Epoch 82/500\n",
      "1302/1315 [============================>.] - ETA: 0s - loss: 0.8527 - mse: 5.1823 - mae: 1.1305\n",
      "Epoch 82: val_loss improved from 1.35829 to 1.35818, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8539 - mse: 5.1969 - mae: 1.1319 - val_loss: 1.3582 - val_mse: 9.6360 - val_mae: 1.6748 - lr: 3.1250e-05\n",
      "Epoch 83/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8540 - mse: 5.1990 - mae: 1.1319\n",
      "Epoch 83: val_loss improved from 1.35818 to 1.35810, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8538 - mse: 5.1963 - mae: 1.1317 - val_loss: 1.3581 - val_mse: 9.6358 - val_mae: 1.6747 - lr: 3.1250e-05\n",
      "Epoch 84/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8539 - mse: 5.1994 - mae: 1.1317\n",
      "Epoch 84: val_loss improved from 1.35810 to 1.35799, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8537 - mse: 5.1957 - mae: 1.1316 - val_loss: 1.3580 - val_mse: 9.6356 - val_mae: 1.6746 - lr: 3.1250e-05\n",
      "Epoch 85/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8518 - mse: 5.1749 - mae: 1.1295\n",
      "Epoch 85: val_loss improved from 1.35799 to 1.35793, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8536 - mse: 5.1949 - mae: 1.1314 - val_loss: 1.3579 - val_mse: 9.6355 - val_mae: 1.6746 - lr: 3.1250e-05\n",
      "Epoch 86/500\n",
      "1307/1315 [============================>.] - ETA: 0s - loss: 0.8524 - mse: 5.1851 - mae: 1.1302\n",
      "Epoch 86: val_loss improved from 1.35793 to 1.35783, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8534 - mse: 5.1942 - mae: 1.1313 - val_loss: 1.3578 - val_mse: 9.6352 - val_mae: 1.6746 - lr: 3.1250e-05\n",
      "Epoch 87/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8534 - mse: 5.1946 - mae: 1.1312\n",
      "Epoch 87: val_loss improved from 1.35783 to 1.35772, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8533 - mse: 5.1936 - mae: 1.1311 - val_loss: 1.3577 - val_mse: 9.6347 - val_mae: 1.6745 - lr: 3.1250e-05\n",
      "Epoch 88/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8511 - mse: 5.1703 - mae: 1.1287\n",
      "Epoch 88: val_loss improved from 1.35772 to 1.35764, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8532 - mse: 5.1929 - mae: 1.1310 - val_loss: 1.3576 - val_mse: 9.6345 - val_mae: 1.6745 - lr: 3.1250e-05\n",
      "Epoch 89/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8530 - mse: 5.1936 - mae: 1.1307\n",
      "Epoch 89: val_loss improved from 1.35764 to 1.35754, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8531 - mse: 5.1922 - mae: 1.1309 - val_loss: 1.3575 - val_mse: 9.6342 - val_mae: 1.6744 - lr: 3.1250e-05\n",
      "Epoch 90/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8531 - mse: 5.1926 - mae: 1.1308\n",
      "Epoch 90: val_loss improved from 1.35754 to 1.35744, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8530 - mse: 5.1915 - mae: 1.1307 - val_loss: 1.3574 - val_mse: 9.6339 - val_mae: 1.6744 - lr: 3.1250e-05\n",
      "Epoch 91/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8514 - mse: 5.1774 - mae: 1.1289\n",
      "Epoch 91: val_loss improved from 1.35744 to 1.35735, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8529 - mse: 5.1909 - mae: 1.1306 - val_loss: 1.3574 - val_mse: 9.6337 - val_mae: 1.6743 - lr: 3.1250e-05\n",
      "Epoch 92/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8529 - mse: 5.1939 - mae: 1.1306\n",
      "Epoch 92: val_loss improved from 1.35735 to 1.35725, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8527 - mse: 5.1902 - mae: 1.1304 - val_loss: 1.3572 - val_mse: 9.6333 - val_mae: 1.6743 - lr: 3.1250e-05\n",
      "Epoch 93/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8525 - mse: 5.1910 - mae: 1.1301\n",
      "Epoch 93: val_loss improved from 1.35725 to 1.35714, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8526 - mse: 5.1896 - mae: 1.1303 - val_loss: 1.3571 - val_mse: 9.6328 - val_mae: 1.6743 - lr: 3.1250e-05\n",
      "Epoch 94/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8520 - mse: 5.1865 - mae: 1.1295\n",
      "Epoch 94: val_loss improved from 1.35714 to 1.35706, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8525 - mse: 5.1889 - mae: 1.1302 - val_loss: 1.3571 - val_mse: 9.6326 - val_mae: 1.6742 - lr: 3.1250e-05\n",
      "Epoch 95/500\n",
      "1299/1315 [============================>.] - ETA: 0s - loss: 0.8509 - mse: 5.1720 - mae: 1.1284\n",
      "Epoch 95: val_loss improved from 1.35706 to 1.35694, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8524 - mse: 5.1883 - mae: 1.1301 - val_loss: 1.3569 - val_mse: 9.6321 - val_mae: 1.6742 - lr: 3.1250e-05\n",
      "Epoch 96/500\n",
      "1302/1315 [============================>.] - ETA: 0s - loss: 0.8511 - mse: 5.1729 - mae: 1.1285\n",
      "Epoch 96: val_loss improved from 1.35694 to 1.35685, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8523 - mse: 5.1877 - mae: 1.1299 - val_loss: 1.3568 - val_mse: 9.6318 - val_mae: 1.6741 - lr: 3.1250e-05\n",
      "Epoch 97/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8523 - mse: 5.1888 - mae: 1.1298\n",
      "Epoch 97: val_loss improved from 1.35685 to 1.35673, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8522 - mse: 5.1870 - mae: 1.1298 - val_loss: 1.3567 - val_mse: 9.6313 - val_mae: 1.6741 - lr: 3.1250e-05\n",
      "Epoch 98/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8522 - mse: 5.1882 - mae: 1.1297\n",
      "Epoch 98: val_loss improved from 1.35673 to 1.35665, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8521 - mse: 5.1864 - mae: 1.1297 - val_loss: 1.3566 - val_mse: 9.6311 - val_mae: 1.6741 - lr: 3.1250e-05\n",
      "Epoch 99/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8518 - mse: 5.1841 - mae: 1.1293\n",
      "Epoch 99: val_loss improved from 1.35665 to 1.35655, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8520 - mse: 5.1858 - mae: 1.1296 - val_loss: 1.3565 - val_mse: 9.6307 - val_mae: 1.6740 - lr: 3.1250e-05\n",
      "Epoch 100/500\n",
      "1303/1315 [============================>.] - ETA: 0s - loss: 0.8504 - mse: 5.1680 - mae: 1.1279\n",
      "Epoch 100: val_loss improved from 1.35655 to 1.35644, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8519 - mse: 5.1851 - mae: 1.1295 - val_loss: 1.3564 - val_mse: 9.6303 - val_mae: 1.6740 - lr: 3.1250e-05\n",
      "Epoch 101/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8517 - mse: 5.1859 - mae: 1.1292\n",
      "Epoch 101: val_loss improved from 1.35644 to 1.35632, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8518 - mse: 5.1845 - mae: 1.1294 - val_loss: 1.3563 - val_mse: 9.6299 - val_mae: 1.6739 - lr: 3.1250e-05\n",
      "Epoch 102/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8519 - mse: 5.1875 - mae: 1.1293\n",
      "Epoch 102: val_loss improved from 1.35632 to 1.35622, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8517 - mse: 5.1839 - mae: 1.1292 - val_loss: 1.3562 - val_mse: 9.6297 - val_mae: 1.6739 - lr: 3.1250e-05\n",
      "Epoch 103/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8501 - mse: 5.1697 - mae: 1.1275\n",
      "Epoch 103: val_loss improved from 1.35622 to 1.35613, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8516 - mse: 5.1832 - mae: 1.1291 - val_loss: 1.3561 - val_mse: 9.6294 - val_mae: 1.6739 - lr: 3.1250e-05\n",
      "Epoch 104/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8515 - mse: 5.1836 - mae: 1.1291\n",
      "Epoch 104: val_loss improved from 1.35613 to 1.35605, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8515 - mse: 5.1826 - mae: 1.1290 - val_loss: 1.3560 - val_mse: 9.6292 - val_mae: 1.6738 - lr: 3.1250e-05\n",
      "Epoch 105/500\n",
      "1301/1315 [============================>.] - ETA: 0s - loss: 0.8506 - mse: 5.1706 - mae: 1.1280\n",
      "Epoch 105: val_loss improved from 1.35605 to 1.35596, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8514 - mse: 5.1820 - mae: 1.1289 - val_loss: 1.3560 - val_mse: 9.6289 - val_mae: 1.6738 - lr: 3.1250e-05\n",
      "Epoch 106/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8511 - mse: 5.1827 - mae: 1.1286\n",
      "Epoch 106: val_loss improved from 1.35596 to 1.35584, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8513 - mse: 5.1813 - mae: 1.1288 - val_loss: 1.3558 - val_mse: 9.6285 - val_mae: 1.6737 - lr: 3.1250e-05\n",
      "Epoch 107/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8513 - mse: 5.1844 - mae: 1.1288\n",
      "Epoch 107: val_loss improved from 1.35584 to 1.35577, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8512 - mse: 5.1807 - mae: 1.1287 - val_loss: 1.3558 - val_mse: 9.6284 - val_mae: 1.6737 - lr: 3.1250e-05\n",
      "Epoch 108/500\n",
      "1300/1315 [============================>.] - ETA: 0s - loss: 0.8504 - mse: 5.1690 - mae: 1.1278\n",
      "Epoch 108: val_loss improved from 1.35577 to 1.35566, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8510 - mse: 5.1801 - mae: 1.1286 - val_loss: 1.3557 - val_mse: 9.6279 - val_mae: 1.6736 - lr: 3.1250e-05\n",
      "Epoch 109/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8492 - mse: 5.1593 - mae: 1.1265\n",
      "Epoch 109: val_loss improved from 1.35566 to 1.35559, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8509 - mse: 5.1795 - mae: 1.1284 - val_loss: 1.3556 - val_mse: 9.6278 - val_mae: 1.6736 - lr: 3.1250e-05\n",
      "Epoch 110/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8503 - mse: 5.1764 - mae: 1.1276\n",
      "Epoch 110: val_loss improved from 1.35559 to 1.35551, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8508 - mse: 5.1789 - mae: 1.1283 - val_loss: 1.3555 - val_mse: 9.6276 - val_mae: 1.6736 - lr: 3.1250e-05\n",
      "Epoch 111/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8509 - mse: 5.1819 - mae: 1.1283\n",
      "Epoch 111: val_loss improved from 1.35551 to 1.35544, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8507 - mse: 5.1783 - mae: 1.1282 - val_loss: 1.3554 - val_mse: 9.6275 - val_mae: 1.6735 - lr: 3.1250e-05\n",
      "Epoch 112/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8491 - mse: 5.1642 - mae: 1.1264\n",
      "Epoch 112: val_loss improved from 1.35544 to 1.35537, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8506 - mse: 5.1777 - mae: 1.1281 - val_loss: 1.3554 - val_mse: 9.6274 - val_mae: 1.6735 - lr: 3.1250e-05\n",
      "Epoch 113/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8506 - mse: 5.1782 - mae: 1.1280\n",
      "Epoch 113: val_loss improved from 1.35537 to 1.35527, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8505 - mse: 5.1771 - mae: 1.1280 - val_loss: 1.3553 - val_mse: 9.6271 - val_mae: 1.6734 - lr: 3.1250e-05\n",
      "Epoch 114/500\n",
      "1307/1315 [============================>.] - ETA: 0s - loss: 0.8494 - mse: 5.1673 - mae: 1.1267\n",
      "Epoch 114: val_loss improved from 1.35527 to 1.35520, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8504 - mse: 5.1765 - mae: 1.1279 - val_loss: 1.3552 - val_mse: 9.6270 - val_mae: 1.6734 - lr: 3.1250e-05\n",
      "Epoch 115/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8502 - mse: 5.1773 - mae: 1.1275\n",
      "Epoch 115: val_loss improved from 1.35520 to 1.35512, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8503 - mse: 5.1760 - mae: 1.1277 - val_loss: 1.3551 - val_mse: 9.6268 - val_mae: 1.6733 - lr: 3.1250e-05\n",
      "Epoch 116/500\n",
      "1303/1315 [============================>.] - ETA: 0s - loss: 0.8488 - mse: 5.1581 - mae: 1.1260\n",
      "Epoch 116: val_loss improved from 1.35512 to 1.35504, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8502 - mse: 5.1754 - mae: 1.1276 - val_loss: 1.3550 - val_mse: 9.6266 - val_mae: 1.6733 - lr: 3.1250e-05\n",
      "Epoch 117/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8502 - mse: 5.1759 - mae: 1.1276\n",
      "Epoch 117: val_loss improved from 1.35504 to 1.35497, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8502 - mse: 5.1748 - mae: 1.1275 - val_loss: 1.3550 - val_mse: 9.6265 - val_mae: 1.6732 - lr: 3.1250e-05\n",
      "Epoch 118/500\n",
      "1302/1315 [============================>.] - ETA: 0s - loss: 0.8488 - mse: 5.1593 - mae: 1.1260\n",
      "Epoch 118: val_loss improved from 1.35497 to 1.35488, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8501 - mse: 5.1743 - mae: 1.1274 - val_loss: 1.3549 - val_mse: 9.6263 - val_mae: 1.6732 - lr: 3.1250e-05\n",
      "Epoch 119/500\n",
      "1300/1315 [============================>.] - ETA: 0s - loss: 0.8493 - mse: 5.1625 - mae: 1.1266\n",
      "Epoch 119: val_loss improved from 1.35488 to 1.35481, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8500 - mse: 5.1737 - mae: 1.1273 - val_loss: 1.3548 - val_mse: 9.6261 - val_mae: 1.6731 - lr: 3.1250e-05\n",
      "Epoch 120/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8493 - mse: 5.1707 - mae: 1.1265\n",
      "Epoch 120: val_loss improved from 1.35481 to 1.35474, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8499 - mse: 5.1732 - mae: 1.1272 - val_loss: 1.3547 - val_mse: 9.6260 - val_mae: 1.6731 - lr: 3.1250e-05\n",
      "Epoch 121/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8495 - mse: 5.1709 - mae: 1.1268\n",
      "Epoch 121: val_loss improved from 1.35474 to 1.35466, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8498 - mse: 5.1726 - mae: 1.1271 - val_loss: 1.3547 - val_mse: 9.6257 - val_mae: 1.6730 - lr: 3.1250e-05\n",
      "Epoch 122/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8479 - mse: 5.1518 - mae: 1.1250\n",
      "Epoch 122: val_loss improved from 1.35466 to 1.35459, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8497 - mse: 5.1720 - mae: 1.1270 - val_loss: 1.3546 - val_mse: 9.6256 - val_mae: 1.6729 - lr: 3.1250e-05\n",
      "Epoch 123/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8497 - mse: 5.1732 - mae: 1.1268\n",
      "Epoch 123: val_loss improved from 1.35459 to 1.35452, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8496 - mse: 5.1715 - mae: 1.1269 - val_loss: 1.3545 - val_mse: 9.6254 - val_mae: 1.6729 - lr: 3.1250e-05\n",
      "Epoch 124/500\n",
      "1303/1315 [============================>.] - ETA: 0s - loss: 0.8480 - mse: 5.1537 - mae: 1.1252\n",
      "Epoch 124: val_loss improved from 1.35452 to 1.35446, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8495 - mse: 5.1710 - mae: 1.1268 - val_loss: 1.3545 - val_mse: 9.6253 - val_mae: 1.6729 - lr: 3.1250e-05\n",
      "Epoch 125/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8488 - mse: 5.1679 - mae: 1.1260\n",
      "Epoch 125: val_loss improved from 1.35446 to 1.35440, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8494 - mse: 5.1704 - mae: 1.1267 - val_loss: 1.3544 - val_mse: 9.6253 - val_mae: 1.6728 - lr: 3.1250e-05\n",
      "Epoch 126/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8472 - mse: 5.1472 - mae: 1.1243\n",
      "Epoch 126: val_loss improved from 1.35440 to 1.35433, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8493 - mse: 5.1699 - mae: 1.1265 - val_loss: 1.3543 - val_mse: 9.6251 - val_mae: 1.6728 - lr: 3.1250e-05\n",
      "Epoch 127/500\n",
      "1301/1315 [============================>.] - ETA: 0s - loss: 0.8484 - mse: 5.1578 - mae: 1.1255\n",
      "Epoch 127: val_loss improved from 1.35433 to 1.35427, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8492 - mse: 5.1693 - mae: 1.1264 - val_loss: 1.3543 - val_mse: 9.6250 - val_mae: 1.6727 - lr: 3.1250e-05\n",
      "Epoch 128/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8486 - mse: 5.1663 - mae: 1.1256\n",
      "Epoch 128: val_loss improved from 1.35427 to 1.35422, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8491 - mse: 5.1688 - mae: 1.1263 - val_loss: 1.3542 - val_mse: 9.6249 - val_mae: 1.6727 - lr: 3.1250e-05\n",
      "Epoch 129/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8475 - mse: 5.1548 - mae: 1.1246\n",
      "Epoch 129: val_loss improved from 1.35422 to 1.35416, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8490 - mse: 5.1683 - mae: 1.1262 - val_loss: 1.3542 - val_mse: 9.6249 - val_mae: 1.6726 - lr: 3.1250e-05\n",
      "Epoch 130/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8490 - mse: 5.1695 - mae: 1.1261\n",
      "Epoch 130: val_loss improved from 1.35416 to 1.35411, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8489 - mse: 5.1678 - mae: 1.1261 - val_loss: 1.3541 - val_mse: 9.6248 - val_mae: 1.6726 - lr: 3.1250e-05\n",
      "Epoch 131/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8486 - mse: 5.1655 - mae: 1.1257\n",
      "Epoch 131: val_loss improved from 1.35411 to 1.35407, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8489 - mse: 5.1672 - mae: 1.1260 - val_loss: 1.3541 - val_mse: 9.6248 - val_mae: 1.6726 - lr: 3.1250e-05\n",
      "Epoch 132/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8488 - mse: 5.1678 - mae: 1.1260\n",
      "Epoch 132: val_loss improved from 1.35407 to 1.35400, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8488 - mse: 5.1667 - mae: 1.1259 - val_loss: 1.3540 - val_mse: 9.6247 - val_mae: 1.6725 - lr: 3.1250e-05\n",
      "Epoch 133/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8466 - mse: 5.1434 - mae: 1.1235\n",
      "Epoch 133: val_loss improved from 1.35400 to 1.35395, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8487 - mse: 5.1662 - mae: 1.1258 - val_loss: 1.3540 - val_mse: 9.6248 - val_mae: 1.6725 - lr: 3.1250e-05\n",
      "Epoch 134/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8484 - mse: 5.1640 - mae: 1.1254\n",
      "Epoch 134: val_loss improved from 1.35395 to 1.35389, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8486 - mse: 5.1657 - mae: 1.1257 - val_loss: 1.3539 - val_mse: 9.6246 - val_mae: 1.6724 - lr: 3.1250e-05\n",
      "Epoch 135/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8486 - mse: 5.1662 - mae: 1.1257\n",
      "Epoch 135: val_loss improved from 1.35389 to 1.35382, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8485 - mse: 5.1652 - mae: 1.1256 - val_loss: 1.3538 - val_mse: 9.6246 - val_mae: 1.6723 - lr: 3.1250e-05\n",
      "Epoch 136/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8463 - mse: 5.1419 - mae: 1.1232\n",
      "Epoch 136: val_loss improved from 1.35382 to 1.35378, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8484 - mse: 5.1646 - mae: 1.1255 - val_loss: 1.3538 - val_mse: 9.6246 - val_mae: 1.6723 - lr: 3.1250e-05\n",
      "Epoch 137/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8465 - mse: 5.1438 - mae: 1.1234\n",
      "Epoch 137: val_loss improved from 1.35378 to 1.35372, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8483 - mse: 5.1641 - mae: 1.1254 - val_loss: 1.3537 - val_mse: 9.6245 - val_mae: 1.6723 - lr: 3.1250e-05\n",
      "Epoch 138/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8482 - mse: 5.1636 - mae: 1.1253\n",
      "Epoch 138: val_loss improved from 1.35372 to 1.35366, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8482 - mse: 5.1636 - mae: 1.1253 - val_loss: 1.3537 - val_mse: 9.6245 - val_mae: 1.6722 - lr: 3.1250e-05\n",
      "Epoch 139/500\n",
      "1302/1315 [============================>.] - ETA: 0s - loss: 0.8469 - mse: 5.1481 - mae: 1.1237\n",
      "Epoch 139: val_loss improved from 1.35366 to 1.35356, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8482 - mse: 5.1631 - mae: 1.1252 - val_loss: 1.3536 - val_mse: 9.6241 - val_mae: 1.6721 - lr: 3.1250e-05\n",
      "Epoch 140/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8463 - mse: 5.1423 - mae: 1.1231\n",
      "Epoch 140: val_loss improved from 1.35356 to 1.35346, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8481 - mse: 5.1626 - mae: 1.1251 - val_loss: 1.3535 - val_mse: 9.6239 - val_mae: 1.6720 - lr: 3.1250e-05\n",
      "Epoch 141/500\n",
      "1307/1315 [============================>.] - ETA: 0s - loss: 0.8469 - mse: 5.1529 - mae: 1.1238\n",
      "Epoch 141: val_loss improved from 1.35346 to 1.35335, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8480 - mse: 5.1621 - mae: 1.1250 - val_loss: 1.3534 - val_mse: 9.6236 - val_mae: 1.6719 - lr: 3.1250e-05\n",
      "Epoch 142/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8461 - mse: 5.1413 - mae: 1.1229\n",
      "Epoch 142: val_loss improved from 1.35335 to 1.35324, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8479 - mse: 5.1616 - mae: 1.1249 - val_loss: 1.3532 - val_mse: 9.6233 - val_mae: 1.6718 - lr: 3.1250e-05\n",
      "Epoch 143/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8457 - mse: 5.1384 - mae: 1.1225\n",
      "Epoch 143: val_loss improved from 1.35324 to 1.35314, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8478 - mse: 5.1611 - mae: 1.1248 - val_loss: 1.3531 - val_mse: 9.6230 - val_mae: 1.6717 - lr: 3.1250e-05\n",
      "Epoch 144/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8457 - mse: 5.1379 - mae: 1.1224\n",
      "Epoch 144: val_loss improved from 1.35314 to 1.35302, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8477 - mse: 5.1606 - mae: 1.1247 - val_loss: 1.3530 - val_mse: 9.6226 - val_mae: 1.6715 - lr: 3.1250e-05\n",
      "Epoch 145/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8477 - mse: 5.1601 - mae: 1.1246\n",
      "Epoch 145: val_loss improved from 1.35302 to 1.35294, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8477 - mse: 5.1601 - mae: 1.1246 - val_loss: 1.3529 - val_mse: 9.6224 - val_mae: 1.6715 - lr: 3.1250e-05\n",
      "Epoch 146/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8461 - mse: 5.1461 - mae: 1.1228\n",
      "Epoch 146: val_loss improved from 1.35294 to 1.35283, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8476 - mse: 5.1596 - mae: 1.1245 - val_loss: 1.3528 - val_mse: 9.6221 - val_mae: 1.6713 - lr: 3.1250e-05\n",
      "Epoch 147/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8460 - mse: 5.1456 - mae: 1.1227\n",
      "Epoch 147: val_loss improved from 1.35283 to 1.35272, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8475 - mse: 5.1591 - mae: 1.1244 - val_loss: 1.3527 - val_mse: 9.6217 - val_mae: 1.6712 - lr: 3.1250e-05\n",
      "Epoch 148/500\n",
      "1301/1315 [============================>.] - ETA: 0s - loss: 0.8466 - mse: 5.1470 - mae: 1.1234\n",
      "Epoch 148: val_loss improved from 1.35272 to 1.35262, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8474 - mse: 5.1586 - mae: 1.1243 - val_loss: 1.3526 - val_mse: 9.6214 - val_mae: 1.6711 - lr: 3.1250e-05\n",
      "Epoch 149/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8458 - mse: 5.1446 - mae: 1.1225\n",
      "Epoch 149: val_loss improved from 1.35262 to 1.35251, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8473 - mse: 5.1581 - mae: 1.1242 - val_loss: 1.3525 - val_mse: 9.6211 - val_mae: 1.6710 - lr: 3.1250e-05\n",
      "Epoch 150/500\n",
      "1299/1315 [============================>.] - ETA: 0s - loss: 0.8457 - mse: 5.1409 - mae: 1.1224\n",
      "Epoch 150: val_loss improved from 1.35251 to 1.35240, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8472 - mse: 5.1576 - mae: 1.1241 - val_loss: 1.3524 - val_mse: 9.6207 - val_mae: 1.6709 - lr: 3.1250e-05\n",
      "Epoch 151/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8470 - mse: 5.1585 - mae: 1.1238\n",
      "Epoch 151: val_loss improved from 1.35240 to 1.35233, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8472 - mse: 5.1571 - mae: 1.1240 - val_loss: 1.3523 - val_mse: 9.6206 - val_mae: 1.6708 - lr: 3.1250e-05\n",
      "Epoch 152/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8471 - mse: 5.1566 - mae: 1.1240\n",
      "Epoch 152: val_loss improved from 1.35233 to 1.35220, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8471 - mse: 5.1566 - mae: 1.1240 - val_loss: 1.3522 - val_mse: 9.6200 - val_mae: 1.6707 - lr: 3.1250e-05\n",
      "Epoch 153/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8469 - mse: 5.1575 - mae: 1.1236\n",
      "Epoch 153: val_loss improved from 1.35220 to 1.35209, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8470 - mse: 5.1561 - mae: 1.1239 - val_loss: 1.3521 - val_mse: 9.6198 - val_mae: 1.6706 - lr: 3.1250e-05\n",
      "Epoch 154/500\n",
      "1301/1315 [============================>.] - ETA: 0s - loss: 0.8461 - mse: 5.1440 - mae: 1.1228\n",
      "Epoch 154: val_loss improved from 1.35209 to 1.35200, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8469 - mse: 5.1556 - mae: 1.1238 - val_loss: 1.3520 - val_mse: 9.6194 - val_mae: 1.6705 - lr: 3.1250e-05\n",
      "Epoch 155/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8451 - mse: 5.1348 - mae: 1.1217\n",
      "Epoch 155: val_loss improved from 1.35200 to 1.35188, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8469 - mse: 5.1551 - mae: 1.1237 - val_loss: 1.3519 - val_mse: 9.6191 - val_mae: 1.6703 - lr: 3.1250e-05\n",
      "Epoch 156/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8453 - mse: 5.1411 - mae: 1.1219\n",
      "Epoch 156: val_loss improved from 1.35188 to 1.35176, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8468 - mse: 5.1546 - mae: 1.1236 - val_loss: 1.3518 - val_mse: 9.6186 - val_mae: 1.6702 - lr: 3.1250e-05\n",
      "Epoch 157/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8469 - mse: 5.1576 - mae: 1.1236\n",
      "Epoch 157: val_loss improved from 1.35176 to 1.35169, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8467 - mse: 5.1541 - mae: 1.1235 - val_loss: 1.3517 - val_mse: 9.6185 - val_mae: 1.6701 - lr: 3.1250e-05\n",
      "Epoch 158/500\n",
      "1302/1315 [============================>.] - ETA: 0s - loss: 0.8453 - mse: 5.1385 - mae: 1.1219\n",
      "Epoch 158: val_loss improved from 1.35169 to 1.35159, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8466 - mse: 5.1536 - mae: 1.1234 - val_loss: 1.3516 - val_mse: 9.6182 - val_mae: 1.6700 - lr: 3.1250e-05\n",
      "Epoch 159/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8460 - mse: 5.1506 - mae: 1.1226\n",
      "Epoch 159: val_loss improved from 1.35159 to 1.35154, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8465 - mse: 5.1532 - mae: 1.1233 - val_loss: 1.3515 - val_mse: 9.6182 - val_mae: 1.6700 - lr: 3.1250e-05\n",
      "Epoch 160/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8466 - mse: 5.1561 - mae: 1.1233\n",
      "Epoch 160: val_loss improved from 1.35154 to 1.35142, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8465 - mse: 5.1527 - mae: 1.1232 - val_loss: 1.3514 - val_mse: 9.6178 - val_mae: 1.6698 - lr: 3.1250e-05\n",
      "Epoch 161/500\n",
      "1303/1315 [============================>.] - ETA: 0s - loss: 0.8449 - mse: 5.1348 - mae: 1.1215\n",
      "Epoch 161: val_loss improved from 1.35142 to 1.35135, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8464 - mse: 5.1522 - mae: 1.1231 - val_loss: 1.3513 - val_mse: 9.6176 - val_mae: 1.6698 - lr: 3.1250e-05\n",
      "Epoch 162/500\n",
      "1307/1315 [============================>.] - ETA: 0s - loss: 0.8453 - mse: 5.1424 - mae: 1.1219\n",
      "Epoch 162: val_loss improved from 1.35135 to 1.35125, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8463 - mse: 5.1517 - mae: 1.1230 - val_loss: 1.3513 - val_mse: 9.6173 - val_mae: 1.6696 - lr: 3.1250e-05\n",
      "Epoch 163/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8464 - mse: 5.1547 - mae: 1.1230\n",
      "Epoch 163: val_loss improved from 1.35125 to 1.35120, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8462 - mse: 5.1512 - mae: 1.1230 - val_loss: 1.3512 - val_mse: 9.6173 - val_mae: 1.6696 - lr: 3.1250e-05\n",
      "Epoch 164/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8462 - mse: 5.1517 - mae: 1.1229\n",
      "Epoch 164: val_loss improved from 1.35120 to 1.35113, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8462 - mse: 5.1507 - mae: 1.1229 - val_loss: 1.3511 - val_mse: 9.6173 - val_mae: 1.6695 - lr: 3.1250e-05\n",
      "Epoch 165/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8458 - mse: 5.1485 - mae: 1.1225\n",
      "Epoch 165: val_loss improved from 1.35113 to 1.35107, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8461 - mse: 5.1502 - mae: 1.1228 - val_loss: 1.3511 - val_mse: 9.6172 - val_mae: 1.6694 - lr: 3.1250e-05\n",
      "Epoch 166/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8454 - mse: 5.1472 - mae: 1.1220\n",
      "Epoch 166: val_loss improved from 1.35107 to 1.35102, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8460 - mse: 5.1498 - mae: 1.1227 - val_loss: 1.3510 - val_mse: 9.6172 - val_mae: 1.6694 - lr: 3.1250e-05\n",
      "Epoch 167/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8457 - mse: 5.1476 - mae: 1.1223\n",
      "Epoch 167: val_loss improved from 1.35102 to 1.35094, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8459 - mse: 5.1493 - mae: 1.1226 - val_loss: 1.3509 - val_mse: 9.6171 - val_mae: 1.6693 - lr: 3.1250e-05\n",
      "Epoch 168/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8460 - mse: 5.1523 - mae: 1.1226\n",
      "Epoch 168: val_loss improved from 1.35094 to 1.35089, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8459 - mse: 5.1488 - mae: 1.1225 - val_loss: 1.3509 - val_mse: 9.6170 - val_mae: 1.6692 - lr: 3.1250e-05\n",
      "Epoch 169/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8458 - mse: 5.1484 - mae: 1.1224\n",
      "Epoch 169: val_loss improved from 1.35089 to 1.35082, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8458 - mse: 5.1484 - mae: 1.1224 - val_loss: 1.3508 - val_mse: 9.6170 - val_mae: 1.6692 - lr: 3.1250e-05\n",
      "Epoch 170/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8455 - mse: 5.1462 - mae: 1.1221\n",
      "Epoch 170: val_loss improved from 1.35082 to 1.35078, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8457 - mse: 5.1479 - mae: 1.1223 - val_loss: 1.3508 - val_mse: 9.6170 - val_mae: 1.6691 - lr: 3.1250e-05\n",
      "Epoch 171/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8436 - mse: 5.1246 - mae: 1.1200\n",
      "Epoch 171: val_loss improved from 1.35078 to 1.35072, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8456 - mse: 5.1474 - mae: 1.1223 - val_loss: 1.3507 - val_mse: 9.6170 - val_mae: 1.6690 - lr: 3.1250e-05\n",
      "Epoch 172/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8457 - mse: 5.1504 - mae: 1.1223\n",
      "Epoch 172: val_loss improved from 1.35072 to 1.35066, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8456 - mse: 5.1470 - mae: 1.1222 - val_loss: 1.3507 - val_mse: 9.6170 - val_mae: 1.6690 - lr: 3.1250e-05\n",
      "Epoch 173/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8456 - mse: 5.1476 - mae: 1.1221\n",
      "Epoch 173: val_loss improved from 1.35066 to 1.35060, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8455 - mse: 5.1465 - mae: 1.1221 - val_loss: 1.3506 - val_mse: 9.6170 - val_mae: 1.6689 - lr: 3.1250e-05\n",
      "Epoch 174/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8456 - mse: 5.1495 - mae: 1.1221\n",
      "Epoch 174: val_loss improved from 1.35060 to 1.35054, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8454 - mse: 5.1461 - mae: 1.1220 - val_loss: 1.3505 - val_mse: 9.6169 - val_mae: 1.6688 - lr: 3.1250e-05\n",
      "Epoch 175/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8451 - mse: 5.1439 - mae: 1.1217\n",
      "Epoch 175: val_loss improved from 1.35054 to 1.35050, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8454 - mse: 5.1456 - mae: 1.1219 - val_loss: 1.3505 - val_mse: 9.6171 - val_mae: 1.6688 - lr: 3.1250e-05\n",
      "Epoch 176/500\n",
      "1307/1315 [============================>.] - ETA: 0s - loss: 0.8442 - mse: 5.1359 - mae: 1.1207\n",
      "Epoch 176: val_loss improved from 1.35050 to 1.35044, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8453 - mse: 5.1451 - mae: 1.1218 - val_loss: 1.3504 - val_mse: 9.6171 - val_mae: 1.6687 - lr: 3.1250e-05\n",
      "Epoch 177/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8437 - mse: 5.1311 - mae: 1.1201\n",
      "Epoch 177: val_loss improved from 1.35044 to 1.35040, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8452 - mse: 5.1447 - mae: 1.1218 - val_loss: 1.3504 - val_mse: 9.6172 - val_mae: 1.6687 - lr: 3.1250e-05\n",
      "Epoch 178/500\n",
      "1302/1315 [============================>.] - ETA: 0s - loss: 0.8438 - mse: 5.1290 - mae: 1.1202\n",
      "Epoch 178: val_loss improved from 1.35040 to 1.35035, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8451 - mse: 5.1442 - mae: 1.1217 - val_loss: 1.3503 - val_mse: 9.6172 - val_mae: 1.6686 - lr: 3.1250e-05\n",
      "Epoch 179/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8451 - mse: 5.1454 - mae: 1.1216\n",
      "Epoch 179: val_loss improved from 1.35035 to 1.35029, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8451 - mse: 5.1437 - mae: 1.1216 - val_loss: 1.3503 - val_mse: 9.6172 - val_mae: 1.6685 - lr: 3.1250e-05\n",
      "Epoch 180/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8451 - mse: 5.1443 - mae: 1.1216\n",
      "Epoch 180: val_loss improved from 1.35029 to 1.35025, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8450 - mse: 5.1433 - mae: 1.1215 - val_loss: 1.3502 - val_mse: 9.6172 - val_mae: 1.6685 - lr: 3.1250e-05\n",
      "Epoch 181/500\n",
      "1302/1315 [============================>.] - ETA: 0s - loss: 0.8436 - mse: 5.1277 - mae: 1.1199\n",
      "Epoch 181: val_loss improved from 1.35025 to 1.35020, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8449 - mse: 5.1428 - mae: 1.1214 - val_loss: 1.3502 - val_mse: 9.6173 - val_mae: 1.6684 - lr: 3.1250e-05\n",
      "Epoch 182/500\n",
      "1302/1315 [============================>.] - ETA: 0s - loss: 0.8435 - mse: 5.1272 - mae: 1.1199\n",
      "Epoch 182: val_loss improved from 1.35020 to 1.35016, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8448 - mse: 5.1424 - mae: 1.1213 - val_loss: 1.3502 - val_mse: 9.6174 - val_mae: 1.6684 - lr: 3.1250e-05\n",
      "Epoch 183/500\n",
      "1303/1315 [============================>.] - ETA: 0s - loss: 0.8433 - mse: 5.1245 - mae: 1.1196\n",
      "Epoch 183: val_loss improved from 1.35016 to 1.35012, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8448 - mse: 5.1419 - mae: 1.1213 - val_loss: 1.3501 - val_mse: 9.6175 - val_mae: 1.6683 - lr: 3.1250e-05\n",
      "Epoch 184/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8448 - mse: 5.1431 - mae: 1.1211\n",
      "Epoch 184: val_loss improved from 1.35012 to 1.35009, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8447 - mse: 5.1414 - mae: 1.1212 - val_loss: 1.3501 - val_mse: 9.6177 - val_mae: 1.6683 - lr: 3.1250e-05\n",
      "Epoch 185/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8447 - mse: 5.1426 - mae: 1.1211\n",
      "Epoch 185: val_loss improved from 1.35009 to 1.35004, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8446 - mse: 5.1410 - mae: 1.1211 - val_loss: 1.3500 - val_mse: 9.6177 - val_mae: 1.6683 - lr: 3.1250e-05\n",
      "Epoch 186/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8430 - mse: 5.1270 - mae: 1.1193\n",
      "Epoch 186: val_loss improved from 1.35004 to 1.35000, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8446 - mse: 5.1406 - mae: 1.1210 - val_loss: 1.3500 - val_mse: 9.6178 - val_mae: 1.6682 - lr: 3.1250e-05\n",
      "Epoch 187/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8445 - mse: 5.1401 - mae: 1.1209\n",
      "Epoch 187: val_loss improved from 1.35000 to 1.34998, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8445 - mse: 5.1401 - mae: 1.1209 - val_loss: 1.3500 - val_mse: 9.6180 - val_mae: 1.6682 - lr: 3.1250e-05\n",
      "Epoch 188/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8445 - mse: 5.1413 - mae: 1.1208\n",
      "Epoch 188: val_loss improved from 1.34998 to 1.34995, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8444 - mse: 5.1396 - mae: 1.1208 - val_loss: 1.3500 - val_mse: 9.6182 - val_mae: 1.6681 - lr: 3.1250e-05\n",
      "Epoch 189/500\n",
      "1302/1315 [============================>.] - ETA: 0s - loss: 0.8430 - mse: 5.1240 - mae: 1.1193\n",
      "Epoch 189: val_loss improved from 1.34995 to 1.34991, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8443 - mse: 5.1392 - mae: 1.1208 - val_loss: 1.3499 - val_mse: 9.6183 - val_mae: 1.6681 - lr: 3.1250e-05\n",
      "Epoch 190/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8441 - mse: 5.1401 - mae: 1.1205\n",
      "Epoch 190: val_loss improved from 1.34991 to 1.34987, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8443 - mse: 5.1387 - mae: 1.1207 - val_loss: 1.3499 - val_mse: 9.6185 - val_mae: 1.6680 - lr: 3.1250e-05\n",
      "Epoch 191/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8424 - mse: 5.1179 - mae: 1.1186\n",
      "Epoch 191: val_loss improved from 1.34987 to 1.34982, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8442 - mse: 5.1383 - mae: 1.1206 - val_loss: 1.3498 - val_mse: 9.6186 - val_mae: 1.6680 - lr: 3.1250e-05\n",
      "Epoch 192/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8442 - mse: 5.1389 - mae: 1.1206\n",
      "Epoch 192: val_loss improved from 1.34982 to 1.34979, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8441 - mse: 5.1378 - mae: 1.1205 - val_loss: 1.3498 - val_mse: 9.6188 - val_mae: 1.6679 - lr: 3.1250e-05\n",
      "Epoch 193/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8425 - mse: 5.1238 - mae: 1.1188\n",
      "Epoch 193: val_loss improved from 1.34979 to 1.34978, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8441 - mse: 5.1374 - mae: 1.1204 - val_loss: 1.3498 - val_mse: 9.6190 - val_mae: 1.6679 - lr: 3.1250e-05\n",
      "Epoch 194/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8422 - mse: 5.1165 - mae: 1.1184\n",
      "Epoch 194: val_loss improved from 1.34978 to 1.34974, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8440 - mse: 5.1369 - mae: 1.1204 - val_loss: 1.3497 - val_mse: 9.6192 - val_mae: 1.6679 - lr: 3.1250e-05\n",
      "Epoch 195/500\n",
      "1300/1315 [============================>.] - ETA: 0s - loss: 0.8433 - mse: 5.1250 - mae: 1.1195\n",
      "Epoch 195: val_loss improved from 1.34974 to 1.34973, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8439 - mse: 5.1365 - mae: 1.1203 - val_loss: 1.3497 - val_mse: 9.6194 - val_mae: 1.6678 - lr: 3.1250e-05\n",
      "Epoch 196/500\n",
      "1307/1315 [============================>.] - ETA: 0s - loss: 0.8428 - mse: 5.1268 - mae: 1.1190\n",
      "Epoch 196: val_loss improved from 1.34973 to 1.34969, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8439 - mse: 5.1360 - mae: 1.1202 - val_loss: 1.3497 - val_mse: 9.6196 - val_mae: 1.6678 - lr: 3.1250e-05\n",
      "Epoch 197/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8439 - mse: 5.1391 - mae: 1.1202\n",
      "Epoch 197: val_loss did not improve from 1.34969\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8438 - mse: 5.1356 - mae: 1.1201 - val_loss: 1.3497 - val_mse: 9.6199 - val_mae: 1.6678 - lr: 3.1250e-05\n",
      "Epoch 198/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8419 - mse: 5.1147 - mae: 1.1180\n",
      "Epoch 198: val_loss improved from 1.34969 to 1.34967, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8437 - mse: 5.1352 - mae: 1.1200 - val_loss: 1.3497 - val_mse: 9.6201 - val_mae: 1.6677 - lr: 3.1250e-05\n",
      "Epoch 199/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8438 - mse: 5.1374 - mae: 1.1201\n",
      "Epoch 199: val_loss improved from 1.34967 to 1.34964, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8436 - mse: 5.1347 - mae: 1.1199 - val_loss: 1.3496 - val_mse: 9.6204 - val_mae: 1.6677 - lr: 3.1250e-05\n",
      "Epoch 200/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8433 - mse: 5.1326 - mae: 1.1196\n",
      "Epoch 200: val_loss improved from 1.34964 to 1.34964, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8436 - mse: 5.1343 - mae: 1.1199 - val_loss: 1.3496 - val_mse: 9.6207 - val_mae: 1.6677 - lr: 3.1250e-05\n",
      "Epoch 201/500\n",
      "1301/1315 [============================>.] - ETA: 0s - loss: 0.8427 - mse: 5.1221 - mae: 1.1188\n",
      "Epoch 201: val_loss improved from 1.34964 to 1.34964, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8435 - mse: 5.1338 - mae: 1.1198 - val_loss: 1.3496 - val_mse: 9.6210 - val_mae: 1.6677 - lr: 3.1250e-05\n",
      "Epoch 202/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8414 - mse: 5.1105 - mae: 1.1174\n",
      "Epoch 202: val_loss improved from 1.34964 to 1.34962, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8434 - mse: 5.1334 - mae: 1.1197 - val_loss: 1.3496 - val_mse: 9.6214 - val_mae: 1.6676 - lr: 3.1250e-05\n",
      "Epoch 203/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8419 - mse: 5.1194 - mae: 1.1179\n",
      "Epoch 203: val_loss did not improve from 1.34962\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8434 - mse: 5.1329 - mae: 1.1196 - val_loss: 1.3496 - val_mse: 9.6216 - val_mae: 1.6676 - lr: 3.1250e-05\n",
      "Epoch 204/500\n",
      "1303/1315 [============================>.] - ETA: 0s - loss: 0.8418 - mse: 5.1150 - mae: 1.1179\n",
      "Epoch 204: val_loss improved from 1.34962 to 1.34961, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8433 - mse: 5.1325 - mae: 1.1195 - val_loss: 1.3496 - val_mse: 9.6220 - val_mae: 1.6676 - lr: 3.1250e-05\n",
      "Epoch 205/500\n",
      "1307/1315 [============================>.] - ETA: 0s - loss: 0.8422 - mse: 5.1228 - mae: 1.1183\n",
      "Epoch 205: val_loss improved from 1.34961 to 1.34960, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8432 - mse: 5.1321 - mae: 1.1195 - val_loss: 1.3496 - val_mse: 9.6224 - val_mae: 1.6676 - lr: 3.1250e-05\n",
      "Epoch 206/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8433 - mse: 5.1351 - mae: 1.1195\n",
      "Epoch 206: val_loss improved from 1.34960 to 1.34960, saving model to base_stne_rnn_weight_ns.h5\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8432 - mse: 5.1316 - mae: 1.1194 - val_loss: 1.3496 - val_mse: 9.6226 - val_mae: 1.6676 - lr: 3.1250e-05\n",
      "Epoch 207/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8585 - mse: 5.1919 - mae: 1.1374\n",
      "Epoch 207: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 6s 5ms/step - loss: 0.8601 - mse: 5.2115 - mae: 1.1391 - val_loss: 1.3591 - val_mse: 9.7317 - val_mae: 1.6762 - lr: 1.5625e-05\n",
      "Epoch 208/500\n",
      "1301/1315 [============================>.] - ETA: 0s - loss: 0.8570 - mse: 5.1900 - mae: 1.1356\n",
      "Epoch 208: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8577 - mse: 5.2013 - mae: 1.1364 - val_loss: 1.3598 - val_mse: 9.7413 - val_mae: 1.6773 - lr: 1.5625e-05\n",
      "Epoch 209/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8573 - mse: 5.2004 - mae: 1.1358\n",
      "Epoch 209: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8572 - mse: 5.1993 - mae: 1.1357 - val_loss: 1.3599 - val_mse: 9.7440 - val_mae: 1.6775 - lr: 1.5625e-05\n",
      "Epoch 210/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8569 - mse: 5.1996 - mae: 1.1353\n",
      "Epoch 210: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8568 - mse: 5.1977 - mae: 1.1353 - val_loss: 1.3598 - val_mse: 9.7451 - val_mae: 1.6775 - lr: 1.5625e-05\n",
      "Epoch 211/500\n",
      "1307/1315 [============================>.] - ETA: 0s - loss: 0.8557 - mse: 5.1878 - mae: 1.1340\n",
      "Epoch 211: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 6s 4ms/step - loss: 0.8565 - mse: 5.1963 - mae: 1.1349 - val_loss: 1.3598 - val_mse: 9.7460 - val_mae: 1.6775 - lr: 1.5625e-05\n",
      "Epoch 212/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8543 - mse: 5.1732 - mae: 1.1326\n",
      "Epoch 212: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8562 - mse: 5.1950 - mae: 1.1346 - val_loss: 1.3599 - val_mse: 9.7469 - val_mae: 1.6776 - lr: 1.5625e-05\n",
      "Epoch 213/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8558 - mse: 5.1922 - mae: 1.1341\n",
      "Epoch 213: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8560 - mse: 5.1939 - mae: 1.1343 - val_loss: 1.3599 - val_mse: 9.7477 - val_mae: 1.6776 - lr: 1.5625e-05\n",
      "Epoch 214/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8554 - mse: 5.1911 - mae: 1.1336\n",
      "Epoch 214: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8558 - mse: 5.1930 - mae: 1.1341 - val_loss: 1.3600 - val_mse: 9.7486 - val_mae: 1.6777 - lr: 1.5625e-05\n",
      "Epoch 215/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8558 - mse: 5.1939 - mae: 1.1341\n",
      "Epoch 215: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8556 - mse: 5.1922 - mae: 1.1339 - val_loss: 1.3600 - val_mse: 9.7495 - val_mae: 1.6778 - lr: 1.5625e-05\n",
      "Epoch 216/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8555 - mse: 5.1932 - mae: 1.1337\n",
      "Epoch 216: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8555 - mse: 5.1914 - mae: 1.1337 - val_loss: 1.3601 - val_mse: 9.7503 - val_mae: 1.6779 - lr: 1.5625e-05\n",
      "Epoch 217/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8690 - mse: 5.2547 - mae: 1.1492\n",
      "Epoch 217: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8689 - mse: 5.2526 - mae: 1.1492 - val_loss: 1.3803 - val_mse: 9.9004 - val_mae: 1.6999 - lr: 7.8125e-06\n",
      "Epoch 218/500\n",
      "1300/1315 [============================>.] - ETA: 0s - loss: 0.8664 - mse: 5.2272 - mae: 1.1463\n",
      "Epoch 218: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8670 - mse: 5.2372 - mae: 1.1470 - val_loss: 1.3830 - val_mse: 9.9274 - val_mae: 1.7036 - lr: 7.8125e-06\n",
      "Epoch 219/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8647 - mse: 5.2149 - mae: 1.1443\n",
      "Epoch 219: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8663 - mse: 5.2334 - mae: 1.1460 - val_loss: 1.3838 - val_mse: 9.9364 - val_mae: 1.7046 - lr: 7.8125e-06\n",
      "Epoch 220/500\n",
      "1302/1315 [============================>.] - ETA: 0s - loss: 0.8646 - mse: 5.2176 - mae: 1.1440\n",
      "Epoch 220: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8658 - mse: 5.2315 - mae: 1.1454 - val_loss: 1.3842 - val_mse: 9.9407 - val_mae: 1.7051 - lr: 7.8125e-06\n",
      "Epoch 221/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8636 - mse: 5.2094 - mae: 1.1428\n",
      "Epoch 221: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8654 - mse: 5.2301 - mae: 1.1449 - val_loss: 1.3843 - val_mse: 9.9431 - val_mae: 1.7053 - lr: 7.8125e-06\n",
      "Epoch 222/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8636 - mse: 5.2106 - mae: 1.1428\n",
      "Epoch 222: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8652 - mse: 5.2290 - mae: 1.1445 - val_loss: 1.3845 - val_mse: 9.9448 - val_mae: 1.7054 - lr: 7.8125e-06\n",
      "Epoch 223/500\n",
      "1300/1315 [============================>.] - ETA: 0s - loss: 0.8643 - mse: 5.2181 - mae: 1.1435\n",
      "Epoch 223: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8649 - mse: 5.2281 - mae: 1.1442 - val_loss: 1.3845 - val_mse: 9.9462 - val_mae: 1.7055 - lr: 7.8125e-06\n",
      "Epoch 224/500\n",
      "1304/1315 [============================>.] - ETA: 0s - loss: 0.8631 - mse: 5.2088 - mae: 1.1422\n",
      "Epoch 224: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8647 - mse: 5.2272 - mae: 1.1440 - val_loss: 1.3846 - val_mse: 9.9472 - val_mae: 1.7056 - lr: 7.8125e-06\n",
      "Epoch 225/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8648 - mse: 5.2300 - mae: 1.1439\n",
      "Epoch 225: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8646 - mse: 5.2264 - mae: 1.1437 - val_loss: 1.3846 - val_mse: 9.9479 - val_mae: 1.7056 - lr: 7.8125e-06\n",
      "Epoch 226/500\n",
      "1305/1315 [============================>.] - ETA: 0s - loss: 0.8625 - mse: 5.2049 - mae: 1.1414\n",
      "Epoch 226: val_loss did not improve from 1.34960\n",
      "1315/1315 [==============================] - 5s 4ms/step - loss: 0.8644 - mse: 5.2257 - mae: 1.1435 - val_loss: 1.3847 - val_mse: 9.9485 - val_mae: 1.7056 - lr: 7.8125e-06\n"
     ]
    }
   ],
   "source": [
    "rnn_history = rnn_model.fit(train_data, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_rnn])\n",
    "rnn_history_ns = rnn_model.fit(train_data_ns, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_rnn_ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1313/Unknown - 19s 7ms/step - loss: 1.6432 - mse: 17.3789 - mae: 1.9600\n",
      "Epoch 1: val_loss improved from inf to 2.15691, saving model to base_stne_gru_weight.h5\n",
      "1315/1315 [==============================] - 23s 10ms/step - loss: 1.6430 - mse: 17.3735 - mae: 1.9597 - val_loss: 2.1569 - val_mse: 18.5380 - val_mae: 2.4811 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 1.0061 - mse: 6.2016 - mae: 1.3052\n",
      "Epoch 2: val_loss improved from 2.15691 to 1.50120, saving model to base_stne_gru_weight.h5\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 1.0072 - mse: 6.2121 - mae: 1.3065 - val_loss: 1.5012 - val_mse: 10.8621 - val_mae: 1.8479 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.9779 - mse: 6.0502 - mae: 1.2711\n",
      "Epoch 3: val_loss improved from 1.50120 to 1.45537, saving model to base_stne_gru_weight.h5\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.9780 - mse: 6.0507 - mae: 1.2712 - val_loss: 1.4554 - val_mse: 10.7657 - val_mae: 1.7823 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.9601 - mse: 5.8889 - mae: 1.2489\n",
      "Epoch 4: val_loss did not improve from 1.45537\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.9611 - mse: 5.9002 - mae: 1.2500 - val_loss: 1.8562 - val_mse: 14.7759 - val_mae: 2.1925 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.9505 - mse: 5.8561 - mae: 1.2376\n",
      "Epoch 5: val_loss did not improve from 1.45537\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.9516 - mse: 5.8635 - mae: 1.2388 - val_loss: 1.5713 - val_mse: 12.1589 - val_mae: 1.9014 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.9514 - mse: 5.8770 - mae: 1.2398\n",
      "Epoch 6: val_loss did not improve from 1.45537\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.9524 - mse: 5.8853 - mae: 1.2409 - val_loss: 1.6834 - val_mse: 13.2426 - val_mae: 2.0032 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.9394 - mse: 5.8168 - mae: 1.2231\n",
      "Epoch 7: val_loss did not improve from 1.45537\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.9401 - mse: 5.8242 - mae: 1.2240 - val_loss: 1.5589 - val_mse: 11.3662 - val_mae: 1.8877 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.9402 - mse: 5.8131 - mae: 1.2257\n",
      "Epoch 8: val_loss did not improve from 1.45537\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.9413 - mse: 5.8200 - mae: 1.2268 - val_loss: 1.6617 - val_mse: 13.2933 - val_mae: 1.9764 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.9292 - mse: 5.7329 - mae: 1.2133\n",
      "Epoch 9: val_loss did not improve from 1.45537\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.9304 - mse: 5.7422 - mae: 1.2146 - val_loss: 1.4595 - val_mse: 10.9882 - val_mae: 1.7673 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.9276 - mse: 5.7397 - mae: 1.2101\n",
      "Epoch 10: val_loss improved from 1.45537 to 1.42993, saving model to base_stne_gru_weight.h5\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.9295 - mse: 5.7552 - mae: 1.2123 - val_loss: 1.4299 - val_mse: 10.4169 - val_mae: 1.7636 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.9201 - mse: 5.6676 - mae: 1.2013\n",
      "Epoch 11: val_loss did not improve from 1.42993\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.9223 - mse: 5.6940 - mae: 1.2035 - val_loss: 1.6798 - val_mse: 13.0218 - val_mae: 1.9927 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.9210 - mse: 5.7035 - mae: 1.2033\n",
      "Epoch 12: val_loss improved from 1.42993 to 1.39688, saving model to base_stne_gru_weight.h5\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.9220 - mse: 5.7094 - mae: 1.2044 - val_loss: 1.3969 - val_mse: 10.0597 - val_mae: 1.7207 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.9304 - mse: 5.7889 - mae: 1.2122\n",
      "Epoch 13: val_loss did not improve from 1.39688\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.9304 - mse: 5.7889 - mae: 1.2122 - val_loss: 1.5296 - val_mse: 11.5243 - val_mae: 1.8409 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.9183 - mse: 5.6882 - mae: 1.1987\n",
      "Epoch 14: val_loss did not improve from 1.39688\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.9212 - mse: 5.7214 - mae: 1.2018 - val_loss: 1.5560 - val_mse: 11.2980 - val_mae: 1.8843 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.9136 - mse: 5.6179 - mae: 1.1940\n",
      "Epoch 15: val_loss did not improve from 1.39688\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.9186 - mse: 5.6654 - mae: 1.1992 - val_loss: 1.5050 - val_mse: 11.0474 - val_mae: 1.8203 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.9123 - mse: 5.6144 - mae: 1.1909\n",
      "Epoch 16: val_loss did not improve from 1.39688\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.9129 - mse: 5.6176 - mae: 1.1916 - val_loss: 1.4646 - val_mse: 10.4803 - val_mae: 1.7803 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.9142 - mse: 5.6630 - mae: 1.1939\n",
      "Epoch 17: val_loss did not improve from 1.39688\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.9160 - mse: 5.6770 - mae: 1.1958 - val_loss: 1.5806 - val_mse: 11.6372 - val_mae: 1.8955 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.9175 - mse: 5.6577 - mae: 1.1958\n",
      "Epoch 18: val_loss did not improve from 1.39688\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.9186 - mse: 5.6688 - mae: 1.1969 - val_loss: 1.6271 - val_mse: 11.7924 - val_mae: 1.9460 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.9138 - mse: 5.6322 - mae: 1.1922\n",
      "Epoch 19: val_loss did not improve from 1.39688\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.9141 - mse: 5.6390 - mae: 1.1925 - val_loss: 1.4205 - val_mse: 10.1705 - val_mae: 1.7379 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "1307/1315 [============================>.] - ETA: 0s - loss: 0.9131 - mse: 5.6271 - mae: 1.1922\n",
      "Epoch 20: val_loss did not improve from 1.39688\n",
      "1315/1315 [==============================] - 9s 7ms/step - loss: 0.9163 - mse: 5.6658 - mae: 1.1955 - val_loss: 1.4203 - val_mse: 10.2677 - val_mae: 1.7414 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.9095 - mse: 5.5938 - mae: 1.1879\n",
      "Epoch 21: val_loss improved from 1.39688 to 1.38976, saving model to base_stne_gru_weight.h5\n",
      "1315/1315 [==============================] - 10s 7ms/step - loss: 0.9112 - mse: 5.6150 - mae: 1.1898 - val_loss: 1.3898 - val_mse: 10.1099 - val_mae: 1.7068 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.9079 - mse: 5.6180 - mae: 1.1852\n",
      "Epoch 22: val_loss did not improve from 1.38976\n",
      "1315/1315 [==============================] - 10s 7ms/step - loss: 0.9077 - mse: 5.6167 - mae: 1.1851 - val_loss: 1.5303 - val_mse: 11.3944 - val_mae: 1.8509 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.9157 - mse: 5.6143 - mae: 1.1949\n",
      "Epoch 23: val_loss did not improve from 1.38976\n",
      "1315/1315 [==============================] - 10s 7ms/step - loss: 0.9157 - mse: 5.6143 - mae: 1.1949 - val_loss: 1.4693 - val_mse: 10.5551 - val_mae: 1.7961 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.9126 - mse: 5.6475 - mae: 1.1903\n",
      "Epoch 24: val_loss did not improve from 1.38976\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.9126 - mse: 5.6469 - mae: 1.1903 - val_loss: 1.4364 - val_mse: 10.3271 - val_mae: 1.7474 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.9030 - mse: 5.5502 - mae: 1.1793\n",
      "Epoch 25: val_loss did not improve from 1.38976\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.9041 - mse: 5.5638 - mae: 1.1804 - val_loss: 1.5371 - val_mse: 11.2080 - val_mae: 1.8491 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.9038 - mse: 5.5563 - mae: 1.1806\n",
      "Epoch 26: val_loss improved from 1.38976 to 1.36908, saving model to base_stne_gru_weight.h5\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.9038 - mse: 5.5563 - mae: 1.1806 - val_loss: 1.3691 - val_mse: 9.9523 - val_mae: 1.6785 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.9009 - mse: 5.5556 - mae: 1.1769\n",
      "Epoch 27: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.9023 - mse: 5.5711 - mae: 1.1783 - val_loss: 1.4432 - val_mse: 10.5389 - val_mae: 1.7561 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.9038 - mse: 5.5844 - mae: 1.1796\n",
      "Epoch 28: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 10s 7ms/step - loss: 0.9039 - mse: 5.5851 - mae: 1.1798 - val_loss: 1.4047 - val_mse: 10.1156 - val_mae: 1.7201 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.9010 - mse: 5.5646 - mae: 1.1775\n",
      "Epoch 29: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 10s 7ms/step - loss: 0.9010 - mse: 5.5646 - mae: 1.1775 - val_loss: 1.4211 - val_mse: 10.2887 - val_mae: 1.7326 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.9026 - mse: 5.5681 - mae: 1.1789\n",
      "Epoch 30: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 10s 7ms/step - loss: 0.9026 - mse: 5.5681 - mae: 1.1789 - val_loss: 1.5217 - val_mse: 10.9155 - val_mae: 1.8419 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.9043 - mse: 5.5592 - mae: 1.1807\n",
      "Epoch 31: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 10s 7ms/step - loss: 0.9051 - mse: 5.5688 - mae: 1.1815 - val_loss: 1.4117 - val_mse: 10.2167 - val_mae: 1.7330 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8973 - mse: 5.5400 - mae: 1.1732\n",
      "Epoch 32: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8977 - mse: 5.5401 - mae: 1.1736 - val_loss: 1.4653 - val_mse: 10.8797 - val_mae: 1.7840 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8993 - mse: 5.5316 - mae: 1.1754\n",
      "Epoch 33: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8992 - mse: 5.5317 - mae: 1.1753 - val_loss: 1.3989 - val_mse: 10.2413 - val_mae: 1.7211 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.9019 - mse: 5.5383 - mae: 1.1778\n",
      "Epoch 34: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.9032 - mse: 5.5502 - mae: 1.1792 - val_loss: 1.4499 - val_mse: 10.3828 - val_mae: 1.7678 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8944 - mse: 5.4933 - mae: 1.1693\n",
      "Epoch 35: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8967 - mse: 5.5193 - mae: 1.1716 - val_loss: 1.5052 - val_mse: 10.9750 - val_mae: 1.8280 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8957 - mse: 5.4944 - mae: 1.1714\n",
      "Epoch 36: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8962 - mse: 5.5033 - mae: 1.1720 - val_loss: 1.4071 - val_mse: 10.2768 - val_mae: 1.7209 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8792 - mse: 5.3874 - mae: 1.1552\n",
      "Epoch 37: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8823 - mse: 5.4173 - mae: 1.1585 - val_loss: 1.3907 - val_mse: 9.9870 - val_mae: 1.7054 - lr: 5.0000e-04\n",
      "Epoch 38/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8784 - mse: 5.3990 - mae: 1.1529\n",
      "Epoch 38: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8783 - mse: 5.3975 - mae: 1.1527 - val_loss: 1.4093 - val_mse: 10.1263 - val_mae: 1.7227 - lr: 5.0000e-04\n",
      "Epoch 39/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8768 - mse: 5.4028 - mae: 1.1512\n",
      "Epoch 39: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 10s 7ms/step - loss: 0.8772 - mse: 5.4056 - mae: 1.1517 - val_loss: 1.3803 - val_mse: 9.9248 - val_mae: 1.6963 - lr: 5.0000e-04\n",
      "Epoch 40/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8767 - mse: 5.3883 - mae: 1.1516\n",
      "Epoch 40: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 10s 7ms/step - loss: 0.8769 - mse: 5.3893 - mae: 1.1518 - val_loss: 1.4027 - val_mse: 10.0261 - val_mae: 1.7165 - lr: 5.0000e-04\n",
      "Epoch 41/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8708 - mse: 5.3447 - mae: 1.1446\n",
      "Epoch 41: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8709 - mse: 5.3460 - mae: 1.1447 - val_loss: 1.3896 - val_mse: 9.9016 - val_mae: 1.7039 - lr: 5.0000e-04\n",
      "Epoch 42/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8743 - mse: 5.4019 - mae: 1.1478\n",
      "Epoch 42: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8743 - mse: 5.4019 - mae: 1.1478 - val_loss: 1.3920 - val_mse: 9.9741 - val_mae: 1.7097 - lr: 5.0000e-04\n",
      "Epoch 43/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8698 - mse: 5.3522 - mae: 1.1433\n",
      "Epoch 43: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8698 - mse: 5.3522 - mae: 1.1433 - val_loss: 1.3703 - val_mse: 9.8905 - val_mae: 1.6868 - lr: 5.0000e-04\n",
      "Epoch 44/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8715 - mse: 5.3660 - mae: 1.1441\n",
      "Epoch 44: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8715 - mse: 5.3660 - mae: 1.1441 - val_loss: 1.3892 - val_mse: 9.9286 - val_mae: 1.7040 - lr: 5.0000e-04\n",
      "Epoch 45/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8730 - mse: 5.3832 - mae: 1.1461\n",
      "Epoch 45: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 0.8730 - mse: 5.3832 - mae: 1.1461 - val_loss: 1.4001 - val_mse: 9.9402 - val_mae: 1.7154 - lr: 5.0000e-04\n",
      "Epoch 46/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8686 - mse: 5.3520 - mae: 1.1410\n",
      "Epoch 46: val_loss did not improve from 1.36908\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8695 - mse: 5.3600 - mae: 1.1420 - val_loss: 1.4046 - val_mse: 10.0836 - val_mae: 1.7211 - lr: 5.0000e-04\n",
      "Epoch 1/500\n",
      "   1313/Unknown - 9s 7ms/step - loss: 0.8611 - mse: 5.2883 - mae: 1.1358\n",
      "Epoch 1: val_loss improved from inf to 1.41865, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8611 - mse: 5.2871 - mae: 1.1358 - val_loss: 1.4187 - val_mse: 10.0982 - val_mae: 1.7318 - lr: 2.5000e-04\n",
      "Epoch 2/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8573 - mse: 5.2726 - mae: 1.1315\n",
      "Epoch 2: val_loss did not improve from 1.41865\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8576 - mse: 5.2724 - mae: 1.1319 - val_loss: 1.4271 - val_mse: 10.1856 - val_mae: 1.7381 - lr: 2.5000e-04\n",
      "Epoch 3/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8559 - mse: 5.2681 - mae: 1.1296\n",
      "Epoch 3: val_loss did not improve from 1.41865\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8560 - mse: 5.2663 - mae: 1.1298 - val_loss: 1.4336 - val_mse: 10.2568 - val_mae: 1.7463 - lr: 2.5000e-04\n",
      "Epoch 4/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8550 - mse: 5.2636 - mae: 1.1289\n",
      "Epoch 4: val_loss did not improve from 1.41865\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 0.8551 - mse: 5.2613 - mae: 1.1290 - val_loss: 1.4326 - val_mse: 10.2556 - val_mae: 1.7458 - lr: 2.5000e-04\n",
      "Epoch 5/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8541 - mse: 5.2590 - mae: 1.1279\n",
      "Epoch 5: val_loss did not improve from 1.41865\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8541 - mse: 5.2568 - mae: 1.1280 - val_loss: 1.4302 - val_mse: 10.2402 - val_mae: 1.7437 - lr: 2.5000e-04\n",
      "Epoch 6/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8527 - mse: 5.2497 - mae: 1.1259\n",
      "Epoch 6: val_loss did not improve from 1.41865\n",
      "1315/1315 [==============================] - 10s 7ms/step - loss: 0.8529 - mse: 5.2510 - mae: 1.1262 - val_loss: 1.4342 - val_mse: 10.2817 - val_mae: 1.7495 - lr: 2.5000e-04\n",
      "Epoch 7/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8523 - mse: 5.2520 - mae: 1.1255\n",
      "Epoch 7: val_loss did not improve from 1.41865\n",
      "1315/1315 [==============================] - 10s 7ms/step - loss: 0.8523 - mse: 5.2499 - mae: 1.1257 - val_loss: 1.4351 - val_mse: 10.2902 - val_mae: 1.7502 - lr: 2.5000e-04\n",
      "Epoch 8/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8519 - mse: 5.2472 - mae: 1.1250\n",
      "Epoch 8: val_loss did not improve from 1.41865\n",
      "1315/1315 [==============================] - 10s 7ms/step - loss: 0.8519 - mse: 5.2472 - mae: 1.1250 - val_loss: 1.4348 - val_mse: 10.2853 - val_mae: 1.7505 - lr: 2.5000e-04\n",
      "Epoch 9/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8508 - mse: 5.2450 - mae: 1.1237\n",
      "Epoch 9: val_loss did not improve from 1.41865\n",
      "1315/1315 [==============================] - 10s 7ms/step - loss: 0.8508 - mse: 5.2410 - mae: 1.1238 - val_loss: 1.4315 - val_mse: 10.2519 - val_mae: 1.7471 - lr: 2.5000e-04\n",
      "Epoch 10/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8501 - mse: 5.2390 - mae: 1.1227\n",
      "Epoch 10: val_loss did not improve from 1.41865\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8501 - mse: 5.2378 - mae: 1.1227 - val_loss: 1.4322 - val_mse: 10.2622 - val_mae: 1.7477 - lr: 2.5000e-04\n",
      "Epoch 11/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8495 - mse: 5.2368 - mae: 1.1218\n",
      "Epoch 11: val_loss did not improve from 1.41865\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8495 - mse: 5.2357 - mae: 1.1218 - val_loss: 1.4324 - val_mse: 10.2522 - val_mae: 1.7486 - lr: 2.5000e-04\n",
      "Epoch 12/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8588 - mse: 5.2655 - mae: 1.1340\n",
      "Epoch 12: val_loss did not improve from 1.41865\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8591 - mse: 5.2672 - mae: 1.1343 - val_loss: 1.4196 - val_mse: 10.1511 - val_mae: 1.7307 - lr: 1.2500e-04\n",
      "Epoch 13/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8549 - mse: 5.2515 - mae: 1.1291\n",
      "Epoch 13: val_loss did not improve from 1.41865\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8553 - mse: 5.2517 - mae: 1.1295 - val_loss: 1.4190 - val_mse: 10.1471 - val_mae: 1.7296 - lr: 1.2500e-04\n",
      "Epoch 14/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8540 - mse: 5.2455 - mae: 1.1278\n",
      "Epoch 14: val_loss improved from 1.41865 to 1.41765, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 10s 7ms/step - loss: 0.8540 - mse: 5.2446 - mae: 1.1278 - val_loss: 1.4177 - val_mse: 10.1337 - val_mae: 1.7283 - lr: 1.2500e-04\n",
      "Epoch 15/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8528 - mse: 5.2399 - mae: 1.1262\n",
      "Epoch 15: val_loss improved from 1.41765 to 1.41589, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8528 - mse: 5.2380 - mae: 1.1263 - val_loss: 1.4159 - val_mse: 10.1166 - val_mae: 1.7265 - lr: 1.2500e-04\n",
      "Epoch 16/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8519 - mse: 5.2345 - mae: 1.1251\n",
      "Epoch 16: val_loss improved from 1.41589 to 1.41312, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 0.8518 - mse: 5.2322 - mae: 1.1251 - val_loss: 1.4131 - val_mse: 10.0955 - val_mae: 1.7237 - lr: 1.2500e-04\n",
      "Epoch 17/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8507 - mse: 5.2249 - mae: 1.1238\n",
      "Epoch 17: val_loss improved from 1.41312 to 1.41055, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 0.8509 - mse: 5.2267 - mae: 1.1240 - val_loss: 1.4106 - val_mse: 10.0752 - val_mae: 1.7210 - lr: 1.2500e-04\n",
      "Epoch 18/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8499 - mse: 5.2221 - mae: 1.1226\n",
      "Epoch 18: val_loss improved from 1.41055 to 1.40890, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8501 - mse: 5.2216 - mae: 1.1230 - val_loss: 1.4089 - val_mse: 10.0613 - val_mae: 1.7196 - lr: 1.2500e-04\n",
      "Epoch 19/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8494 - mse: 5.2188 - mae: 1.1220\n",
      "Epoch 19: val_loss improved from 1.40890 to 1.40751, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8494 - mse: 5.2168 - mae: 1.1221 - val_loss: 1.4075 - val_mse: 10.0490 - val_mae: 1.7183 - lr: 1.2500e-04\n",
      "Epoch 20/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8487 - mse: 5.2146 - mae: 1.1211\n",
      "Epoch 20: val_loss improved from 1.40751 to 1.40552, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8487 - mse: 5.2122 - mae: 1.1211 - val_loss: 1.4055 - val_mse: 10.0369 - val_mae: 1.7164 - lr: 1.2500e-04\n",
      "Epoch 21/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8482 - mse: 5.2104 - mae: 1.1204\n",
      "Epoch 21: val_loss improved from 1.40552 to 1.40449, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8481 - mse: 5.2080 - mae: 1.1204 - val_loss: 1.4045 - val_mse: 10.0264 - val_mae: 1.7154 - lr: 1.2500e-04\n",
      "Epoch 22/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8475 - mse: 5.2045 - mae: 1.1197\n",
      "Epoch 22: val_loss improved from 1.40449 to 1.40375, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8475 - mse: 5.2037 - mae: 1.1197 - val_loss: 1.4037 - val_mse: 10.0218 - val_mae: 1.7146 - lr: 1.2500e-04\n",
      "Epoch 23/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8465 - mse: 5.1975 - mae: 1.1185\n",
      "Epoch 23: val_loss improved from 1.40375 to 1.40136, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8468 - mse: 5.1994 - mae: 1.1188 - val_loss: 1.4014 - val_mse: 10.0102 - val_mae: 1.7122 - lr: 1.2500e-04\n",
      "Epoch 24/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8460 - mse: 5.1965 - mae: 1.1179\n",
      "Epoch 24: val_loss did not improve from 1.40136\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8463 - mse: 5.1954 - mae: 1.1182 - val_loss: 1.4023 - val_mse: 10.0166 - val_mae: 1.7133 - lr: 1.2500e-04\n",
      "Epoch 25/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8458 - mse: 5.1927 - mae: 1.1176\n",
      "Epoch 25: val_loss did not improve from 1.40136\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8457 - mse: 5.1918 - mae: 1.1176 - val_loss: 1.4034 - val_mse: 10.0264 - val_mae: 1.7146 - lr: 1.2500e-04\n",
      "Epoch 26/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8450 - mse: 5.1864 - mae: 1.1168\n",
      "Epoch 26: val_loss did not improve from 1.40136\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8453 - mse: 5.1883 - mae: 1.1171 - val_loss: 1.4045 - val_mse: 10.0338 - val_mae: 1.7156 - lr: 1.2500e-04\n",
      "Epoch 27/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8448 - mse: 5.1887 - mae: 1.1164\n",
      "Epoch 27: val_loss did not improve from 1.40136\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8447 - mse: 5.1850 - mae: 1.1164 - val_loss: 1.4040 - val_mse: 10.0320 - val_mae: 1.7149 - lr: 1.2500e-04\n",
      "Epoch 28/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8440 - mse: 5.1823 - mae: 1.1156\n",
      "Epoch 28: val_loss did not improve from 1.40136\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 0.8442 - mse: 5.1814 - mae: 1.1159 - val_loss: 1.4056 - val_mse: 10.0441 - val_mae: 1.7167 - lr: 1.2500e-04\n",
      "Epoch 29/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8434 - mse: 5.1790 - mae: 1.1150\n",
      "Epoch 29: val_loss did not improve from 1.40136\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 0.8437 - mse: 5.1780 - mae: 1.1153 - val_loss: 1.4062 - val_mse: 10.0502 - val_mae: 1.7171 - lr: 1.2500e-04\n",
      "Epoch 30/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8432 - mse: 5.1778 - mae: 1.1148\n",
      "Epoch 30: val_loss did not improve from 1.40136\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8431 - mse: 5.1754 - mae: 1.1147 - val_loss: 1.4068 - val_mse: 10.0554 - val_mae: 1.7177 - lr: 1.2500e-04\n",
      "Epoch 31/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8427 - mse: 5.1719 - mae: 1.1143\n",
      "Epoch 31: val_loss did not improve from 1.40136\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8427 - mse: 5.1719 - mae: 1.1143 - val_loss: 1.4089 - val_mse: 10.0718 - val_mae: 1.7198 - lr: 1.2500e-04\n",
      "Epoch 32/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8424 - mse: 5.1717 - mae: 1.1138\n",
      "Epoch 32: val_loss did not improve from 1.40136\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8423 - mse: 5.1693 - mae: 1.1137 - val_loss: 1.4088 - val_mse: 10.0737 - val_mae: 1.7195 - lr: 1.2500e-04\n",
      "Epoch 33/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8418 - mse: 5.1681 - mae: 1.1131\n",
      "Epoch 33: val_loss did not improve from 1.40136\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8418 - mse: 5.1660 - mae: 1.1132 - val_loss: 1.4099 - val_mse: 10.0815 - val_mae: 1.7207 - lr: 1.2500e-04\n",
      "Epoch 34/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8555 - mse: 5.2042 - mae: 1.1287\n",
      "Epoch 34: val_loss improved from 1.40136 to 1.36928, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 0.8553 - mse: 5.2013 - mae: 1.1285 - val_loss: 1.3693 - val_mse: 9.7758 - val_mae: 1.6795 - lr: 6.2500e-05\n",
      "Epoch 35/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8522 - mse: 5.1885 - mae: 1.1251\n",
      "Epoch 35: val_loss improved from 1.36928 to 1.36767, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8529 - mse: 5.1914 - mae: 1.1258 - val_loss: 1.3677 - val_mse: 9.7656 - val_mae: 1.6776 - lr: 6.2500e-05\n",
      "Epoch 36/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8511 - mse: 5.1839 - mae: 1.1237\n",
      "Epoch 36: val_loss improved from 1.36767 to 1.36680, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8517 - mse: 5.1867 - mae: 1.1244 - val_loss: 1.3668 - val_mse: 9.7624 - val_mae: 1.6766 - lr: 6.2500e-05\n",
      "Epoch 37/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8511 - mse: 5.1863 - mae: 1.1237\n",
      "Epoch 37: val_loss improved from 1.36680 to 1.36656, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8509 - mse: 5.1834 - mae: 1.1235 - val_loss: 1.3666 - val_mse: 9.7630 - val_mae: 1.6762 - lr: 6.2500e-05\n",
      "Epoch 38/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8500 - mse: 5.1816 - mae: 1.1224\n",
      "Epoch 38: val_loss improved from 1.36656 to 1.36624, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8501 - mse: 5.1801 - mae: 1.1225 - val_loss: 1.3662 - val_mse: 9.7629 - val_mae: 1.6756 - lr: 6.2500e-05\n",
      "Epoch 39/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8497 - mse: 5.1811 - mae: 1.1219\n",
      "Epoch 39: val_loss improved from 1.36624 to 1.36587, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8495 - mse: 5.1771 - mae: 1.1218 - val_loss: 1.3659 - val_mse: 9.7635 - val_mae: 1.6752 - lr: 6.2500e-05\n",
      "Epoch 40/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8491 - mse: 5.1785 - mae: 1.1213\n",
      "Epoch 40: val_loss did not improve from 1.36587\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8490 - mse: 5.1746 - mae: 1.1211 - val_loss: 1.3662 - val_mse: 9.7668 - val_mae: 1.6754 - lr: 6.2500e-05\n",
      "Epoch 41/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8485 - mse: 5.1721 - mae: 1.1206\n",
      "Epoch 41: val_loss did not improve from 1.36587\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8485 - mse: 5.1721 - mae: 1.1206 - val_loss: 1.3667 - val_mse: 9.7704 - val_mae: 1.6760 - lr: 6.2500e-05\n",
      "Epoch 42/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8481 - mse: 5.1720 - mae: 1.1201\n",
      "Epoch 42: val_loss did not improve from 1.36587\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8480 - mse: 5.1696 - mae: 1.1201 - val_loss: 1.3666 - val_mse: 9.7713 - val_mae: 1.6758 - lr: 6.2500e-05\n",
      "Epoch 43/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8469 - mse: 5.1641 - mae: 1.1187\n",
      "Epoch 43: val_loss did not improve from 1.36587\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8475 - mse: 5.1670 - mae: 1.1195 - val_loss: 1.3668 - val_mse: 9.7738 - val_mae: 1.6760 - lr: 6.2500e-05\n",
      "Epoch 44/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8473 - mse: 5.1676 - mae: 1.1192\n",
      "Epoch 44: val_loss did not improve from 1.36587\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8472 - mse: 5.1651 - mae: 1.1192 - val_loss: 1.3665 - val_mse: 9.7726 - val_mae: 1.6756 - lr: 6.2500e-05\n",
      "Epoch 45/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8467 - mse: 5.1643 - mae: 1.1185\n",
      "Epoch 45: val_loss did not improve from 1.36587\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8468 - mse: 5.1627 - mae: 1.1186 - val_loss: 1.3668 - val_mse: 9.7752 - val_mae: 1.6758 - lr: 6.2500e-05\n",
      "Epoch 46/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8464 - mse: 5.1627 - mae: 1.1182\n",
      "Epoch 46: val_loss did not improve from 1.36587\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8465 - mse: 5.1612 - mae: 1.1183 - val_loss: 1.3665 - val_mse: 9.7753 - val_mae: 1.6754 - lr: 6.2500e-05\n",
      "Epoch 47/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8460 - mse: 5.1605 - mae: 1.1177\n",
      "Epoch 47: val_loss did not improve from 1.36587\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8461 - mse: 5.1590 - mae: 1.1179 - val_loss: 1.3665 - val_mse: 9.7767 - val_mae: 1.6755 - lr: 6.2500e-05\n",
      "Epoch 48/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8459 - mse: 5.1597 - mae: 1.1176\n",
      "Epoch 48: val_loss did not improve from 1.36587\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8457 - mse: 5.1568 - mae: 1.1174 - val_loss: 1.3662 - val_mse: 9.7742 - val_mae: 1.6750 - lr: 6.2500e-05\n",
      "Epoch 49/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8454 - mse: 5.1550 - mae: 1.1170\n",
      "Epoch 49: val_loss did not improve from 1.36587\n",
      "1315/1315 [==============================] - 10s 8ms/step - loss: 0.8454 - mse: 5.1550 - mae: 1.1170 - val_loss: 1.3660 - val_mse: 9.7739 - val_mae: 1.6749 - lr: 6.2500e-05\n",
      "Epoch 50/500\n",
      "1306/1315 [============================>.] - ETA: 0s - loss: 0.8603 - mse: 5.2081 - mae: 1.1348\n",
      "Epoch 50: val_loss improved from 1.36587 to 1.34571, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 9s 7ms/step - loss: 0.8615 - mse: 5.2199 - mae: 1.1361 - val_loss: 1.3457 - val_mse: 9.6686 - val_mae: 1.6528 - lr: 3.1250e-05\n",
      "Epoch 51/500\n",
      "1308/1315 [============================>.] - ETA: 0s - loss: 0.8583 - mse: 5.2057 - mae: 1.1318\n",
      "Epoch 51: val_loss improved from 1.34571 to 1.34401, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 9s 7ms/step - loss: 0.8587 - mse: 5.2075 - mae: 1.1323 - val_loss: 1.3440 - val_mse: 9.6627 - val_mae: 1.6511 - lr: 3.1250e-05\n",
      "Epoch 52/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8572 - mse: 5.2025 - mae: 1.1306\n",
      "Epoch 52: val_loss improved from 1.34401 to 1.34294, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 9s 7ms/step - loss: 0.8574 - mse: 5.2040 - mae: 1.1308 - val_loss: 1.3429 - val_mse: 9.6586 - val_mae: 1.6498 - lr: 3.1250e-05\n",
      "Epoch 53/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8570 - mse: 5.2048 - mae: 1.1303\n",
      "Epoch 53: val_loss improved from 1.34294 to 1.34245, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 11s 8ms/step - loss: 0.8567 - mse: 5.2014 - mae: 1.1299 - val_loss: 1.3425 - val_mse: 9.6577 - val_mae: 1.6492 - lr: 3.1250e-05\n",
      "Epoch 54/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8564 - mse: 5.2026 - mae: 1.1296\n",
      "Epoch 54: val_loss improved from 1.34245 to 1.34201, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8561 - mse: 5.1992 - mae: 1.1292 - val_loss: 1.3420 - val_mse: 9.6571 - val_mae: 1.6487 - lr: 3.1250e-05\n",
      "Epoch 55/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8553 - mse: 5.1953 - mae: 1.1283\n",
      "Epoch 55: val_loss improved from 1.34201 to 1.34148, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 11s 9ms/step - loss: 0.8555 - mse: 5.1968 - mae: 1.1285 - val_loss: 1.3415 - val_mse: 9.6562 - val_mae: 1.6481 - lr: 3.1250e-05\n",
      "Epoch 56/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8554 - mse: 5.1992 - mae: 1.1282\n",
      "Epoch 56: val_loss improved from 1.34148 to 1.34075, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8550 - mse: 5.1949 - mae: 1.1279 - val_loss: 1.3408 - val_mse: 9.6547 - val_mae: 1.6473 - lr: 3.1250e-05\n",
      "Epoch 57/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8549 - mse: 5.1958 - mae: 1.1277\n",
      "Epoch 57: val_loss improved from 1.34075 to 1.34060, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8546 - mse: 5.1929 - mae: 1.1275 - val_loss: 1.3406 - val_mse: 9.6558 - val_mae: 1.6470 - lr: 3.1250e-05\n",
      "Epoch 58/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8544 - mse: 5.1940 - mae: 1.1271\n",
      "Epoch 58: val_loss improved from 1.34060 to 1.34024, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8543 - mse: 5.1914 - mae: 1.1270 - val_loss: 1.3402 - val_mse: 9.6556 - val_mae: 1.6465 - lr: 3.1250e-05\n",
      "Epoch 59/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8543 - mse: 5.1927 - mae: 1.1269\n",
      "Epoch 59: val_loss improved from 1.34024 to 1.34016, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8540 - mse: 5.1899 - mae: 1.1266 - val_loss: 1.3402 - val_mse: 9.6568 - val_mae: 1.6464 - lr: 3.1250e-05\n",
      "Epoch 60/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8539 - mse: 5.1912 - mae: 1.1265\n",
      "Epoch 60: val_loss improved from 1.34016 to 1.33978, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8536 - mse: 5.1883 - mae: 1.1262 - val_loss: 1.3398 - val_mse: 9.6560 - val_mae: 1.6459 - lr: 3.1250e-05\n",
      "Epoch 61/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8535 - mse: 5.1882 - mae: 1.1260\n",
      "Epoch 61: val_loss did not improve from 1.33978\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8533 - mse: 5.1870 - mae: 1.1259 - val_loss: 1.3398 - val_mse: 9.6574 - val_mae: 1.6459 - lr: 3.1250e-05\n",
      "Epoch 62/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8528 - mse: 5.1841 - mae: 1.1253\n",
      "Epoch 62: val_loss improved from 1.33978 to 1.33947, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 14s 10ms/step - loss: 0.8530 - mse: 5.1856 - mae: 1.1255 - val_loss: 1.3395 - val_mse: 9.6573 - val_mae: 1.6456 - lr: 3.1250e-05\n",
      "Epoch 63/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8529 - mse: 5.1854 - mae: 1.1253\n",
      "Epoch 63: val_loss did not improve from 1.33947\n",
      "1315/1315 [==============================] - 14s 11ms/step - loss: 0.8527 - mse: 5.1842 - mae: 1.1251 - val_loss: 1.3396 - val_mse: 9.6593 - val_mae: 1.6457 - lr: 3.1250e-05\n",
      "Epoch 64/500\n",
      "1311/1315 [============================>.] - ETA: 0s - loss: 0.8527 - mse: 5.1856 - mae: 1.1250\n",
      "Epoch 64: val_loss improved from 1.33947 to 1.33937, saving model to base_stne_gru_weight_ns.h5\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8524 - mse: 5.1828 - mae: 1.1248 - val_loss: 1.3394 - val_mse: 9.6594 - val_mae: 1.6455 - lr: 3.1250e-05\n",
      "Epoch 65/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8524 - mse: 5.1854 - mae: 1.1247\n",
      "Epoch 65: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 14s 11ms/step - loss: 0.8521 - mse: 5.1812 - mae: 1.1244 - val_loss: 1.3398 - val_mse: 9.6625 - val_mae: 1.6460 - lr: 3.1250e-05\n",
      "Epoch 66/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8521 - mse: 5.1842 - mae: 1.1244\n",
      "Epoch 66: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 14s 11ms/step - loss: 0.8518 - mse: 5.1800 - mae: 1.1241 - val_loss: 1.3395 - val_mse: 9.6625 - val_mae: 1.6457 - lr: 3.1250e-05\n",
      "Epoch 67/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8515 - mse: 5.1785 - mae: 1.1237\n",
      "Epoch 67: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8515 - mse: 5.1785 - mae: 1.1237 - val_loss: 1.3396 - val_mse: 9.6637 - val_mae: 1.6458 - lr: 3.1250e-05\n",
      "Epoch 68/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8514 - mse: 5.1785 - mae: 1.1236\n",
      "Epoch 68: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8513 - mse: 5.1773 - mae: 1.1234 - val_loss: 1.3395 - val_mse: 9.6639 - val_mae: 1.6457 - lr: 3.1250e-05\n",
      "Epoch 69/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8514 - mse: 5.1803 - mae: 1.1234\n",
      "Epoch 69: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8511 - mse: 5.1760 - mae: 1.1231 - val_loss: 1.3397 - val_mse: 9.6662 - val_mae: 1.6460 - lr: 3.1250e-05\n",
      "Epoch 70/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8510 - mse: 5.1759 - mae: 1.1230\n",
      "Epoch 70: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8508 - mse: 5.1747 - mae: 1.1229 - val_loss: 1.3395 - val_mse: 9.6659 - val_mae: 1.6458 - lr: 3.1250e-05\n",
      "Epoch 71/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8509 - mse: 5.1775 - mae: 1.1228\n",
      "Epoch 71: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8506 - mse: 5.1733 - mae: 1.1225 - val_loss: 1.3397 - val_mse: 9.6678 - val_mae: 1.6460 - lr: 3.1250e-05\n",
      "Epoch 72/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8506 - mse: 5.1763 - mae: 1.1226\n",
      "Epoch 72: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8503 - mse: 5.1721 - mae: 1.1223 - val_loss: 1.3396 - val_mse: 9.6674 - val_mae: 1.6458 - lr: 3.1250e-05\n",
      "Epoch 73/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8504 - mse: 5.1741 - mae: 1.1223\n",
      "Epoch 73: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8501 - mse: 5.1708 - mae: 1.1220 - val_loss: 1.3396 - val_mse: 9.6684 - val_mae: 1.6459 - lr: 3.1250e-05\n",
      "Epoch 74/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8502 - mse: 5.1728 - mae: 1.1221\n",
      "Epoch 74: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8499 - mse: 5.1695 - mae: 1.1217 - val_loss: 1.3398 - val_mse: 9.6701 - val_mae: 1.6460 - lr: 3.1250e-05\n",
      "Epoch 75/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8672 - mse: 5.2592 - mae: 1.1420\n",
      "Epoch 75: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8671 - mse: 5.2581 - mae: 1.1419 - val_loss: 1.3603 - val_mse: 9.8486 - val_mae: 1.6656 - lr: 1.5625e-05\n",
      "Epoch 76/500\n",
      "1309/1315 [============================>.] - ETA: 0s - loss: 0.8651 - mse: 5.2514 - mae: 1.1388\n",
      "Epoch 76: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8650 - mse: 5.2485 - mae: 1.1387 - val_loss: 1.3619 - val_mse: 9.8690 - val_mae: 1.6671 - lr: 1.5625e-05\n",
      "Epoch 77/500\n",
      "1314/1315 [============================>.] - ETA: 0s - loss: 0.8637 - mse: 5.2423 - mae: 1.1372\n",
      "Epoch 77: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8640 - mse: 5.2442 - mae: 1.1375 - val_loss: 1.3620 - val_mse: 9.8732 - val_mae: 1.6672 - lr: 1.5625e-05\n",
      "Epoch 78/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8636 - mse: 5.2443 - mae: 1.1370\n",
      "Epoch 78: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8632 - mse: 5.2412 - mae: 1.1367 - val_loss: 1.3618 - val_mse: 9.8730 - val_mae: 1.6669 - lr: 1.5625e-05\n",
      "Epoch 79/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8630 - mse: 5.2418 - mae: 1.1363\n",
      "Epoch 79: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8627 - mse: 5.2387 - mae: 1.1360 - val_loss: 1.3615 - val_mse: 9.8727 - val_mae: 1.6666 - lr: 1.5625e-05\n",
      "Epoch 80/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8625 - mse: 5.2405 - mae: 1.1357\n",
      "Epoch 80: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 12s 9ms/step - loss: 0.8622 - mse: 5.2365 - mae: 1.1354 - val_loss: 1.3613 - val_mse: 9.8722 - val_mae: 1.6663 - lr: 1.5625e-05\n",
      "Epoch 81/500\n",
      "1313/1315 [============================>.] - ETA: 0s - loss: 0.8619 - mse: 5.2358 - mae: 1.1350\n",
      "Epoch 81: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8618 - mse: 5.2349 - mae: 1.1349 - val_loss: 1.3610 - val_mse: 9.8708 - val_mae: 1.6660 - lr: 1.5625e-05\n",
      "Epoch 82/500\n",
      "1312/1315 [============================>.] - ETA: 0s - loss: 0.8618 - mse: 5.2364 - mae: 1.1349\n",
      "Epoch 82: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8615 - mse: 5.2334 - mae: 1.1345 - val_loss: 1.3609 - val_mse: 9.8707 - val_mae: 1.6659 - lr: 1.5625e-05\n",
      "Epoch 83/500\n",
      "1310/1315 [============================>.] - ETA: 0s - loss: 0.8615 - mse: 5.2362 - mae: 1.1344\n",
      "Epoch 83: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8612 - mse: 5.2321 - mae: 1.1342 - val_loss: 1.3608 - val_mse: 9.8705 - val_mae: 1.6657 - lr: 1.5625e-05\n",
      "Epoch 84/500\n",
      "1315/1315 [==============================] - ETA: 0s - loss: 0.8609 - mse: 5.2310 - mae: 1.1338\n",
      "Epoch 84: val_loss did not improve from 1.33937\n",
      "1315/1315 [==============================] - 13s 10ms/step - loss: 0.8609 - mse: 5.2310 - mae: 1.1338 - val_loss: 1.3607 - val_mse: 9.8701 - val_mae: 1.6655 - lr: 1.5625e-05\n"
     ]
    }
   ],
   "source": [
    "gru_history = gru_model.fit(train_data, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_gru])\n",
    "gru_history_ns = gru_model.fit(train_data_ns, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_gru_ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------lstm_history-------------\n",
      "lstm_history Validation Loss: 1.2900581359863281\n",
      "lstm_history Validation MSE: 9.1972017288208\n",
      "lstm_history Validation MAE: 1.600001335144043\n",
      "-------------lstm_history_ns-------------\n",
      "lstm_history_ns Validation Loss: 1.2993721961975098\n",
      "lstm_history_ns Validation MSE: 9.25202465057373\n",
      "lstm_history_ns Validation MAE: 1.6082416772842407\n",
      "-------------rnn_history-------------\n",
      "rnn_history Validation Loss: 1.351880669593811\n",
      "rnn_history Validation MSE: 9.608440399169922\n",
      "rnn_history Validation MAE: 1.667106032371521\n",
      "-------------rnn_history_ns-------------\n",
      "rnn_history_ns Validation Loss: 1.3496030569076538\n",
      "rnn_history_ns Validation MSE: 9.616933822631836\n",
      "rnn_history_ns Validation MAE: 1.6675586700439453\n",
      "-------------gru_history-------------\n",
      "gru_history Validation Loss: 1.3690770864486694\n",
      "gru_history Validation MSE: 9.89048957824707\n",
      "gru_history Validation MAE: 1.6785365343093872\n",
      "-------------gru_history_ns-------------\n",
      "gru_history_ns Validation Loss: 1.3393667936325073\n",
      "gru_history_ns Validation MSE: 9.654655456542969\n",
      "gru_history_ns Validation MAE: 1.645501732826233\n"
     ]
    }
   ],
   "source": [
    "# 종합 결과\n",
    "\n",
    "history_list = [\"lstm_history\", \"rnn_history\", \"gru_history\", \"lstm_history_ns\", \"rnn_history_ns\", \"gru_history_ns\"]\n",
    "def result(historys) :\n",
    "  for name, history in globals().items() :\n",
    "    if name in history_list :\n",
    "      print(f\"-------------{name}-------------\")\n",
    "      val_loss = min(history.history['val_loss'])\n",
    "      val_mse = min(history.history['val_mse'])\n",
    "      val_mae = min(history.history['val_mae'])\n",
    "      print(f\"{name} Validation Loss:\", val_loss)\n",
    "      print(f\"{name} Validation MSE:\", val_mse)\n",
    "      print(f\"{name} Validation MAE:\", val_mae)\n",
    "\n",
    "result(history_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/lstm_model_stne_base_only\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/lstm_model_stne_base_only\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/rnn_model_stne_base_only\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/rnn_model_stne_base_only\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses, gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/gru_model_stne_base_only\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/gru_model_stne_base_only\\assets\n"
     ]
    }
   ],
   "source": [
    "lstm_save_path = f\"./Models/lstm_model_stne_base_only\"\n",
    "rnn_save_path = f\"./Models/rnn_model_stne_base_only\"\n",
    "gru_save_path = f\"./Models/gru_model_stne_base_only\"\n",
    "\n",
    "save_model(lstm_model, lstm_save_path, overwrite=True)\n",
    "save_model(rnn_model, rnn_save_path, overwrite=True)\n",
    "save_model(gru_model, gru_save_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기 테스트\n",
    "\n",
    "# load_path = f\"./Models/lstm_model\"\n",
    "# loaded_model = load_model(load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = loaded_model.get_weights()\n",
    "\n",
    "# for i, weight in enumerate(weights) :\n",
    "#   print(f\"Weight {i} :\")\n",
    "#   print(weight)\n",
    "#   print(\"------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
