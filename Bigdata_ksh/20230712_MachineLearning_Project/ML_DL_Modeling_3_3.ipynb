{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pymysql\n",
    "import dotenv\n",
    "import os\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Normalization/Standardization\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, Dropout, Conv1D, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.saving import save_model\n",
    "\n",
    "# 경고 무시 코드 추가\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def pltconfig_default() :\n",
    "  sns.reset_defaults()\n",
    "  %matplotlib inline\n",
    "\n",
    "pltconfig_default()\n",
    "\n",
    "matplotlib.rcParams\n",
    "\n",
    "matplotlib.rcParams['font.family']\n",
    "\n",
    "current_font_list = matplotlib.rcParams['font.family']\n",
    "\n",
    "font_path = 'C:\\\\Windows\\\\Fonts\\\\batang.ttc'\n",
    "\n",
    "kfont = matplotlib.font_manager.FontProperties(fname=font_path).get_name()\n",
    "\n",
    "matplotlib.rcParams['font.family'] = [kfont] + current_font_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17422, 9)\n"
     ]
    }
   ],
   "source": [
    "St_NotEncode_data = pd.read_pickle(\"StandardScalar_final_data\")\n",
    "\n",
    "print(St_NotEncode_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler Not Encode Data\n",
      "(17422, 1) (17422,)\n",
      "(13937, 1) (3485, 1) (13937,) (3485,)\n",
      "=======================================\n"
     ]
    }
   ],
   "source": [
    "# Feature와 Label 분리하기 (일조시간)\n",
    "def Feature_Label(datafile) :\n",
    "    X = datafile.iloc[:,[4]]\n",
    "    y = datafile.iloc[:,-1]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "print(\"StandardScaler Not Encode Data\")\n",
    "SNE_X, SNE_y = Feature_Label(St_NotEncode_data)\n",
    "print(SNE_X.shape, SNE_y.shape)\n",
    "SNE_X_train, SNE_X_test, SNE_y_train, SNE_y_test = train_test_split(SNE_X, SNE_y, test_size=0.2, random_state=10, shuffle=False)\n",
    "print(SNE_X_train.shape, SNE_X_test.shape, SNE_y_train.shape, SNE_y_test.shape)\n",
    "print(\"=======================================\")\n",
    "\n",
    "\n",
    "WINDOW_SIZE=3\n",
    "BATCH_SIZE=28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 내용을 함수 형태로 만들고 싶은 경우\n",
    "\n",
    "def windowed_dataset(x, y, window_size, batch_size, shuffle) :\n",
    "  ds_x = tf.data.Dataset.from_tensor_slices(x).window(window_size, stride=1, shift=1, drop_remainder=True) \n",
    "  ds_x = ds_x.flat_map(lambda x : x.batch(window_size))\n",
    "  \n",
    "  ds_y = tf.data.Dataset.from_tensor_slices(y[window_size:])\n",
    "  \n",
    "  ds = tf.data.Dataset.zip((ds_x, ds_y))\n",
    "  \n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(1000)\n",
    "  \n",
    "  return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = windowed_dataset(SNE_X_train, SNE_y_train, WINDOW_SIZE, BATCH_SIZE, True)\n",
    "train_data_ns = windowed_dataset(SNE_X_train, SNE_y_train, WINDOW_SIZE, BATCH_SIZE, False)\n",
    "test_data = windowed_dataset(SNE_X_test, SNE_y_test, WINDOW_SIZE, BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 3, 1), (28,)\n"
     ]
    }
   ],
   "source": [
    "for data in train_data.take(1) :\n",
    "  print(f'{data[0].shape}, {data[1].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential([\n",
    "  Conv1D(filters=32, kernel_size=30,\n",
    "         padding='causal',\n",
    "         activation='relu',\n",
    "         input_shape=[WINDOW_SIZE, 1]),\n",
    "  LSTM(128, activation='tanh', return_sequences=True),  \n",
    "  LSTM(64, activation='tanh', return_sequences=True),\n",
    "  LSTM(32, activation='tanh'),\n",
    "  Dense(8, activation='relu'),\n",
    "  Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = Sequential([\n",
    "  Conv1D(filters=32, kernel_size=30,\n",
    "         padding='causal', \n",
    "         activation='relu',\n",
    "         input_shape=[WINDOW_SIZE, 1]),\n",
    "  SimpleRNN(128, activation='tanh', return_sequences=True),  \n",
    "  SimpleRNN(64, activation='tanh', return_sequences=True),\n",
    "  SimpleRNN(32, activation='tanh'),\n",
    "  Dense(8, activation='relu'),\n",
    "  Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = Sequential([\n",
    "  Conv1D(filters=32, kernel_size=30,\n",
    "         padding='causal', \n",
    "         activation='relu',\n",
    "         input_shape=[WINDOW_SIZE, 1]),\n",
    "  GRU(128, activation='tanh', return_sequences=True),  \n",
    "  GRU(64, activation='tanh', return_sequences=True),\n",
    "  GRU(32, activation='tanh'),\n",
    "  Dense(8, activation='relu'),\n",
    "  Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = Huber() \n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "lstm_model.compile(loss=loss, optimizer=optimizer, metrics=['mse', 'mae'])\n",
    "rnn_model.compile(loss=loss, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), metrics=['mse', 'mae'])\n",
    "gru_model.compile(loss=loss, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10)\n",
    "       \n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "mc_lstm = ModelCheckpoint('new_multi_stne_lstm_weight_c1.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_lstm_ns = ModelCheckpoint('new_multi_stne_lstm_weight_ns_c1.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_rnn = ModelCheckpoint('new_multi_stne_rnn_weight_c1.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_rnn_ns = ModelCheckpoint('new_multi_stne_rnn_weight_ns_c1.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_gru = ModelCheckpoint('new_multi_stne_gru_weight_c1.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_gru_ns = ModelCheckpoint('new_multi_stne_gru_weight_ns_c1.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    497/Unknown - 14s 7ms/step - loss: 7614.8755 - mse: 183358000.0000 - mae: 7615.2715\n",
      "Epoch 1: val_loss improved from inf to 7097.84619, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 19s 18ms/step - loss: 7616.2876 - mse: 183374352.0000 - mae: 7616.6836 - val_loss: 7097.8462 - val_mse: 170910672.0000 - val_mae: 7098.2729 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 7552.7285 - mse: 180925168.0000 - mae: 7553.1099\n",
      "Epoch 2: val_loss improved from 7097.84619 to 7035.25195, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 7560.4473 - mse: 181012752.0000 - mae: 7560.8296 - val_loss: 7035.2520 - val_mse: 167947104.0000 - val_mae: 7035.7202 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 7462.1250 - mse: 176890720.0000 - mae: 7462.5098\n",
      "Epoch 3: val_loss improved from 7035.25195 to 6933.33887, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 7468.7354 - mse: 177118096.0000 - mae: 7469.1206 - val_loss: 6933.3389 - val_mse: 163542752.0000 - val_mae: 6933.7788 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 7348.1572 - mse: 171871456.0000 - mae: 7348.5386\n",
      "Epoch 4: val_loss improved from 6933.33887 to 6814.85107, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 7344.5137 - mse: 171715456.0000 - mae: 7344.8950 - val_loss: 6814.8511 - val_mse: 158106768.0000 - val_mae: 6815.2192 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 7185.8672 - mse: 165337200.0000 - mae: 7186.2529\n",
      "Epoch 5: val_loss improved from 6814.85107 to 6659.53027, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 7185.8672 - mse: 165337200.0000 - mae: 7186.2529 - val_loss: 6659.5303 - val_mse: 151560688.0000 - val_mae: 6659.9292 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 7004.5498 - mse: 158054352.0000 - mae: 7004.9292\n",
      "Epoch 6: val_loss improved from 6659.53027 to 6479.37549, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 7002.9194 - mse: 157970560.0000 - mae: 7003.2988 - val_loss: 6479.3755 - val_mse: 144626224.0000 - val_mae: 6479.6709 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 6808.5942 - mse: 150251664.0000 - mae: 6808.9673\n",
      "Epoch 7: val_loss improved from 6479.37549 to 6305.67529, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 6807.9731 - mse: 150178864.0000 - mae: 6808.3462 - val_loss: 6305.6753 - val_mse: 136846128.0000 - val_mae: 6306.0811 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 6603.8872 - mse: 141819600.0000 - mae: 6604.2642\n",
      "Epoch 8: val_loss improved from 6305.67529 to 6138.98389, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 6605.6265 - mse: 141784032.0000 - mae: 6606.0039 - val_loss: 6138.9839 - val_mse: 129231704.0000 - val_mae: 6139.3994 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 6415.7275 - mse: 134135576.0000 - mae: 6416.1001\n",
      "Epoch 9: val_loss improved from 6138.98389 to 5938.93457, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 6418.0039 - mse: 133994088.0000 - mae: 6418.3770 - val_loss: 5938.9346 - val_mse: 122077184.0000 - val_mae: 5939.3813 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 6189.9634 - mse: 125448384.0000 - mae: 6190.3384\n",
      "Epoch 10: val_loss improved from 5938.93457 to 5728.44336, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 6187.4927 - mse: 125271728.0000 - mae: 6187.8667 - val_loss: 5728.4434 - val_mse: 113528136.0000 - val_mae: 5728.8164 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 5984.3716 - mse: 117301880.0000 - mae: 5984.7505\n",
      "Epoch 11: val_loss improved from 5728.44336 to 5538.85449, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 5981.9404 - mse: 117153016.0000 - mae: 5982.3203 - val_loss: 5538.8545 - val_mse: 106292232.0000 - val_mae: 5539.2637 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 5776.5669 - mse: 108951248.0000 - mae: 5776.9546\n",
      "Epoch 12: val_loss improved from 5538.85449 to 5363.88086, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 5772.6982 - mse: 108799032.0000 - mae: 5773.0864 - val_loss: 5363.8809 - val_mse: 98663048.0000 - val_mae: 5364.2900 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 5616.9263 - mse: 102017616.0000 - mae: 5617.3105\n",
      "Epoch 13: val_loss improved from 5363.88086 to 5243.71680, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 5616.9263 - mse: 102017616.0000 - mae: 5617.3105 - val_loss: 5243.7168 - val_mse: 92389584.0000 - val_mae: 5244.1382 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 5412.6997 - mse: 93720280.0000 - mae: 5413.0796\n",
      "Epoch 14: val_loss improved from 5243.71680 to 4997.60938, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 5409.4199 - mse: 93570416.0000 - mae: 5409.7998 - val_loss: 4997.6094 - val_mse: 83980016.0000 - val_mae: 4997.9961 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 5161.0728 - mse: 85938816.0000 - mae: 5161.4453\n",
      "Epoch 15: val_loss improved from 4997.60938 to 4815.81836, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 5162.9751 - mse: 85877928.0000 - mae: 5163.3477 - val_loss: 4815.8184 - val_mse: 78021576.0000 - val_mae: 4816.0840 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 4991.3818 - mse: 79544840.0000 - mae: 4991.7607\n",
      "Epoch 16: val_loss improved from 4815.81836 to 4665.83154, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 4992.2183 - mse: 79530376.0000 - mae: 4992.5986 - val_loss: 4665.8315 - val_mse: 72104200.0000 - val_mae: 4666.3057 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 4824.8584 - mse: 73692448.0000 - mae: 4825.2417\n",
      "Epoch 17: val_loss improved from 4665.83154 to 4507.60059, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 4826.2930 - mse: 73735720.0000 - mae: 4826.6768 - val_loss: 4507.6006 - val_mse: 66711572.0000 - val_mae: 4508.0483 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 4716.5728 - mse: 69643880.0000 - mae: 4717.0122\n",
      "Epoch 18: val_loss improved from 4507.60059 to 4353.72705, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 5s 9ms/step - loss: 4716.5728 - mse: 69643880.0000 - mae: 4717.0122 - val_loss: 4353.7271 - val_mse: 62993356.0000 - val_mae: 4354.1436 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 4555.5010 - mse: 64383540.0000 - mae: 4555.9204\n",
      "Epoch 19: val_loss did not improve from 4353.72705\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 4554.3242 - mse: 64289824.0000 - mae: 4554.7441 - val_loss: 4362.7129 - val_mse: 57882064.0000 - val_mae: 4363.2109 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 4384.0000 - mse: 59660516.0000 - mae: 4384.4258\n",
      "Epoch 20: val_loss improved from 4353.72705 to 4075.76221, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 4392.0205 - mse: 59734184.0000 - mae: 4392.4463 - val_loss: 4075.7622 - val_mse: 54089664.0000 - val_mae: 4076.1777 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 4264.7471 - mse: 56240768.0000 - mae: 4265.1201\n",
      "Epoch 21: val_loss improved from 4075.76221 to 3936.00195, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 4278.0322 - mse: 56454856.0000 - mae: 4278.4053 - val_loss: 3936.0020 - val_mse: 50597084.0000 - val_mae: 3936.3438 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 4156.0586 - mse: 53444956.0000 - mae: 4156.4214\n",
      "Epoch 22: val_loss improved from 3936.00195 to 3848.46362, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 9ms/step - loss: 4166.2192 - mse: 53636560.0000 - mae: 4166.5825 - val_loss: 3848.4636 - val_mse: 48463584.0000 - val_mae: 3848.9058 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 4053.8525 - mse: 51109368.0000 - mae: 4054.2200\n",
      "Epoch 23: val_loss improved from 3848.46362 to 3764.26904, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 4053.9478 - mse: 51089824.0000 - mae: 4054.3154 - val_loss: 3764.2690 - val_mse: 45908820.0000 - val_mae: 3764.7034 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3959.2673 - mse: 48375204.0000 - mae: 3959.6392\n",
      "Epoch 24: val_loss improved from 3764.26904 to 3654.30518, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 9ms/step - loss: 3963.3643 - mse: 48435140.0000 - mae: 3963.7358 - val_loss: 3654.3052 - val_mse: 43346532.0000 - val_mae: 3654.6968 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3897.6455 - mse: 47279648.0000 - mae: 3898.0237\n",
      "Epoch 25: val_loss improved from 3654.30518 to 3647.93994, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 9ms/step - loss: 3903.1389 - mse: 47354292.0000 - mae: 3903.5178 - val_loss: 3647.9399 - val_mse: 43130380.0000 - val_mae: 3648.3713 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3840.5920 - mse: 45921252.0000 - mae: 3840.9797\n",
      "Epoch 26: val_loss improved from 3647.93994 to 3549.32373, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3844.1001 - mse: 45974036.0000 - mae: 3844.4885 - val_loss: 3549.3237 - val_mse: 41370348.0000 - val_mae: 3549.7490 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3777.9705 - mse: 44608228.0000 - mae: 3778.3577\n",
      "Epoch 27: val_loss improved from 3549.32373 to 3491.28271, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 9ms/step - loss: 3789.2803 - mse: 44805884.0000 - mae: 3789.6672 - val_loss: 3491.2827 - val_mse: 40389996.0000 - val_mae: 3491.6514 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3732.2661 - mse: 43654508.0000 - mae: 3732.6453\n",
      "Epoch 28: val_loss improved from 3491.28271 to 3455.36475, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3732.2661 - mse: 43654508.0000 - mae: 3732.6453 - val_loss: 3455.3647 - val_mse: 39475852.0000 - val_mae: 3455.7551 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3671.6719 - mse: 42865212.0000 - mae: 3672.0583\n",
      "Epoch 29: val_loss did not improve from 3455.36475\n",
      "498/498 [==============================] - 4s 9ms/step - loss: 3683.4204 - mse: 43093872.0000 - mae: 3683.8071 - val_loss: 3475.4836 - val_mse: 40268620.0000 - val_mae: 3475.8447 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "490/498 [============================>.] - ETA: 0s - loss: 3622.0198 - mse: 41976124.0000 - mae: 3622.3877\n",
      "Epoch 30: val_loss improved from 3455.36475 to 3363.37012, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 9ms/step - loss: 3630.7668 - mse: 42175084.0000 - mae: 3631.1357 - val_loss: 3363.3701 - val_mse: 38666548.0000 - val_mae: 3363.8015 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3580.1379 - mse: 41631028.0000 - mae: 3580.5085\n",
      "Epoch 31: val_loss did not improve from 3363.37012\n",
      "498/498 [==============================] - 4s 9ms/step - loss: 3588.4001 - mse: 41734496.0000 - mae: 3588.7717 - val_loss: 3386.5061 - val_mse: 38383392.0000 - val_mae: 3386.9302 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3562.3718 - mse: 41730916.0000 - mae: 3562.7617\n",
      "Epoch 32: val_loss improved from 3363.37012 to 3347.20337, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3567.0105 - mse: 41825256.0000 - mae: 3567.4004 - val_loss: 3347.2034 - val_mse: 38568784.0000 - val_mae: 3347.6660 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3536.9734 - mse: 41552552.0000 - mae: 3537.3584\n",
      "Epoch 33: val_loss improved from 3347.20337 to 3339.63721, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3541.2849 - mse: 41633580.0000 - mae: 3541.6702 - val_loss: 3339.6372 - val_mse: 38942892.0000 - val_mae: 3340.0474 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3519.3384 - mse: 41982516.0000 - mae: 3519.7161\n",
      "Epoch 34: val_loss did not improve from 3339.63721\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3524.7346 - mse: 42109184.0000 - mae: 3525.1123 - val_loss: 3386.7805 - val_mse: 39680100.0000 - val_mae: 3387.2017 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3500.8438 - mse: 41522600.0000 - mae: 3501.2153\n",
      "Epoch 35: val_loss improved from 3339.63721 to 3305.35791, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 9ms/step - loss: 3505.0203 - mse: 41549452.0000 - mae: 3505.3921 - val_loss: 3305.3579 - val_mse: 38400028.0000 - val_mae: 3305.7415 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 3463.9729 - mse: 41528404.0000 - mae: 3464.3496\n",
      "Epoch 36: val_loss improved from 3305.35791 to 3296.52954, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 9ms/step - loss: 3479.1985 - mse: 41771048.0000 - mae: 3479.5757 - val_loss: 3296.5295 - val_mse: 39322592.0000 - val_mae: 3296.9150 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3464.5801 - mse: 41708456.0000 - mae: 3464.9578\n",
      "Epoch 37: val_loss improved from 3296.52954 to 3225.43774, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3468.3784 - mse: 41707228.0000 - mae: 3468.7571 - val_loss: 3225.4377 - val_mse: 38158036.0000 - val_mae: 3225.8611 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3444.3125 - mse: 41383700.0000 - mae: 3444.6807\n",
      "Epoch 38: val_loss did not improve from 3225.43774\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3444.3125 - mse: 41383700.0000 - mae: 3444.6807 - val_loss: 3268.4775 - val_mse: 38156476.0000 - val_mae: 3268.8870 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 3434.1123 - mse: 41780876.0000 - mae: 3434.4858\n",
      "Epoch 39: val_loss did not improve from 3225.43774\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3447.2141 - mse: 41929040.0000 - mae: 3447.5884 - val_loss: 3240.5420 - val_mse: 37944432.0000 - val_mae: 3240.9668 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3455.9126 - mse: 41586744.0000 - mae: 3456.2832\n",
      "Epoch 40: val_loss did not improve from 3225.43774\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3456.0264 - mse: 41588004.0000 - mae: 3456.3970 - val_loss: 3311.0242 - val_mse: 38460424.0000 - val_mae: 3311.4543 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3423.2993 - mse: 42270528.0000 - mae: 3423.6729\n",
      "Epoch 41: val_loss did not improve from 3225.43774\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3423.2993 - mse: 42270528.0000 - mae: 3423.6729 - val_loss: 3269.9563 - val_mse: 37866784.0000 - val_mae: 3270.3936 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3411.6719 - mse: 41829412.0000 - mae: 3412.0420\n",
      "Epoch 42: val_loss did not improve from 3225.43774\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3407.6082 - mse: 41788004.0000 - mae: 3407.9788 - val_loss: 3323.6707 - val_mse: 41310212.0000 - val_mae: 3324.1047 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3448.7668 - mse: 42997868.0000 - mae: 3449.1360\n",
      "Epoch 43: val_loss improved from 3225.43774 to 3205.79468, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 9ms/step - loss: 3448.7668 - mse: 42997868.0000 - mae: 3449.1360 - val_loss: 3205.7947 - val_mse: 39160592.0000 - val_mae: 3206.2234 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 3414.5281 - mse: 42142200.0000 - mae: 3414.8989\n",
      "Epoch 44: val_loss improved from 3205.79468 to 3197.21216, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3418.9900 - mse: 42248684.0000 - mae: 3419.3616 - val_loss: 3197.2122 - val_mse: 38815592.0000 - val_mae: 3197.6260 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3430.4949 - mse: 42321196.0000 - mae: 3430.8674\n",
      "Epoch 45: val_loss did not improve from 3197.21216\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3428.8477 - mse: 42298308.0000 - mae: 3429.2202 - val_loss: 3321.8367 - val_mse: 38080428.0000 - val_mae: 3322.2351 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3401.5208 - mse: 41714864.0000 - mae: 3401.8918\n",
      "Epoch 46: val_loss did not improve from 3197.21216\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3403.2673 - mse: 41718672.0000 - mae: 3403.6387 - val_loss: 3245.4473 - val_mse: 39663548.0000 - val_mae: 3245.8567 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3411.3123 - mse: 42077712.0000 - mae: 3411.6868\n",
      "Epoch 47: val_loss did not improve from 3197.21216\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3416.6333 - mse: 42212428.0000 - mae: 3417.0085 - val_loss: 3221.2881 - val_mse: 39250804.0000 - val_mae: 3221.7090 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 3421.3899 - mse: 42392700.0000 - mae: 3421.7607\n",
      "Epoch 48: val_loss improved from 3197.21216 to 3193.45337, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 9ms/step - loss: 3419.6226 - mse: 42388008.0000 - mae: 3419.9939 - val_loss: 3193.4534 - val_mse: 38563520.0000 - val_mae: 3193.8767 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3402.9297 - mse: 42034360.0000 - mae: 3403.3000\n",
      "Epoch 49: val_loss did not improve from 3193.45337\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3409.3655 - mse: 42142468.0000 - mae: 3409.7361 - val_loss: 3194.4971 - val_mse: 39104812.0000 - val_mae: 3194.9133 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3398.1436 - mse: 41750960.0000 - mae: 3398.5139\n",
      "Epoch 50: val_loss did not improve from 3193.45337\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3403.5288 - mse: 41850036.0000 - mae: 3403.8999 - val_loss: 3218.4673 - val_mse: 40469164.0000 - val_mae: 3218.9148 - lr: 0.0010\n",
      "Epoch 51/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3386.9470 - mse: 42275692.0000 - mae: 3387.3201\n",
      "Epoch 51: val_loss did not improve from 3193.45337\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3393.1589 - mse: 42365596.0000 - mae: 3393.5320 - val_loss: 3221.4199 - val_mse: 37490008.0000 - val_mae: 3221.8293 - lr: 0.0010\n",
      "Epoch 52/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3387.9023 - mse: 42012588.0000 - mae: 3388.2756\n",
      "Epoch 52: val_loss did not improve from 3193.45337\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3391.4136 - mse: 42085936.0000 - mae: 3391.7874 - val_loss: 3248.0688 - val_mse: 40119564.0000 - val_mae: 3248.4375 - lr: 0.0010\n",
      "Epoch 53/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3431.1626 - mse: 42754424.0000 - mae: 3431.5337\n",
      "Epoch 53: val_loss did not improve from 3193.45337\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3435.4758 - mse: 42814364.0000 - mae: 3435.8472 - val_loss: 3291.4023 - val_mse: 39355136.0000 - val_mae: 3291.8188 - lr: 0.0010\n",
      "Epoch 54/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3453.8762 - mse: 43122628.0000 - mae: 3454.2532\n",
      "Epoch 54: val_loss improved from 3193.45337 to 3187.45312, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 9ms/step - loss: 3451.9343 - mse: 43085632.0000 - mae: 3452.3115 - val_loss: 3187.4531 - val_mse: 38528436.0000 - val_mae: 3187.8479 - lr: 0.0010\n",
      "Epoch 55/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3391.9919 - mse: 42127512.0000 - mae: 3392.3621\n",
      "Epoch 55: val_loss did not improve from 3187.45312\n",
      "498/498 [==============================] - 4s 9ms/step - loss: 3393.0608 - mse: 42154488.0000 - mae: 3393.4312 - val_loss: 3194.8713 - val_mse: 38322368.0000 - val_mae: 3195.2380 - lr: 0.0010\n",
      "Epoch 56/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3400.5146 - mse: 41904528.0000 - mae: 3400.8831\n",
      "Epoch 56: val_loss did not improve from 3187.45312\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3407.2944 - mse: 42023192.0000 - mae: 3407.6633 - val_loss: 3219.1174 - val_mse: 37984140.0000 - val_mae: 3219.5405 - lr: 0.0010\n",
      "Epoch 57/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3399.1575 - mse: 42232984.0000 - mae: 3399.5273\n",
      "Epoch 57: val_loss did not improve from 3187.45312\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3403.5896 - mse: 42277348.0000 - mae: 3403.9595 - val_loss: 3203.4141 - val_mse: 38232464.0000 - val_mae: 3203.8245 - lr: 0.0010\n",
      "Epoch 58/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 3370.7014 - mse: 41681096.0000 - mae: 3371.0703\n",
      "Epoch 58: val_loss did not improve from 3187.45312\n",
      "498/498 [==============================] - 4s 9ms/step - loss: 3392.2148 - mse: 42123712.0000 - mae: 3392.5845 - val_loss: 3193.8923 - val_mse: 38476780.0000 - val_mae: 3194.3179 - lr: 0.0010\n",
      "Epoch 59/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3408.9094 - mse: 42490424.0000 - mae: 3409.2810\n",
      "Epoch 59: val_loss improved from 3187.45312 to 3185.57104, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3409.4851 - mse: 42479316.0000 - mae: 3409.8567 - val_loss: 3185.5710 - val_mse: 37563108.0000 - val_mae: 3185.9871 - lr: 0.0010\n",
      "Epoch 60/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 3387.1589 - mse: 41611696.0000 - mae: 3387.5222\n",
      "Epoch 60: val_loss improved from 3185.57104 to 3162.26172, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3393.8584 - mse: 41707808.0000 - mae: 3394.2231 - val_loss: 3162.2617 - val_mse: 38586032.0000 - val_mae: 3162.6736 - lr: 0.0010\n",
      "Epoch 61/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3415.7476 - mse: 42493580.0000 - mae: 3416.1172\n",
      "Epoch 61: val_loss did not improve from 3162.26172\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3417.3594 - mse: 42498752.0000 - mae: 3417.7292 - val_loss: 3246.0347 - val_mse: 37370336.0000 - val_mae: 3246.4741 - lr: 0.0010\n",
      "Epoch 62/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3419.5051 - mse: 42257912.0000 - mae: 3419.8757\n",
      "Epoch 62: val_loss did not improve from 3162.26172\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3422.9375 - mse: 42301296.0000 - mae: 3423.3088 - val_loss: 3234.1357 - val_mse: 39453804.0000 - val_mae: 3234.5649 - lr: 0.0010\n",
      "Epoch 63/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3383.1318 - mse: 42401768.0000 - mae: 3383.5020\n",
      "Epoch 63: val_loss did not improve from 3162.26172\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3383.1318 - mse: 42401768.0000 - mae: 3383.5020 - val_loss: 3192.5835 - val_mse: 40072668.0000 - val_mae: 3193.0117 - lr: 0.0010\n",
      "Epoch 64/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3401.3977 - mse: 42451196.0000 - mae: 3401.7681\n",
      "Epoch 64: val_loss did not improve from 3162.26172\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3401.3977 - mse: 42451196.0000 - mae: 3401.7681 - val_loss: 3180.4893 - val_mse: 39547644.0000 - val_mae: 3180.8975 - lr: 0.0010\n",
      "Epoch 65/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3426.4670 - mse: 42883076.0000 - mae: 3426.8367\n",
      "Epoch 65: val_loss did not improve from 3162.26172\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3425.1431 - mse: 42863068.0000 - mae: 3425.5132 - val_loss: 3197.8850 - val_mse: 40478068.0000 - val_mae: 3198.2944 - lr: 0.0010\n",
      "Epoch 66/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3392.0881 - mse: 42287296.0000 - mae: 3392.4565\n",
      "Epoch 66: val_loss did not improve from 3162.26172\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3396.7183 - mse: 42347908.0000 - mae: 3397.0869 - val_loss: 3195.9529 - val_mse: 39720804.0000 - val_mae: 3196.3677 - lr: 0.0010\n",
      "Epoch 67/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3419.1523 - mse: 42489740.0000 - mae: 3419.5210\n",
      "Epoch 67: val_loss improved from 3162.26172 to 3160.47437, saving model to new_multi_stne_lstm_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3419.1523 - mse: 42489740.0000 - mae: 3419.5210 - val_loss: 3160.4744 - val_mse: 39463116.0000 - val_mae: 3160.8945 - lr: 0.0010\n",
      "Epoch 68/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3400.2002 - mse: 42014892.0000 - mae: 3400.5723\n",
      "Epoch 68: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3406.6638 - mse: 42198840.0000 - mae: 3407.0361 - val_loss: 3174.9277 - val_mse: 39999400.0000 - val_mae: 3175.3091 - lr: 0.0010\n",
      "Epoch 69/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 3394.0425 - mse: 42742968.0000 - mae: 3394.4106\n",
      "Epoch 69: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3396.6038 - mse: 42726668.0000 - mae: 3396.9727 - val_loss: 3181.9854 - val_mse: 40202808.0000 - val_mae: 3182.3918 - lr: 0.0010\n",
      "Epoch 70/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3381.2244 - mse: 42808744.0000 - mae: 3381.5977\n",
      "Epoch 70: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 9ms/step - loss: 3382.9080 - mse: 42814848.0000 - mae: 3383.2817 - val_loss: 3186.1265 - val_mse: 39387668.0000 - val_mae: 3186.5193 - lr: 0.0010\n",
      "Epoch 71/500\n",
      "490/498 [============================>.] - ETA: 0s - loss: 3368.0242 - mse: 42084816.0000 - mae: 3368.3914\n",
      "Epoch 71: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3372.5999 - mse: 42123548.0000 - mae: 3372.9680 - val_loss: 3194.6399 - val_mse: 38858056.0000 - val_mae: 3195.0576 - lr: 0.0010\n",
      "Epoch 72/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3386.7827 - mse: 42315380.0000 - mae: 3387.1521\n",
      "Epoch 72: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3391.7727 - mse: 42407644.0000 - mae: 3392.1423 - val_loss: 3179.2817 - val_mse: 40117708.0000 - val_mae: 3179.6531 - lr: 0.0010\n",
      "Epoch 73/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3376.6016 - mse: 42398716.0000 - mae: 3376.9700\n",
      "Epoch 73: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3377.6719 - mse: 42401572.0000 - mae: 3378.0405 - val_loss: 3189.6047 - val_mse: 40267548.0000 - val_mae: 3190.0098 - lr: 0.0010\n",
      "Epoch 74/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3366.4568 - mse: 42407200.0000 - mae: 3366.8289\n",
      "Epoch 74: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3372.4817 - mse: 42502480.0000 - mae: 3372.8540 - val_loss: 3272.9182 - val_mse: 37714988.0000 - val_mae: 3273.3447 - lr: 0.0010\n",
      "Epoch 75/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3405.3242 - mse: 42622132.0000 - mae: 3405.6943\n",
      "Epoch 75: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3403.0542 - mse: 42541408.0000 - mae: 3403.4243 - val_loss: 3182.4070 - val_mse: 39917780.0000 - val_mae: 3182.8079 - lr: 0.0010\n",
      "Epoch 76/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3390.0046 - mse: 43012524.0000 - mae: 3390.3721\n",
      "Epoch 76: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3402.4604 - mse: 43268508.0000 - mae: 3402.8284 - val_loss: 3215.9241 - val_mse: 39423172.0000 - val_mae: 3216.3296 - lr: 0.0010\n",
      "Epoch 77/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3385.7351 - mse: 41894508.0000 - mae: 3386.1067\n",
      "Epoch 77: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3383.8970 - mse: 41880176.0000 - mae: 3384.2690 - val_loss: 3182.7148 - val_mse: 39273160.0000 - val_mae: 3183.0977 - lr: 0.0010\n",
      "Epoch 78/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 3368.5181 - mse: 42015212.0000 - mae: 3368.8875\n",
      "Epoch 78: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3375.5776 - mse: 42057256.0000 - mae: 3375.9480 - val_loss: 3433.0486 - val_mse: 40701624.0000 - val_mae: 3433.4695 - lr: 5.0000e-04\n",
      "Epoch 79/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3380.6501 - mse: 42316088.0000 - mae: 3381.0205\n",
      "Epoch 79: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3383.2559 - mse: 42349428.0000 - mae: 3383.6265 - val_loss: 3183.8696 - val_mse: 39245336.0000 - val_mae: 3184.2576 - lr: 5.0000e-04\n",
      "Epoch 80/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3366.0620 - mse: 42226768.0000 - mae: 3366.4299\n",
      "Epoch 80: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3366.0620 - mse: 42226768.0000 - mae: 3366.4299 - val_loss: 3212.2124 - val_mse: 38029472.0000 - val_mae: 3212.6367 - lr: 5.0000e-04\n",
      "Epoch 81/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3367.7212 - mse: 42200728.0000 - mae: 3368.0920\n",
      "Epoch 81: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3367.1426 - mse: 42191056.0000 - mae: 3367.5134 - val_loss: 3178.2446 - val_mse: 39978764.0000 - val_mae: 3178.6562 - lr: 5.0000e-04\n",
      "Epoch 82/500\n",
      "490/498 [============================>.] - ETA: 0s - loss: 3347.0388 - mse: 41990548.0000 - mae: 3347.4080\n",
      "Epoch 82: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3355.5774 - mse: 42107796.0000 - mae: 3355.9478 - val_loss: 3179.6985 - val_mse: 39407532.0000 - val_mae: 3180.1233 - lr: 5.0000e-04\n",
      "Epoch 83/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3357.3665 - mse: 41868340.0000 - mae: 3357.7373\n",
      "Epoch 83: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3357.7708 - mse: 41894540.0000 - mae: 3358.1418 - val_loss: 3172.1863 - val_mse: 39820544.0000 - val_mae: 3172.5940 - lr: 5.0000e-04\n",
      "Epoch 84/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 3344.8645 - mse: 41900268.0000 - mae: 3345.2388\n",
      "Epoch 84: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3354.5864 - mse: 42089544.0000 - mae: 3354.9614 - val_loss: 3210.6306 - val_mse: 37925472.0000 - val_mae: 3211.0371 - lr: 5.0000e-04\n",
      "Epoch 85/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 3328.2476 - mse: 41564884.0000 - mae: 3328.6213\n",
      "Epoch 85: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3348.7527 - mse: 41925456.0000 - mae: 3349.1270 - val_loss: 3178.8733 - val_mse: 39856536.0000 - val_mae: 3179.2827 - lr: 5.0000e-04\n",
      "Epoch 86/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 3335.7051 - mse: 41559304.0000 - mae: 3336.0737\n",
      "Epoch 86: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3348.1831 - mse: 41782284.0000 - mae: 3348.5522 - val_loss: 3209.6821 - val_mse: 38032592.0000 - val_mae: 3210.0964 - lr: 5.0000e-04\n",
      "Epoch 87/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3337.3735 - mse: 41781684.0000 - mae: 3337.7429\n",
      "Epoch 87: val_loss did not improve from 3160.47437\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3339.3318 - mse: 41820824.0000 - mae: 3339.7017 - val_loss: 3185.6821 - val_mse: 39896504.0000 - val_mae: 3186.0999 - lr: 5.0000e-04\n",
      "Epoch 1/500\n",
      "    497/Unknown - 4s 7ms/step - loss: 3354.8879 - mse: 42266764.0000 - mae: 3355.2610\n",
      "Epoch 1: val_loss improved from inf to 3182.10620, saving model to new_multi_stne_lstm_weight_ns_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3358.1904 - mse: 42310520.0000 - mae: 3358.5635 - val_loss: 3182.1062 - val_mse: 40074724.0000 - val_mae: 3182.5159 - lr: 2.5000e-04\n",
      "Epoch 2/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3359.5652 - mse: 42073148.0000 - mae: 3359.9368\n",
      "Epoch 2: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3359.5652 - mse: 42073148.0000 - mae: 3359.9368 - val_loss: 3187.5039 - val_mse: 40181876.0000 - val_mae: 3187.9126 - lr: 2.5000e-04\n",
      "Epoch 3/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3353.1902 - mse: 42117836.0000 - mae: 3353.5625\n",
      "Epoch 3: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3362.0149 - mse: 42188456.0000 - mae: 3362.3875 - val_loss: 3188.6135 - val_mse: 40161304.0000 - val_mae: 3189.0208 - lr: 2.5000e-04\n",
      "Epoch 4/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3351.8379 - mse: 42075220.0000 - mae: 3352.2090\n",
      "Epoch 4: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3355.0215 - mse: 42117360.0000 - mae: 3355.3926 - val_loss: 3193.4207 - val_mse: 40160008.0000 - val_mae: 3193.8262 - lr: 2.5000e-04\n",
      "Epoch 5/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 3353.8054 - mse: 42105380.0000 - mae: 3354.1729\n",
      "Epoch 5: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3359.0693 - mse: 42076156.0000 - mae: 3359.4370 - val_loss: 3195.7471 - val_mse: 40172576.0000 - val_mae: 3196.1519 - lr: 2.5000e-04\n",
      "Epoch 6/500\n",
      "490/498 [============================>.] - ETA: 0s - loss: 3346.3965 - mse: 41940404.0000 - mae: 3346.7644\n",
      "Epoch 6: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3356.1367 - mse: 42048224.0000 - mae: 3356.5051 - val_loss: 3195.6912 - val_mse: 40074196.0000 - val_mae: 3196.0933 - lr: 2.5000e-04\n",
      "Epoch 7/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3346.6052 - mse: 41850864.0000 - mae: 3346.9775\n",
      "Epoch 7: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3353.3816 - mse: 41952624.0000 - mae: 3353.7539 - val_loss: 3194.1421 - val_mse: 39930048.0000 - val_mae: 3194.5474 - lr: 2.5000e-04\n",
      "Epoch 8/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3349.8015 - mse: 41747168.0000 - mae: 3350.1697\n",
      "Epoch 8: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3354.0261 - mse: 41807016.0000 - mae: 3354.3945 - val_loss: 3197.1787 - val_mse: 39867660.0000 - val_mae: 3197.5835 - lr: 2.5000e-04\n",
      "Epoch 9/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3342.7988 - mse: 41647324.0000 - mae: 3343.1658\n",
      "Epoch 9: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3351.9514 - mse: 41728296.0000 - mae: 3352.3186 - val_loss: 3195.6226 - val_mse: 39633004.0000 - val_mae: 3196.0254 - lr: 2.5000e-04\n",
      "Epoch 10/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3352.0767 - mse: 41705328.0000 - mae: 3352.4456\n",
      "Epoch 10: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3352.0767 - mse: 41705328.0000 - mae: 3352.4456 - val_loss: 3197.9211 - val_mse: 39586216.0000 - val_mae: 3198.3276 - lr: 2.5000e-04\n",
      "Epoch 11/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 3343.5664 - mse: 41709412.0000 - mae: 3343.9346\n",
      "Epoch 11: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3350.0737 - mse: 41723168.0000 - mae: 3350.4426 - val_loss: 3196.6453 - val_mse: 39496592.0000 - val_mae: 3197.0498 - lr: 2.5000e-04\n",
      "Epoch 12/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3353.3721 - mse: 41930392.0000 - mae: 3353.7456\n",
      "Epoch 12: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3353.3721 - mse: 41930392.0000 - mae: 3353.7456 - val_loss: 3194.3984 - val_mse: 39432128.0000 - val_mae: 3194.7742 - lr: 1.2500e-04\n",
      "Epoch 13/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3333.5884 - mse: 41722992.0000 - mae: 3333.9578\n",
      "Epoch 13: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3341.8643 - mse: 41812320.0000 - mae: 3342.2339 - val_loss: 3196.4297 - val_mse: 39411000.0000 - val_mae: 3196.8059 - lr: 1.2500e-04\n",
      "Epoch 14/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3344.1592 - mse: 41867100.0000 - mae: 3344.5305\n",
      "Epoch 14: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3348.3477 - mse: 41924004.0000 - mae: 3348.7190 - val_loss: 3198.1455 - val_mse: 39947428.0000 - val_mae: 3198.5222 - lr: 1.2500e-04\n",
      "Epoch 15/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3340.5986 - mse: 41658908.0000 - mae: 3340.9705\n",
      "Epoch 15: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3346.9258 - mse: 41748396.0000 - mae: 3347.2981 - val_loss: 3195.6624 - val_mse: 39602880.0000 - val_mae: 3196.0369 - lr: 1.2500e-04\n",
      "Epoch 16/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 3341.8826 - mse: 41816552.0000 - mae: 3342.2537\n",
      "Epoch 16: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3346.7222 - mse: 41776220.0000 - mae: 3347.0933 - val_loss: 3194.5364 - val_mse: 39535068.0000 - val_mae: 3194.9104 - lr: 1.2500e-04\n",
      "Epoch 17/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 3338.5569 - mse: 41860060.0000 - mae: 3338.9268\n",
      "Epoch 17: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3344.5491 - mse: 41858868.0000 - mae: 3344.9197 - val_loss: 3198.3059 - val_mse: 39779316.0000 - val_mae: 3198.6821 - lr: 1.2500e-04\n",
      "Epoch 18/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3333.4688 - mse: 41722336.0000 - mae: 3333.8386\n",
      "Epoch 18: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3341.5520 - mse: 41806344.0000 - mae: 3341.9221 - val_loss: 3197.6169 - val_mse: 39806856.0000 - val_mae: 3197.9934 - lr: 1.2500e-04\n",
      "Epoch 19/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3334.0959 - mse: 41736392.0000 - mae: 3334.4673\n",
      "Epoch 19: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3338.2864 - mse: 41793236.0000 - mae: 3338.6580 - val_loss: 3199.6252 - val_mse: 39859132.0000 - val_mae: 3200.0017 - lr: 1.2500e-04\n",
      "Epoch 20/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3331.7144 - mse: 41774120.0000 - mae: 3332.0869\n",
      "Epoch 20: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3337.9966 - mse: 41862332.0000 - mae: 3338.3689 - val_loss: 3198.9216 - val_mse: 39884468.0000 - val_mae: 3199.2974 - lr: 1.2500e-04\n",
      "Epoch 21/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3334.1111 - mse: 41833688.0000 - mae: 3334.4827\n",
      "Epoch 21: val_loss did not improve from 3182.10620\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 3338.2400 - mse: 41888820.0000 - mae: 3338.6118 - val_loss: 3200.1338 - val_mse: 39880756.0000 - val_mae: 3200.5107 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "lstm_history = lstm_model.fit(train_data, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_lstm])\n",
    "lstm_history_ns = lstm_model.fit(train_data_ns, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_lstm_ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    486/Unknown - 5s 4ms/step - loss: 7633.3105 - mse: 184573648.0000 - mae: 7633.6924\n",
      "Epoch 1: val_loss improved from inf to 7117.62939, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 7s 6ms/step - loss: 7624.3828 - mse: 183766480.0000 - mae: 7624.7661 - val_loss: 7117.6294 - val_mse: 171725792.0000 - val_mae: 7118.0562 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "490/498 [============================>.] - ETA: 0s - loss: 7592.7051 - mse: 182591104.0000 - mae: 7593.0952\n",
      "Epoch 2: val_loss improved from 7117.62939 to 7094.01660, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 3ms/step - loss: 7601.3877 - mse: 182695536.0000 - mae: 7601.7788 - val_loss: 7094.0166 - val_mse: 170415072.0000 - val_mae: 7094.4849 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 7560.8662 - mse: 180823152.0000 - mae: 7561.2607\n",
      "Epoch 3: val_loss improved from 7094.01660 to 7047.12744, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 7562.4536 - mse: 180852656.0000 - mae: 7562.8477 - val_loss: 7047.1274 - val_mse: 168375264.0000 - val_mae: 7047.5312 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 7489.4834 - mse: 177870944.0000 - mae: 7489.8721\n",
      "Epoch 4: val_loss improved from 7047.12744 to 7002.45410, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 3ms/step - loss: 7509.6250 - mse: 178236000.0000 - mae: 7510.0142 - val_loss: 7002.4541 - val_mse: 165687696.0000 - val_mae: 7002.8921 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 7447.5889 - mse: 175440288.0000 - mae: 7447.9780\n",
      "Epoch 5: val_loss improved from 7002.45410 to 6950.59668, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 7445.8682 - mse: 175384752.0000 - mae: 7446.2583 - val_loss: 6950.5967 - val_mse: 162789408.0000 - val_mae: 6951.0479 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 7351.3579 - mse: 171693152.0000 - mae: 7351.7510\n",
      "Epoch 6: val_loss improved from 6950.59668 to 6881.61914, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 7356.7305 - mse: 171784768.0000 - mae: 7357.1230 - val_loss: 6881.6191 - val_mse: 159150784.0000 - val_mae: 6882.0576 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 7260.5229 - mse: 167756512.0000 - mae: 7260.9175\n",
      "Epoch 7: val_loss improved from 6881.61914 to 6748.16064, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 7264.1807 - mse: 167868848.0000 - mae: 7264.5752 - val_loss: 6748.1606 - val_mse: 155403504.0000 - val_mae: 6748.5698 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 7124.3979 - mse: 162778448.0000 - mae: 7124.7817\n",
      "Epoch 8: val_loss improved from 6748.16064 to 6728.54639, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 7146.3867 - mse: 163298240.0000 - mae: 7146.7710 - val_loss: 6728.5464 - val_mse: 151055904.0000 - val_mae: 6728.9619 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "489/498 [============================>.] - ETA: 0s - loss: 7120.2935 - mse: 158523552.0000 - mae: 7120.6797\n",
      "Epoch 9: val_loss improved from 6728.54639 to 6632.02051, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 7105.6675 - mse: 158014064.0000 - mae: 7106.0542 - val_loss: 6632.0205 - val_mse: 146219728.0000 - val_mae: 6632.4146 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 7007.4648 - mse: 153262800.0000 - mae: 7007.8506\n",
      "Epoch 10: val_loss improved from 6632.02051 to 6552.53760, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 7014.2729 - mse: 153391504.0000 - mae: 7014.6592 - val_loss: 6552.5376 - val_mse: 141994176.0000 - val_mae: 6552.9883 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 6921.0039 - mse: 148730560.0000 - mae: 6921.3872\n",
      "Epoch 11: val_loss improved from 6552.53760 to 6464.36523, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 6920.4966 - mse: 148614928.0000 - mae: 6920.8809 - val_loss: 6464.3652 - val_mse: 137453520.0000 - val_mae: 6464.7812 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "485/498 [============================>.] - ETA: 0s - loss: 6822.9424 - mse: 144124128.0000 - mae: 6823.3301\n",
      "Epoch 12: val_loss improved from 6464.36523 to 6383.23535, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 6827.3726 - mse: 143811584.0000 - mae: 6827.7617 - val_loss: 6383.2354 - val_mse: 133127856.0000 - val_mae: 6383.6440 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 6733.0923 - mse: 138927248.0000 - mae: 6733.4800\n",
      "Epoch 13: val_loss improved from 6383.23535 to 6294.84668, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 6735.6221 - mse: 138987152.0000 - mae: 6736.0098 - val_loss: 6294.8467 - val_mse: 128579664.0000 - val_mae: 6295.2300 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "488/498 [============================>.] - ETA: 0s - loss: 6628.5962 - mse: 133908600.0000 - mae: 6628.9849\n",
      "Epoch 14: val_loss improved from 6294.84668 to 6213.20898, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 6641.7383 - mse: 134103744.0000 - mae: 6642.1284 - val_loss: 6213.2090 - val_mse: 124192864.0000 - val_mae: 6213.6558 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "489/498 [============================>.] - ETA: 0s - loss: 6543.4834 - mse: 129240368.0000 - mae: 6543.8691\n",
      "Epoch 15: val_loss improved from 6213.20898 to 6129.77881, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 6552.0186 - mse: 129354456.0000 - mae: 6552.4048 - val_loss: 6129.7788 - val_mse: 119760160.0000 - val_mae: 6130.1982 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 6429.8179 - mse: 125833184.0000 - mae: 6430.2085\n",
      "Epoch 16: val_loss improved from 6129.77881 to 5842.30859, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 6424.4976 - mse: 125615944.0000 - mae: 6424.8877 - val_loss: 5842.3086 - val_mse: 115945096.0000 - val_mae: 5842.7563 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "489/498 [============================>.] - ETA: 0s - loss: 6144.9639 - mse: 121408760.0000 - mae: 6145.3555\n",
      "Epoch 17: val_loss improved from 5842.30859 to 5705.47559, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 6146.8901 - mse: 121288112.0000 - mae: 6147.2827 - val_loss: 5705.4756 - val_mse: 111329864.0000 - val_mae: 5705.9229 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "486/498 [============================>.] - ETA: 0s - loss: 6176.8711 - mse: 115844672.0000 - mae: 6177.2720\n",
      "Epoch 18: val_loss did not improve from 5705.47559\n",
      "498/498 [==============================] - 2s 3ms/step - loss: 6189.3057 - mse: 115834216.0000 - mae: 6189.7090 - val_loss: 5903.2808 - val_mse: 106917272.0000 - val_mae: 5903.7124 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "483/498 [============================>.] - ETA: 0s - loss: 5847.3545 - mse: 108408008.0000 - mae: 5847.7295\n",
      "Epoch 19: val_loss improved from 5705.47559 to 5343.00439, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 5863.8081 - mse: 108691040.0000 - mae: 5864.1851 - val_loss: 5343.0044 - val_mse: 98363496.0000 - val_mae: 5343.4321 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "484/498 [============================>.] - ETA: 0s - loss: 5920.9766 - mse: 103782272.0000 - mae: 5921.3550\n",
      "Epoch 20: val_loss did not improve from 5343.00439\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 5932.2920 - mse: 103796952.0000 - mae: 5932.6704 - val_loss: 5734.9272 - val_mse: 97344960.0000 - val_mae: 5735.3188 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 5997.2271 - mse: 100804736.0000 - mae: 5997.6123\n",
      "Epoch 21: val_loss did not improve from 5343.00439\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 5999.8267 - mse: 100865184.0000 - mae: 6000.2119 - val_loss: 5602.7002 - val_mse: 93220352.0000 - val_mae: 5603.0967 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 5575.9531 - mse: 94926488.0000 - mae: 5576.3359\n",
      "Epoch 22: val_loss improved from 5343.00439 to 5027.54932, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 5575.7852 - mse: 94950368.0000 - mae: 5576.1689 - val_loss: 5027.5493 - val_mse: 85973240.0000 - val_mae: 5027.9346 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 5270.7090 - mse: 89465384.0000 - mae: 5271.0869\n",
      "Epoch 23: val_loss improved from 5027.54932 to 4911.31885, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 3s 5ms/step - loss: 5269.4976 - mse: 89385008.0000 - mae: 5269.8755 - val_loss: 4911.3188 - val_mse: 81140040.0000 - val_mae: 4911.7778 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 5191.2983 - mse: 85407720.0000 - mae: 5191.6821\n",
      "Epoch 24: val_loss improved from 4911.31885 to 4908.51367, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 5ms/step - loss: 5193.6758 - mse: 85276656.0000 - mae: 5194.0605 - val_loss: 4908.5137 - val_mse: 78093536.0000 - val_mae: 4908.9419 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 5044.6860 - mse: 80594720.0000 - mae: 5045.0669\n",
      "Epoch 25: val_loss improved from 4908.51367 to 4723.48535, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 5049.6392 - mse: 80547256.0000 - mae: 5050.0210 - val_loss: 4723.4854 - val_mse: 72766104.0000 - val_mae: 4723.9438 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 4891.8159 - mse: 75106056.0000 - mae: 4892.1914\n",
      "Epoch 26: val_loss improved from 4723.48535 to 4535.40283, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 5ms/step - loss: 4889.5581 - mse: 75080160.0000 - mae: 4889.9336 - val_loss: 4535.4028 - val_mse: 68061656.0000 - val_mae: 4535.8149 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 4743.5161 - mse: 70657368.0000 - mae: 4743.8916\n",
      "Epoch 27: val_loss improved from 4535.40283 to 4522.94629, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 4743.5161 - mse: 70657368.0000 - mae: 4743.8916 - val_loss: 4522.9463 - val_mse: 64908168.0000 - val_mae: 4523.3262 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 4629.6055 - mse: 67069140.0000 - mae: 4630.0278\n",
      "Epoch 28: val_loss improved from 4522.94629 to 4345.94043, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 4628.5088 - mse: 67045516.0000 - mae: 4628.9316 - val_loss: 4345.9404 - val_mse: 61853176.0000 - val_mae: 4346.3701 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 4515.3271 - mse: 63898456.0000 - mae: 4515.7202\n",
      "Epoch 29: val_loss improved from 4345.94043 to 4204.68896, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 4523.4204 - mse: 64030684.0000 - mae: 4523.8135 - val_loss: 4204.6890 - val_mse: 58369424.0000 - val_mae: 4205.0942 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 4401.0884 - mse: 60654532.0000 - mae: 4401.4727\n",
      "Epoch 30: val_loss improved from 4204.68896 to 4089.69922, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 4416.1104 - mse: 60859972.0000 - mae: 4416.4951 - val_loss: 4089.6992 - val_mse: 56254488.0000 - val_mae: 4090.1438 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 4327.4810 - mse: 58447240.0000 - mae: 4327.8677\n",
      "Epoch 31: val_loss improved from 4089.69922 to 4034.30225, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 4323.7725 - mse: 58338056.0000 - mae: 4324.1572 - val_loss: 4034.3022 - val_mse: 53334608.0000 - val_mae: 4034.6150 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 4230.7119 - mse: 56132504.0000 - mae: 4231.0845\n",
      "Epoch 32: val_loss improved from 4034.30225 to 3922.08862, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 4238.9492 - mse: 56242176.0000 - mae: 4239.3218 - val_loss: 3922.0886 - val_mse: 51546740.0000 - val_mae: 3922.4817 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 4154.4268 - mse: 53903860.0000 - mae: 4154.7964\n",
      "Epoch 33: val_loss improved from 3922.08862 to 3905.90869, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 4158.6748 - mse: 53977500.0000 - mae: 4159.0444 - val_loss: 3905.9087 - val_mse: 49635916.0000 - val_mae: 3906.2871 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 4088.2510 - mse: 51558884.0000 - mae: 4088.6274\n",
      "Epoch 34: val_loss did not improve from 3905.90869\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 4089.2119 - mse: 51543112.0000 - mae: 4089.5881 - val_loss: 3912.0391 - val_mse: 48217812.0000 - val_mae: 3912.3914 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 4042.4297 - mse: 50455664.0000 - mae: 4042.8293\n",
      "Epoch 35: val_loss improved from 3905.90869 to 3894.51147, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 4042.4297 - mse: 50455664.0000 - mae: 4042.8293 - val_loss: 3894.5115 - val_mse: 46978152.0000 - val_mae: 3894.9006 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 3959.3979 - mse: 48701176.0000 - mae: 3959.7727\n",
      "Epoch 36: val_loss improved from 3894.51147 to 3694.30981, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3968.2661 - mse: 48885448.0000 - mae: 3968.6414 - val_loss: 3694.3098 - val_mse: 44131844.0000 - val_mae: 3694.6885 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 3904.7026 - mse: 47783032.0000 - mae: 3905.1023\n",
      "Epoch 37: val_loss improved from 3694.30981 to 3665.02954, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3895.5898 - mse: 47617352.0000 - mae: 3895.9905 - val_loss: 3665.0295 - val_mse: 43324532.0000 - val_mae: 3665.4646 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "485/498 [============================>.] - ETA: 0s - loss: 3823.1528 - mse: 45993284.0000 - mae: 3823.5247\n",
      "Epoch 38: val_loss improved from 3665.02954 to 3659.46216, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3848.5667 - mse: 46390504.0000 - mae: 3848.9402 - val_loss: 3659.4622 - val_mse: 43081808.0000 - val_mae: 3659.8945 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "487/498 [============================>.] - ETA: 0s - loss: 3797.6885 - mse: 45307356.0000 - mae: 3798.0637\n",
      "Epoch 39: val_loss improved from 3659.46216 to 3593.51172, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3805.9956 - mse: 45426836.0000 - mae: 3806.3718 - val_loss: 3593.5117 - val_mse: 42367560.0000 - val_mae: 3593.9312 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 3758.3354 - mse: 44663708.0000 - mae: 3758.7148\n",
      "Epoch 40: val_loss improved from 3593.51172 to 3511.57275, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3757.3499 - mse: 44607540.0000 - mae: 3757.7278 - val_loss: 3511.5728 - val_mse: 41115572.0000 - val_mae: 3511.9041 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3715.1536 - mse: 43522204.0000 - mae: 3715.5303\n",
      "Epoch 41: val_loss did not improve from 3511.57275\n",
      "498/498 [==============================] - 2s 3ms/step - loss: 3716.9238 - mse: 43544060.0000 - mae: 3717.3008 - val_loss: 3549.9353 - val_mse: 40641124.0000 - val_mae: 3550.2656 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3692.2256 - mse: 43428312.0000 - mae: 3692.6033\n",
      "Epoch 42: val_loss did not improve from 3511.57275\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3692.5540 - mse: 43431456.0000 - mae: 3692.9319 - val_loss: 3513.1179 - val_mse: 41652560.0000 - val_mae: 3513.5369 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3674.8809 - mse: 43674916.0000 - mae: 3675.2517\n",
      "Epoch 43: val_loss improved from 3511.57275 to 3471.54980, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3681.9595 - mse: 43801208.0000 - mae: 3682.3311 - val_loss: 3471.5498 - val_mse: 40678620.0000 - val_mae: 3471.9229 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3652.4072 - mse: 42885964.0000 - mae: 3652.7832\n",
      "Epoch 44: val_loss improved from 3471.54980 to 3466.65625, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3651.2407 - mse: 42873436.0000 - mae: 3651.6167 - val_loss: 3466.6562 - val_mse: 40082516.0000 - val_mae: 3467.0427 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "489/498 [============================>.] - ETA: 0s - loss: 3613.9165 - mse: 42445084.0000 - mae: 3614.2871\n",
      "Epoch 45: val_loss improved from 3466.65625 to 3345.02783, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3617.5444 - mse: 42475176.0000 - mae: 3617.9158 - val_loss: 3345.0278 - val_mse: 38146468.0000 - val_mae: 3345.3879 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "489/498 [============================>.] - ETA: 0s - loss: 3592.4666 - mse: 41909600.0000 - mae: 3592.8452\n",
      "Epoch 46: val_loss did not improve from 3345.02783\n",
      "498/498 [==============================] - 2s 3ms/step - loss: 3610.2415 - mse: 42197880.0000 - mae: 3610.6208 - val_loss: 3389.9414 - val_mse: 40379152.0000 - val_mae: 3390.3765 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3619.8733 - mse: 43254948.0000 - mae: 3620.2561\n",
      "Epoch 47: val_loss did not improve from 3345.02783\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3617.1428 - mse: 43256240.0000 - mae: 3617.5266 - val_loss: 3515.4775 - val_mse: 41943012.0000 - val_mae: 3515.9001 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "483/498 [============================>.] - ETA: 0s - loss: 3651.7297 - mse: 43713308.0000 - mae: 3652.1221\n",
      "Epoch 48: val_loss did not improve from 3345.02783\n",
      "498/498 [==============================] - 2s 3ms/step - loss: 3654.5032 - mse: 43704084.0000 - mae: 3654.8965 - val_loss: 3474.8774 - val_mse: 41492844.0000 - val_mae: 3475.1970 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 3613.5571 - mse: 43445068.0000 - mae: 3613.9482\n",
      "Epoch 49: val_loss improved from 3345.02783 to 3318.27002, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3627.8469 - mse: 43649680.0000 - mae: 3628.2383 - val_loss: 3318.2700 - val_mse: 38546220.0000 - val_mae: 3318.6846 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 3509.9353 - mse: 41342516.0000 - mae: 3510.3071\n",
      "Epoch 50: val_loss improved from 3318.27002 to 3281.93140, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3525.5393 - mse: 41585164.0000 - mae: 3525.9124 - val_loss: 3281.9314 - val_mse: 38772312.0000 - val_mae: 3282.4043 - lr: 0.0010\n",
      "Epoch 51/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3544.5168 - mse: 41575332.0000 - mae: 3544.8938\n",
      "Epoch 51: val_loss did not improve from 3281.93140\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3549.1238 - mse: 41624748.0000 - mae: 3549.5010 - val_loss: 3326.4741 - val_mse: 37060056.0000 - val_mae: 3326.8577 - lr: 0.0010\n",
      "Epoch 52/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3622.4441 - mse: 43616624.0000 - mae: 3622.8267\n",
      "Epoch 52: val_loss did not improve from 3281.93140\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3626.9883 - mse: 43661960.0000 - mae: 3627.3713 - val_loss: 3437.5923 - val_mse: 41489240.0000 - val_mae: 3438.0540 - lr: 0.0010\n",
      "Epoch 53/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 3541.0359 - mse: 41894464.0000 - mae: 3541.4136\n",
      "Epoch 53: val_loss did not improve from 3281.93140\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3551.4070 - mse: 42035604.0000 - mae: 3551.7849 - val_loss: 3319.7607 - val_mse: 37108440.0000 - val_mae: 3320.1709 - lr: 0.0010\n",
      "Epoch 54/500\n",
      "487/498 [============================>.] - ETA: 0s - loss: 3505.4832 - mse: 41428392.0000 - mae: 3505.8584\n",
      "Epoch 54: val_loss did not improve from 3281.93140\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3512.5483 - mse: 41472948.0000 - mae: 3512.9243 - val_loss: 3377.9507 - val_mse: 39483028.0000 - val_mae: 3378.3701 - lr: 0.0010\n",
      "Epoch 55/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3529.6833 - mse: 42403616.0000 - mae: 3530.0598\n",
      "Epoch 55: val_loss did not improve from 3281.93140\n",
      "498/498 [==============================] - 2s 3ms/step - loss: 3531.4885 - mse: 42417048.0000 - mae: 3531.8650 - val_loss: 3368.7461 - val_mse: 39822248.0000 - val_mae: 3369.1057 - lr: 0.0010\n",
      "Epoch 56/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3531.1709 - mse: 41850360.0000 - mae: 3531.5569\n",
      "Epoch 56: val_loss did not improve from 3281.93140\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3531.1709 - mse: 41850360.0000 - mae: 3531.5569 - val_loss: 3285.4822 - val_mse: 39116696.0000 - val_mae: 3285.8433 - lr: 0.0010\n",
      "Epoch 57/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 3508.7942 - mse: 41781676.0000 - mae: 3509.1912\n",
      "Epoch 57: val_loss did not improve from 3281.93140\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3525.1824 - mse: 41993908.0000 - mae: 3525.5798 - val_loss: 3321.4197 - val_mse: 39233404.0000 - val_mae: 3321.8032 - lr: 0.0010\n",
      "Epoch 58/500\n",
      "483/498 [============================>.] - ETA: 0s - loss: 3503.0850 - mse: 42132604.0000 - mae: 3503.4619\n",
      "Epoch 58: val_loss improved from 3281.93140 to 3253.49780, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3519.3342 - mse: 42238852.0000 - mae: 3519.7104 - val_loss: 3253.4978 - val_mse: 38092904.0000 - val_mae: 3253.8235 - lr: 0.0010\n",
      "Epoch 59/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 3471.8313 - mse: 41591228.0000 - mae: 3472.2136\n",
      "Epoch 59: val_loss did not improve from 3253.49780\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3484.9868 - mse: 41790952.0000 - mae: 3485.3699 - val_loss: 3267.4556 - val_mse: 38550060.0000 - val_mae: 3267.8286 - lr: 0.0010\n",
      "Epoch 60/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3519.7734 - mse: 42309336.0000 - mae: 3520.1731\n",
      "Epoch 60: val_loss did not improve from 3253.49780\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3521.5283 - mse: 42409920.0000 - mae: 3521.9285 - val_loss: 3381.4041 - val_mse: 38855768.0000 - val_mae: 3381.8816 - lr: 0.0010\n",
      "Epoch 61/500\n",
      "487/498 [============================>.] - ETA: 0s - loss: 3503.1133 - mse: 41407980.0000 - mae: 3503.5200\n",
      "Epoch 61: val_loss did not improve from 3253.49780\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3519.7532 - mse: 41772108.0000 - mae: 3520.1584 - val_loss: 3290.8547 - val_mse: 39082956.0000 - val_mae: 3291.2290 - lr: 0.0010\n",
      "Epoch 62/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3490.5413 - mse: 42412328.0000 - mae: 3490.9253\n",
      "Epoch 62: val_loss did not improve from 3253.49780\n",
      "498/498 [==============================] - 2s 3ms/step - loss: 3490.0684 - mse: 42418260.0000 - mae: 3490.4524 - val_loss: 3265.6201 - val_mse: 40984612.0000 - val_mae: 3266.0435 - lr: 0.0010\n",
      "Epoch 63/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3471.6614 - mse: 43339952.0000 - mae: 3472.0293\n",
      "Epoch 63: val_loss did not improve from 3253.49780\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3476.7493 - mse: 43448876.0000 - mae: 3477.1172 - val_loss: 3301.4180 - val_mse: 41387916.0000 - val_mae: 3301.8369 - lr: 0.0010\n",
      "Epoch 64/500\n",
      "487/498 [============================>.] - ETA: 0s - loss: 3467.0894 - mse: 42887424.0000 - mae: 3467.4631\n",
      "Epoch 64: val_loss improved from 3253.49780 to 3198.69556, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3480.2593 - mse: 43091960.0000 - mae: 3480.6335 - val_loss: 3198.6956 - val_mse: 38709672.0000 - val_mae: 3199.0642 - lr: 0.0010\n",
      "Epoch 65/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3501.6777 - mse: 43074816.0000 - mae: 3502.0618\n",
      "Epoch 65: val_loss did not improve from 3198.69556\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3510.9409 - mse: 43229496.0000 - mae: 3511.3254 - val_loss: 3335.9397 - val_mse: 42606744.0000 - val_mae: 3336.3479 - lr: 0.0010\n",
      "Epoch 66/500\n",
      "488/498 [============================>.] - ETA: 0s - loss: 3422.2217 - mse: 42932376.0000 - mae: 3422.5911\n",
      "Epoch 66: val_loss improved from 3198.69556 to 3183.67847, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3436.4849 - mse: 43149028.0000 - mae: 3436.8555 - val_loss: 3183.6785 - val_mse: 38185204.0000 - val_mae: 3184.1096 - lr: 0.0010\n",
      "Epoch 67/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3467.8931 - mse: 42347596.0000 - mae: 3468.2690\n",
      "Epoch 67: val_loss did not improve from 3183.67847\n",
      "498/498 [==============================] - 2s 3ms/step - loss: 3469.9177 - mse: 42399644.0000 - mae: 3470.2937 - val_loss: 3241.8601 - val_mse: 39960008.0000 - val_mae: 3242.3408 - lr: 0.0010\n",
      "Epoch 68/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3460.7021 - mse: 43738320.0000 - mae: 3461.0730\n",
      "Epoch 68: val_loss did not improve from 3183.67847\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3460.7021 - mse: 43738320.0000 - mae: 3461.0730 - val_loss: 3337.0198 - val_mse: 40336096.0000 - val_mae: 3337.5093 - lr: 0.0010\n",
      "Epoch 69/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 3464.9312 - mse: 42092432.0000 - mae: 3465.3093\n",
      "Epoch 69: val_loss did not improve from 3183.67847\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3477.8994 - mse: 42402600.0000 - mae: 3478.2788 - val_loss: 3380.0613 - val_mse: 41740748.0000 - val_mae: 3380.5222 - lr: 0.0010\n",
      "Epoch 70/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3464.9548 - mse: 42522676.0000 - mae: 3465.3320\n",
      "Epoch 70: val_loss did not improve from 3183.67847\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3468.9502 - mse: 42607184.0000 - mae: 3469.3274 - val_loss: 3336.0928 - val_mse: 41741140.0000 - val_mae: 3336.4114 - lr: 0.0010\n",
      "Epoch 71/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 3460.8464 - mse: 42835216.0000 - mae: 3461.2195\n",
      "Epoch 71: val_loss did not improve from 3183.67847\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3459.1575 - mse: 42760748.0000 - mae: 3459.5308 - val_loss: 3297.6797 - val_mse: 40045352.0000 - val_mae: 3298.0957 - lr: 0.0010\n",
      "Epoch 72/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3562.6887 - mse: 43267056.0000 - mae: 3563.0876\n",
      "Epoch 72: val_loss did not improve from 3183.67847\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3565.0715 - mse: 43339580.0000 - mae: 3565.4709 - val_loss: 3285.3376 - val_mse: 39231012.0000 - val_mae: 3285.8279 - lr: 0.0010\n",
      "Epoch 73/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3554.2456 - mse: 43055860.0000 - mae: 3554.6211\n",
      "Epoch 73: val_loss did not improve from 3183.67847\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3563.9500 - mse: 43154572.0000 - mae: 3564.3267 - val_loss: 3257.0015 - val_mse: 38131116.0000 - val_mae: 3257.4443 - lr: 0.0010\n",
      "Epoch 74/500\n",
      "488/498 [============================>.] - ETA: 0s - loss: 3498.7500 - mse: 43078300.0000 - mae: 3499.1335\n",
      "Epoch 74: val_loss did not improve from 3183.67847\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3499.4927 - mse: 43026828.0000 - mae: 3499.8752 - val_loss: 3272.1943 - val_mse: 38749096.0000 - val_mae: 3272.5671 - lr: 0.0010\n",
      "Epoch 75/500\n",
      "487/498 [============================>.] - ETA: 0s - loss: 3428.2593 - mse: 42666780.0000 - mae: 3428.6362\n",
      "Epoch 75: val_loss did not improve from 3183.67847\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3442.3743 - mse: 42951348.0000 - mae: 3442.7515 - val_loss: 3249.9551 - val_mse: 42071208.0000 - val_mae: 3250.4141 - lr: 0.0010\n",
      "Epoch 76/500\n",
      "485/498 [============================>.] - ETA: 0s - loss: 3432.3599 - mse: 42390500.0000 - mae: 3432.7747\n",
      "Epoch 76: val_loss did not improve from 3183.67847\n",
      "498/498 [==============================] - 2s 3ms/step - loss: 3445.5547 - mse: 42534148.0000 - mae: 3445.9707 - val_loss: 3292.8723 - val_mse: 39457540.0000 - val_mae: 3293.3562 - lr: 0.0010\n",
      "Epoch 77/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3435.2595 - mse: 42788252.0000 - mae: 3435.6406\n",
      "Epoch 77: val_loss did not improve from 3183.67847\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3435.2708 - mse: 42782096.0000 - mae: 3435.6521 - val_loss: 3193.3350 - val_mse: 40266204.0000 - val_mae: 3193.7932 - lr: 5.0000e-04\n",
      "Epoch 78/500\n",
      "490/498 [============================>.] - ETA: 0s - loss: 3407.0454 - mse: 42598028.0000 - mae: 3407.4260\n",
      "Epoch 78: val_loss improved from 3183.67847 to 3172.65088, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3421.0530 - mse: 42820516.0000 - mae: 3421.4329 - val_loss: 3172.6509 - val_mse: 39755532.0000 - val_mae: 3172.9514 - lr: 5.0000e-04\n",
      "Epoch 79/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3432.2295 - mse: 43071668.0000 - mae: 3432.5974\n",
      "Epoch 79: val_loss did not improve from 3172.65088\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3439.6602 - mse: 43232976.0000 - mae: 3440.0283 - val_loss: 3175.3665 - val_mse: 38098680.0000 - val_mae: 3175.7349 - lr: 5.0000e-04\n",
      "Epoch 80/500\n",
      "489/498 [============================>.] - ETA: 0s - loss: 3416.2173 - mse: 42019600.0000 - mae: 3416.5898\n",
      "Epoch 80: val_loss did not improve from 3172.65088\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3420.1353 - mse: 42085128.0000 - mae: 3420.5081 - val_loss: 3173.9038 - val_mse: 39575880.0000 - val_mae: 3174.2932 - lr: 5.0000e-04\n",
      "Epoch 81/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 3409.6274 - mse: 42627048.0000 - mae: 3410.0173\n",
      "Epoch 81: val_loss improved from 3172.65088 to 3148.00269, saving model to new_multi_stne_rnn_weight_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3411.4893 - mse: 42640336.0000 - mae: 3411.8801 - val_loss: 3148.0027 - val_mse: 38456804.0000 - val_mae: 3148.4688 - lr: 5.0000e-04\n",
      "Epoch 82/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 3391.6333 - mse: 42282852.0000 - mae: 3392.0415\n",
      "Epoch 82: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3394.0745 - mse: 42374660.0000 - mae: 3394.4827 - val_loss: 3159.2231 - val_mse: 39225268.0000 - val_mae: 3159.6838 - lr: 5.0000e-04\n",
      "Epoch 83/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3419.0051 - mse: 42318572.0000 - mae: 3419.3960\n",
      "Epoch 83: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 3ms/step - loss: 3419.0051 - mse: 42318572.0000 - mae: 3419.3960 - val_loss: 3168.3105 - val_mse: 38073096.0000 - val_mae: 3168.8083 - lr: 5.0000e-04\n",
      "Epoch 84/500\n",
      "488/498 [============================>.] - ETA: 0s - loss: 3400.0862 - mse: 42156976.0000 - mae: 3400.4771\n",
      "Epoch 84: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3407.5344 - mse: 42116588.0000 - mae: 3407.9248 - val_loss: 3156.8723 - val_mse: 38068148.0000 - val_mae: 3157.2717 - lr: 5.0000e-04\n",
      "Epoch 85/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3517.0786 - mse: 42430456.0000 - mae: 3517.4587\n",
      "Epoch 85: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 3ms/step - loss: 3516.7053 - mse: 42417996.0000 - mae: 3517.0857 - val_loss: 3305.7000 - val_mse: 37480512.0000 - val_mae: 3306.1335 - lr: 5.0000e-04\n",
      "Epoch 86/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3433.9001 - mse: 41901736.0000 - mae: 3434.2759\n",
      "Epoch 86: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3439.1836 - mse: 41997696.0000 - mae: 3439.5596 - val_loss: 3170.0847 - val_mse: 38381364.0000 - val_mae: 3170.4880 - lr: 5.0000e-04\n",
      "Epoch 87/500\n",
      "489/498 [============================>.] - ETA: 0s - loss: 3365.5989 - mse: 41719644.0000 - mae: 3365.9661\n",
      "Epoch 87: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3385.4102 - mse: 42055372.0000 - mae: 3385.7781 - val_loss: 3180.8987 - val_mse: 38294968.0000 - val_mae: 3181.2844 - lr: 5.0000e-04\n",
      "Epoch 88/500\n",
      "490/498 [============================>.] - ETA: 0s - loss: 3403.8870 - mse: 42743620.0000 - mae: 3404.2627\n",
      "Epoch 88: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3406.6467 - mse: 42711252.0000 - mae: 3407.0232 - val_loss: 3159.5796 - val_mse: 37947628.0000 - val_mae: 3159.9417 - lr: 5.0000e-04\n",
      "Epoch 89/500\n",
      "486/498 [============================>.] - ETA: 0s - loss: 3437.2498 - mse: 41832144.0000 - mae: 3437.6211\n",
      "Epoch 89: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3463.6050 - mse: 42364552.0000 - mae: 3463.9775 - val_loss: 3184.0193 - val_mse: 37318144.0000 - val_mae: 3184.4263 - lr: 5.0000e-04\n",
      "Epoch 90/500\n",
      "490/498 [============================>.] - ETA: 0s - loss: 3446.1653 - mse: 41493420.0000 - mae: 3446.5422\n",
      "Epoch 90: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 3ms/step - loss: 3453.0750 - mse: 41583312.0000 - mae: 3453.4526 - val_loss: 3217.6443 - val_mse: 38187068.0000 - val_mae: 3218.0706 - lr: 5.0000e-04\n",
      "Epoch 91/500\n",
      "488/498 [============================>.] - ETA: 0s - loss: 3411.8416 - mse: 42463624.0000 - mae: 3412.2085\n",
      "Epoch 91: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3407.7163 - mse: 42324076.0000 - mae: 3408.0852 - val_loss: 3160.9856 - val_mse: 38556596.0000 - val_mae: 3161.4509 - lr: 5.0000e-04\n",
      "Epoch 92/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3396.2412 - mse: 42127028.0000 - mae: 3396.6165\n",
      "Epoch 92: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 3ms/step - loss: 3398.3464 - mse: 42108240.0000 - mae: 3398.7227 - val_loss: 3156.2661 - val_mse: 38435732.0000 - val_mae: 3156.6785 - lr: 2.5000e-04\n",
      "Epoch 93/500\n",
      "484/498 [============================>.] - ETA: 0s - loss: 3372.1685 - mse: 41779620.0000 - mae: 3372.5366\n",
      "Epoch 93: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3378.9993 - mse: 41929752.0000 - mae: 3379.3682 - val_loss: 3157.6643 - val_mse: 38498836.0000 - val_mae: 3158.0430 - lr: 2.5000e-04\n",
      "Epoch 94/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 3380.9358 - mse: 42399472.0000 - mae: 3381.3062\n",
      "Epoch 94: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3384.7490 - mse: 42469876.0000 - mae: 3385.1201 - val_loss: 3159.8354 - val_mse: 38589216.0000 - val_mae: 3160.2524 - lr: 2.5000e-04\n",
      "Epoch 95/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3371.1140 - mse: 42172756.0000 - mae: 3371.4839\n",
      "Epoch 95: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3371.1140 - mse: 42172756.0000 - mae: 3371.4839 - val_loss: 3159.6492 - val_mse: 38636792.0000 - val_mae: 3160.0947 - lr: 2.5000e-04\n",
      "Epoch 96/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3366.8123 - mse: 42023464.0000 - mae: 3367.1816\n",
      "Epoch 96: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3370.1211 - mse: 42100996.0000 - mae: 3370.4905 - val_loss: 3171.0881 - val_mse: 38891848.0000 - val_mae: 3171.4988 - lr: 2.5000e-04\n",
      "Epoch 97/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3369.6145 - mse: 42204776.0000 - mae: 3369.9827\n",
      "Epoch 97: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3375.6960 - mse: 42307692.0000 - mae: 3376.0647 - val_loss: 3162.9675 - val_mse: 38633288.0000 - val_mae: 3163.3367 - lr: 2.5000e-04\n",
      "Epoch 98/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3408.6145 - mse: 42179576.0000 - mae: 3408.9861\n",
      "Epoch 98: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3411.1018 - mse: 42210404.0000 - mae: 3411.4741 - val_loss: 3194.4646 - val_mse: 37893092.0000 - val_mae: 3194.8938 - lr: 2.5000e-04\n",
      "Epoch 99/500\n",
      "490/498 [============================>.] - ETA: 0s - loss: 3376.1387 - mse: 41444060.0000 - mae: 3376.5117\n",
      "Epoch 99: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3373.6536 - mse: 41296060.0000 - mae: 3374.0273 - val_loss: 3163.3655 - val_mse: 38535524.0000 - val_mae: 3163.7893 - lr: 2.5000e-04\n",
      "Epoch 100/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3382.6177 - mse: 41843776.0000 - mae: 3382.9878\n",
      "Epoch 100: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3384.3921 - mse: 41893000.0000 - mae: 3384.7625 - val_loss: 3174.5022 - val_mse: 38619204.0000 - val_mae: 3174.9241 - lr: 2.5000e-04\n",
      "Epoch 101/500\n",
      "488/498 [============================>.] - ETA: 0s - loss: 3375.0752 - mse: 41803276.0000 - mae: 3375.4395\n",
      "Epoch 101: val_loss did not improve from 3148.00269\n",
      "498/498 [==============================] - 2s 3ms/step - loss: 3383.3989 - mse: 41857544.0000 - mae: 3383.7644 - val_loss: 3170.7161 - val_mse: 38355968.0000 - val_mae: 3171.1582 - lr: 2.5000e-04\n",
      "Epoch 1/500\n",
      "    487/Unknown - 2s 4ms/step - loss: 3351.0767 - mse: 41659356.0000 - mae: 3351.4448\n",
      "Epoch 1: val_loss improved from inf to 3172.40283, saving model to new_multi_stne_rnn_weight_ns_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3367.8918 - mse: 41844656.0000 - mae: 3368.2610 - val_loss: 3172.4028 - val_mse: 38548964.0000 - val_mae: 3172.7944 - lr: 1.2500e-04\n",
      "Epoch 2/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3358.9604 - mse: 41807328.0000 - mae: 3359.3298\n",
      "Epoch 2: val_loss did not improve from 3172.40283\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3364.6365 - mse: 41884732.0000 - mae: 3365.0061 - val_loss: 3172.5781 - val_mse: 38575244.0000 - val_mae: 3172.9705 - lr: 1.2500e-04\n",
      "Epoch 3/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3351.4021 - mse: 41962108.0000 - mae: 3351.7693\n",
      "Epoch 3: val_loss did not improve from 3172.40283\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3360.0493 - mse: 42023156.0000 - mae: 3360.4170 - val_loss: 3174.0911 - val_mse: 38827248.0000 - val_mae: 3174.4827 - lr: 1.2500e-04\n",
      "Epoch 4/500\n",
      "486/498 [============================>.] - ETA: 0s - loss: 3341.8188 - mse: 41828380.0000 - mae: 3342.1904\n",
      "Epoch 4: val_loss did not improve from 3172.40283\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3359.3911 - mse: 41997160.0000 - mae: 3359.7634 - val_loss: 3175.5647 - val_mse: 38851268.0000 - val_mae: 3175.9460 - lr: 1.2500e-04\n",
      "Epoch 5/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3362.7390 - mse: 42063896.0000 - mae: 3363.1101\n",
      "Epoch 5: val_loss did not improve from 3172.40283\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3362.7390 - mse: 42063896.0000 - mae: 3363.1101 - val_loss: 3176.6743 - val_mse: 38854320.0000 - val_mae: 3177.0493 - lr: 1.2500e-04\n",
      "Epoch 6/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3358.4163 - mse: 41865904.0000 - mae: 3358.7869\n",
      "Epoch 6: val_loss did not improve from 3172.40283\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3362.4121 - mse: 41919664.0000 - mae: 3362.7832 - val_loss: 3176.7529 - val_mse: 38518520.0000 - val_mae: 3177.1367 - lr: 1.2500e-04\n",
      "Epoch 7/500\n",
      "490/498 [============================>.] - ETA: 0s - loss: 3350.7046 - mse: 41630216.0000 - mae: 3351.0754\n",
      "Epoch 7: val_loss did not improve from 3172.40283\n",
      "498/498 [==============================] - 2s 3ms/step - loss: 3359.0935 - mse: 41712384.0000 - mae: 3359.4648 - val_loss: 3176.7808 - val_mse: 38576276.0000 - val_mae: 3177.1675 - lr: 1.2500e-04\n",
      "Epoch 8/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3350.1863 - mse: 41705096.0000 - mae: 3350.5576\n",
      "Epoch 8: val_loss did not improve from 3172.40283\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3358.5908 - mse: 41763920.0000 - mae: 3358.9622 - val_loss: 3177.6204 - val_mse: 38672704.0000 - val_mae: 3178.0020 - lr: 1.2500e-04\n",
      "Epoch 9/500\n",
      "487/498 [============================>.] - ETA: 0s - loss: 3342.3215 - mse: 41634716.0000 - mae: 3342.6943\n",
      "Epoch 9: val_loss did not improve from 3172.40283\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3359.1299 - mse: 41816760.0000 - mae: 3359.5034 - val_loss: 3173.0005 - val_mse: 38573944.0000 - val_mae: 3173.3799 - lr: 1.2500e-04\n",
      "Epoch 10/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3353.3171 - mse: 41805876.0000 - mae: 3353.6892\n",
      "Epoch 10: val_loss improved from 3172.40283 to 3171.59351, saving model to new_multi_stne_rnn_weight_ns_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3357.2141 - mse: 41856512.0000 - mae: 3357.5859 - val_loss: 3171.5935 - val_mse: 38633172.0000 - val_mae: 3171.9722 - lr: 1.2500e-04\n",
      "Epoch 11/500\n",
      "487/498 [============================>.] - ETA: 0s - loss: 3339.9270 - mse: 41728788.0000 - mae: 3340.2974\n",
      "Epoch 11: val_loss improved from 3171.59351 to 3171.40845, saving model to new_multi_stne_rnn_weight_ns_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3356.6467 - mse: 41906292.0000 - mae: 3357.0178 - val_loss: 3171.4084 - val_mse: 38611480.0000 - val_mae: 3171.7759 - lr: 1.2500e-04\n",
      "Epoch 12/500\n",
      "486/498 [============================>.] - ETA: 0s - loss: 3338.0791 - mse: 41815340.0000 - mae: 3338.4497\n",
      "Epoch 12: val_loss did not improve from 3171.40845\n",
      "498/498 [==============================] - 2s 3ms/step - loss: 3355.5210 - mse: 41981284.0000 - mae: 3355.8911 - val_loss: 3171.8125 - val_mse: 38778052.0000 - val_mae: 3172.1912 - lr: 1.2500e-04\n",
      "Epoch 13/500\n",
      "486/498 [============================>.] - ETA: 0s - loss: 3335.5327 - mse: 41776300.0000 - mae: 3335.9038\n",
      "Epoch 13: val_loss did not improve from 3171.40845\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3352.9868 - mse: 41942052.0000 - mae: 3353.3584 - val_loss: 3172.6829 - val_mse: 38788952.0000 - val_mae: 3173.0347 - lr: 1.2500e-04\n",
      "Epoch 14/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3346.1399 - mse: 41987920.0000 - mae: 3346.5103\n",
      "Epoch 14: val_loss improved from 3171.40845 to 3171.37988, saving model to new_multi_stne_rnn_weight_ns_c1.h5\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3350.1443 - mse: 42039796.0000 - mae: 3350.5146 - val_loss: 3171.3799 - val_mse: 38727168.0000 - val_mae: 3171.7568 - lr: 1.2500e-04\n",
      "Epoch 15/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 3340.6455 - mse: 41933308.0000 - mae: 3341.0178\n",
      "Epoch 15: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3346.5850 - mse: 41926012.0000 - mae: 3346.9580 - val_loss: 3172.2151 - val_mse: 38783236.0000 - val_mae: 3172.5850 - lr: 1.2500e-04\n",
      "Epoch 16/500\n",
      "488/498 [============================>.] - ETA: 0s - loss: 3336.7485 - mse: 41658440.0000 - mae: 3337.1206\n",
      "Epoch 16: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3348.5352 - mse: 41773048.0000 - mae: 3348.9072 - val_loss: 3175.5657 - val_mse: 38839804.0000 - val_mae: 3175.9353 - lr: 1.2500e-04\n",
      "Epoch 17/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3347.5786 - mse: 41519244.0000 - mae: 3347.9521\n",
      "Epoch 17: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3356.1531 - mse: 41581132.0000 - mae: 3356.5271 - val_loss: 3180.8665 - val_mse: 38637792.0000 - val_mae: 3181.2261 - lr: 1.2500e-04\n",
      "Epoch 18/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3344.0181 - mse: 41665556.0000 - mae: 3344.3882\n",
      "Epoch 18: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3352.5747 - mse: 41724344.0000 - mae: 3352.9451 - val_loss: 3178.1443 - val_mse: 38810556.0000 - val_mae: 3178.5225 - lr: 1.2500e-04\n",
      "Epoch 19/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3348.9153 - mse: 41738104.0000 - mae: 3349.2856\n",
      "Epoch 19: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3352.8330 - mse: 41789372.0000 - mae: 3353.2034 - val_loss: 3175.6130 - val_mse: 38822992.0000 - val_mae: 3175.9619 - lr: 1.2500e-04\n",
      "Epoch 20/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3355.8076 - mse: 41673540.0000 - mae: 3356.1782\n",
      "Epoch 20: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3358.7380 - mse: 41709540.0000 - mae: 3359.1086 - val_loss: 3179.0828 - val_mse: 38321648.0000 - val_mae: 3179.4658 - lr: 1.2500e-04\n",
      "Epoch 21/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3354.2754 - mse: 41547224.0000 - mae: 3354.6460\n",
      "Epoch 21: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3354.2754 - mse: 41547224.0000 - mae: 3354.6460 - val_loss: 3178.3582 - val_mse: 38442044.0000 - val_mae: 3178.7380 - lr: 1.2500e-04\n",
      "Epoch 22/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3349.9805 - mse: 41530544.0000 - mae: 3350.3481\n",
      "Epoch 22: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3352.8386 - mse: 41564780.0000 - mae: 3353.2061 - val_loss: 3174.7000 - val_mse: 38432960.0000 - val_mae: 3175.0518 - lr: 1.2500e-04\n",
      "Epoch 23/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3351.3267 - mse: 41545528.0000 - mae: 3351.6963\n",
      "Epoch 23: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3351.3267 - mse: 41545528.0000 - mae: 3351.6963 - val_loss: 3174.1055 - val_mse: 38496096.0000 - val_mae: 3174.4678 - lr: 1.2500e-04\n",
      "Epoch 24/500\n",
      "487/498 [============================>.] - ETA: 0s - loss: 3332.7500 - mse: 41568736.0000 - mae: 3333.1255\n",
      "Epoch 24: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 3ms/step - loss: 3349.7197 - mse: 41751452.0000 - mae: 3350.0947 - val_loss: 3173.3760 - val_mse: 38483732.0000 - val_mae: 3173.7209 - lr: 1.2500e-04\n",
      "Epoch 25/500\n",
      "485/498 [============================>.] - ETA: 0s - loss: 3324.7058 - mse: 41594464.0000 - mae: 3325.0803\n",
      "Epoch 25: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 5ms/step - loss: 3342.9751 - mse: 41778268.0000 - mae: 3343.3503 - val_loss: 3175.6501 - val_mse: 38727728.0000 - val_mae: 3176.0325 - lr: 6.2500e-05\n",
      "Epoch 26/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3336.4138 - mse: 41727608.0000 - mae: 3336.7888\n",
      "Epoch 26: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3340.4495 - mse: 41781936.0000 - mae: 3340.8247 - val_loss: 3175.4043 - val_mse: 38780668.0000 - val_mae: 3175.7839 - lr: 6.2500e-05\n",
      "Epoch 27/500\n",
      "489/498 [============================>.] - ETA: 0s - loss: 3336.4861 - mse: 41750276.0000 - mae: 3336.8589\n",
      "Epoch 27: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3346.1353 - mse: 41853276.0000 - mae: 3346.5081 - val_loss: 3173.6357 - val_mse: 38843824.0000 - val_mae: 3174.0076 - lr: 6.2500e-05\n",
      "Epoch 28/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3345.7397 - mse: 41881812.0000 - mae: 3346.1096\n",
      "Epoch 28: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 5ms/step - loss: 3348.7148 - mse: 41919944.0000 - mae: 3349.0845 - val_loss: 3176.7827 - val_mse: 38867960.0000 - val_mae: 3177.1680 - lr: 6.2500e-05\n",
      "Epoch 29/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3334.8855 - mse: 41734792.0000 - mae: 3335.2578\n",
      "Epoch 29: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3340.6748 - mse: 41812092.0000 - mae: 3341.0476 - val_loss: 3175.3618 - val_mse: 38854800.0000 - val_mae: 3175.7312 - lr: 6.2500e-05\n",
      "Epoch 30/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 3333.3525 - mse: 41822732.0000 - mae: 3333.7227\n",
      "Epoch 30: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 5ms/step - loss: 3338.2725 - mse: 41781936.0000 - mae: 3338.6433 - val_loss: 3176.7021 - val_mse: 38871384.0000 - val_mae: 3177.0759 - lr: 6.2500e-05\n",
      "Epoch 31/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 3333.2605 - mse: 41816240.0000 - mae: 3333.6323\n",
      "Epoch 31: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3338.1782 - mse: 41775880.0000 - mae: 3338.5498 - val_loss: 3176.7000 - val_mse: 38863004.0000 - val_mae: 3177.0649 - lr: 6.2500e-05\n",
      "Epoch 32/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3356.0369 - mse: 41841144.0000 - mae: 3356.4087\n",
      "Epoch 32: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3359.9636 - mse: 41893980.0000 - mae: 3360.3352 - val_loss: 3177.6597 - val_mse: 38259400.0000 - val_mae: 3178.0266 - lr: 6.2500e-05\n",
      "Epoch 33/500\n",
      "491/498 [============================>.] - ETA: 0s - loss: 3335.3289 - mse: 41584672.0000 - mae: 3335.6929\n",
      "Epoch 33: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 5ms/step - loss: 3340.2231 - mse: 41546852.0000 - mae: 3340.5874 - val_loss: 3176.4395 - val_mse: 38845352.0000 - val_mae: 3176.7998 - lr: 6.2500e-05\n",
      "Epoch 34/500\n",
      "490/498 [============================>.] - ETA: 0s - loss: 3329.0422 - mse: 41675760.0000 - mae: 3329.4131\n",
      "Epoch 34: val_loss did not improve from 3171.37988\n",
      "498/498 [==============================] - 2s 4ms/step - loss: 3337.7883 - mse: 41761656.0000 - mae: 3338.1594 - val_loss: 3176.9817 - val_mse: 38833864.0000 - val_mae: 3177.3359 - lr: 6.2500e-05\n"
     ]
    }
   ],
   "source": [
    "rnn_history = rnn_model.fit(train_data, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_rnn])\n",
    "rnn_history_ns = rnn_model.fit(train_data_ns, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_rnn_ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    498/Unknown - 14s 7ms/step - loss: 7614.9609 - mse: 183370800.0000 - mae: 7615.3311\n",
      "Epoch 1: val_loss improved from inf to 7095.79785, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 16s 12ms/step - loss: 7614.9609 - mse: 183370800.0000 - mae: 7615.3311 - val_loss: 7095.7979 - val_mse: 170886832.0000 - val_mae: 7096.2158 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 7540.6865 - mse: 180545152.0000 - mae: 7541.0757\n",
      "Epoch 2: val_loss improved from 7095.79785 to 7012.77490, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 7552.8262 - mse: 180751408.0000 - mae: 7553.2158 - val_loss: 7012.7749 - val_mse: 167291744.0000 - val_mae: 7013.2676 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 7429.5776 - mse: 175548672.0000 - mae: 7429.9722\n",
      "Epoch 3: val_loss improved from 7012.77490 to 6897.45898, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 4s 9ms/step - loss: 7438.3032 - mse: 175904800.0000 - mae: 7438.6978 - val_loss: 6897.4590 - val_mse: 162110784.0000 - val_mae: 6897.8984 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 7278.7207 - mse: 169316480.0000 - mae: 7279.1074\n",
      "Epoch 4: val_loss improved from 6897.45898 to 6733.43311, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 7276.4204 - mse: 169238128.0000 - mae: 7276.8071 - val_loss: 6733.4331 - val_mse: 155285072.0000 - val_mae: 6733.8374 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 7088.9692 - mse: 161411984.0000 - mae: 7089.3560\n",
      "Epoch 5: val_loss improved from 6733.43311 to 6553.93896, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 7088.9692 - mse: 161411984.0000 - mae: 7089.3560 - val_loss: 6553.9390 - val_mse: 147672320.0000 - val_mae: 6554.3555 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 6917.4307 - mse: 152854048.0000 - mae: 6917.8062\n",
      "Epoch 6: val_loss did not improve from 6553.93896\n",
      "498/498 [==============================] - 4s 8ms/step - loss: 6921.0537 - mse: 152945840.0000 - mae: 6921.4292 - val_loss: 7487.9243 - val_mse: 140593808.0000 - val_mae: 7488.4189 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 7032.1997 - mse: 148155264.0000 - mae: 7032.6147\n",
      "Epoch 7: val_loss improved from 6553.93896 to 6275.31885, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 7033.8228 - mse: 148145568.0000 - mae: 7034.2378 - val_loss: 6275.3188 - val_mse: 135392288.0000 - val_mae: 6275.7944 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 6555.9409 - mse: 139248656.0000 - mae: 6556.3335\n",
      "Epoch 8: val_loss improved from 6275.31885 to 6016.58545, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 6555.9409 - mse: 139248656.0000 - mae: 6556.3335 - val_loss: 6016.5854 - val_mse: 125649248.0000 - val_mae: 6017.0742 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 6305.8770 - mse: 129594096.0000 - mae: 6306.2700\n",
      "Epoch 9: val_loss improved from 6016.58545 to 5852.36670, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 9ms/step - loss: 6306.1157 - mse: 129625032.0000 - mae: 6306.5083 - val_loss: 5852.3667 - val_mse: 118116968.0000 - val_mae: 5852.7910 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 6080.7700 - mse: 119996304.0000 - mae: 6081.1543\n",
      "Epoch 10: val_loss improved from 5852.36670 to 5639.21533, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 6087.6021 - mse: 120171744.0000 - mae: 6087.9868 - val_loss: 5639.2153 - val_mse: 109182760.0000 - val_mae: 5639.6479 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 5886.5859 - mse: 111671488.0000 - mae: 5886.9756\n",
      "Epoch 11: val_loss improved from 5639.21533 to 5472.31055, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 5890.4419 - mse: 111726560.0000 - mae: 5890.8315 - val_loss: 5472.3105 - val_mse: 101425136.0000 - val_mae: 5472.7134 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 5702.4756 - mse: 103879704.0000 - mae: 5702.8633\n",
      "Epoch 12: val_loss improved from 5472.31055 to 5252.62109, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 5699.2778 - mse: 103839352.0000 - mae: 5699.6650 - val_loss: 5252.6211 - val_mse: 93035504.0000 - val_mae: 5253.0454 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 5480.7612 - mse: 95497816.0000 - mae: 5481.1450\n",
      "Epoch 13: val_loss improved from 5252.62109 to 5067.34277, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 9ms/step - loss: 5482.3979 - mse: 95541448.0000 - mae: 5482.7822 - val_loss: 5067.3428 - val_mse: 85764080.0000 - val_mae: 5067.7524 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 5268.5010 - mse: 87505088.0000 - mae: 5268.8882\n",
      "Epoch 14: val_loss improved from 5067.34277 to 4882.56055, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 5265.0352 - mse: 87359712.0000 - mae: 5265.4238 - val_loss: 4882.5605 - val_mse: 78271048.0000 - val_mae: 4883.0068 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 5041.2427 - mse: 79913112.0000 - mae: 5041.6250\n",
      "Epoch 15: val_loss improved from 4882.56055 to 4675.84961, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 5045.0918 - mse: 79944408.0000 - mae: 5045.4746 - val_loss: 4675.8496 - val_mse: 71512896.0000 - val_mae: 4676.2925 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 4873.8618 - mse: 73743552.0000 - mae: 4874.2480\n",
      "Epoch 16: val_loss improved from 4675.84961 to 4447.43408, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 4871.8198 - mse: 73696312.0000 - mae: 4872.2070 - val_loss: 4447.4341 - val_mse: 64939548.0000 - val_mae: 4447.8906 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 4602.9326 - mse: 66079680.0000 - mae: 4603.3311\n",
      "Epoch 17: val_loss improved from 4447.43408 to 4245.05664, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 4601.9785 - mse: 66047000.0000 - mae: 4602.3770 - val_loss: 4245.0566 - val_mse: 58913084.0000 - val_mae: 4245.5098 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 4425.1357 - mse: 60930612.0000 - mae: 4425.5166\n",
      "Epoch 18: val_loss improved from 4245.05664 to 4057.99731, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 9ms/step - loss: 4425.6870 - mse: 60919040.0000 - mae: 4426.0674 - val_loss: 4057.9973 - val_mse: 54447112.0000 - val_mae: 4058.4004 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 4265.4263 - mse: 56532984.0000 - mae: 4265.8008\n",
      "Epoch 19: val_loss improved from 4057.99731 to 3939.23608, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 4268.5596 - mse: 56574120.0000 - mae: 4268.9346 - val_loss: 3939.2361 - val_mse: 50768288.0000 - val_mae: 3939.6514 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 4138.8555 - mse: 53135508.0000 - mae: 4139.2529\n",
      "Epoch 20: val_loss improved from 3939.23608 to 3837.35205, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 4138.8706 - mse: 53161416.0000 - mae: 4139.2681 - val_loss: 3837.3521 - val_mse: 48064068.0000 - val_mae: 3837.7798 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 4018.7834 - mse: 50337824.0000 - mae: 4019.1689\n",
      "Epoch 21: val_loss improved from 3837.35205 to 3708.68848, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 4017.4116 - mse: 50307684.0000 - mae: 4017.7971 - val_loss: 3708.6885 - val_mse: 45646376.0000 - val_mae: 3709.1851 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3924.9192 - mse: 48296860.0000 - mae: 3925.2915\n",
      "Epoch 22: val_loss did not improve from 3708.68848\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3924.9192 - mse: 48296860.0000 - mae: 3925.2915 - val_loss: 3712.9021 - val_mse: 44423208.0000 - val_mae: 3713.3025 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3902.3459 - mse: 47161448.0000 - mae: 3902.7322\n",
      "Epoch 23: val_loss improved from 3708.68848 to 3671.09961, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3911.2979 - mse: 47272204.0000 - mae: 3911.6846 - val_loss: 3671.0996 - val_mse: 43010208.0000 - val_mae: 3671.5012 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3848.2302 - mse: 45743968.0000 - mae: 3848.6084\n",
      "Epoch 24: val_loss improved from 3671.09961 to 3592.19238, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3848.5508 - mse: 45789800.0000 - mae: 3848.9292 - val_loss: 3592.1924 - val_mse: 41710496.0000 - val_mae: 3592.6152 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3783.7205 - mse: 44927520.0000 - mae: 3784.1001\n",
      "Epoch 25: val_loss improved from 3592.19238 to 3555.65454, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3784.2761 - mse: 44953968.0000 - mae: 3784.6562 - val_loss: 3555.6545 - val_mse: 41334352.0000 - val_mae: 3556.0569 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3732.6343 - mse: 44457500.0000 - mae: 3733.0129\n",
      "Epoch 26: val_loss did not improve from 3555.65454\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3735.9695 - mse: 44498312.0000 - mae: 3736.3484 - val_loss: 3559.3335 - val_mse: 42003712.0000 - val_mae: 3559.7466 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3721.1299 - mse: 44394740.0000 - mae: 3721.5088\n",
      "Epoch 27: val_loss improved from 3555.65454 to 3354.39209, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3722.8291 - mse: 44417796.0000 - mae: 3723.2083 - val_loss: 3354.3921 - val_mse: 38438276.0000 - val_mae: 3354.8022 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "492/498 [============================>.] - ETA: 0s - loss: 3577.5688 - mse: 41623788.0000 - mae: 3577.9438\n",
      "Epoch 28: val_loss did not improve from 3354.39209\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3588.6970 - mse: 41770796.0000 - mae: 3589.0728 - val_loss: 3452.4790 - val_mse: 39433800.0000 - val_mae: 3452.8843 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3573.2219 - mse: 42076452.0000 - mae: 3573.5977\n",
      "Epoch 29: val_loss improved from 3354.39209 to 3324.97559, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3569.6804 - mse: 42018632.0000 - mae: 3570.0566 - val_loss: 3324.9756 - val_mse: 38952128.0000 - val_mae: 3325.3843 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3608.4641 - mse: 43066480.0000 - mae: 3608.8491\n",
      "Epoch 30: val_loss did not improve from 3324.97559\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3612.5071 - mse: 43137872.0000 - mae: 3612.8921 - val_loss: 3333.5786 - val_mse: 38735552.0000 - val_mae: 3333.9922 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3579.4580 - mse: 42502264.0000 - mae: 3579.8354\n",
      "Epoch 31: val_loss did not improve from 3324.97559\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3579.4580 - mse: 42502264.0000 - mae: 3579.8354 - val_loss: 3399.1821 - val_mse: 40205940.0000 - val_mae: 3399.5833 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3564.1089 - mse: 42372964.0000 - mae: 3564.4836\n",
      "Epoch 32: val_loss did not improve from 3324.97559\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3563.8364 - mse: 42364040.0000 - mae: 3564.2112 - val_loss: 3394.1172 - val_mse: 40906000.0000 - val_mae: 3394.5178 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3548.2786 - mse: 42659424.0000 - mae: 3548.6533\n",
      "Epoch 33: val_loss did not improve from 3324.97559\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3550.4602 - mse: 42715248.0000 - mae: 3550.8350 - val_loss: 3370.5137 - val_mse: 40200588.0000 - val_mae: 3370.9180 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3524.5869 - mse: 42153172.0000 - mae: 3524.9629\n",
      "Epoch 34: val_loss did not improve from 3324.97559\n",
      "498/498 [==============================] - 5s 9ms/step - loss: 3524.1211 - mse: 42169204.0000 - mae: 3524.4966 - val_loss: 3343.0403 - val_mse: 39829376.0000 - val_mae: 3343.4099 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3483.8340 - mse: 42194388.0000 - mae: 3484.2046\n",
      "Epoch 35: val_loss did not improve from 3324.97559\n",
      "498/498 [==============================] - 5s 9ms/step - loss: 3490.4143 - mse: 42289732.0000 - mae: 3490.7852 - val_loss: 3367.5376 - val_mse: 41894272.0000 - val_mae: 3367.9302 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3482.1577 - mse: 42267168.0000 - mae: 3482.5254\n",
      "Epoch 36: val_loss improved from 3324.97559 to 3255.33374, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3490.1357 - mse: 42322348.0000 - mae: 3490.5044 - val_loss: 3255.3337 - val_mse: 38702364.0000 - val_mae: 3255.7480 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3452.1421 - mse: 41753228.0000 - mae: 3452.5098\n",
      "Epoch 37: val_loss did not improve from 3255.33374\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3452.1421 - mse: 41753228.0000 - mae: 3452.5098 - val_loss: 3283.9595 - val_mse: 40042944.0000 - val_mae: 3284.3472 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3482.1619 - mse: 42464300.0000 - mae: 3482.5288\n",
      "Epoch 38: val_loss improved from 3255.33374 to 3243.71655, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3478.3198 - mse: 42377080.0000 - mae: 3478.6873 - val_loss: 3243.7166 - val_mse: 38349012.0000 - val_mae: 3244.0859 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3460.8066 - mse: 41940256.0000 - mae: 3461.1741\n",
      "Epoch 39: val_loss improved from 3243.71655 to 3240.77881, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3460.8066 - mse: 41940256.0000 - mae: 3461.1741 - val_loss: 3240.7788 - val_mse: 38685484.0000 - val_mae: 3241.1567 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3456.9949 - mse: 42121140.0000 - mae: 3457.3655\n",
      "Epoch 40: val_loss did not improve from 3240.77881\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3466.7466 - mse: 42372952.0000 - mae: 3467.1177 - val_loss: 3320.7502 - val_mse: 40996308.0000 - val_mae: 3321.1858 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3453.6284 - mse: 41886792.0000 - mae: 3454.0049\n",
      "Epoch 41: val_loss improved from 3240.77881 to 3234.06738, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3454.7112 - mse: 41863968.0000 - mae: 3455.0879 - val_loss: 3234.0674 - val_mse: 38846024.0000 - val_mae: 3234.4297 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3452.7683 - mse: 42067420.0000 - mae: 3453.1377\n",
      "Epoch 42: val_loss did not improve from 3234.06738\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3450.1726 - mse: 42042044.0000 - mae: 3450.5422 - val_loss: 3287.0723 - val_mse: 37754348.0000 - val_mae: 3287.4641 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3446.4656 - mse: 42010916.0000 - mae: 3446.8301\n",
      "Epoch 43: val_loss did not improve from 3234.06738\n",
      "498/498 [==============================] - 5s 9ms/step - loss: 3448.5737 - mse: 42040640.0000 - mae: 3448.9385 - val_loss: 3364.0867 - val_mse: 42967584.0000 - val_mae: 3364.5378 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3456.9670 - mse: 43043172.0000 - mae: 3457.3440\n",
      "Epoch 44: val_loss did not improve from 3234.06738\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3456.9670 - mse: 43043172.0000 - mae: 3457.3440 - val_loss: 3265.8691 - val_mse: 39705884.0000 - val_mae: 3266.2722 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3478.6621 - mse: 42981448.0000 - mae: 3479.0388\n",
      "Epoch 45: val_loss did not improve from 3234.06738\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3479.4526 - mse: 42986364.0000 - mae: 3479.8296 - val_loss: 3308.3486 - val_mse: 41099076.0000 - val_mae: 3308.7832 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3494.3254 - mse: 43389992.0000 - mae: 3494.7058\n",
      "Epoch 46: val_loss did not improve from 3234.06738\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3502.4141 - mse: 43572872.0000 - mae: 3502.7947 - val_loss: 3264.9558 - val_mse: 39570652.0000 - val_mae: 3265.3604 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3501.9131 - mse: 43100128.0000 - mae: 3502.2881\n",
      "Epoch 47: val_loss did not improve from 3234.06738\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3504.7268 - mse: 43160628.0000 - mae: 3505.1023 - val_loss: 3276.2178 - val_mse: 39607528.0000 - val_mae: 3276.6582 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3455.7500 - mse: 42870420.0000 - mae: 3456.1196\n",
      "Epoch 48: val_loss did not improve from 3234.06738\n",
      "498/498 [==============================] - 5s 9ms/step - loss: 3455.7500 - mse: 42870420.0000 - mae: 3456.1196 - val_loss: 3248.7217 - val_mse: 40173940.0000 - val_mae: 3249.0410 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3450.5256 - mse: 42994476.0000 - mae: 3450.8979\n",
      "Epoch 49: val_loss did not improve from 3234.06738\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3450.3347 - mse: 42994084.0000 - mae: 3450.7073 - val_loss: 3261.9507 - val_mse: 40499856.0000 - val_mae: 3262.3386 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3439.3640 - mse: 42153844.0000 - mae: 3439.7412\n",
      "Epoch 50: val_loss did not improve from 3234.06738\n",
      "498/498 [==============================] - 5s 11ms/step - loss: 3440.4517 - mse: 42148628.0000 - mae: 3440.8289 - val_loss: 3299.9316 - val_mse: 38136660.0000 - val_mae: 3300.2773 - lr: 0.0010\n",
      "Epoch 51/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3459.6060 - mse: 42473960.0000 - mae: 3459.9832\n",
      "Epoch 51: val_loss did not improve from 3234.06738\n",
      "498/498 [==============================] - 6s 12ms/step - loss: 3459.1663 - mse: 42461956.0000 - mae: 3459.5432 - val_loss: 3390.5964 - val_mse: 44079888.0000 - val_mae: 3391.0437 - lr: 0.0010\n",
      "Epoch 52/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3445.7791 - mse: 42920328.0000 - mae: 3446.1516\n",
      "Epoch 52: val_loss improved from 3234.06738 to 3211.62891, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 6s 11ms/step - loss: 3447.2207 - mse: 42919608.0000 - mae: 3447.5935 - val_loss: 3211.6289 - val_mse: 39181904.0000 - val_mae: 3212.0391 - lr: 5.0000e-04\n",
      "Epoch 53/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3428.2544 - mse: 42283264.0000 - mae: 3428.6272\n",
      "Epoch 53: val_loss did not improve from 3211.62891\n",
      "498/498 [==============================] - 6s 11ms/step - loss: 3428.8086 - mse: 42283504.0000 - mae: 3429.1816 - val_loss: 3236.4004 - val_mse: 38001440.0000 - val_mae: 3236.8198 - lr: 5.0000e-04\n",
      "Epoch 54/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3427.4785 - mse: 42420728.0000 - mae: 3427.8525\n",
      "Epoch 54: val_loss improved from 3211.62891 to 3205.31543, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3426.4519 - mse: 42361188.0000 - mae: 3426.8262 - val_loss: 3205.3154 - val_mse: 39694132.0000 - val_mae: 3205.7397 - lr: 5.0000e-04\n",
      "Epoch 55/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3451.0686 - mse: 43162892.0000 - mae: 3451.4434\n",
      "Epoch 55: val_loss did not improve from 3205.31543\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3453.3247 - mse: 43194084.0000 - mae: 3453.6997 - val_loss: 3242.2683 - val_mse: 40534972.0000 - val_mae: 3242.7009 - lr: 5.0000e-04\n",
      "Epoch 56/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3407.8918 - mse: 42487396.0000 - mae: 3408.2690\n",
      "Epoch 56: val_loss did not improve from 3205.31543\n",
      "498/498 [==============================] - 5s 11ms/step - loss: 3406.3623 - mse: 42459804.0000 - mae: 3406.7395 - val_loss: 3289.6992 - val_mse: 41702056.0000 - val_mae: 3290.1267 - lr: 5.0000e-04\n",
      "Epoch 57/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3418.0798 - mse: 42508332.0000 - mae: 3418.4631\n",
      "Epoch 57: val_loss did not improve from 3205.31543\n",
      "498/498 [==============================] - 5s 11ms/step - loss: 3417.8354 - mse: 42485064.0000 - mae: 3418.2185 - val_loss: 3228.6252 - val_mse: 37824964.0000 - val_mae: 3228.9751 - lr: 5.0000e-04\n",
      "Epoch 58/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3408.4146 - mse: 42122028.0000 - mae: 3408.7966\n",
      "Epoch 58: val_loss improved from 3205.31543 to 3191.71387, saving model to new_multi_stne_gru_weight_c1.h5\n",
      "498/498 [==============================] - 5s 11ms/step - loss: 3409.2283 - mse: 42114692.0000 - mae: 3409.6108 - val_loss: 3191.7139 - val_mse: 39137684.0000 - val_mae: 3192.1047 - lr: 5.0000e-04\n",
      "Epoch 59/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3399.7090 - mse: 42130148.0000 - mae: 3400.0933\n",
      "Epoch 59: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3405.8330 - mse: 42195076.0000 - mae: 3406.2173 - val_loss: 3195.5149 - val_mse: 39130388.0000 - val_mae: 3195.8860 - lr: 5.0000e-04\n",
      "Epoch 60/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3404.1921 - mse: 41781828.0000 - mae: 3404.5667\n",
      "Epoch 60: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3410.1006 - mse: 41958492.0000 - mae: 3410.4751 - val_loss: 3202.0527 - val_mse: 39275372.0000 - val_mae: 3202.4546 - lr: 5.0000e-04\n",
      "Epoch 61/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3401.3372 - mse: 42100764.0000 - mae: 3401.7126\n",
      "Epoch 61: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3401.4158 - mse: 42087280.0000 - mae: 3401.7913 - val_loss: 3212.1577 - val_mse: 39278428.0000 - val_mae: 3212.5923 - lr: 5.0000e-04\n",
      "Epoch 62/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3402.4961 - mse: 42039412.0000 - mae: 3402.8806\n",
      "Epoch 62: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3411.7502 - mse: 42206500.0000 - mae: 3412.1353 - val_loss: 3193.6414 - val_mse: 38935152.0000 - val_mae: 3194.0715 - lr: 5.0000e-04\n",
      "Epoch 63/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3393.2598 - mse: 41965056.0000 - mae: 3393.6399\n",
      "Epoch 63: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3394.6396 - mse: 41972004.0000 - mae: 3395.0198 - val_loss: 3214.4363 - val_mse: 37986840.0000 - val_mae: 3214.8318 - lr: 5.0000e-04\n",
      "Epoch 64/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3408.0706 - mse: 42222436.0000 - mae: 3408.4458\n",
      "Epoch 64: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3408.0706 - mse: 42222436.0000 - mae: 3408.4458 - val_loss: 3200.3984 - val_mse: 39141420.0000 - val_mae: 3200.7856 - lr: 5.0000e-04\n",
      "Epoch 65/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3399.3042 - mse: 41957472.0000 - mae: 3399.6785\n",
      "Epoch 65: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3405.8008 - mse: 42063784.0000 - mae: 3406.1753 - val_loss: 3253.9280 - val_mse: 37720672.0000 - val_mae: 3254.3384 - lr: 5.0000e-04\n",
      "Epoch 66/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3400.2927 - mse: 42032252.0000 - mae: 3400.6711\n",
      "Epoch 66: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3403.3997 - mse: 42108612.0000 - mae: 3403.7786 - val_loss: 3191.7546 - val_mse: 39063036.0000 - val_mae: 3192.1501 - lr: 5.0000e-04\n",
      "Epoch 67/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3384.8589 - mse: 41825868.0000 - mae: 3385.2322\n",
      "Epoch 67: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 5s 11ms/step - loss: 3392.9917 - mse: 41982680.0000 - mae: 3393.3652 - val_loss: 3196.6729 - val_mse: 39314824.0000 - val_mae: 3197.0571 - lr: 5.0000e-04\n",
      "Epoch 68/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3397.2991 - mse: 42077228.0000 - mae: 3397.6697\n",
      "Epoch 68: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 6s 12ms/step - loss: 3397.2361 - mse: 42102476.0000 - mae: 3397.6077 - val_loss: 3209.4451 - val_mse: 39244652.0000 - val_mae: 3209.8879 - lr: 5.0000e-04\n",
      "Epoch 69/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3400.8669 - mse: 41768500.0000 - mae: 3401.2324\n",
      "Epoch 69: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 6s 12ms/step - loss: 3400.8096 - mse: 41758424.0000 - mae: 3401.1753 - val_loss: 3203.0225 - val_mse: 38749528.0000 - val_mae: 3203.4788 - lr: 2.5000e-04\n",
      "Epoch 70/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3411.0337 - mse: 42067412.0000 - mae: 3411.4058\n",
      "Epoch 70: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 6s 11ms/step - loss: 3411.8433 - mse: 42077072.0000 - mae: 3412.2156 - val_loss: 3205.1641 - val_mse: 39325472.0000 - val_mae: 3205.5852 - lr: 2.5000e-04\n",
      "Epoch 71/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3390.7349 - mse: 41787364.0000 - mae: 3391.1113\n",
      "Epoch 71: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3396.9607 - mse: 41874368.0000 - mae: 3397.3376 - val_loss: 3212.2935 - val_mse: 39364328.0000 - val_mae: 3212.7085 - lr: 2.5000e-04\n",
      "Epoch 72/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3396.1929 - mse: 41791832.0000 - mae: 3396.5579\n",
      "Epoch 72: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3399.6914 - mse: 41857584.0000 - mae: 3400.0569 - val_loss: 3200.5298 - val_mse: 38942972.0000 - val_mae: 3200.9658 - lr: 2.5000e-04\n",
      "Epoch 73/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3398.9287 - mse: 41908680.0000 - mae: 3399.3049\n",
      "Epoch 73: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 5s 11ms/step - loss: 3399.7263 - mse: 41925904.0000 - mae: 3400.1030 - val_loss: 3201.3367 - val_mse: 39265928.0000 - val_mae: 3201.7717 - lr: 2.5000e-04\n",
      "Epoch 74/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3399.5869 - mse: 41919248.0000 - mae: 3399.9619\n",
      "Epoch 74: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 6s 11ms/step - loss: 3402.0320 - mse: 41973752.0000 - mae: 3402.4065 - val_loss: 3203.8655 - val_mse: 39160372.0000 - val_mae: 3204.2019 - lr: 2.5000e-04\n",
      "Epoch 75/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3401.9031 - mse: 41783560.0000 - mae: 3402.2742\n",
      "Epoch 75: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 5s 11ms/step - loss: 3406.3586 - mse: 41839444.0000 - mae: 3406.7300 - val_loss: 3203.8877 - val_mse: 39410948.0000 - val_mae: 3204.2544 - lr: 2.5000e-04\n",
      "Epoch 76/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3394.3948 - mse: 41956548.0000 - mae: 3394.7710\n",
      "Epoch 76: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 6s 12ms/step - loss: 3394.5342 - mse: 41936320.0000 - mae: 3394.9106 - val_loss: 3201.0208 - val_mse: 39048840.0000 - val_mae: 3201.4546 - lr: 2.5000e-04\n",
      "Epoch 77/500\n",
      "493/498 [============================>.] - ETA: 0s - loss: 3385.3923 - mse: 41804124.0000 - mae: 3385.7715\n",
      "Epoch 77: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 5s 11ms/step - loss: 3391.0349 - mse: 41869084.0000 - mae: 3391.4138 - val_loss: 3201.9644 - val_mse: 39245092.0000 - val_mae: 3202.3450 - lr: 2.5000e-04\n",
      "Epoch 78/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3391.3091 - mse: 41605956.0000 - mae: 3391.6855\n",
      "Epoch 78: val_loss did not improve from 3191.71387\n",
      "498/498 [==============================] - 5s 11ms/step - loss: 3391.7112 - mse: 41601048.0000 - mae: 3392.0879 - val_loss: 3198.9644 - val_mse: 39298864.0000 - val_mae: 3199.3730 - lr: 2.5000e-04\n",
      "Epoch 1/500\n",
      "    498/Unknown - 5s 10ms/step - loss: 3394.1375 - mse: 41755988.0000 - mae: 3394.5176\n",
      "Epoch 1: val_loss improved from inf to 3204.53613, saving model to new_multi_stne_gru_weight_ns_c1.h5\n",
      "498/498 [==============================] - 6s 11ms/step - loss: 3394.1375 - mse: 41755988.0000 - mae: 3394.5176 - val_loss: 3204.5361 - val_mse: 39305332.0000 - val_mae: 3204.9463 - lr: 1.2500e-04\n",
      "Epoch 2/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3402.3010 - mse: 41815064.0000 - mae: 3402.6746\n",
      "Epoch 2: val_loss improved from 3204.53613 to 3202.40381, saving model to new_multi_stne_gru_weight_ns_c1.h5\n",
      "498/498 [==============================] - 6s 11ms/step - loss: 3402.3010 - mse: 41815064.0000 - mae: 3402.6746 - val_loss: 3202.4038 - val_mse: 39184436.0000 - val_mae: 3202.8015 - lr: 1.2500e-04\n",
      "Epoch 3/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3397.3733 - mse: 41742288.0000 - mae: 3397.7473\n",
      "Epoch 3: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 6s 11ms/step - loss: 3397.3733 - mse: 41742288.0000 - mae: 3397.7473 - val_loss: 3203.5400 - val_mse: 39227964.0000 - val_mae: 3203.9399 - lr: 1.2500e-04\n",
      "Epoch 4/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3386.1091 - mse: 41572072.0000 - mae: 3386.4832\n",
      "Epoch 4: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 5s 11ms/step - loss: 3393.0127 - mse: 41674776.0000 - mae: 3393.3872 - val_loss: 3204.4692 - val_mse: 39235584.0000 - val_mae: 3204.8938 - lr: 1.2500e-04\n",
      "Epoch 5/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3387.3801 - mse: 41622180.0000 - mae: 3387.7510\n",
      "Epoch 5: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3391.9084 - mse: 41682244.0000 - mae: 3392.2791 - val_loss: 3204.5950 - val_mse: 39275212.0000 - val_mae: 3204.9888 - lr: 1.2500e-04\n",
      "Epoch 6/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3385.9023 - mse: 41600668.0000 - mae: 3386.2742\n",
      "Epoch 6: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3392.8325 - mse: 41703788.0000 - mae: 3393.2043 - val_loss: 3205.8748 - val_mse: 39311784.0000 - val_mae: 3206.2527 - lr: 1.2500e-04\n",
      "Epoch 7/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3395.2534 - mse: 41750312.0000 - mae: 3395.6262\n",
      "Epoch 7: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 6s 11ms/step - loss: 3395.2534 - mse: 41750312.0000 - mae: 3395.6262 - val_loss: 3206.7771 - val_mse: 39350604.0000 - val_mae: 3207.1562 - lr: 1.2500e-04\n",
      "Epoch 8/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3389.4985 - mse: 41705748.0000 - mae: 3389.8679\n",
      "Epoch 8: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 5s 11ms/step - loss: 3389.4985 - mse: 41705748.0000 - mae: 3389.8679 - val_loss: 3207.6680 - val_mse: 39406608.0000 - val_mae: 3208.0439 - lr: 1.2500e-04\n",
      "Epoch 9/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3388.9270 - mse: 41680980.0000 - mae: 3389.2991\n",
      "Epoch 9: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3388.9270 - mse: 41680980.0000 - mae: 3389.2991 - val_loss: 3208.8159 - val_mse: 39340108.0000 - val_mae: 3209.2048 - lr: 1.2500e-04\n",
      "Epoch 10/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3384.7056 - mse: 41583312.0000 - mae: 3385.0759\n",
      "Epoch 10: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3388.3040 - mse: 41631892.0000 - mae: 3388.6743 - val_loss: 3207.2119 - val_mse: 39423932.0000 - val_mae: 3207.5999 - lr: 1.2500e-04\n",
      "Epoch 11/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3388.4702 - mse: 41680312.0000 - mae: 3388.8396\n",
      "Epoch 11: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3388.4702 - mse: 41680312.0000 - mae: 3388.8396 - val_loss: 3207.6758 - val_mse: 39412240.0000 - val_mae: 3208.0779 - lr: 1.2500e-04\n",
      "Epoch 12/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3385.2371 - mse: 41631400.0000 - mae: 3385.6042\n",
      "Epoch 12: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 5s 11ms/step - loss: 3388.9148 - mse: 41681860.0000 - mae: 3389.2820 - val_loss: 3208.9070 - val_mse: 39322864.0000 - val_mae: 3209.3179 - lr: 1.2500e-04\n",
      "Epoch 13/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3378.6211 - mse: 41647748.0000 - mae: 3378.9927\n",
      "Epoch 13: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3387.0732 - mse: 41741380.0000 - mae: 3387.4448 - val_loss: 3210.2393 - val_mse: 39474240.0000 - val_mae: 3210.6128 - lr: 6.2500e-05\n",
      "Epoch 14/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3385.2283 - mse: 41727596.0000 - mae: 3385.5989\n",
      "Epoch 14: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3385.2283 - mse: 41727596.0000 - mae: 3385.5989 - val_loss: 3210.5583 - val_mse: 39486116.0000 - val_mae: 3210.9395 - lr: 6.2500e-05\n",
      "Epoch 15/500\n",
      "496/498 [============================>.] - ETA: 0s - loss: 3381.7458 - mse: 41679520.0000 - mae: 3382.1150\n",
      "Epoch 15: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3386.1877 - mse: 41737628.0000 - mae: 3386.5569 - val_loss: 3210.4946 - val_mse: 39472304.0000 - val_mae: 3210.8777 - lr: 6.2500e-05\n",
      "Epoch 16/500\n",
      "495/498 [============================>.] - ETA: 0s - loss: 3378.6978 - mse: 41661736.0000 - mae: 3379.0732\n",
      "Epoch 16: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3385.5740 - mse: 41762804.0000 - mae: 3385.9497 - val_loss: 3210.1833 - val_mse: 39469824.0000 - val_mae: 3210.5664 - lr: 6.2500e-05\n",
      "Epoch 17/500\n",
      "498/498 [==============================] - ETA: 0s - loss: 3386.3401 - mse: 41743996.0000 - mae: 3386.7097\n",
      "Epoch 17: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3386.3401 - mse: 41743996.0000 - mae: 3386.7097 - val_loss: 3209.7209 - val_mse: 39469588.0000 - val_mae: 3210.1060 - lr: 6.2500e-05\n",
      "Epoch 18/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3380.7227 - mse: 41660272.0000 - mae: 3381.0967\n",
      "Epoch 18: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3384.2561 - mse: 41707064.0000 - mae: 3384.6301 - val_loss: 3210.4050 - val_mse: 39445496.0000 - val_mae: 3210.7905 - lr: 6.2500e-05\n",
      "Epoch 19/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3381.6465 - mse: 41662660.0000 - mae: 3382.0176\n",
      "Epoch 19: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3385.1873 - mse: 41709688.0000 - mae: 3385.5586 - val_loss: 3209.8562 - val_mse: 39437304.0000 - val_mae: 3210.2390 - lr: 6.2500e-05\n",
      "Epoch 20/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3377.5735 - mse: 41640056.0000 - mae: 3377.9404\n",
      "Epoch 20: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3385.8870 - mse: 41732896.0000 - mae: 3386.2544 - val_loss: 3209.9099 - val_mse: 39450840.0000 - val_mae: 3210.2917 - lr: 6.2500e-05\n",
      "Epoch 21/500\n",
      "497/498 [============================>.] - ETA: 0s - loss: 3382.0354 - mse: 41672736.0000 - mae: 3382.4111\n",
      "Epoch 21: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 5s 11ms/step - loss: 3385.5608 - mse: 41719440.0000 - mae: 3385.9365 - val_loss: 3209.5596 - val_mse: 39461764.0000 - val_mae: 3209.9382 - lr: 6.2500e-05\n",
      "Epoch 22/500\n",
      "494/498 [============================>.] - ETA: 0s - loss: 3376.7253 - mse: 41632204.0000 - mae: 3377.0925\n",
      "Epoch 22: val_loss did not improve from 3202.40381\n",
      "498/498 [==============================] - 5s 10ms/step - loss: 3385.0667 - mse: 41725272.0000 - mae: 3385.4341 - val_loss: 3209.8650 - val_mse: 39459124.0000 - val_mae: 3210.2437 - lr: 6.2500e-05\n"
     ]
    }
   ],
   "source": [
    "gru_history = gru_model.fit(train_data, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_gru])\n",
    "gru_history_ns = gru_model.fit(train_data_ns, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_gru_ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------lstm_history-------------\n",
      "lstm_history Validation Loss: 3160.474365234375\n",
      "lstm_history Validation MSE: 37370336.0\n",
      "lstm_history Validation MAE: 3160.89453125\n",
      "-------------lstm_history_ns-------------\n",
      "lstm_history_ns Validation Loss: 3182.106201171875\n",
      "lstm_history_ns Validation MSE: 39411000.0\n",
      "lstm_history_ns Validation MAE: 3182.515869140625\n",
      "-------------rnn_history-------------\n",
      "rnn_history Validation Loss: 3148.002685546875\n",
      "rnn_history Validation MSE: 37060056.0\n",
      "rnn_history Validation MAE: 3148.46875\n",
      "-------------rnn_history_ns-------------\n",
      "rnn_history_ns Validation Loss: 3171.3798828125\n",
      "rnn_history_ns Validation MSE: 38259400.0\n",
      "rnn_history_ns Validation MAE: 3171.7568359375\n",
      "-------------gru_history-------------\n",
      "gru_history Validation Loss: 3191.7138671875\n",
      "gru_history Validation MSE: 37720672.0\n",
      "gru_history Validation MAE: 3192.104736328125\n",
      "-------------gru_history_ns-------------\n",
      "gru_history_ns Validation Loss: 3202.40380859375\n",
      "gru_history_ns Validation MSE: 39184436.0\n",
      "gru_history_ns Validation MAE: 3202.801513671875\n"
     ]
    }
   ],
   "source": [
    "# 종합 결과\n",
    "\n",
    "history_list = [\"lstm_history\", \"rnn_history\", \"gru_history\", \"lstm_history_ns\", \"rnn_history_ns\", \"gru_history_ns\"]\n",
    "def result(historys) :\n",
    "  for name, history in globals().items() :\n",
    "    if name in history_list :\n",
    "      print(f\"-------------{name}-------------\")\n",
    "      val_loss = min(history.history['val_loss'])\n",
    "      val_mse = min(history.history['val_mse'])\n",
    "      val_mae = min(history.history['val_mae'])\n",
    "      print(f\"{name} Validation Loss:\", val_loss)\n",
    "      print(f\"{name} Validation MSE:\", val_mse)\n",
    "      print(f\"{name} Validation MAE:\", val_mae)\n",
    "\n",
    "result(history_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/lstm_model_stne_c1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/lstm_model_stne_c1\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/rnn_model_stne_c1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/rnn_model_stne_c1\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/gru_model_stne_c1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/gru_model_stne_c1\\assets\n"
     ]
    }
   ],
   "source": [
    "lstm_save_path = f\"./Models/lstm_model_stne_c1\"\n",
    "rnn_save_path = f\"./Models/rnn_model_stne_c1\"\n",
    "gru_save_path = f\"./Models/gru_model_stne_c1\"\n",
    "\n",
    "save_model(lstm_model, lstm_save_path, overwrite=True)\n",
    "save_model(rnn_model, rnn_save_path, overwrite=True)\n",
    "save_model(gru_model, gru_save_path, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52578, 9)\n"
     ]
    }
   ],
   "source": [
    "St_NotEncode_Basic_data = pd.read_pickle(\"Basic_StandardScalar_final_data\")\n",
    "  \n",
    "print(St_NotEncode_Basic_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler Not Encode Data\n",
      "(17422, 1) (17422,)\n",
      "(42062, 2) (10516, 2) (42062,) (10516,)\n",
      "=======================================\n"
     ]
    }
   ],
   "source": [
    "# Feature와 Label 분리하기 (풍속, 습도, 일조시간, 일사량, 전운량)\n",
    "def Feature_Label(datafile) :\n",
    "    X = datafile.iloc[:,[4,5]]\n",
    "    y = datafile.iloc[:,-1]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "print(\"StandardScaler Not Encode Data\")\n",
    "SB_X, SB_y = Feature_Label(St_NotEncode_Basic_data)\n",
    "print(SNE_X.shape, SNE_y.shape)\n",
    "SB_X_train, SB_X_test, SB_y_train, SB_y_test = train_test_split(SB_X, SB_y, test_size=0.2, random_state=10, shuffle=False)\n",
    "print(SB_X_train.shape, SB_X_test.shape, SB_y_train.shape, SB_y_test.shape)\n",
    "print(\"=======================================\")\n",
    "\n",
    "\n",
    "WINDOW_SIZE=3\n",
    "BATCH_SIZE=28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(x, y, window_size, batch_size, shuffle) :\n",
    "  ds_x = tf.data.Dataset.from_tensor_slices(x).window(window_size, stride=1, shift=1, drop_remainder=True) \n",
    "  ds_x = ds_x.flat_map(lambda x : x.batch(window_size))\n",
    "  \n",
    "  ds_y = tf.data.Dataset.from_tensor_slices(y[window_size:])\n",
    "  \n",
    "  ds = tf.data.Dataset.zip((ds_x, ds_y))\n",
    "  \n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(1000)\n",
    "  \n",
    "  return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = windowed_dataset(SB_X_train, SB_y_train, WINDOW_SIZE, BATCH_SIZE, True)\n",
    "train_data_ns = windowed_dataset(SB_X_train, SB_y_train, WINDOW_SIZE, BATCH_SIZE, False)\n",
    "test_data = windowed_dataset(SB_X_test, SB_y_test, WINDOW_SIZE, BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 3, 2), (28,)\n"
     ]
    }
   ],
   "source": [
    "for data in train_data.take(1) :\n",
    "  print(f'{data[0].shape}, {data[1].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential([\n",
    "  Conv1D(filters=32, kernel_size=30,\n",
    "         padding='causal',\n",
    "         activation='relu',\n",
    "         input_shape=[WINDOW_SIZE, 2]),\n",
    "  LSTM(128, activation='tanh', return_sequences=True),  \n",
    "  LSTM(64, activation='tanh', return_sequences=True),\n",
    "  LSTM(32, activation='tanh'),\n",
    "  Dense(8, activation='relu'),\n",
    "  Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = Sequential([\n",
    "  Conv1D(filters=32, kernel_size=30,\n",
    "         padding='causal', \n",
    "         activation='relu',\n",
    "         input_shape=[WINDOW_SIZE, 2]),\n",
    "  SimpleRNN(128, activation='tanh', return_sequences=True),  \n",
    "  SimpleRNN(64, activation='tanh', return_sequences=True),\n",
    "  SimpleRNN(32, activation='tanh'),\n",
    "  Dense(8, activation='relu'),\n",
    "  Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = Sequential([\n",
    "  Conv1D(filters=32, kernel_size=30,\n",
    "         padding='causal', \n",
    "         activation='relu',\n",
    "         input_shape=[WINDOW_SIZE, 2]),\n",
    "  GRU(128, activation='tanh', return_sequences=True),  \n",
    "  GRU(64, activation='tanh', return_sequences=True),\n",
    "  GRU(32, activation='tanh'),\n",
    "  Dense(8, activation='relu'),\n",
    "  Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = Huber() \n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "lstm_model.compile(loss=loss, optimizer=optimizer, metrics=['mse', 'mae'])\n",
    "rnn_model.compile(loss=loss, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), metrics=['mse', 'mae'])\n",
    "gru_model.compile(loss=loss, optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001), metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10)\n",
    "       \n",
    "es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "mc_lstm = ModelCheckpoint('base_multi_stne_lstm_weight_c2.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_lstm_ns = ModelCheckpoint('base_multi_stne_lstm_weight_ns_c2.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_rnn = ModelCheckpoint('base_multi_stne_rnn_weight_c2.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_rnn_ns = ModelCheckpoint('base_multi_stne_rnn_weight_ns_c2.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_gru = ModelCheckpoint('base_multi_stne_gru_weight_c2.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "mc_gru_ns = ModelCheckpoint('base_multi_stne_gru_weight_ns_c2.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "   1499/Unknown - 35s 9ms/step - loss: 2.1048 - mse: 25.5503 - mae: 2.4631\n",
      "Epoch 1: val_loss improved from inf to 2.15057, saving model to base_multi_stne_lstm_weight_c2.h5\n",
      "1503/1503 [==============================] - 39s 11ms/step - loss: 2.1036 - mse: 25.5221 - mae: 2.4620 - val_loss: 2.1506 - val_mse: 22.2719 - val_mae: 2.5207 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.3452 - mse: 9.9153 - mae: 1.6847\n",
      "Epoch 2: val_loss did not improve from 2.15057\n",
      "1503/1503 [==============================] - 14s 9ms/step - loss: 1.3446 - mse: 9.9097 - mae: 1.6840 - val_loss: 2.1765 - val_mse: 22.3181 - val_mae: 2.5446 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.3126 - mse: 9.7369 - mae: 1.6471\n",
      "Epoch 3: val_loss improved from 2.15057 to 2.02315, saving model to base_multi_stne_lstm_weight_c2.h5\n",
      "1503/1503 [==============================] - 14s 9ms/step - loss: 1.3124 - mse: 9.7362 - mae: 1.6469 - val_loss: 2.0231 - val_mse: 20.0415 - val_mae: 2.3903 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "1497/1503 [============================>.] - ETA: 0s - loss: 1.2949 - mse: 9.5617 - mae: 1.6282\n",
      "Epoch 4: val_loss did not improve from 2.02315\n",
      "1503/1503 [==============================] - 15s 10ms/step - loss: 1.2960 - mse: 9.5832 - mae: 1.6293 - val_loss: 2.4958 - val_mse: 26.9084 - val_mae: 2.8720 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2948 - mse: 9.6041 - mae: 1.6276\n",
      "Epoch 5: val_loss did not improve from 2.02315\n",
      "1503/1503 [==============================] - 15s 10ms/step - loss: 1.2965 - mse: 9.6220 - mae: 1.6294 - val_loss: 2.4931 - val_mse: 27.3833 - val_mae: 2.8330 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2746 - mse: 9.4416 - mae: 1.6039\n",
      "Epoch 6: val_loss improved from 2.02315 to 1.94224, saving model to base_multi_stne_lstm_weight_c2.h5\n",
      "1503/1503 [==============================] - 16s 10ms/step - loss: 1.2746 - mse: 9.4416 - mae: 1.6039 - val_loss: 1.9422 - val_mse: 19.6394 - val_mae: 2.3162 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2736 - mse: 9.3691 - mae: 1.6037\n",
      "Epoch 7: val_loss did not improve from 1.94224\n",
      "1503/1503 [==============================] - 16s 11ms/step - loss: 1.2740 - mse: 9.3715 - mae: 1.6041 - val_loss: 2.0121 - val_mse: 20.2531 - val_mae: 2.3864 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "1497/1503 [============================>.] - ETA: 0s - loss: 1.2673 - mse: 9.4068 - mae: 1.5951\n",
      "Epoch 8: val_loss did not improve from 1.94224\n",
      "1503/1503 [==============================] - 16s 10ms/step - loss: 1.2692 - mse: 9.4388 - mae: 1.5971 - val_loss: 2.2051 - val_mse: 22.7931 - val_mae: 2.5705 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2699 - mse: 9.3428 - mae: 1.5984\n",
      "Epoch 9: val_loss did not improve from 1.94224\n",
      "1503/1503 [==============================] - 15s 10ms/step - loss: 1.2703 - mse: 9.3470 - mae: 1.5988 - val_loss: 2.2696 - val_mse: 23.6711 - val_mae: 2.6361 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2584 - mse: 9.2847 - mae: 1.5851\n",
      "Epoch 10: val_loss did not improve from 1.94224\n",
      "1503/1503 [==============================] - 15s 10ms/step - loss: 1.2615 - mse: 9.3445 - mae: 1.5883 - val_loss: 2.0888 - val_mse: 21.4523 - val_mae: 2.4750 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2524 - mse: 9.1635 - mae: 1.5798\n",
      "Epoch 11: val_loss did not improve from 1.94224\n",
      "1503/1503 [==============================] - 15s 10ms/step - loss: 1.2543 - mse: 9.2123 - mae: 1.5818 - val_loss: 1.9460 - val_mse: 19.7506 - val_mae: 2.3201 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.2537 - mse: 9.2381 - mae: 1.5787\n",
      "Epoch 12: val_loss did not improve from 1.94224\n",
      "1503/1503 [==============================] - 16s 10ms/step - loss: 1.2558 - mse: 9.2626 - mae: 1.5810 - val_loss: 1.9541 - val_mse: 19.0806 - val_mae: 2.3123 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2566 - mse: 9.3236 - mae: 1.5820\n",
      "Epoch 13: val_loss did not improve from 1.94224\n",
      "1503/1503 [==============================] - 15s 10ms/step - loss: 1.2571 - mse: 9.3325 - mae: 1.5825 - val_loss: 2.1688 - val_mse: 22.3836 - val_mae: 2.5288 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2391 - mse: 9.1405 - mae: 1.5641\n",
      "Epoch 14: val_loss did not improve from 1.94224\n",
      "1503/1503 [==============================] - 16s 11ms/step - loss: 1.2393 - mse: 9.1412 - mae: 1.5643 - val_loss: 2.0162 - val_mse: 20.6028 - val_mae: 2.3931 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.2464 - mse: 9.1910 - mae: 1.5721\n",
      "Epoch 15: val_loss did not improve from 1.94224\n",
      "1503/1503 [==============================] - 15s 10ms/step - loss: 1.2494 - mse: 9.2319 - mae: 1.5751 - val_loss: 2.1186 - val_mse: 21.9901 - val_mae: 2.4700 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2354 - mse: 9.1342 - mae: 1.5593\n",
      "Epoch 16: val_loss improved from 1.94224 to 1.94205, saving model to base_multi_stne_lstm_weight_c2.h5\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.2354 - mse: 9.1348 - mae: 1.5594 - val_loss: 1.9420 - val_mse: 19.5450 - val_mae: 2.3101 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2408 - mse: 9.1548 - mae: 1.5657\n",
      "Epoch 17: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 16s 11ms/step - loss: 1.2411 - mse: 9.1603 - mae: 1.5660 - val_loss: 2.0162 - val_mse: 20.4857 - val_mae: 2.3780 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2353 - mse: 9.1363 - mae: 1.5604\n",
      "Epoch 18: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.2360 - mse: 9.1411 - mae: 1.5611 - val_loss: 2.0991 - val_mse: 21.4273 - val_mae: 2.4649 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2308 - mse: 9.1073 - mae: 1.5550\n",
      "Epoch 19: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2325 - mse: 9.1234 - mae: 1.5568 - val_loss: 1.9792 - val_mse: 19.9066 - val_mae: 2.3462 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2297 - mse: 9.0835 - mae: 1.5536\n",
      "Epoch 20: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 19s 13ms/step - loss: 1.2308 - mse: 9.1002 - mae: 1.5548 - val_loss: 2.1022 - val_mse: 21.3942 - val_mae: 2.4798 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2178 - mse: 9.0205 - mae: 1.5398\n",
      "Epoch 21: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 20s 13ms/step - loss: 1.2186 - mse: 9.0248 - mae: 1.5406 - val_loss: 2.2410 - val_mse: 23.3985 - val_mae: 2.5987 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2147 - mse: 8.9306 - mae: 1.5361\n",
      "Epoch 22: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 19s 13ms/step - loss: 1.2146 - mse: 8.9282 - mae: 1.5360 - val_loss: 2.1671 - val_mse: 21.9839 - val_mae: 2.5381 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2205 - mse: 8.9940 - mae: 1.5413\n",
      "Epoch 23: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 19s 13ms/step - loss: 1.2229 - mse: 9.0439 - mae: 1.5439 - val_loss: 2.1057 - val_mse: 21.7643 - val_mae: 2.4903 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2240 - mse: 9.0241 - mae: 1.5485\n",
      "Epoch 24: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 20s 13ms/step - loss: 1.2240 - mse: 9.0235 - mae: 1.5484 - val_loss: 2.1833 - val_mse: 22.6684 - val_mae: 2.5365 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2135 - mse: 8.9164 - mae: 1.5350\n",
      "Epoch 25: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 19s 13ms/step - loss: 1.2136 - mse: 8.9178 - mae: 1.5351 - val_loss: 2.1830 - val_mse: 22.7412 - val_mae: 2.5763 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2148 - mse: 8.9030 - mae: 1.5378\n",
      "Epoch 26: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 19s 13ms/step - loss: 1.2148 - mse: 8.9024 - mae: 1.5377 - val_loss: 2.1219 - val_mse: 21.5202 - val_mae: 2.4964 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2243 - mse: 8.9559 - mae: 1.5484\n",
      "Epoch 27: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2255 - mse: 8.9666 - mae: 1.5497 - val_loss: 2.0508 - val_mse: 20.7173 - val_mae: 2.4210 - lr: 5.0000e-04\n",
      "Epoch 28/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2101 - mse: 8.9149 - mae: 1.5309\n",
      "Epoch 28: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 19s 13ms/step - loss: 1.2116 - mse: 8.9328 - mae: 1.5325 - val_loss: 2.0905 - val_mse: 21.0461 - val_mae: 2.4633 - lr: 5.0000e-04\n",
      "Epoch 29/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2048 - mse: 8.8405 - mae: 1.5238\n",
      "Epoch 29: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 19s 13ms/step - loss: 1.2047 - mse: 8.8389 - mae: 1.5238 - val_loss: 1.9583 - val_mse: 19.5629 - val_mae: 2.3279 - lr: 5.0000e-04\n",
      "Epoch 30/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2051 - mse: 8.8634 - mae: 1.5242\n",
      "Epoch 30: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 19s 13ms/step - loss: 1.2072 - mse: 8.8973 - mae: 1.5263 - val_loss: 2.1506 - val_mse: 21.9113 - val_mae: 2.4991 - lr: 5.0000e-04\n",
      "Epoch 31/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2038 - mse: 8.8042 - mae: 1.5227\n",
      "Epoch 31: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 20s 13ms/step - loss: 1.2051 - mse: 8.8355 - mae: 1.5241 - val_loss: 2.0220 - val_mse: 20.3331 - val_mae: 2.3951 - lr: 5.0000e-04\n",
      "Epoch 32/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2031 - mse: 8.8459 - mae: 1.5222\n",
      "Epoch 32: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 20s 13ms/step - loss: 1.2037 - mse: 8.8502 - mae: 1.5229 - val_loss: 2.2347 - val_mse: 23.1419 - val_mae: 2.5894 - lr: 5.0000e-04\n",
      "Epoch 33/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2006 - mse: 8.7866 - mae: 1.5199\n",
      "Epoch 33: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 20s 13ms/step - loss: 1.2020 - mse: 8.8097 - mae: 1.5213 - val_loss: 2.0866 - val_mse: 21.1281 - val_mae: 2.4482 - lr: 5.0000e-04\n",
      "Epoch 34/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2081 - mse: 8.8722 - mae: 1.5284\n",
      "Epoch 34: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 20s 13ms/step - loss: 1.2082 - mse: 8.8721 - mae: 1.5284 - val_loss: 2.1593 - val_mse: 21.7808 - val_mae: 2.5830 - lr: 5.0000e-04\n",
      "Epoch 35/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2025 - mse: 8.8426 - mae: 1.5222\n",
      "Epoch 35: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 20s 13ms/step - loss: 1.2031 - mse: 8.8676 - mae: 1.5228 - val_loss: 2.0980 - val_mse: 21.1874 - val_mae: 2.4565 - lr: 5.0000e-04\n",
      "Epoch 36/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.1962 - mse: 8.8144 - mae: 1.5154\n",
      "Epoch 36: val_loss did not improve from 1.94205\n",
      "1503/1503 [==============================] - 19s 13ms/step - loss: 1.1959 - mse: 8.8097 - mae: 1.5151 - val_loss: 2.1161 - val_mse: 21.5312 - val_mae: 2.4747 - lr: 5.0000e-04\n",
      "Epoch 1/500\n",
      "   1501/Unknown - 18s 12ms/step - loss: 1.2299 - mse: 9.0308 - mae: 1.5515\n",
      "Epoch 1: val_loss improved from inf to 2.07733, saving model to base_multi_stne_lstm_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 21s 14ms/step - loss: 1.2306 - mse: 9.0346 - mae: 1.5523 - val_loss: 2.0773 - val_mse: 20.5286 - val_mae: 2.5080 - lr: 2.5000e-04\n",
      "Epoch 2/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2460 - mse: 9.1713 - mae: 1.5685\n",
      "Epoch 2: val_loss improved from 2.07733 to 2.03915, saving model to base_multi_stne_lstm_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 20s 13ms/step - loss: 1.2479 - mse: 9.1832 - mae: 1.5706 - val_loss: 2.0392 - val_mse: 20.5367 - val_mae: 2.4030 - lr: 2.5000e-04\n",
      "Epoch 3/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2500 - mse: 9.2028 - mae: 1.5727\n",
      "Epoch 3: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 20s 13ms/step - loss: 1.2507 - mse: 9.2072 - mae: 1.5735 - val_loss: 2.0537 - val_mse: 20.7208 - val_mae: 2.4151 - lr: 2.5000e-04\n",
      "Epoch 4/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2490 - mse: 9.1944 - mae: 1.5720\n",
      "Epoch 4: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 1.2504 - mse: 9.2012 - mae: 1.5735 - val_loss: 2.0683 - val_mse: 20.8672 - val_mae: 2.4628 - lr: 2.5000e-04\n",
      "Epoch 5/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2497 - mse: 9.1808 - mae: 1.5729\n",
      "Epoch 5: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2498 - mse: 9.1810 - mae: 1.5729 - val_loss: 2.2069 - val_mse: 21.0242 - val_mae: 2.6460 - lr: 2.5000e-04\n",
      "Epoch 6/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2471 - mse: 9.1530 - mae: 1.5701\n",
      "Epoch 6: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 1.2471 - mse: 9.1530 - mae: 1.5701 - val_loss: 2.1838 - val_mse: 20.9757 - val_mae: 2.6225 - lr: 2.5000e-04\n",
      "Epoch 7/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2404 - mse: 9.0905 - mae: 1.5625\n",
      "Epoch 7: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2411 - mse: 9.0949 - mae: 1.5633 - val_loss: 2.0873 - val_mse: 20.7746 - val_mae: 2.5135 - lr: 2.5000e-04\n",
      "Epoch 8/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2364 - mse: 9.0539 - mae: 1.5577\n",
      "Epoch 8: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 1.2377 - mse: 9.0604 - mae: 1.5592 - val_loss: 2.0643 - val_mse: 20.6307 - val_mae: 2.4817 - lr: 2.5000e-04\n",
      "Epoch 9/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2348 - mse: 9.0459 - mae: 1.5558\n",
      "Epoch 9: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2355 - mse: 9.0503 - mae: 1.5566 - val_loss: 2.0603 - val_mse: 20.5056 - val_mae: 2.4833 - lr: 2.5000e-04\n",
      "Epoch 10/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2338 - mse: 9.0448 - mae: 1.5548\n",
      "Epoch 10: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.2351 - mse: 9.0513 - mae: 1.5562 - val_loss: 2.0593 - val_mse: 20.5182 - val_mae: 2.4814 - lr: 2.5000e-04\n",
      "Epoch 11/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2340 - mse: 9.0462 - mae: 1.5545\n",
      "Epoch 11: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.2353 - mse: 9.0528 - mae: 1.5560 - val_loss: 2.0752 - val_mse: 20.5730 - val_mae: 2.5051 - lr: 2.5000e-04\n",
      "Epoch 12/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2321 - mse: 9.0315 - mae: 1.5529\n",
      "Epoch 12: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2328 - mse: 9.0364 - mae: 1.5537 - val_loss: 2.1759 - val_mse: 20.7166 - val_mae: 2.6146 - lr: 2.5000e-04\n",
      "Epoch 13/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.3189 - mse: 9.7043 - mae: 1.6439\n",
      "Epoch 13: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.3202 - mse: 9.7115 - mae: 1.6453 - val_loss: 2.1111 - val_mse: 21.5714 - val_mae: 2.4773 - lr: 1.2500e-04\n",
      "Epoch 14/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.3036 - mse: 9.5711 - mae: 1.6274\n",
      "Epoch 14: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.3036 - mse: 9.5715 - mae: 1.6275 - val_loss: 2.1143 - val_mse: 21.6197 - val_mae: 2.4818 - lr: 1.2500e-04\n",
      "Epoch 15/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.2955 - mse: 9.5069 - mae: 1.6185\n",
      "Epoch 15: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2971 - mse: 9.5156 - mae: 1.6202 - val_loss: 2.1155 - val_mse: 21.5745 - val_mae: 2.5084 - lr: 1.2500e-04\n",
      "Epoch 16/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2930 - mse: 9.4682 - mae: 1.6157\n",
      "Epoch 16: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2930 - mse: 9.4682 - mae: 1.6157 - val_loss: 2.1208 - val_mse: 21.6011 - val_mae: 2.5202 - lr: 1.2500e-04\n",
      "Epoch 17/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2891 - mse: 9.4274 - mae: 1.6120\n",
      "Epoch 17: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2900 - mse: 9.4343 - mae: 1.6130 - val_loss: 2.1274 - val_mse: 21.7442 - val_mae: 2.5158 - lr: 1.2500e-04\n",
      "Epoch 18/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2855 - mse: 9.3955 - mae: 1.6083\n",
      "Epoch 18: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2856 - mse: 9.3960 - mae: 1.6084 - val_loss: 2.2090 - val_mse: 21.9666 - val_mae: 2.6491 - lr: 1.2500e-04\n",
      "Epoch 19/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2823 - mse: 9.3707 - mae: 1.6042\n",
      "Epoch 19: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2839 - mse: 9.3810 - mae: 1.6059 - val_loss: 2.1402 - val_mse: 21.9479 - val_mae: 2.5234 - lr: 1.2500e-04\n",
      "Epoch 20/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.2783 - mse: 9.3449 - mae: 1.6010\n",
      "Epoch 20: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2802 - mse: 9.3555 - mae: 1.6030 - val_loss: 2.2090 - val_mse: 22.0229 - val_mae: 2.6481 - lr: 1.2500e-04\n",
      "Epoch 21/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2805 - mse: 9.3608 - mae: 1.6035\n",
      "Epoch 21: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.2806 - mse: 9.3614 - mae: 1.6035 - val_loss: 2.1544 - val_mse: 21.9548 - val_mae: 2.5670 - lr: 1.2500e-04\n",
      "Epoch 22/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2781 - mse: 9.3533 - mae: 1.6007\n",
      "Epoch 22: val_loss did not improve from 2.03915\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.2791 - mse: 9.3609 - mae: 1.6017 - val_loss: 2.1485 - val_mse: 21.9094 - val_mae: 2.5578 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "lstm_history = lstm_model.fit(train_data, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_lstm])\n",
    "lstm_history_ns = lstm_model.fit(train_data_ns, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_lstm_ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "   1496/Unknown - 20s 5ms/step - loss: 1.9174 - mse: 20.4215 - mae: 2.2698\n",
      "Epoch 1: val_loss improved from inf to 2.09451, saving model to base_multi_stne_rnn_weight_c2.h5\n",
      "1503/1503 [==============================] - 23s 7ms/step - loss: 1.9180 - mse: 20.4213 - mae: 2.2704 - val_loss: 2.0945 - val_mse: 20.9069 - val_mae: 2.4726 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.3711 - mse: 10.3292 - mae: 1.7087\n",
      "Epoch 2: val_loss improved from 2.09451 to 2.04254, saving model to base_multi_stne_rnn_weight_c2.h5\n",
      "1503/1503 [==============================] - 9s 6ms/step - loss: 1.3711 - mse: 10.3286 - mae: 1.7086 - val_loss: 2.0425 - val_mse: 20.8824 - val_mae: 2.4142 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.3429 - mse: 10.0331 - mae: 1.6798\n",
      "Epoch 3: val_loss did not improve from 2.04254\n",
      "1503/1503 [==============================] - 9s 6ms/step - loss: 1.3447 - mse: 10.0569 - mae: 1.6816 - val_loss: 2.1859 - val_mse: 22.5960 - val_mae: 2.5335 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.3314 - mse: 9.9473 - mae: 1.6665\n",
      "Epoch 4: val_loss did not improve from 2.04254\n",
      "1503/1503 [==============================] - 9s 6ms/step - loss: 1.3314 - mse: 9.9473 - mae: 1.6665 - val_loss: 2.1598 - val_mse: 22.2230 - val_mae: 2.5350 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "1493/1503 [============================>.] - ETA: 0s - loss: 1.3061 - mse: 9.6231 - mae: 1.6405\n",
      "Epoch 5: val_loss did not improve from 2.04254\n",
      "1503/1503 [==============================] - 9s 6ms/step - loss: 1.3119 - mse: 9.7247 - mae: 1.6465 - val_loss: 2.4589 - val_mse: 25.9279 - val_mae: 2.8326 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2984 - mse: 9.6376 - mae: 1.6318\n",
      "Epoch 6: val_loss improved from 2.04254 to 1.97465, saving model to base_multi_stne_rnn_weight_c2.h5\n",
      "1503/1503 [==============================] - 9s 6ms/step - loss: 1.2998 - mse: 9.6534 - mae: 1.6332 - val_loss: 1.9747 - val_mse: 19.8069 - val_mae: 2.3381 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2986 - mse: 9.6366 - mae: 1.6319\n",
      "Epoch 7: val_loss did not improve from 1.97465\n",
      "1503/1503 [==============================] - 9s 6ms/step - loss: 1.2986 - mse: 9.6366 - mae: 1.6319 - val_loss: 2.0831 - val_mse: 20.8819 - val_mae: 2.4436 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.3022 - mse: 9.7089 - mae: 1.6336\n",
      "Epoch 8: val_loss did not improve from 1.97465\n",
      "1503/1503 [==============================] - 9s 6ms/step - loss: 1.3028 - mse: 9.7133 - mae: 1.6342 - val_loss: 2.1630 - val_mse: 22.2760 - val_mae: 2.5306 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "1494/1503 [============================>.] - ETA: 0s - loss: 1.2924 - mse: 9.5472 - mae: 1.6245\n",
      "Epoch 9: val_loss did not improve from 1.97465\n",
      "1503/1503 [==============================] - 9s 6ms/step - loss: 1.2936 - mse: 9.5570 - mae: 1.6259 - val_loss: 2.6135 - val_mse: 28.7827 - val_mae: 2.9808 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2784 - mse: 9.5490 - mae: 1.6083\n",
      "Epoch 10: val_loss did not improve from 1.97465\n",
      "1503/1503 [==============================] - 8s 6ms/step - loss: 1.2806 - mse: 9.5863 - mae: 1.6106 - val_loss: 2.3167 - val_mse: 24.0692 - val_mae: 2.7200 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "1493/1503 [============================>.] - ETA: 0s - loss: 1.2881 - mse: 9.4521 - mae: 1.6216\n",
      "Epoch 11: val_loss did not improve from 1.97465\n",
      "1503/1503 [==============================] - 9s 6ms/step - loss: 1.2917 - mse: 9.5015 - mae: 1.6253 - val_loss: 2.1821 - val_mse: 22.7093 - val_mae: 2.5518 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.2797 - mse: 9.4560 - mae: 1.6109\n",
      "Epoch 12: val_loss did not improve from 1.97465\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2810 - mse: 9.4777 - mae: 1.6123 - val_loss: 2.0565 - val_mse: 20.9741 - val_mae: 2.4285 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "1496/1503 [============================>.] - ETA: 0s - loss: 1.2651 - mse: 9.3419 - mae: 1.5954\n",
      "Epoch 13: val_loss did not improve from 1.97465\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2679 - mse: 9.3643 - mae: 1.5984 - val_loss: 2.2207 - val_mse: 22.8497 - val_mae: 2.5947 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2673 - mse: 9.3659 - mae: 1.5985\n",
      "Epoch 14: val_loss did not improve from 1.97465\n",
      "1503/1503 [==============================] - 9s 6ms/step - loss: 1.2673 - mse: 9.3659 - mae: 1.5985 - val_loss: 2.1985 - val_mse: 22.8072 - val_mae: 2.5710 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "1490/1503 [============================>.] - ETA: 0s - loss: 1.2725 - mse: 9.3070 - mae: 1.6036\n",
      "Epoch 15: val_loss did not improve from 1.97465\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2804 - mse: 9.4641 - mae: 1.6117 - val_loss: 2.3931 - val_mse: 25.7110 - val_mae: 2.7656 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2757 - mse: 9.4834 - mae: 1.6041\n",
      "Epoch 16: val_loss did not improve from 1.97465\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2779 - mse: 9.5248 - mae: 1.6064 - val_loss: 2.0166 - val_mse: 20.4447 - val_mae: 2.3841 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2492 - mse: 9.2285 - mae: 1.5784\n",
      "Epoch 17: val_loss did not improve from 1.97465\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2492 - mse: 9.2285 - mae: 1.5784 - val_loss: 2.4487 - val_mse: 22.8789 - val_mae: 2.9004 - lr: 5.0000e-04\n",
      "Epoch 18/500\n",
      "1492/1503 [============================>.] - ETA: 0s - loss: 1.2359 - mse: 9.0461 - mae: 1.5640\n",
      "Epoch 18: val_loss did not improve from 1.97465\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2404 - mse: 9.1045 - mae: 1.5687 - val_loss: 2.0403 - val_mse: 20.1533 - val_mae: 2.4017 - lr: 5.0000e-04\n",
      "Epoch 19/500\n",
      "1497/1503 [============================>.] - ETA: 0s - loss: 1.2368 - mse: 9.0880 - mae: 1.5614\n",
      "Epoch 19: val_loss improved from 1.97465 to 1.96599, saving model to base_multi_stne_rnn_weight_c2.h5\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2382 - mse: 9.1062 - mae: 1.5630 - val_loss: 1.9660 - val_mse: 19.5269 - val_mae: 2.3389 - lr: 5.0000e-04\n",
      "Epoch 20/500\n",
      "1495/1503 [============================>.] - ETA: 0s - loss: 1.2321 - mse: 9.0570 - mae: 1.5578\n",
      "Epoch 20: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2349 - mse: 9.0963 - mae: 1.5607 - val_loss: 2.2758 - val_mse: 23.5716 - val_mae: 2.6463 - lr: 5.0000e-04\n",
      "Epoch 21/500\n",
      "1494/1503 [============================>.] - ETA: 0s - loss: 1.2256 - mse: 9.0251 - mae: 1.5493\n",
      "Epoch 21: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2286 - mse: 9.0570 - mae: 1.5526 - val_loss: 2.0401 - val_mse: 20.4433 - val_mae: 2.4138 - lr: 5.0000e-04\n",
      "Epoch 22/500\n",
      "1497/1503 [============================>.] - ETA: 0s - loss: 1.2229 - mse: 9.0221 - mae: 1.5474\n",
      "Epoch 22: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2250 - mse: 9.0478 - mae: 1.5496 - val_loss: 2.2118 - val_mse: 22.6947 - val_mae: 2.5612 - lr: 5.0000e-04\n",
      "Epoch 23/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2207 - mse: 9.0058 - mae: 1.5476\n",
      "Epoch 23: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2206 - mse: 9.0052 - mae: 1.5475 - val_loss: 2.2449 - val_mse: 23.5399 - val_mae: 2.6045 - lr: 5.0000e-04\n",
      "Epoch 24/500\n",
      "1496/1503 [============================>.] - ETA: 0s - loss: 1.2182 - mse: 8.8986 - mae: 1.5441\n",
      "Epoch 24: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 7s 4ms/step - loss: 1.2232 - mse: 9.0130 - mae: 1.5491 - val_loss: 2.1626 - val_mse: 22.0782 - val_mae: 2.5063 - lr: 5.0000e-04\n",
      "Epoch 25/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2188 - mse: 8.9958 - mae: 1.5417\n",
      "Epoch 25: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2196 - mse: 9.0108 - mae: 1.5425 - val_loss: 2.2320 - val_mse: 22.8119 - val_mae: 2.6379 - lr: 5.0000e-04\n",
      "Epoch 26/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2118 - mse: 8.9350 - mae: 1.5384\n",
      "Epoch 26: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2119 - mse: 8.9356 - mae: 1.5385 - val_loss: 2.3160 - val_mse: 24.5301 - val_mae: 2.6678 - lr: 5.0000e-04\n",
      "Epoch 27/500\n",
      "1497/1503 [============================>.] - ETA: 0s - loss: 1.2129 - mse: 8.8735 - mae: 1.5364\n",
      "Epoch 27: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2140 - mse: 8.8840 - mae: 1.5375 - val_loss: 2.2525 - val_mse: 23.2171 - val_mae: 2.6109 - lr: 5.0000e-04\n",
      "Epoch 28/500\n",
      "1492/1503 [============================>.] - ETA: 0s - loss: 1.2055 - mse: 8.8273 - mae: 1.5294\n",
      "Epoch 28: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2098 - mse: 8.8999 - mae: 1.5339 - val_loss: 2.2301 - val_mse: 22.8894 - val_mae: 2.5877 - lr: 5.0000e-04\n",
      "Epoch 29/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.2104 - mse: 8.8689 - mae: 1.5391\n",
      "Epoch 29: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2116 - mse: 8.8840 - mae: 1.5405 - val_loss: 2.1702 - val_mse: 22.3521 - val_mae: 2.5312 - lr: 5.0000e-04\n",
      "Epoch 30/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2152 - mse: 8.8350 - mae: 1.5440\n",
      "Epoch 30: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2170 - mse: 8.8514 - mae: 1.5459 - val_loss: 2.1174 - val_mse: 21.3972 - val_mae: 2.4760 - lr: 2.5000e-04\n",
      "Epoch 31/500\n",
      "1494/1503 [============================>.] - ETA: 0s - loss: 1.2102 - mse: 8.8377 - mae: 1.5407\n",
      "Epoch 31: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2120 - mse: 8.8629 - mae: 1.5426 - val_loss: 2.2013 - val_mse: 22.7417 - val_mae: 2.5573 - lr: 2.5000e-04\n",
      "Epoch 32/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2073 - mse: 8.8241 - mae: 1.5315\n",
      "Epoch 32: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 8s 6ms/step - loss: 1.2071 - mse: 8.8217 - mae: 1.5313 - val_loss: 2.2215 - val_mse: 22.6334 - val_mae: 2.5769 - lr: 2.5000e-04\n",
      "Epoch 33/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2112 - mse: 8.8032 - mae: 1.5347\n",
      "Epoch 33: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 8s 6ms/step - loss: 1.2122 - mse: 8.8189 - mae: 1.5358 - val_loss: 2.2039 - val_mse: 22.6103 - val_mae: 2.5598 - lr: 2.5000e-04\n",
      "Epoch 34/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2045 - mse: 8.7472 - mae: 1.5309\n",
      "Epoch 34: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2045 - mse: 8.7472 - mae: 1.5309 - val_loss: 2.0408 - val_mse: 20.5016 - val_mae: 2.3929 - lr: 2.5000e-04\n",
      "Epoch 35/500\n",
      "1497/1503 [============================>.] - ETA: 0s - loss: 1.2006 - mse: 8.7118 - mae: 1.5264\n",
      "Epoch 35: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2019 - mse: 8.7252 - mae: 1.5277 - val_loss: 2.2002 - val_mse: 22.6270 - val_mae: 2.5524 - lr: 2.5000e-04\n",
      "Epoch 36/500\n",
      "1497/1503 [============================>.] - ETA: 0s - loss: 1.1937 - mse: 8.6937 - mae: 1.5175\n",
      "Epoch 36: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.1964 - mse: 8.7227 - mae: 1.5204 - val_loss: 2.2060 - val_mse: 22.8239 - val_mae: 2.5657 - lr: 2.5000e-04\n",
      "Epoch 37/500\n",
      "1495/1503 [============================>.] - ETA: 0s - loss: 1.2024 - mse: 8.7048 - mae: 1.5258\n",
      "Epoch 37: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2043 - mse: 8.7265 - mae: 1.5277 - val_loss: 2.1540 - val_mse: 22.0495 - val_mae: 2.5082 - lr: 2.5000e-04\n",
      "Epoch 38/500\n",
      "1492/1503 [============================>.] - ETA: 0s - loss: 1.1970 - mse: 8.6664 - mae: 1.5217\n",
      "Epoch 38: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2027 - mse: 8.7565 - mae: 1.5275 - val_loss: 2.1465 - val_mse: 21.9435 - val_mae: 2.4969 - lr: 2.5000e-04\n",
      "Epoch 39/500\n",
      "1495/1503 [============================>.] - ETA: 0s - loss: 1.2028 - mse: 8.7559 - mae: 1.5270\n",
      "Epoch 39: val_loss did not improve from 1.96599\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2059 - mse: 8.7943 - mae: 1.5303 - val_loss: 2.0660 - val_mse: 20.8707 - val_mae: 2.4298 - lr: 2.5000e-04\n",
      "Epoch 1/500\n",
      "   1498/Unknown - 7s 4ms/step - loss: 1.2366 - mse: 8.9692 - mae: 1.5630\n",
      "Epoch 1: val_loss improved from inf to 2.13027, saving model to base_multi_stne_rnn_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2385 - mse: 8.9813 - mae: 1.5650 - val_loss: 2.1303 - val_mse: 21.5186 - val_mae: 2.5370 - lr: 1.2500e-04\n",
      "Epoch 2/500\n",
      "1493/1503 [============================>.] - ETA: 0s - loss: 1.2504 - mse: 9.0828 - mae: 1.5782\n",
      "Epoch 2: val_loss did not improve from 2.13027\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2544 - mse: 9.1187 - mae: 1.5823 - val_loss: 2.1576 - val_mse: 21.5722 - val_mae: 2.5880 - lr: 1.2500e-04\n",
      "Epoch 3/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2606 - mse: 9.1782 - mae: 1.5893\n",
      "Epoch 3: val_loss improved from 2.13027 to 2.12699, saving model to base_multi_stne_rnn_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2621 - mse: 9.1858 - mae: 1.5908 - val_loss: 2.1270 - val_mse: 21.6459 - val_mae: 2.5032 - lr: 1.2500e-04\n",
      "Epoch 4/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2582 - mse: 9.1657 - mae: 1.5848\n",
      "Epoch 4: val_loss did not improve from 2.12699\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2582 - mse: 9.1657 - mae: 1.5848 - val_loss: 2.1393 - val_mse: 21.7087 - val_mae: 2.5461 - lr: 1.2500e-04\n",
      "Epoch 5/500\n",
      "1490/1503 [============================>.] - ETA: 0s - loss: 1.2510 - mse: 9.0939 - mae: 1.5763\n",
      "Epoch 5: val_loss did not improve from 2.12699\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2552 - mse: 9.1295 - mae: 1.5807 - val_loss: 2.1344 - val_mse: 21.7831 - val_mae: 2.5032 - lr: 1.2500e-04\n",
      "Epoch 6/500\n",
      "1495/1503 [============================>.] - ETA: 0s - loss: 1.2503 - mse: 9.0801 - mae: 1.5754\n",
      "Epoch 6: val_loss improved from 2.12699 to 2.11791, saving model to base_multi_stne_rnn_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2531 - mse: 9.0988 - mae: 1.5784 - val_loss: 2.1179 - val_mse: 21.5367 - val_mae: 2.4704 - lr: 1.2500e-04\n",
      "Epoch 7/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2543 - mse: 9.1462 - mae: 1.5805\n",
      "Epoch 7: val_loss improved from 2.11791 to 2.11078, saving model to base_multi_stne_rnn_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2557 - mse: 9.1542 - mae: 1.5821 - val_loss: 2.1108 - val_mse: 21.4372 - val_mae: 2.4622 - lr: 1.2500e-04\n",
      "Epoch 8/500\n",
      "1493/1503 [============================>.] - ETA: 0s - loss: 1.2475 - mse: 9.1177 - mae: 1.5730\n",
      "Epoch 8: val_loss improved from 2.11078 to 2.10986, saving model to base_multi_stne_rnn_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2516 - mse: 9.1550 - mae: 1.5773 - val_loss: 2.1099 - val_mse: 21.5219 - val_mae: 2.4617 - lr: 1.2500e-04\n",
      "Epoch 9/500\n",
      "1495/1503 [============================>.] - ETA: 0s - loss: 1.2462 - mse: 9.1100 - mae: 1.5710\n",
      "Epoch 9: val_loss improved from 2.10986 to 2.10353, saving model to base_multi_stne_rnn_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2489 - mse: 9.1285 - mae: 1.5739 - val_loss: 2.1035 - val_mse: 21.4147 - val_mae: 2.4871 - lr: 1.2500e-04\n",
      "Epoch 10/500\n",
      "1493/1503 [============================>.] - ETA: 0s - loss: 1.2418 - mse: 9.0505 - mae: 1.5661\n",
      "Epoch 10: val_loss improved from 2.10353 to 2.10048, saving model to base_multi_stne_rnn_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2457 - mse: 9.0860 - mae: 1.5702 - val_loss: 2.1005 - val_mse: 21.3733 - val_mae: 2.4770 - lr: 1.2500e-04\n",
      "Epoch 11/500\n",
      "1494/1503 [============================>.] - ETA: 0s - loss: 1.2402 - mse: 9.0436 - mae: 1.5632\n",
      "Epoch 11: val_loss did not improve from 2.10048\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2434 - mse: 9.0640 - mae: 1.5666 - val_loss: 2.1194 - val_mse: 21.4145 - val_mae: 2.5300 - lr: 1.2500e-04\n",
      "Epoch 12/500\n",
      "1497/1503 [============================>.] - ETA: 0s - loss: 1.2371 - mse: 9.0030 - mae: 1.5609\n",
      "Epoch 12: val_loss did not improve from 2.10048\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2389 - mse: 9.0139 - mae: 1.5628 - val_loss: 2.1123 - val_mse: 21.4816 - val_mae: 2.4771 - lr: 1.2500e-04\n",
      "Epoch 13/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2373 - mse: 8.9823 - mae: 1.5616\n",
      "Epoch 13: val_loss did not improve from 2.10048\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2373 - mse: 8.9825 - mae: 1.5617 - val_loss: 2.1106 - val_mse: 21.3121 - val_mae: 2.5175 - lr: 1.2500e-04\n",
      "Epoch 14/500\n",
      "1488/1503 [============================>.] - ETA: 0s - loss: 1.2312 - mse: 8.9282 - mae: 1.5542\n",
      "Epoch 14: val_loss improved from 2.10048 to 2.09009, saving model to base_multi_stne_rnn_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2355 - mse: 8.9615 - mae: 1.5589 - val_loss: 2.0901 - val_mse: 21.1788 - val_mae: 2.4722 - lr: 1.2500e-04\n",
      "Epoch 15/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2314 - mse: 8.9247 - mae: 1.5565\n",
      "Epoch 15: val_loss improved from 2.09009 to 2.07903, saving model to base_multi_stne_rnn_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2321 - mse: 8.9282 - mae: 1.5572 - val_loss: 2.0790 - val_mse: 21.0266 - val_mae: 2.4691 - lr: 1.2500e-04\n",
      "Epoch 16/500\n",
      "1489/1503 [============================>.] - ETA: 0s - loss: 1.2266 - mse: 8.8791 - mae: 1.5517\n",
      "Epoch 16: val_loss improved from 2.07903 to 2.07042, saving model to base_multi_stne_rnn_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2306 - mse: 8.9111 - mae: 1.5559 - val_loss: 2.0704 - val_mse: 20.9498 - val_mae: 2.4530 - lr: 1.2500e-04\n",
      "Epoch 17/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.2280 - mse: 8.8949 - mae: 1.5529\n",
      "Epoch 17: val_loss improved from 2.07042 to 2.06855, saving model to base_multi_stne_rnn_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2296 - mse: 8.9027 - mae: 1.5545 - val_loss: 2.0685 - val_mse: 20.9656 - val_mae: 2.4335 - lr: 1.2500e-04\n",
      "Epoch 18/500\n",
      "1495/1503 [============================>.] - ETA: 0s - loss: 1.2253 - mse: 8.8656 - mae: 1.5502\n",
      "Epoch 18: val_loss did not improve from 2.06855\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2280 - mse: 8.8827 - mae: 1.5530 - val_loss: 2.0770 - val_mse: 21.0762 - val_mae: 2.4404 - lr: 1.2500e-04\n",
      "Epoch 19/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2261 - mse: 8.8730 - mae: 1.5503\n",
      "Epoch 19: val_loss did not improve from 2.06855\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2279 - mse: 8.8835 - mae: 1.5521 - val_loss: 2.0779 - val_mse: 21.0802 - val_mae: 2.4472 - lr: 1.2500e-04\n",
      "Epoch 20/500\n",
      "1497/1503 [============================>.] - ETA: 0s - loss: 1.2271 - mse: 8.8865 - mae: 1.5516\n",
      "Epoch 20: val_loss did not improve from 2.06855\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2288 - mse: 8.8961 - mae: 1.5534 - val_loss: 2.0754 - val_mse: 21.0498 - val_mae: 2.4513 - lr: 1.2500e-04\n",
      "Epoch 21/500\n",
      "1492/1503 [============================>.] - ETA: 0s - loss: 1.2246 - mse: 8.8573 - mae: 1.5489\n",
      "Epoch 21: val_loss did not improve from 2.06855\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2287 - mse: 8.8951 - mae: 1.5531 - val_loss: 2.0717 - val_mse: 20.9943 - val_mae: 2.4557 - lr: 1.2500e-04\n",
      "Epoch 22/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2311 - mse: 8.9121 - mae: 1.5555\n",
      "Epoch 22: val_loss did not improve from 2.06855\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2311 - mse: 8.9121 - mae: 1.5555 - val_loss: 2.0730 - val_mse: 21.0196 - val_mae: 2.4450 - lr: 1.2500e-04\n",
      "Epoch 23/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2262 - mse: 8.8796 - mae: 1.5499\n",
      "Epoch 23: val_loss improved from 2.06855 to 2.06662, saving model to base_multi_stne_rnn_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2275 - mse: 8.8861 - mae: 1.5513 - val_loss: 2.0666 - val_mse: 20.9413 - val_mae: 2.4422 - lr: 1.2500e-04\n",
      "Epoch 24/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2232 - mse: 8.8432 - mae: 1.5473\n",
      "Epoch 24: val_loss did not improve from 2.06662\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2233 - mse: 8.8434 - mae: 1.5473 - val_loss: 2.0997 - val_mse: 20.9969 - val_mae: 2.5227 - lr: 1.2500e-04\n",
      "Epoch 25/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2213 - mse: 8.8289 - mae: 1.5466\n",
      "Epoch 25: val_loss improved from 2.06662 to 2.05391, saving model to base_multi_stne_rnn_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2220 - mse: 8.8325 - mae: 1.5473 - val_loss: 2.0539 - val_mse: 20.7999 - val_mae: 2.4372 - lr: 1.2500e-04\n",
      "Epoch 26/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2209 - mse: 8.8234 - mae: 1.5454\n",
      "Epoch 26: val_loss improved from 2.05391 to 2.04904, saving model to base_multi_stne_rnn_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2226 - mse: 8.8345 - mae: 1.5473 - val_loss: 2.0490 - val_mse: 20.7564 - val_mae: 2.4334 - lr: 1.2500e-04\n",
      "Epoch 27/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2234 - mse: 8.8411 - mae: 1.5477\n",
      "Epoch 27: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 8s 6ms/step - loss: 1.2234 - mse: 8.8411 - mae: 1.5477 - val_loss: 2.0558 - val_mse: 20.8789 - val_mae: 2.4417 - lr: 1.2500e-04\n",
      "Epoch 28/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.2233 - mse: 8.8472 - mae: 1.5478\n",
      "Epoch 28: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2250 - mse: 8.8562 - mae: 1.5495 - val_loss: 2.0836 - val_mse: 21.0754 - val_mae: 2.4966 - lr: 1.2500e-04\n",
      "Epoch 29/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2262 - mse: 8.8830 - mae: 1.5502\n",
      "Epoch 29: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2269 - mse: 8.8863 - mae: 1.5509 - val_loss: 2.0866 - val_mse: 21.0682 - val_mae: 2.5025 - lr: 1.2500e-04\n",
      "Epoch 30/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2236 - mse: 8.8458 - mae: 1.5486\n",
      "Epoch 30: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 7s 5ms/step - loss: 1.2255 - mse: 8.8575 - mae: 1.5505 - val_loss: 2.0726 - val_mse: 21.0733 - val_mae: 2.4244 - lr: 1.2500e-04\n",
      "Epoch 31/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2203 - mse: 8.8258 - mae: 1.5448\n",
      "Epoch 31: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2216 - mse: 8.8323 - mae: 1.5462 - val_loss: 2.0670 - val_mse: 20.9688 - val_mae: 2.4562 - lr: 1.2500e-04\n",
      "Epoch 32/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2230 - mse: 8.8503 - mae: 1.5476\n",
      "Epoch 32: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 9s 6ms/step - loss: 1.2231 - mse: 8.8505 - mae: 1.5477 - val_loss: 2.0650 - val_mse: 20.9538 - val_mae: 2.4292 - lr: 1.2500e-04\n",
      "Epoch 33/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2234 - mse: 8.8691 - mae: 1.5495\n",
      "Epoch 33: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 9s 6ms/step - loss: 1.2234 - mse: 8.8691 - mae: 1.5495 - val_loss: 2.0707 - val_mse: 21.0104 - val_mae: 2.4221 - lr: 1.2500e-04\n",
      "Epoch 34/500\n",
      "1493/1503 [============================>.] - ETA: 0s - loss: 1.2186 - mse: 8.8142 - mae: 1.5434\n",
      "Epoch 34: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 8s 5ms/step - loss: 1.2224 - mse: 8.8488 - mae: 1.5474 - val_loss: 2.0620 - val_mse: 20.9070 - val_mae: 2.4460 - lr: 1.2500e-04\n",
      "Epoch 35/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2225 - mse: 8.8525 - mae: 1.5476\n",
      "Epoch 35: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 1.2238 - mse: 8.8587 - mae: 1.5489 - val_loss: 2.0918 - val_mse: 20.9788 - val_mae: 2.5121 - lr: 1.2500e-04\n",
      "Epoch 36/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2250 - mse: 8.8694 - mae: 1.5514\n",
      "Epoch 36: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 1.2257 - mse: 8.8735 - mae: 1.5522 - val_loss: 2.0796 - val_mse: 21.0734 - val_mae: 2.4306 - lr: 1.2500e-04\n",
      "Epoch 37/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2994 - mse: 9.4329 - mae: 1.6307\n",
      "Epoch 37: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 1.3002 - mse: 9.4382 - mae: 1.6315 - val_loss: 2.1342 - val_mse: 21.7600 - val_mae: 2.5255 - lr: 6.2500e-05\n",
      "Epoch 38/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.2892 - mse: 9.3425 - mae: 1.6208\n",
      "Epoch 38: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 1.2908 - mse: 9.3525 - mae: 1.6225 - val_loss: 2.1340 - val_mse: 21.7625 - val_mae: 2.5263 - lr: 6.2500e-05\n",
      "Epoch 39/500\n",
      "1490/1503 [============================>.] - ETA: 0s - loss: 1.2824 - mse: 9.2825 - mae: 1.6126\n",
      "Epoch 39: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 1.2861 - mse: 9.3162 - mae: 1.6167 - val_loss: 2.1662 - val_mse: 21.8009 - val_mae: 2.5940 - lr: 6.2500e-05\n",
      "Epoch 40/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.2836 - mse: 9.2966 - mae: 1.6141\n",
      "Epoch 40: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 1.2854 - mse: 9.3073 - mae: 1.6160 - val_loss: 2.1314 - val_mse: 21.8040 - val_mae: 2.4998 - lr: 6.2500e-05\n",
      "Epoch 41/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2816 - mse: 9.2761 - mae: 1.6115\n",
      "Epoch 41: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 1.2816 - mse: 9.2761 - mae: 1.6115 - val_loss: 2.1616 - val_mse: 21.8216 - val_mae: 2.5865 - lr: 6.2500e-05\n",
      "Epoch 42/500\n",
      "1492/1503 [============================>.] - ETA: 0s - loss: 1.2753 - mse: 9.2313 - mae: 1.6046\n",
      "Epoch 42: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 1.2793 - mse: 9.2694 - mae: 1.6089 - val_loss: 2.1479 - val_mse: 21.8614 - val_mae: 2.5580 - lr: 6.2500e-05\n",
      "Epoch 43/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2775 - mse: 9.2401 - mae: 1.6062\n",
      "Epoch 43: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 1.2775 - mse: 9.2401 - mae: 1.6062 - val_loss: 2.1669 - val_mse: 21.8940 - val_mae: 2.5918 - lr: 6.2500e-05\n",
      "Epoch 44/500\n",
      "1493/1503 [============================>.] - ETA: 0s - loss: 1.2710 - mse: 9.2027 - mae: 1.5990\n",
      "Epoch 44: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 1.2748 - mse: 9.2377 - mae: 1.6030 - val_loss: 2.1458 - val_mse: 21.9894 - val_mae: 2.5227 - lr: 6.2500e-05\n",
      "Epoch 45/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.2716 - mse: 9.2027 - mae: 1.6001\n",
      "Epoch 45: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 1.2734 - mse: 9.2130 - mae: 1.6020 - val_loss: 2.1454 - val_mse: 21.9821 - val_mae: 2.5298 - lr: 6.2500e-05\n",
      "Epoch 46/500\n",
      "1489/1503 [============================>.] - ETA: 0s - loss: 1.2679 - mse: 9.1788 - mae: 1.5960\n",
      "Epoch 46: val_loss did not improve from 2.04904\n",
      "1503/1503 [==============================] - 6s 4ms/step - loss: 1.2717 - mse: 9.2103 - mae: 1.6000 - val_loss: 2.1526 - val_mse: 22.0727 - val_mae: 2.4989 - lr: 6.2500e-05\n"
     ]
    }
   ],
   "source": [
    "rnn_history = rnn_model.fit(train_data, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_rnn])\n",
    "rnn_history_ns = rnn_model.fit(train_data_ns, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_rnn_ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "   1501/Unknown - 18s 8ms/step - loss: 2.4044 - mse: 31.3898 - mae: 2.7680\n",
      "Epoch 1: val_loss improved from inf to 2.19081, saving model to base_multi_stne_gru_weight_c2.h5\n",
      "1503/1503 [==============================] - 20s 9ms/step - loss: 2.4038 - mse: 31.3812 - mae: 2.7674 - val_loss: 2.1908 - val_mse: 22.5529 - val_mae: 2.5103 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "1497/1503 [============================>.] - ETA: 0s - loss: 1.3324 - mse: 9.8716 - mae: 1.6743\n",
      "Epoch 2: val_loss improved from 2.19081 to 2.01207, saving model to base_multi_stne_gru_weight_c2.h5\n",
      "1503/1503 [==============================] - 12s 8ms/step - loss: 1.3348 - mse: 9.9240 - mae: 1.6767 - val_loss: 2.0121 - val_mse: 20.1755 - val_mae: 2.3901 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.3235 - mse: 9.8502 - mae: 1.6589\n",
      "Epoch 3: val_loss did not improve from 2.01207\n",
      "1503/1503 [==============================] - 13s 9ms/step - loss: 1.3255 - mse: 9.8951 - mae: 1.6611 - val_loss: 2.3710 - val_mse: 19.9723 - val_mae: 2.8314 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.3081 - mse: 9.7306 - mae: 1.6432\n",
      "Epoch 4: val_loss did not improve from 2.01207\n",
      "1503/1503 [==============================] - 13s 9ms/step - loss: 1.3081 - mse: 9.7304 - mae: 1.6432 - val_loss: 2.2866 - val_mse: 23.1788 - val_mae: 2.6304 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2879 - mse: 9.5940 - mae: 1.6196\n",
      "Epoch 5: val_loss improved from 2.01207 to 1.92881, saving model to base_multi_stne_gru_weight_c2.h5\n",
      "1503/1503 [==============================] - 14s 9ms/step - loss: 1.2881 - mse: 9.5965 - mae: 1.6198 - val_loss: 1.9288 - val_mse: 19.4100 - val_mae: 2.2823 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2724 - mse: 9.4321 - mae: 1.6022\n",
      "Epoch 6: val_loss did not improve from 1.92881\n",
      "1503/1503 [==============================] - 14s 9ms/step - loss: 1.2725 - mse: 9.4324 - mae: 1.6023 - val_loss: 2.0953 - val_mse: 21.3701 - val_mae: 2.4753 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.2783 - mse: 9.3898 - mae: 1.6114\n",
      "Epoch 7: val_loss did not improve from 1.92881\n",
      "1503/1503 [==============================] - 13s 9ms/step - loss: 1.2800 - mse: 9.4153 - mae: 1.6133 - val_loss: 2.4282 - val_mse: 23.4539 - val_mae: 2.8756 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2650 - mse: 9.3329 - mae: 1.5947\n",
      "Epoch 8: val_loss did not improve from 1.92881\n",
      "1503/1503 [==============================] - 13s 9ms/step - loss: 1.2661 - mse: 9.3491 - mae: 1.5959 - val_loss: 2.4256 - val_mse: 25.8065 - val_mae: 2.8159 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2568 - mse: 9.2769 - mae: 1.5854\n",
      "Epoch 9: val_loss did not improve from 1.92881\n",
      "1503/1503 [==============================] - 14s 9ms/step - loss: 1.2572 - mse: 9.2765 - mae: 1.5859 - val_loss: 2.1509 - val_mse: 22.4250 - val_mae: 2.5197 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2569 - mse: 9.3237 - mae: 1.5833\n",
      "Epoch 10: val_loss did not improve from 1.92881\n",
      "1503/1503 [==============================] - 14s 9ms/step - loss: 1.2576 - mse: 9.3320 - mae: 1.5840 - val_loss: 1.9590 - val_mse: 19.6859 - val_mae: 2.3127 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2523 - mse: 9.3068 - mae: 1.5804\n",
      "Epoch 11: val_loss did not improve from 1.92881\n",
      "1503/1503 [==============================] - 14s 9ms/step - loss: 1.2536 - mse: 9.3202 - mae: 1.5817 - val_loss: 2.1812 - val_mse: 21.5697 - val_mae: 2.6211 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2544 - mse: 9.2121 - mae: 1.5820\n",
      "Epoch 12: val_loss did not improve from 1.92881\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.2545 - mse: 9.2145 - mae: 1.5822 - val_loss: 2.0203 - val_mse: 20.5124 - val_mae: 2.4219 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2516 - mse: 9.2818 - mae: 1.5767\n",
      "Epoch 13: val_loss did not improve from 1.92881\n",
      "1503/1503 [==============================] - 17s 12ms/step - loss: 1.2521 - mse: 9.2870 - mae: 1.5773 - val_loss: 2.0841 - val_mse: 21.2681 - val_mae: 2.4731 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2502 - mse: 9.2626 - mae: 1.5767\n",
      "Epoch 14: val_loss improved from 1.92881 to 1.92264, saving model to base_multi_stne_gru_weight_c2.h5\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.2502 - mse: 9.2622 - mae: 1.5767 - val_loss: 1.9226 - val_mse: 19.1529 - val_mae: 2.2847 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2480 - mse: 9.2702 - mae: 1.5703\n",
      "Epoch 15: val_loss did not improve from 1.92264\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.2483 - mse: 9.2781 - mae: 1.5706 - val_loss: 2.2121 - val_mse: 23.2450 - val_mae: 2.5904 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2389 - mse: 9.1890 - mae: 1.5637\n",
      "Epoch 16: val_loss did not improve from 1.92264\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2391 - mse: 9.1909 - mae: 1.5640 - val_loss: 2.1157 - val_mse: 21.4121 - val_mae: 2.4894 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2393 - mse: 9.2100 - mae: 1.5633\n",
      "Epoch 17: val_loss did not improve from 1.92264\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2393 - mse: 9.2100 - mae: 1.5633 - val_loss: 1.9450 - val_mse: 19.4084 - val_mae: 2.3079 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2354 - mse: 9.1189 - mae: 1.5585\n",
      "Epoch 18: val_loss did not improve from 1.92264\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2370 - mse: 9.1424 - mae: 1.5601 - val_loss: 1.9758 - val_mse: 19.5030 - val_mae: 2.3407 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2486 - mse: 9.2992 - mae: 1.5739\n",
      "Epoch 19: val_loss did not improve from 1.92264\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2502 - mse: 9.3399 - mae: 1.5756 - val_loss: 2.1533 - val_mse: 22.5245 - val_mae: 2.5217 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2370 - mse: 9.0988 - mae: 1.5605\n",
      "Epoch 20: val_loss did not improve from 1.92264\n",
      "1503/1503 [==============================] - 19s 13ms/step - loss: 1.2384 - mse: 9.1180 - mae: 1.5619 - val_loss: 2.1733 - val_mse: 23.0103 - val_mae: 2.5437 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2384 - mse: 9.1132 - mae: 1.5618\n",
      "Epoch 21: val_loss improved from 1.92264 to 1.89921, saving model to base_multi_stne_gru_weight_c2.h5\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.2384 - mse: 9.1126 - mae: 1.5617 - val_loss: 1.8992 - val_mse: 18.8564 - val_mae: 2.2622 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2331 - mse: 9.3091 - mae: 1.5546\n",
      "Epoch 22: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.2332 - mse: 9.3135 - mae: 1.5547 - val_loss: 2.0874 - val_mse: 20.8868 - val_mae: 2.4637 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2324 - mse: 9.1466 - mae: 1.5551\n",
      "Epoch 23: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.2324 - mse: 9.1466 - mae: 1.5551 - val_loss: 2.1161 - val_mse: 21.5402 - val_mae: 2.4960 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2253 - mse: 9.0349 - mae: 1.5469\n",
      "Epoch 24: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 16s 11ms/step - loss: 1.2260 - mse: 9.0412 - mae: 1.5477 - val_loss: 2.3011 - val_mse: 24.3888 - val_mae: 2.6791 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2209 - mse: 9.0723 - mae: 1.5435\n",
      "Epoch 25: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.2209 - mse: 9.0723 - mae: 1.5435 - val_loss: 2.0548 - val_mse: 21.2807 - val_mae: 2.4308 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2173 - mse: 9.0317 - mae: 1.5392\n",
      "Epoch 26: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.2180 - mse: 9.0582 - mae: 1.5399 - val_loss: 2.1731 - val_mse: 22.3648 - val_mae: 2.5509 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2238 - mse: 9.0277 - mae: 1.5490\n",
      "Epoch 27: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2251 - mse: 9.0456 - mae: 1.5504 - val_loss: 2.3104 - val_mse: 24.4260 - val_mae: 2.6780 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2132 - mse: 8.9768 - mae: 1.5351\n",
      "Epoch 28: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2132 - mse: 8.9763 - mae: 1.5351 - val_loss: 1.9992 - val_mse: 20.1862 - val_mae: 2.3677 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2226 - mse: 9.0033 - mae: 1.5455\n",
      "Epoch 29: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2228 - mse: 9.0063 - mae: 1.5458 - val_loss: 2.0212 - val_mse: 20.4100 - val_mae: 2.3933 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2176 - mse: 8.9945 - mae: 1.5402\n",
      "Epoch 30: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2180 - mse: 9.0027 - mae: 1.5406 - val_loss: 2.1155 - val_mse: 21.6849 - val_mae: 2.4886 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.1995 - mse: 8.8172 - mae: 1.5212\n",
      "Epoch 31: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 17s 12ms/step - loss: 1.1996 - mse: 8.8175 - mae: 1.5213 - val_loss: 2.1189 - val_mse: 22.0554 - val_mae: 2.4800 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2165 - mse: 8.9789 - mae: 1.5373\n",
      "Epoch 32: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2167 - mse: 8.9811 - mae: 1.5374 - val_loss: 2.1375 - val_mse: 21.9118 - val_mae: 2.5054 - lr: 5.0000e-04\n",
      "Epoch 33/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.2033 - mse: 8.8838 - mae: 1.5234\n",
      "Epoch 33: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2031 - mse: 8.8792 - mae: 1.5232 - val_loss: 2.1362 - val_mse: 21.8391 - val_mae: 2.4986 - lr: 5.0000e-04\n",
      "Epoch 34/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2036 - mse: 8.8616 - mae: 1.5236\n",
      "Epoch 34: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.2036 - mse: 8.8616 - mae: 1.5236 - val_loss: 2.0322 - val_mse: 20.3588 - val_mae: 2.3991 - lr: 5.0000e-04\n",
      "Epoch 35/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2025 - mse: 8.8913 - mae: 1.5213\n",
      "Epoch 35: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2027 - mse: 8.8902 - mae: 1.5216 - val_loss: 2.1798 - val_mse: 22.3047 - val_mae: 2.5354 - lr: 5.0000e-04\n",
      "Epoch 36/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.1984 - mse: 8.8232 - mae: 1.5177\n",
      "Epoch 36: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.1982 - mse: 8.8196 - mae: 1.5175 - val_loss: 2.3124 - val_mse: 24.3063 - val_mae: 2.6808 - lr: 5.0000e-04\n",
      "Epoch 37/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.1878 - mse: 8.6679 - mae: 1.5066\n",
      "Epoch 37: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.1892 - mse: 8.6930 - mae: 1.5080 - val_loss: 2.2545 - val_mse: 23.4344 - val_mae: 2.6193 - lr: 5.0000e-04\n",
      "Epoch 38/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.1936 - mse: 8.7269 - mae: 1.5117\n",
      "Epoch 38: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.1937 - mse: 8.7328 - mae: 1.5118 - val_loss: 2.2356 - val_mse: 23.2007 - val_mae: 2.6020 - lr: 5.0000e-04\n",
      "Epoch 39/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.1896 - mse: 8.7325 - mae: 1.5083\n",
      "Epoch 39: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 17s 12ms/step - loss: 1.1899 - mse: 8.7331 - mae: 1.5086 - val_loss: 2.0830 - val_mse: 21.2157 - val_mae: 2.4499 - lr: 5.0000e-04\n",
      "Epoch 40/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.1904 - mse: 8.7048 - mae: 1.5096\n",
      "Epoch 40: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.1915 - mse: 8.7399 - mae: 1.5108 - val_loss: 2.0394 - val_mse: 20.6064 - val_mae: 2.4021 - lr: 5.0000e-04\n",
      "Epoch 41/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.1875 - mse: 8.7508 - mae: 1.5070\n",
      "Epoch 41: val_loss did not improve from 1.89921\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.1878 - mse: 8.7572 - mae: 1.5073 - val_loss: 2.1197 - val_mse: 21.5514 - val_mae: 2.4808 - lr: 5.0000e-04\n",
      "Epoch 1/500\n",
      "   1500/Unknown - 16s 11ms/step - loss: 1.2005 - mse: 8.8109 - mae: 1.5219\n",
      "Epoch 1: val_loss improved from inf to 2.04002, saving model to base_multi_stne_gru_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 19s 13ms/step - loss: 1.2024 - mse: 8.8229 - mae: 1.5239 - val_loss: 2.0400 - val_mse: 20.4402 - val_mae: 2.3990 - lr: 2.5000e-04\n",
      "Epoch 2/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2139 - mse: 8.8865 - mae: 1.5356\n",
      "Epoch 2: val_loss improved from 2.04002 to 2.03914, saving model to base_multi_stne_gru_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2140 - mse: 8.8872 - mae: 1.5357 - val_loss: 2.0391 - val_mse: 20.5070 - val_mae: 2.3994 - lr: 2.5000e-04\n",
      "Epoch 3/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2187 - mse: 8.9122 - mae: 1.5401\n",
      "Epoch 3: val_loss did not improve from 2.03914\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2187 - mse: 8.9122 - mae: 1.5401 - val_loss: 2.0437 - val_mse: 20.5765 - val_mae: 2.4034 - lr: 2.5000e-04\n",
      "Epoch 4/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.2191 - mse: 8.9219 - mae: 1.5399\n",
      "Epoch 4: val_loss did not improve from 2.03914\n",
      "1503/1503 [==============================] - 20s 13ms/step - loss: 1.2208 - mse: 8.9321 - mae: 1.5418 - val_loss: 2.0483 - val_mse: 20.6299 - val_mae: 2.4106 - lr: 2.5000e-04\n",
      "Epoch 5/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2220 - mse: 8.9340 - mae: 1.5441\n",
      "Epoch 5: val_loss improved from 2.03914 to 2.03701, saving model to base_multi_stne_gru_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 19s 13ms/step - loss: 1.2234 - mse: 8.9419 - mae: 1.5456 - val_loss: 2.0370 - val_mse: 20.4937 - val_mae: 2.3953 - lr: 2.5000e-04\n",
      "Epoch 6/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.2188 - mse: 8.9140 - mae: 1.5399\n",
      "Epoch 6: val_loss improved from 2.03701 to 2.02240, saving model to base_multi_stne_gru_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 19s 13ms/step - loss: 1.2206 - mse: 8.9236 - mae: 1.5418 - val_loss: 2.0224 - val_mse: 20.2717 - val_mae: 2.3783 - lr: 2.5000e-04\n",
      "Epoch 7/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2126 - mse: 8.8759 - mae: 1.5330\n",
      "Epoch 7: val_loss did not improve from 2.02240\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2141 - mse: 8.8846 - mae: 1.5347 - val_loss: 2.0263 - val_mse: 20.3415 - val_mae: 2.3855 - lr: 2.5000e-04\n",
      "Epoch 8/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2165 - mse: 8.8771 - mae: 1.5376\n",
      "Epoch 8: val_loss improved from 2.02240 to 2.01992, saving model to base_multi_stne_gru_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2166 - mse: 8.8775 - mae: 1.5377 - val_loss: 2.0199 - val_mse: 20.2372 - val_mae: 2.3765 - lr: 2.5000e-04\n",
      "Epoch 9/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2097 - mse: 8.8842 - mae: 1.5301\n",
      "Epoch 9: val_loss did not improve from 2.01992\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.2098 - mse: 8.8845 - mae: 1.5302 - val_loss: 2.0200 - val_mse: 20.2619 - val_mae: 2.3768 - lr: 2.5000e-04\n",
      "Epoch 10/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2059 - mse: 8.8201 - mae: 1.5266\n",
      "Epoch 10: val_loss improved from 2.01992 to 2.01665, saving model to base_multi_stne_gru_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 17s 12ms/step - loss: 1.2067 - mse: 8.8255 - mae: 1.5275 - val_loss: 2.0167 - val_mse: 20.2435 - val_mae: 2.3877 - lr: 2.5000e-04\n",
      "Epoch 11/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2072 - mse: 8.8476 - mae: 1.5261\n",
      "Epoch 11: val_loss improved from 2.01665 to 2.01193, saving model to base_multi_stne_gru_weight_ns_c2.h5\n",
      "1503/1503 [==============================] - 19s 13ms/step - loss: 1.2088 - mse: 8.8568 - mae: 1.5278 - val_loss: 2.0119 - val_mse: 20.1708 - val_mae: 2.3683 - lr: 2.5000e-04\n",
      "Epoch 12/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.1977 - mse: 8.7889 - mae: 1.5163\n",
      "Epoch 12: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 19s 12ms/step - loss: 1.1996 - mse: 8.8022 - mae: 1.5184 - val_loss: 2.0246 - val_mse: 20.3611 - val_mae: 2.3777 - lr: 2.5000e-04\n",
      "Epoch 13/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.1956 - mse: 8.7836 - mae: 1.5137\n",
      "Epoch 13: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.1956 - mse: 8.7836 - mae: 1.5137 - val_loss: 2.0297 - val_mse: 20.4568 - val_mae: 2.3856 - lr: 2.5000e-04\n",
      "Epoch 14/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.1907 - mse: 8.7496 - mae: 1.5088\n",
      "Epoch 14: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.1926 - mse: 8.7598 - mae: 1.5108 - val_loss: 2.0277 - val_mse: 20.4428 - val_mae: 2.3849 - lr: 2.5000e-04\n",
      "Epoch 15/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.1875 - mse: 8.7050 - mae: 1.5056\n",
      "Epoch 15: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 16s 11ms/step - loss: 1.1890 - mse: 8.7138 - mae: 1.5073 - val_loss: 2.0236 - val_mse: 20.4119 - val_mae: 2.3793 - lr: 2.5000e-04\n",
      "Epoch 16/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.1856 - mse: 8.7071 - mae: 1.5037\n",
      "Epoch 16: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 19s 13ms/step - loss: 1.1875 - mse: 8.7203 - mae: 1.5058 - val_loss: 2.0322 - val_mse: 20.5030 - val_mae: 2.3843 - lr: 2.5000e-04\n",
      "Epoch 17/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.1844 - mse: 8.6646 - mae: 1.5021\n",
      "Epoch 17: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.1852 - mse: 8.6705 - mae: 1.5030 - val_loss: 2.0465 - val_mse: 20.6953 - val_mae: 2.3990 - lr: 2.5000e-04\n",
      "Epoch 18/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.1844 - mse: 8.6814 - mae: 1.5020\n",
      "Epoch 18: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.1853 - mse: 8.6873 - mae: 1.5029 - val_loss: 2.0446 - val_mse: 20.6997 - val_mae: 2.3985 - lr: 2.5000e-04\n",
      "Epoch 19/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.1851 - mse: 8.6323 - mae: 1.5028\n",
      "Epoch 19: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 18s 12ms/step - loss: 1.1860 - mse: 8.6388 - mae: 1.5038 - val_loss: 2.0549 - val_mse: 20.8707 - val_mae: 2.4134 - lr: 2.5000e-04\n",
      "Epoch 20/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.1836 - mse: 8.6504 - mae: 1.5004\n",
      "Epoch 20: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 17s 11ms/step - loss: 1.1853 - mse: 8.6603 - mae: 1.5023 - val_loss: 2.0553 - val_mse: 20.8680 - val_mae: 2.4098 - lr: 2.5000e-04\n",
      "Epoch 21/500\n",
      "1500/1503 [============================>.] - ETA: 0s - loss: 1.1866 - mse: 8.6356 - mae: 1.5042\n",
      "Epoch 21: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 16s 10ms/step - loss: 1.1885 - mse: 8.6484 - mae: 1.5061 - val_loss: 2.0623 - val_mse: 20.9568 - val_mae: 2.4294 - lr: 2.5000e-04\n",
      "Epoch 22/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2605 - mse: 9.1941 - mae: 1.5825\n",
      "Epoch 22: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 16s 10ms/step - loss: 1.2605 - mse: 9.1944 - mae: 1.5826 - val_loss: 2.1360 - val_mse: 21.8421 - val_mae: 2.4905 - lr: 1.2500e-04\n",
      "Epoch 23/500\n",
      "1501/1503 [============================>.] - ETA: 0s - loss: 1.2479 - mse: 9.0767 - mae: 1.5695\n",
      "Epoch 23: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 15s 10ms/step - loss: 1.2488 - mse: 9.0828 - mae: 1.5704 - val_loss: 2.1271 - val_mse: 21.7759 - val_mae: 2.4813 - lr: 1.2500e-04\n",
      "Epoch 24/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2438 - mse: 9.0689 - mae: 1.5641\n",
      "Epoch 24: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 15s 10ms/step - loss: 1.2453 - mse: 9.0772 - mae: 1.5657 - val_loss: 2.1205 - val_mse: 21.7042 - val_mae: 2.4771 - lr: 1.2500e-04\n",
      "Epoch 25/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2401 - mse: 9.0166 - mae: 1.5609\n",
      "Epoch 25: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 16s 11ms/step - loss: 1.2417 - mse: 9.0258 - mae: 1.5625 - val_loss: 2.1261 - val_mse: 21.7688 - val_mae: 2.4857 - lr: 1.2500e-04\n",
      "Epoch 26/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.2351 - mse: 8.9913 - mae: 1.5564\n",
      "Epoch 26: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 15s 10ms/step - loss: 1.2369 - mse: 9.0005 - mae: 1.5583 - val_loss: 2.1311 - val_mse: 21.8335 - val_mae: 2.4914 - lr: 1.2500e-04\n",
      "Epoch 27/500\n",
      "1502/1503 [============================>.] - ETA: 0s - loss: 1.2332 - mse: 8.9503 - mae: 1.5541\n",
      "Epoch 27: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 15s 10ms/step - loss: 1.2333 - mse: 8.9507 - mae: 1.5542 - val_loss: 2.1344 - val_mse: 21.8854 - val_mae: 2.4954 - lr: 1.2500e-04\n",
      "Epoch 28/500\n",
      "1498/1503 [============================>.] - ETA: 0s - loss: 1.2294 - mse: 8.9350 - mae: 1.5497\n",
      "Epoch 28: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 15s 10ms/step - loss: 1.2312 - mse: 8.9437 - mae: 1.5516 - val_loss: 2.1345 - val_mse: 21.8989 - val_mae: 2.4994 - lr: 1.2500e-04\n",
      "Epoch 29/500\n",
      "1503/1503 [==============================] - ETA: 0s - loss: 1.2291 - mse: 8.9312 - mae: 1.5502\n",
      "Epoch 29: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 15s 10ms/step - loss: 1.2291 - mse: 8.9312 - mae: 1.5502 - val_loss: 2.1344 - val_mse: 21.8985 - val_mae: 2.4970 - lr: 1.2500e-04\n",
      "Epoch 30/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2257 - mse: 8.9272 - mae: 1.5458\n",
      "Epoch 30: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 16s 10ms/step - loss: 1.2273 - mse: 8.9360 - mae: 1.5474 - val_loss: 2.1341 - val_mse: 21.8984 - val_mae: 2.4986 - lr: 1.2500e-04\n",
      "Epoch 31/500\n",
      "1499/1503 [============================>.] - ETA: 0s - loss: 1.2228 - mse: 8.9186 - mae: 1.5428\n",
      "Epoch 31: val_loss did not improve from 2.01193\n",
      "1503/1503 [==============================] - 14s 9ms/step - loss: 1.2243 - mse: 8.9273 - mae: 1.5444 - val_loss: 2.1354 - val_mse: 21.9214 - val_mae: 2.4984 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "gru_history = gru_model.fit(train_data, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_gru])\n",
    "gru_history_ns = gru_model.fit(train_data_ns, validation_data=test_data, epochs=500, callbacks=[reduce_lr, es, mc_gru_ns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------lstm_history-------------\n",
      "lstm_history Validation Loss: 1.9420496225357056\n",
      "lstm_history Validation MSE: 19.080568313598633\n",
      "lstm_history Validation MAE: 2.3100786209106445\n",
      "-------------lstm_history_ns-------------\n",
      "lstm_history_ns Validation Loss: 2.039152145385742\n",
      "lstm_history_ns Validation MSE: 20.505569458007812\n",
      "lstm_history_ns Validation MAE: 2.4030139446258545\n",
      "-------------rnn_history-------------\n",
      "rnn_history Validation Loss: 1.9659862518310547\n",
      "rnn_history Validation MSE: 19.526901245117188\n",
      "rnn_history Validation MAE: 2.3381295204162598\n",
      "-------------rnn_history_ns-------------\n",
      "rnn_history_ns Validation Loss: 2.0490355491638184\n",
      "rnn_history_ns Validation MSE: 20.756359100341797\n",
      "rnn_history_ns Validation MAE: 2.4220988750457764\n",
      "-------------gru_history-------------\n",
      "gru_history Validation Loss: 1.8992069959640503\n",
      "gru_history Validation MSE: 18.856443405151367\n",
      "gru_history Validation MAE: 2.262178659439087\n",
      "-------------gru_history_ns-------------\n",
      "gru_history_ns Validation Loss: 2.0119338035583496\n",
      "gru_history_ns Validation MSE: 20.170827865600586\n",
      "gru_history_ns Validation MAE: 2.3682703971862793\n"
     ]
    }
   ],
   "source": [
    "# 종합 결과\n",
    "\n",
    "history_list = [\"lstm_history\", \"rnn_history\", \"gru_history\", \"lstm_history_ns\", \"rnn_history_ns\", \"gru_history_ns\"]\n",
    "def result(historys) :\n",
    "  for name, history in globals().items() :\n",
    "    if name in history_list :\n",
    "      print(f\"-------------{name}-------------\")\n",
    "      val_loss = min(history.history['val_loss'])\n",
    "      val_mse = min(history.history['val_mse'])\n",
    "      val_mae = min(history.history['val_mae'])\n",
    "      print(f\"{name} Validation Loss:\", val_loss)\n",
    "      print(f\"{name} Validation MSE:\", val_mse)\n",
    "      print(f\"{name} Validation MAE:\", val_mae)\n",
    "\n",
    "result(history_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/lstm_model_stne_base_c2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/lstm_model_stne_base_c2\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/rnn_model_stne_base_c2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/rnn_model_stne_base_c2\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses, gru_cell_4_layer_call_fn, gru_cell_4_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/gru_model_stne_base_c2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Models/gru_model_stne_base_c2\\assets\n"
     ]
    }
   ],
   "source": [
    "lstm_save_path = f\"./Models/lstm_model_stne_base_c2\"\n",
    "rnn_save_path = f\"./Models/rnn_model_stne_base_c2\"\n",
    "gru_save_path = f\"./Models/gru_model_stne_base_c2\"\n",
    "\n",
    "save_model(lstm_model, lstm_save_path, overwrite=True)\n",
    "save_model(rnn_model, rnn_save_path, overwrite=True)\n",
    "save_model(gru_model, gru_save_path, overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
